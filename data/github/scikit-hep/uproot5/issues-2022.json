[
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.29.1 \u2192 v2.31.0](https://github.com/asottile/pyupgrade/compare/v2.29.1...v2.31.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-01-03T19:37:01Z",
  "comments":0,
  "created_at":"2022-01-03T19:23:58Z",
  "draft":false,
  "id":1092758335,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4wetXT",
  "number":533,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-01-03T19:37:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-01-03T19:37:02Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-01-04T19:34:51Z",
  "comments":2,
  "created_at":"2022-01-04T18:19:22Z",
  "draft":false,
  "id":1093637066,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4whjn-",
  "number":534,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-01-04T19:34:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add test with Python 3.10.",
  "updated_at":"2022-01-04T19:34:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"It seems like the [iterate()](https://uproot.readthedocs.io/en/latest/uproot.behaviors.TBranch.iterate.html) function has a memory leak, i.e memory usage increases although step_size is specified.\r\n\r\nCode to reproduce this issue:\r\n```\r\nroot_file_name = './test.root'\r\ndetector_name = 'telescope0'\r\nwith uproot.open(root_file_name)[\"PixelHit/%s\" % detector_name] as rdata:\r\n    for batch in rdata.iterate(library=\"np\", step_size=10):\r\n```\r\n\r\nI am using uproot version 4.1.9.\r\n\r\nI attached the file for reproducing it.\r\n[test.txt](https://github.com/scikit-hep/uproot4/files/7865109/test.txt)\r\n\r\n",
  "closed_at":"2022-01-14T03:05:56Z",
  "comments":2,
  "created_at":"2022-01-13T18:23:49Z",
  "id":1102135882,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5BsUJK",
  "number":536,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Memory leak in iterate function",
  "updated_at":"2022-01-14T11:11:51Z",
  "user":"MDQ6VXNlcjIyNTQ0MzAy"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"There are actually two memory leaks: one is in Uproot. This one is due to the fact that ROOT instance versions can sometimes be `0` while the class version is something else, and Uproot was repeatedly redefining the class, which was both slow and contributed to global memory (because they're new classes). The commit in this PR fixes that (checks for instance version `0` and no matching `known_version`, tries maximum `known_version` instead).\r\n\r\nThe other memory leak is in NumPy: https://github.com/numpy/numpy/issues/6581#issuecomment-1012678379\r\n\r\nIf you follow the thread back, people have been talking about it since 2009 (SciPy ticket 1003, ported to GitHub in 2012, superceded by the above issue in 2015, and there's an open PR https://github.com/numpy/numpy/pull/15065, last touched in 2021).\r\n\r\nWe have NumPy object arrays with cyclic dependencies because (at least) `STLVector` and friends have NumPy `values`, which can sometimes be objects (because it's ROOT data), and those objects can point to themselves through `_parent`. I don't like the idea of the STL collections sometimes being NumPy (when they're numbers) and sometimes not (when they're objects), and a quick attempt at implementation led to instant test failures, so no. Too many design decisions were based on the idea that a NumPy object array is just a fancy Python list (including not having memory leaks, like a Python list). Maybe some of these objects don't need to have `_parent`? What about cyclic references through the Cursor's `refs`? Either way, it's getting messy quick.\r\n\r\nOf course, if NumPy's bug gets fixed, no changes would be needed in Uproot. Ideally, that's what ought to happen.",
  "closed_at":"2022-01-14T03:05:56Z",
  "comments":0,
  "created_at":"2022-01-14T02:50:37Z",
  "draft":false,
  "id":1102822328,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4w_YUg",
  "number":537,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-01-14T03:05:56Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed one memory leak in complex objects",
  "updated_at":"2022-01-14T03:05:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"`FileSink` seems to be designed such that it can also handle file objects. The only thing that is blocking this functionality is that `FileSink.from_object` does not return anything, which I assume is a mistake.\r\nThis change adds the missing return statement and a bit of documentation to open/recreate/update.",
  "closed_at":"2022-01-17T17:41:18Z",
  "comments":0,
  "created_at":"2022-01-17T14:49:53Z",
  "draft":false,
  "id":1105952236,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4xJ4V4",
  "number":538,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-01-17T17:41:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Allow reading and writing from/to already opened files",
  "updated_at":"2022-01-17T17:41:18Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This is of course something of an edge-case with [EOS tokens](https://eos-docs.web.cern.ch/using/tokens.html), which contain colons `:`. This means xrootd paths can have a format which may confuse `uproot4`, which looks for an object-in-file path by default:\r\n\r\nhttps://github.com/scikit-hep/uproot4/blob/3fe33aff6d6ed88203eed90f4edb5f2bc720f3e6/src/uproot/_util.py#L241\r\n\r\nThis means when using `uproot.open('root://some_xrootd_path//eos/mount?authx=token:with_colon')`, the token (needed for the authentication) will be cut short.\r\n\r\nCan we switch off the object-in-file path parsing, or workaround it somehow?\r\n\r\nVersion 4.1.9",
  "closed_at":"2022-01-18T17:26:43Z",
  "comments":0,
  "created_at":"2022-01-18T16:22:45Z",
  "id":1107107621,
  "labels":null,
  "locked":true,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5B_R8l",
  "number":540,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Not possible to escape colon in filenames / avoid object-in-file path syntax (?)",
  "updated_at":"2022-01-18T17:26:43Z",
  "user":"MDQ6VXNlcjU2NDEwOTc4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Please consider the following source code\r\n\r\n```python\r\nimport uproot\r\nimport numpy as np\r\n\r\n\r\nwith uproot.recreate(\"test.root\") as f:\r\n    f[\"Tree\"] = {\"x\": np.array([1,2,3,4,5])}\r\n\r\nf = uproot.open(\"test.root\")\r\nprint(f.classname_of(\"Tree/x\"))\r\n```\r\n\r\nI would expect it to print \"TBranch\". However, it actually raises an exception: `AttributeError: 'Model_TTree_v20' object has no attribute 'key'`.\r\n\r\nUproot version: 4.1.9\r\n",
  "closed_at":null,
  "comments":2,
  "created_at":"2022-01-18T17:32:19Z",
  "id":1107181197,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5B_j6N",
  "number":542,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"classname_of gives Exception when used on TBranch",
  "updated_at":"2022-11-28T20:57:07Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I'm repeatedly calling `extend` on a Tree inside a file made with `uproot.recreate`. At some point I can get the following exception: ```KeyError: 'fBasketBytes'```. The traceback points to this line: https://github.com/scikit-hep/uproot4/blob/3fe33aff6d6ed88203eed90f4edb5f2bc720f3e6/src/uproot/writing/_cascadetree.py#L479\r\n\r\nUnfortunately this happens after processing several gigabytes of private data and I'm not able to figure out a simple script to reproduce this issue. Let me try to write down what I know:\r\nI have the feeling this always happens when the if condition is true in this line: https://github.com/scikit-hep/uproot4/blob/3fe33aff6d6ed88203eed90f4edb5f2bc720f3e6/src/uproot/writing/_cascadetree.py#L472\r\nFrom debugging I see `self._branch_data` has an element with `kind` equal to `'record'`. This kind of element does not have `fBasketBytes` and thus once the for loop reaches this item (in fact it is the first item), the exception occurs. Is there maybe a check like\r\n```python\r\nif datum[\"kind\"] == \"record\":\r\n    continue\r\n```\r\nmissing? Is see this several times in the code, but there is no such check inside the for loop where the exception happens.\r\n\r\nI could try to give something reproducible if I knew how to get `self._num_baskets >= self._basket_capacity - 1` to true.\r\n\r\n\r\nUproot version 4.1.9",
  "closed_at":"2022-01-24T15:41:39Z",
  "comments":3,
  "created_at":"2022-01-21T15:27:29Z",
  "id":1110593656,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5CMlB4",
  "number":546,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"KeyError in WritableTree.extend",
  "updated_at":"2022-01-24T15:41:39Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-01-24T15:41:40Z",
  "comments":0,
  "created_at":"2022-01-21T19:49:32Z",
  "draft":false,
  "id":1110842402,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4xZzgw",
  "number":547,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-01-24T15:41:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed Tree-extending with 'record' in the 'Tree._branch_data'.",
  "updated_at":"2022-01-24T15:41:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/psf/black: 21.12b0 \u2192 22.1.0](https://github.com/psf/black/compare/21.12b0...22.1.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-02-02T21:26:19Z",
  "comments":9,
  "created_at":"2022-01-31T20:14:39Z",
  "draft":false,
  "id":1119886662,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4x3IF4",
  "number":551,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-02-02T21:26:19Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-02-02T21:26:19Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Hi, I ran into this deprecation warning in tests and wanted to report it. This is not really a \"bug\", but that category was the closest I could think of.\r\n\r\n```bash\r\n$ python --version\r\nPython 3.9.10\r\n$ python -Wall\r\nPython 3.9.10 | packaged by conda-forge | (main, Jan 30 2022, 18:02:27)\r\n[Clang 11.1.0 ] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import uproot\r\n>>> uproot.__version__\r\n'4.1.9'\r\n>>> uproot.extras.awkward()\r\n[...]/lib/python3.9/site-packages/awkward/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  if distutils.version.LooseVersion(numpy.__version__) < distutils.version.LooseVersion(\r\n[...]/lib/python3.9/site-packages/awkward/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  if distutils.version.LooseVersion(numpy.__version__) < distutils.version.LooseVersion(\r\n[...]/lib/python3.9/site-packages/uproot/extras.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  if LooseVersion(\"1\") < LooseVersion(awkward.__version__) < LooseVersion(\"2\"):\r\n[...]/lib/python3.9/site-packages/uproot/extras.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  if LooseVersion(\"1\") < LooseVersion(awkward.__version__) < LooseVersion(\"2\"):\r\n[...]/lib/python3.9/site-packages/uproot/extras.py:36: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n  if LooseVersion(\"1\") < LooseVersion(awkward.__version__) < LooseVersion(\"2\"):\r\n<module 'awkward' from '[...]/lib/python3.9/site-packages/awkward/__init__.py'>\r\n```\r\n\r\nI did not explicitly test master, but looking at the code the behavior should be the same: https://github.com/scikit-hep/uproot4/blob/6fd8863d932ca52f45d84cf5eec5b9c81b1bcfec/src/uproot/extras.py#L35",
  "closed_at":"2022-05-11T20:19:02Z",
  "comments":6,
  "created_at":"2022-02-01T12:50:37Z",
  "id":1120632222,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Cy32e",
  "number":552,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"DeprecationWarning from distutils use for getting version",
  "updated_at":"2022-05-11T20:19:02Z",
  "user":"MDQ6VXNlcjQ1MDA5MzU1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"This is an addition to the Stack Overflow question I posted [here](https://stackoverflow.com/questions/70878968/set-interpretation-as-multi-dim-array-when-reading-tbranchelement).\r\n\r\nI'm using upRoot Version: `4.1.7`. I've attached an example ROOT file as issue-553.txt.\r\n\r\nI have a file that contains TGeoTracks on one branch element. TGeoTracks have two private members that I'm interested in, a number of points and an array that's 4*nPoints (https://root.cern.ch/doc/master/TGeoTrack_8h_source.html#l00040). \r\n\r\n```cpp\r\nprivate :\r\n   Int_t          fPointsSize; // capacity of points array\r\n   Int_t          fNpoints;    // number of stored points\r\n   Double_t      *fPoints;     //[fNpoints] array of points (x,y,z,t) belonging to this track\r\n```\r\n\r\nThis is that the ROOT file looks like in the TBrowser:\r\n\r\n[![enter image description here][1]][1]\r\n\r\nNote that the interpretation in the TBrowser is slightly misleading since all four elements per event are stored in the same histogram.\r\n\r\nNow, I'm trying to read the file with uproot. The default interpreation for this branch element was wrong:\r\n\r\n```python\r\nmcFileThin1_5 = uproot.open(\"/media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain-thinKapton/mom-1_5/Lumi_MC_0.root\")\r\nstartXarray = mcFileThin1_5[\"pndsim/GeoTracks.fPoints\"]\r\nprint(startXarray.interpretation)\r\n\r\nAsObjects(AsArray(True, False, AsArray(False, True, dtype('>f8'), ()), ()))\r\n```\r\n\r\nSo i tried with a custom interpretation:\r\n\r\n```python\r\nmcFileThin1_5 = uproot.open(\"/media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain-thinKapton/mom-1_5/Lumi_MC_0.root\")\r\nstartXarray = mcFileThin1_5[\"pndsim/GeoTracks.fPoints\"]\r\n\r\ndtype = np.dtype([(\"x\", \">f8\"),(\"y\", \">f8\"),(\"z\", \">f8\"),(\"t\", \">f8\")])\r\ninterpret = uproot.AsDtype(dtype)\r\narr = mcFileThin1_5[\"pndsim/GeoTracks.fPoints\"].array(interpret)\r\n```\r\n\r\nBut that fails:\r\n\r\n```\r\nValueError: basket 0 in tree/branch /pndsim;4:GeoTracks/GeoTracks.fPoints has the wrong number of bytes (22902) for interpretation AsDtype(\"[('x', '>f8'), ('y', '>f8'), ('z', '>f8'), ('t', '>f8')]\")\r\nin file /media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain-thinKapton/mom-1_5/Lumi_MC_0.root\r\n```\r\n\r\nHow can I specify the interpretation of this branch element to be four doubles per point?\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/WrhRH.png\r\n\r\n",
  "closed_at":"2022-02-04T18:23:11Z",
  "comments":4,
  "created_at":"2022-02-04T12:37:29Z",
  "id":1124157633,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5DAUjB",
  "number":553,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Manually set Interpretation as multi dim Array",
  "updated_at":"2022-02-07T13:07:55Z",
  "user":"MDQ6VXNlcjEzMjAxNzMx"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"In this file: http://submit08.mit.edu/~freerc/?dir=Jim\r\n\r\nthere's a histogram in\r\n\r\n```\r\nDQMData/Run 315270/DT/Run summary/02-Segments/Wheel2/Sector9/Station4/hResDist_W2_St4_Sec9_SL3\r\n```\r\n\r\nthat is raising\r\n\r\n```python\r\n/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc8-opt/lib/python3.9/site-packages/uproot/containers.py in read(self, chunk, cursor, context, file, selffile, parent, header)\r\n   1136 \r\n   1137         else:\r\n-> 1138             raise NotImplementedError(\r\n   1139                 \"\"\"non-memberwise serialization of {0}\r\n   1140 in file {1}\"\"\".format(\r\n\r\nNotImplementedError: non-memberwise serialization of AsMap\r\nin file DQM_V0001_R000315270__SingleMuon__Run2018A-12Nov2019_UL2018-v2__DQMIO.root\r\n```\r\n\r\nwhen you try to read it. This will be a good case to use to figure out non-memberwise std::map deserialization.",
  "closed_at":"2022-10-05T19:24:57Z",
  "comments":0,
  "created_at":"2022-02-08T23:34:28Z",
  "id":1127870866,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5DOfGS",
  "number":556,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Implement non-memberwise std::map found in a histogram",
  "updated_at":"2022-10-05T19:24:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-02-10T21:41:26Z",
  "comments":0,
  "created_at":"2022-02-10T20:53:17Z",
  "draft":false,
  "id":1130944111,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4ybhFE",
  "number":557,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-02-10T21:41:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Centralize 'from_module' checking and check the whole mro.",
  "updated_at":"2022-02-10T21:41:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello, \r\nI ran into the problem that uproot cannot interpret square brackets in the streamer title of a root file yielding the following error message (see also attached Jupyter notebook [uproot_streamerproblem.zip](https://github.com/scikit-hep/uproot4/files/8061182/uproot_streamerproblem.zip)) :\r\n\r\n```python\r\nUnknownInterpretation                     Traceback (most recent call last)\r\nInput In [14], in <module>\r\n      1 # how it should look like\r\n----> 2 ftshits.arrays([\"FTSHit.fDx\", \"FTSHit.fZ\"], library=\"pd\")\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:1111, in HasBranches.arrays(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library, how)\r\n   1108         return None\r\n   1110 aliases = _regularize_aliases(self, aliases)\r\n-> 1111 arrays, expression_context, branchid_interpretation = _regularize_expressions(\r\n   1112     self,\r\n   1113     expressions,\r\n   1114     cut,\r\n   1115     filter_name,\r\n   1116     filter_typename,\r\n   1117     filter_branch,\r\n   1118     keys,\r\n   1119     aliases,\r\n   1120     language,\r\n   1121     get_from_cache,\r\n   1122 )\r\n   1124 ranges_or_baskets = []\r\n   1125 checked = set()\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3327, in _regularize_expressions(hasbranches, expressions, cut, filter_name, filter_typename, filter_branch, keys, aliases, language, get_from_cache)\r\n   3325 for expression, interp in items:\r\n   3326     if interp is None:\r\n-> 3327         _regularize_expression(\r\n   3328             hasbranches,\r\n   3329             expression,\r\n   3330             keys,\r\n   3331             aliases,\r\n   3332             language,\r\n   3333             get_from_cache,\r\n   3334             arrays,\r\n   3335             expression_context,\r\n   3336             branchid_interpretation,\r\n   3337             (),\r\n   3338             False,\r\n   3339             None,\r\n   3340         )\r\n   3341     else:\r\n   3342         branch = hasbranches[expression]\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3172, in _regularize_expression(hasbranches, expression, keys, aliases, language, get_from_cache, arrays, expression_context, branchid_interpretation, symbol_path, is_cut, rename)\r\n   3170 branch = hasbranches.get(expression)\r\n   3171 if branch is not None:\r\n-> 3172     _regularize_branchname(\r\n   3173         hasbranches,\r\n   3174         expression,\r\n   3175         branch,\r\n   3176         branch.interpretation,\r\n   3177         get_from_cache,\r\n   3178         arrays,\r\n   3179         expression_context,\r\n   3180         branchid_interpretation,\r\n   3181         is_primary,\r\n   3182         is_cut,\r\n   3183     )\r\n   3185 else:\r\n   3186     if expression in aliases:\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3100, in _regularize_branchname(hasbranches, branchname, branch, interpretation, get_from_cache, arrays, expression_context, branchid_interpretation, is_primary, is_cut)\r\n   3088 def _regularize_branchname(\r\n   3089     hasbranches,\r\n   3090     branchname,\r\n   (...)\r\n   3098     is_cut,\r\n   3099 ):\r\n-> 3100     got = get_from_cache(branchname, interpretation)\r\n   3101     if got is not None:\r\n   3102         arrays[branch.cache_key] = got\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:1101, in HasBranches.arrays.<locals>.get_from_cache(branchname, interpretation)\r\n   1096 def get_from_cache(branchname, interpretation):\r\n   1097     if array_cache is not None:\r\n   1098         cache_key = \"{0}:{1}:{2}:{3}-{4}:{5}\".format(\r\n   1099             self.cache_key,\r\n   1100             branchname,\r\n-> 1101             interpretation.cache_key,\r\n   1102             entry_start,\r\n   1103             entry_stop,\r\n   1104             library.name,\r\n   1105         )\r\n   1106         return array_cache.get(cache_key)\r\n   1107     else:\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/interpretation/identify.py:1184, in UnknownInterpretation.cache_key(self)\r\n   1182 @property\r\n   1183 def cache_key(self):\r\n-> 1184     raise self\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:2211, in TBranch.interpretation(self)\r\n   2209 if self._interpretation is None:\r\n   2210     try:\r\n-> 2211         self._interpretation = uproot.interpretation.identify.interpretation_of(\r\n   2212             self, {}\r\n   2213         )\r\n   2214     except uproot.interpretation.identify.UnknownInterpretation as err:\r\n   2215         self._interpretation = err\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/interpretation/identify.py:384, in interpretation_of(branch, context, simplify)\r\n    380 is_double32 = (\r\n    381     leaftype == uproot.const.kDouble32 or leaf.classname == \"TLeafD32\"\r\n    382 )\r\n    383 if is_float16 or is_double32:\r\n--> 384     out = _float16_or_double32(branch, context, leaf, is_float16, dims)\r\n    386 else:\r\n    387     if (\r\n    388         branch.member(\"fClassName\", none_if_missing=True) == \"TObject\"\r\n    389         and branch.name.split(\".\")[-1] == \"fBits\"\r\n    390     ):\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/interpretation/identify.py:256, in _float16_or_double32(branch, context, leaf, is_float16, dims)\r\n    249 except SyntaxError:\r\n    250     raise UnknownInterpretation(\r\n    251         \"cannot parse streamer title {0} (as Python)\".format(repr(source)),\r\n    252         branch.file.file_path,\r\n    253         branch.object_path,\r\n    254     )\r\n--> 256 transformed = ast.Expression(_float16_double32_walk_ast(parsed, branch, source))\r\n    257 spec = eval(compile(transformed, repr(title), \"eval\"))\r\n    258 if (\r\n    259     len(spec) == 2\r\n    260     and uproot._util.isnum(spec[0])\r\n    261     and uproot._util.isnum(spec[1])\r\n    262 ):\r\n\r\nFile ~/anaconda3/envs/deep_tracking/lib/python3.9/site-packages/uproot/interpretation/identify.py:214, in _float16_double32_walk_ast(node, branch, source)\r\n    205     out = ast.List(\r\n    206         [\r\n    207             _float16_double32_walk_ast(node.elts[0], branch, source),\r\n   (...)\r\n    211         node.ctx,\r\n    212     )\r\n    213 else:\r\n--> 214     raise UnknownInterpretation(\r\n    215         \"cannot compute streamer title {0}\".format(repr(source)),\r\n    216         branch.file.file_path,\r\n    217         branch.object_path,\r\n    218     )\r\n    219 out.lineno, out.col_offset = node.lineno, node.col_offset\r\n    220 return out\r\n\r\nUnknownInterpretation: cannot compute streamer title '[cm]'\r\n```\r\nThis seems to be solvable by updating the identify.py file in the interpretation directory accordingly to [identify.txt](https://github.com/scikit-hep/uproot4/files/8061252/identify.txt) but maybe you know better methods to solve this problem? Thanks!\r\n",
  "closed_at":"2022-02-21T15:12:13Z",
  "comments":3,
  "created_at":"2022-02-14T13:59:18Z",
  "id":1137344887,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5DyoF3",
  "number":558,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Problems with square brackets in streamer title",
  "updated_at":"2022-02-21T15:12:13Z",
  "user":"MDQ6VXNlcjUyNDk3Njcw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Expected behavior:\r\n\r\n```python\r\nwith uproot.open(\"input.root\") as f:\r\n   obj = f[\"histogram\"]\r\n   obj. # (here pop out list of member and methods, such as to_numpy)\r\n   obj.to_numpy # (shift+tab: show documentation of to_numpy function)\r\n```\r\n\r\nCurrent behavior:\r\n- nothings pops up.\r\n\r\nTest environment:\r\n- python3.9 + Jupiter-lab or ipython",
  "closed_at":"2022-02-14T21:46:23Z",
  "comments":5,
  "created_at":"2022-02-14T19:44:51Z",
  "id":1137759152,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5D0NOw",
  "number":559,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Enable autocomplete of loaded objects from root files",
  "updated_at":"2022-08-03T19:50:23Z",
  "user":"MDQ6VXNlcjMyMDU5Mzg="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-02-21T15:12:14Z",
  "comments":0,
  "created_at":"2022-02-14T22:28:18Z",
  "draft":false,
  "id":1137925160,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4y0ZJ9",
  "number":561,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-02-21T15:12:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"If the title of Float16/Double32 is not parsable, assume defaults.",
  "updated_at":"2022-02-21T15:12:15Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Pandas 1.4.1 throws FutureWarnings when loading data into a pandas dataframe. This is not a critical bug but it will require your attention in the future.\r\n```\r\npython: 3.10\r\nuproot: 4.20\r\npandas: 1.4.1\r\n```\r\nFrom an ipython session:\r\n```\r\nIn [1]: import uproot\r\n\r\nIn [2]: import pandas\r\n\r\nIn [3]: pandas.__version__\r\nOut[3]: '1.4.1'\r\n\r\nIn [4]: uproot.__version__\r\nOut[4]: '4.2.0'\r\n\r\nIn [5]: uproot.open(\"file.root\")[\"DecayTree\"].arrays(library=\"pd\")\r\n/pathto/.local/anaconda3/envs/ftcalib/lib/python3.10/site-packages/uproot/interpretation/library.py:747: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\r\n  return (getattr(pandas, \"RangeIndex\", pandas.Int64Index), pandas.Int64Index)\r\n```",
  "closed_at":"2022-02-21T16:00:42Z",
  "comments":1,
  "created_at":"2022-02-20T13:16:15Z",
  "id":1145017026,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5EP5LC",
  "number":562,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"pandas FutureWarning: pandas.Int64Index is deprecated",
  "updated_at":"2022-02-21T16:00:42Z",
  "user":"MDQ6VXNlcjEyMTQzMDEw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Apologies if I use the incorrect keywords - that might be a part of my problems ;).\r\n\r\nAt the lowest level I am trying to\r\n\r\n```python\r\nmuon_py, muon_pz = input_tree.arrays([\"Muon_Py\", \"Muon_Pz\"], how=tuple)\r\nmuon_momentum = np.hypot(muon_py, muon_pz) # stand-in for arbitrary user function or awkward user data\r\n# missing steps\r\n# the below should work now\r\narrays = input_tree.arrays([\"Muon_Py\", \"Muon_Pz\", \"Muon_momentum\"], how=tuple)\r\n```\r\n\r\nEssentially, I would like to make use of the `.arrays` functionality for user-defined data, but `input_tree` is of type `Model_TTree_v19` - i.e. has no `extend` functionality.\r\nI know I can use `aliases` for data that is well represented through an expression with existing data, but I am looking for a more general solution, .e.g\r\n\r\n```python\r\narrays = input_tree.arrays([\"Muon_Py\", \"Muon_Pz\", \"Muon_momentum\"], how=tuple, extra_data={\"Muon_momentum\" : muon_momentum})\r\n```\r\nin a similar way that `numexpr.evaluate` uses `local_dict`.\r\n\r\n- Is that something that is already possible?\r\n- Would you recommend a workaround using `library.group` in a wrapper?\r\n- Would such an extension to the functionality make sense at all from your design perspective?",
  "closed_at":"2022-02-21T14:12:36Z",
  "comments":1,
  "created_at":"2022-02-21T10:23:59Z",
  "id":1145602980,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5ESIOk",
  "number":563,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"\"extend\" for read-only TTrees/merging user-defined content",
  "updated_at":"2022-02-21T14:12:36Z",
  "user":"MDQ6VXNlcjEyMTMyNzY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-02-21T16:00:42Z",
  "comments":0,
  "created_at":"2022-02-21T15:52:07Z",
  "draft":false,
  "id":1145968517,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4zPMMw",
  "number":564,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-02-21T16:00:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove references to deprecated 'distutils' and Pandas 'Int64Index'.",
  "updated_at":"2022-02-21T16:00:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Committed via https://github.com/asottile/all-repos",
  "closed_at":"2022-02-25T18:42:04Z",
  "comments":0,
  "created_at":"2022-02-25T17:42:44Z",
  "draft":false,
  "id":1150700585,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4zeobh",
  "number":565,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-02-25T18:42:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: wheel not required for setuptools PEP 517 (all-repos)",
  "updated_at":"2022-02-25T18:42:05Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Dear uproot developers,\r\nIn my very naive understanding, uproot4 (=\"uproot\" nowadays) is supposed to be a rewrite of uproot3 and the feature sets between 3 and 4 do not necessarily match. Should the feature sets of uproot4 and uproot (The library you get via `pip install uproot`) not be identical? I noticed, that the version numbers differ (ok) and that there is no `recreate` method in uproot4, but it exists in uproot and uproot3. Writing is supported in uproot4 since recently, right?\r\nMy guess is that this is just a bug that went unnoticed, because no one actually explicitly installs \"uproot4\" except me ^^ am I wrong?\r\nThanks!\r\n\r\n```\r\nIn [8]: import uproot\r\n\r\nIn [9]: import uproot3\r\n\r\nIn [10]: import uproot4\r\n\r\nIn [11]: uproot.__version__\r\nOut[11]: '4.2.0'\r\n\r\nIn [12]: uproot3.__version__\r\nOut[12]: '3.14.4'\r\n\r\nIn [13]: uproot4.__version__\r\nOut[13]: '0.1.2'\r\n\r\nIn [14]: uproot.recreate\r\nOut[14]: <function uproot.writing.writable.recreate(file_path, **options)>\r\n\r\nIn [15]: uproot3.recreate\r\nOut[15]: uproot3.write.TFile.TFileRecreate\r\n\r\nIn [16]: uproot4.recreate\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nInput In [16], in <module>\r\n----> 1 uproot4.recreate\r\n\r\nAttributeError: module 'uproot4' has no attribute 'recreate'\r\n```\r\n",
  "closed_at":"2022-05-11T21:09:05Z",
  "comments":3,
  "created_at":"2022-03-01T23:13:05Z",
  "id":1155924390,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5E5gGm",
  "number":568,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"uproot4.recreate does not exist",
  "updated_at":"2022-05-11T21:09:05Z",
  "user":"MDQ6VXNlcjEyMTQzMDEw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Dear uproot team,\r\n\r\nI am seeing the following issue with uproot 4.1.8, 4.1.9 and 4.2.0 (I have not tried other versions). The TObject/fBits branch data type is interpreted as 8 bit instead of 32 bit. This leads to issues when trying to read the branch entries as I suspect the binary gets split in the wrong way and the number of branch entries does not match anymore. It leads to an error. This is causing some problems when for example using uproot to compare to root files.\r\n\r\nHere an example:\r\n```python\r\n>>> import uproot\r\n>>> events = uproot.open(\"file.root:MCTruthTree\")\r\n>>> events[\"MCTruthEvent/TObject/fBits\"].array(library=\"pd\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/fruth/miniforge3/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 2095, in array\r\n    _ranges_or_baskets_to_arrays(\r\n  File \"/Users/fruth/miniforge3/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3510, in _ranges_or_baskets_to_arrays\r\n    uproot.source.futures.delayed_raise(*obj)\r\n  File \"/Users/fruth/miniforge3/lib/python3.9/site-packages/uproot/source/futures.py\", line 46, in delayed_raise\r\n    raise exception_value.with_traceback(traceback)\r\n  File \"/Users/fruth/miniforge3/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3464, in basket_to_array\r\n    raise ValueError(\r\nValueError: basket 0 in tree/branch /MCTruthTree;1:MCTruthEvent/TObject/fBits has the wrong number of entries (expected 50, obtained 200) when interpreted as AsDtype('uint8')\r\n",
  "closed_at":"2022-03-07T17:38:28Z",
  "comments":3,
  "created_at":"2022-03-04T16:57:56Z",
  "id":1159851595,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5FIe5L",
  "number":569,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Wrong data type for TObject/fBits",
  "updated_at":"2022-03-07T17:38:28Z",
  "user":"U_kgDOBgRteQ"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This PR _reverses_ the second \"fix\" in #454, which was motivated by issue #438, raised by @kratsg.\r\n\r\nReading the text of PR #454, it's clear that I didn't believe `fBits` is actually 1 byte, I did it as an expedient because the file from Delphes had sometimes 4 bytes, sometimes 6 bytes, and at least assuming it's 1 byte would prevent it from raising error messages in `AsGrouped`. Reverting that may break @kratsg's workflow, but it didn't actually need the `fBits`\u2014they were just coming along for the ride in `AsGrouped`. Would it be possible to instead avoid `AsGrouped`?\r\n\r\nThe file that this PR is based on, from @tfruth, demonstrates that the `fBits` really is 4 bytes. Maybe the Delphes ROOT writer is just wrong here. Anyway, the code can only be one way (PR #454 shows that I tried and failed to find any indicator for \"4 bytes\" vs \"6 bytes\") and this appears to be the correct one.\r\n\r\nBoth of you are affected by this. If it matters, please test against this PR!",
  "closed_at":"2022-03-07T17:38:29Z",
  "comments":12,
  "created_at":"2022-03-04T19:53:58Z",
  "draft":false,
  "id":1159999526,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4z-TJ-",
  "number":570,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-03-07T17:38:28Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fBits is 4 bytes",
  "updated_at":"2022-03-09T00:13:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Our users observed a significant performance regression (10x and more) and it turns out to be introduced somewhere between 4.1.2 and 4.1.3 (release on 29th September 2021). The `awkward` version is the latest `1.8.0`.\r\n\r\nI went through the release notes in https://github.com/scikit-hep/uproot4/releases/tag/4.1.3 and I first reverted https://github.com/scikit-hep/uproot4/pull/441 which also needed the `objectarray1d` function from `uproot._util` (see https://github.com/scikit-hep/uproot4/pull/442/files) but it did not help.\r\n\r\nI also went through the other PRs but they seemed unrelated, so I started a `git bisect` with\r\n\r\nGood: `382bb62f47a05f6111d3787e3235f9e56d9e113e` (4.1.2)\r\nBad: `03cb08ccb1f47ce0b082117f41a112af1ab403ee` (4.1.3)\r\n\r\nand identified the https://github.com/scikit-hep/uproot4/commit/007b10014003a74d0e89e0166e21a6218de0d445 from @nsmith- which introduced the performance regression:\r\n\r\n```\r\n\u2591 tamasgal@silentbox-(2):uproot4 \ue0a0  (git)-[4.1.3~8|bisect]- py-system\r\n\u2591 13:30:56 > git bisect good\r\n007b10014003a74d0e89e0166e21a6218de0d445 is the first bad commit\r\ncommit 007b10014003a74d0e89e0166e21a6218de0d445\r\nAuthor: Nicholas Smith <nick.smith@cern.ch>\r\nDate:   Mon Sep 20 14:09:59 2021 -0500\r\n\r\n    Implement regular array support for TClonesArray (#442)\r\n\r\n    * Implement regular array support for TClonesArray\r\n\r\n    * Add a small test\r\n\r\n    * Fix issue with incidentally regular TRefArray lists\r\n\r\n    * Cannot trust dict order\r\n\r\n src/uproot/_util.py                     | 13 +++++++++\r\n src/uproot/containers.py                | 45 ++++++++++++++++++++++---------\r\n src/uproot/interpretation/identify.py   |  4 +--\r\n src/uproot/interpretation/library.py    | 20 +++++++++++---\r\n src/uproot/interpretation/numerical.py  | 11 ++++++++\r\n src/uproot/interpretation/objects.py    | 48 +++++++++++++++++++++++++++------\r\n tests/test_0442-regular-TClonesArray.py | 40 +++++++++++++++++++++++++++\r\n 7 files changed, 155 insertions(+), 26 deletions(-)\r\n create mode 100644 tests/test_0442-regular-TClonesArray.py\r\n```\r\n\r\nI investigated our codes and found the exact call which causes the problem: it's indeed the reading of doubly nested arrays.\r\n\r\nWith `uproot 4.1.2`, the following code is almost instantaneous whereas with `uproot 4.1.3` it takes about 1.5 minutes (for a 1.5GB file):\r\n\r\n```\r\n>>> import uproot\r\n>>> f = uproot.open(\"doubly_nested_regression.root\")\r\n>>> f[\"E/Evt/trks/trks.rec_stages\"].array()\r\n<Array [[[1, 2, 5, 3, 5, 4], ... 1], [1], [1]]] type='158262 * var * var * int32'>\r\n```\r\n\r\nHere is the file http://131.188.161.12:30002/doubly_nested_regression.root\r\n\r\n@jpivarski you probably remember that you introduced some special hack to squeeze a lot out of doubly-nested structures, see https://github.com/scikit-hep/awkward-1.0/issues/968 and https://github.com/scikit-hep/awkward-1.0/blob/main/src/awkward/_connect/_uproot.py#L35 so my first thought was that these became ineffective with the changes introduced in https://github.com/scikit-hep/uproot4/commit/007b10014003a74d0e89e0166e21a6218de0d445 but I am just speculating `; )`",
  "closed_at":"2022-03-14T20:00:22Z",
  "comments":4,
  "created_at":"2022-03-14T13:07:16Z",
  "id":1168351247,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Fo6AP",
  "number":572,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Performance regression (>10x) from 4.1.2 to 4.1.3",
  "updated_at":"2022-03-14T21:14:41Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Please test, @tamasgal.",
  "closed_at":"2022-03-14T20:00:23Z",
  "comments":4,
  "created_at":"2022-03-14T18:29:16Z",
  "draft":false,
  "id":1168756530,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss40amX_",
  "number":573,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-03-14T20:00:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Restore performance hack for AsArray(True, False, AsVector(False, dtype)).",
  "updated_at":"2022-03-14T20:00:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.31.0 \u2192 v2.31.1](https://github.com/asottile/pyupgrade/compare/v2.31.0...v2.31.1)\n- [github.com/mgedmin/check-manifest: 0.47 \u2192 0.48](https://github.com/mgedmin/check-manifest/compare/0.47...0.48)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-03-14T21:55:13Z",
  "comments":0,
  "created_at":"2022-03-14T21:34:23Z",
  "draft":false,
  "id":1168934334,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss40bMnF",
  "number":575,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-03-14T21:55:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-03-14T21:55:13Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"While experimenting with Unicode characters, I ran into an issues when writing `.root` files containing objects with Unicode characters in their names. This might admittedly be an extremely niche use case, but I did not find Unicode characters mentioned in issues/discussion/documentation, and thought it may be useful to document this here if others run into the same thing.\r\n\r\nThe following works just fine:\r\n```python\r\nimport uproot\r\nimport numpy as np\r\n\r\nwith uproot.recreate(\"tmp.root\") as file:\r\n    file[\"\ud83d\ude00\"] = np.histogram(np.random.normal(0, 1, 10))\r\n```\r\n\r\nI cannot read the resulting file though. This can be demonstrated by trying to access the histogram:\r\n```python\r\nimport uproot\r\nimport numpy as np\r\n\r\nwith uproot.recreate(\"tmp.root\") as file:\r\n    file[\"\ud83d\ude00\"] = np.histogram(np.random.normal(0, 1, 10))\r\n    file[\"\ud83d\ude00\"]\r\n```\r\nresults in \r\n```pytb\r\nTraceback (most recent call last):\r\n  File \"[...]/test.py\", line 10, in <module>\r\n    file[\"\ud83d\ude00\"]\r\n  File \"[...]/lib/python3.9/site-packages/uproot/writing/writable.py\", line 957, in __getitem__\r\n    return self._get_del_search(where, True)\r\n  File \"[...]/lib/python3.9/site-packages/uproot/writing/writable.py\", line 950, in _get_del_search\r\n    return self._get(item, cycle)\r\n  File \"[...]/lib/python3.9/site-packages/uproot/writing/writable.py\", line 1018, in _get\r\n    return readonlykey.get()\r\n  File \"[...]/lib/python3.9/site-packages/uproot/reading.py\", line 2493, in get\r\n    chunk, cursor = self.get_uncompressed_chunk_cursor()\r\n  File \"[...]/lib/python3.9/site-packages/uproot/reading.py\", line 2549, in get_uncompressed_chunk_cursor\r\n    uncompressed_chunk = uproot.compression.decompress(\r\n  File \"[...]/lib/python3.9/site-packages/uproot/compression.py\", line 413, in decompress\r\n    uncompressed_bytestring = decompressor.decompress(\r\n  File \"[...]/lib/python3.9/site-packages/uproot/compression.py\", line 93, in decompress\r\n    return zlib.decompress(data)\r\nzlib.error: Error -3 while decompressing data: incorrect data check\r\n```\r\n\r\nI also tried `file[file.keys()[0]]`, which behaves in the same way.\r\n\r\nThe issue also appears when re-opening the file instead (in a new block via `uproot.open`), and also when using `ROOT` instead of `uproot`:\r\n```\r\nR__unzip: error -3 in inflate (zlib)\r\n```\r\n\r\nSince the error message suggests that this is compression-related, I tried writing with `compression=None`. This works fine, and can subsequently be read both with `uproot` and `ROOT`.\r\n\r\nI opened this as a bug in case it actually is something related to encoding on the `uproot` side. If this type of pattern is not supported, perhaps it would be useful to check for the presence of Unicode characters when the decompression fails, and then inform the user about it? If the resulting files are broken (which the user may not know until trying to read them later), a check may even be useful when writing already (I do not know whether the resulting overhead may be a performance concern though).\r\n\r\nsoftware versions: `Python` 3.9.10, `uproot` 4.2.2, `ROOT` 6.24.06",
  "closed_at":"2022-03-21T19:07:24Z",
  "comments":4,
  "created_at":"2022-03-21T13:23:00Z",
  "id":1175382685,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5GDuqd",
  "number":576,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"File writing with Unicode characters and compression",
  "updated_at":"2022-03-21T19:07:24Z",
  "user":"MDQ6VXNlcjQ1MDA5MzU1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-03-21T19:07:24Z",
  "comments":0,
  "created_at":"2022-03-21T19:00:03Z",
  "draft":false,
  "id":1175813788,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss40wyR9",
  "number":577,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-03-21T19:07:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Test file-writing with Unicode names and fix it.",
  "updated_at":"2022-03-21T19:07:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Evaluation Task Submission by Kush Kothari\r\n\r\nThis PR lays the groundwork for the `uproot.dask` function. It borrows some logic from the deprecated `uproot.lazy` function and further builds on this with dask.\r\n\r\n```\r\nuproot.dask(file)\r\n```\r\nOR\r\n```\r\nuproot.dask([file1,file2,file3,...])\r\n```\r\nThese now return a Python dictionary which maps branchnames onto the corresponding dask arrays. When multiple files are provided, `uproot.dask` returns arrays that have been concatenated end-to-end. Many of the arguments simply pass through, so I have included as many as I could from `uproot.lazy`.\r\n\r\nScreenshots of `uproot.dask` in action follow below.",
  "closed_at":"2022-06-01T20:59:19Z",
  "comments":6,
  "created_at":"2022-03-24T10:56:58Z",
  "draft":false,
  "id":1179344022,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss408ToP",
  "number":578,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-01T20:59:19Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"GSoC uproot.dask",
  "updated_at":"2022-06-01T20:59:19Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"See https://github.com/psf/black/issues/2964 for details.\r\n\r\nCommitted via https://github.com/asottile/all-repos",
  "closed_at":"2022-03-29T14:29:16Z",
  "comments":0,
  "created_at":"2022-03-29T04:15:16Z",
  "draft":false,
  "id":1184276879,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss41Mxdm",
  "number":579,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-03-29T14:29:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: bump black to 22.3.0 due to click 8.1 release",
  "updated_at":"2022-03-29T14:29:17Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Currently, when `uproot` writes `hist` histograms without flow bins, the property isn't checked and regular edge bins get written as flow bins causing weird issues with reading. \r\n\r\n```\r\nimport uproot\r\nimport hist\r\nimport numpy as np\r\nimport mplhep as hep\r\n\r\nh = hist.new.Reg(20, 0, 20, name='msd', flow=False).Weight().fill(np.random.normal(10, 6, 1000))\r\n\r\nfout = uproot.recreate('test.root')\r\nfout['test'] = h\r\nfout.close()\r\n\r\nfin = uproot.open('test.root')\r\nh_read = fin['test']\r\nfin.close()\r\n\r\nlen(h.values()), len(h_read.values()), len(h.axes[0].edges)\r\n\r\n>>> (20, 18, 21)\r\n```\r\n\r\nThis PR materializes the empty flow bins as Nans when writing and filters them out again when reading to match the current expected behaviour. The caveat is that when only one flow bin exists when storing, it won't be obvious which one it is when reading the TH1 with `values(flow=True)` Possibly this should return a masked array instead to be clearer, but I didn't want to change the return type here. \r\n",
  "closed_at":"2022-04-05T18:04:14Z",
  "comments":16,
  "created_at":"2022-04-01T16:06:54Z",
  "draft":false,
  "id":1190005770,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss41gAHi",
  "number":580,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: missing hist flow bins handling",
  "updated_at":"2022-04-09T11:13:30Z",
  "user":"MDQ6VXNlcjEzMjI2NTAw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/setup-cfg-fmt: v1.20.0 \u2192 v1.20.1](https://github.com/asottile/setup-cfg-fmt/compare/v1.20.0...v1.20.1)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-04-04T20:08:46Z",
  "comments":0,
  "created_at":"2022-04-04T19:27:22Z",
  "draft":false,
  "id":1192218929,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss41m8xG",
  "number":581,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-04-04T20:08:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-04-04T20:08:47Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This should replace #580.\r\n\r\nInstead of padding and removing padded bins, this PR just corrects Uproot's understanding of what hist means by `flow=True` on histograms with no built-in flow bins. It removes a bug in histogram-writing, but everything else stays the same.\r\n\r\nThis PR also doesn't address Uproot's and hist's disagreement about whether `axes[0].edges` is a property or a method, but that would be an API breaking change. This PR also changes behavior, but it's unequivocally a bug fix. Uproot was previously assuming something wrong about how hist behaves and was writing corrupted ROOT files as a result. If anyone finds this PR, searching for an explanation for the change in behavior, the old behavior was wrong and you should re-write your files of histograms.\r\n\r\nThis PR _does not_ need to be coordinated with any particular version of hist. hist's behavior is not changing.",
  "closed_at":"2022-04-05T18:10:36Z",
  "comments":0,
  "created_at":"2022-04-05T14:00:21Z",
  "draft":false,
  "id":1193193330,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss41qMdZ",
  "number":582,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-04-05T18:10:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"In hist, flow=True only has flow bins if the histogram object has them.",
  "updated_at":"2022-04-05T18:10:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I have a ROOT file that I want to read using uproot and export a pandas DataFrame. The command I'm using is\r\n```py\r\ndf = uproot.open(\"dvntuple.root\")[\"Hlt2Dstp2D0Pip_D02KmKpPimPip_Tuple/DecayTree\"].arrays(library=\"pd\", entry_stop=8)\r\n```\r\nHowever, `df` is a `tuple` rather than `pandas.core.frame.DataFrame`. It's a tuple of two different DataFrames - `df[0]` has 8 rows and 893 columns, `df[1]` has 9 rows and 804 columns.\r\n\r\nIs this expected?\r\n\r\nI couldn't create a smaller test file as the file created by running the following command doesn't cause this behavior.\r\n```sh\r\nrooteventselector -l10 dvntuple.root:Hlt2Dstp2D0Pip_D02KmKpPimPip_Tuple/DecayTree mwe.root\r\n```\r\nThe original largish file (1.7 GB) is available [here](https://cernbox.cern.ch/index.php/s/wnCckGSxgPxvMdB).\r\n\r\n\r\nuproot 4.2.2",
  "closed_at":"2022-04-08T16:18:59Z",
  "comments":8,
  "created_at":"2022-04-08T15:37:40Z",
  "id":1197479566,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5HYBaO",
  "number":583,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"arrays(library=\"pd\") returns a tuple",
  "updated_at":"2022-04-11T18:26:36Z",
  "user":"MDQ6VXNlcjIzMDUyMDU0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.31.1 \u2192 v2.32.0](https://github.com/asottile/pyupgrade/compare/v2.31.1...v2.32.0)\n- [github.com/pre-commit/pre-commit-hooks: v4.1.0 \u2192 v4.2.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.1.0...v4.2.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-04-11T20:28:14Z",
  "comments":0,
  "created_at":"2022-04-11T20:15:22Z",
  "draft":false,
  "id":1200483380,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss42Bxmu",
  "number":584,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-04-11T20:28:14Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-04-11T20:28:15Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"### Qualifying Task Submission\r\n\r\nadded `uproot.dask`\r\n\r\nThis is a prototype `uproot.dask` function that works only for `library=\"np\"` on arrays of plain numeric data.\r\n\r\n<pre><code>uproot.dask(\"files*.root:tree\", [\"x\", \"y\"])</code></pre>\r\n\r\n\r\nThis function  when properly utilized, returns Python dict and dask.array(s).\r\nIt goes through the normal Uproot machinery to produce the array, but it delays it as a Dask task.\r\n\r\nThis is to eventually replace the `uproot.lazy` function which uses Awkward arrays features.\r\n\r\nWhen calling `.compute()` utilizing this function, it returns the same data as `uproot.concatenate`, except that the file-reading does not start until `.compute()` is called.\r\n\r\nSample cases of utilizing this function are included in the following comments",
  "closed_at":"2022-06-07T14:58:14Z",
  "comments":1,
  "created_at":"2022-04-16T04:20:58Z",
  "draft":false,
  "id":1206009687,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss42T8hE",
  "number":585,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"GSoC uproot.dask",
  "updated_at":"2022-06-07T14:58:14Z",
  "user":"MDQ6VXNlcjcwOTkwMzQx"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"uproot seems to have trouble reading objects with std::arrays of std::vectors in them. \r\n\r\nAttached is a reproducer, tested with uproot 4.2.2 and ROOT 6.24/06 on Fedora 35 (you should just be able to type make to compile the necessary C++ stuff and run the example)\r\n\r\n[stdarray.tar.gz](https://github.com/scikit-hep/uproot4/files/8510513/stdarray.tar.gz)\r\n\r\nThe example object is simple:\r\n\r\n```\r\nclass ExampleFail : public TObject\r\n{\r\n  public: \r\n    ExampleFail(); \r\n    std::array<std::vector<double>,2> twovectors; \r\n\r\n  ClassDef(ExampleFail,1); \r\n};\r\n\r\n```\r\n\r\nFor reference, here is ROOT's streamerinfo:\r\n```\r\nStreamerInfo for class: ExampleFail, version=1, checksum=0xa015597b\r\n  TObject        BASE            offset=  0 type=66 Basic ROOT object   \r\n  vector<double> twovectors[2]   offset=  0 type=82            \r\n```\r\n\r\nAnd uproot's is\r\n\r\n```\r\nExampleFail (v1): TObject (v1)\r\n    twovectors: vector<double> (TStreamerObjectAny)\r\n```\r\n\r\nTrying to load the object ends up failing with:\r\n```\r\nValueError: unknown class vector<double> that cannot be skipped because its number of bytes is unknown\r\n```\r\n\r\nI did also try using `std::vector<double> twovectors[2]` instead, but that failed in a different way. \r\n\r\nObviously a workaround is to just use nested std::vectors instead, but that is not quite the same thing. ",
  "closed_at":null,
  "comments":1,
  "created_at":"2022-04-19T07:01:47Z",
  "id":1207853164,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5H_mBs",
  "number":586,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Reading non-TTree objects with std::array<std::vector> members",
  "updated_at":"2022-04-20T16:23:53Z",
  "user":"MDQ6VXNlcjkyMDY1Njk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I suspect this is not behaving as intended\r\nhttps://github.com/scikit-hep/uproot4/blob/main/src/uproot/behaviors/TGraphAsymmErrors.py#L35\r\n\r\nBoth low and high errors are given as positive numbers so instead of returning the \"band\", this returns their magnitude difference.",
  "closed_at":"2022-04-22T11:41:37Z",
  "comments":6,
  "created_at":"2022-04-21T11:27:30Z",
  "id":1210898770,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5ILNlS",
  "number":587,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"TGAsymm errors(\"diff\")",
  "updated_at":"2022-04-22T11:41:38Z",
  "user":"MDQ6VXNlcjEzMjI2NTAw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"OS; MacOS Monterey 12.2.1 (I can also try a linux box if that's useful)\r\npython; 3.10.4 (using ipython 8.2.0)\r\nawkward; 1.8.0\r\nuproot; 4.2.2\r\n\r\nSo I was following the notes in https://github.com/scikit-hep/uproot4/issues/123 to read a DAOD_PHYSLITE file, in particular, I'm reading the first file posted [DAOD_PHYSLITE.art.pool.root](https://cernbox.cern.ch/index.php/s/53DqhefxcTGBhCH/download).\r\n\r\nThe reading goes fine and I can get values, only when I try to read the fields of the returned array I get an error. Is that something that would normally work?\r\n\r\nMinimal broken example;\r\n```python\r\nimport uproot\r\nimport awkward as ak\r\nf = uproot.open(\"DAOD_PHYSLITE.art.pool.root\")\r\nt = f[\"CollectionTree\"]\r\narrays = t[\"AnalysisElectronsAuxDyn.trackParticleLinks\"].array(library=\"np\")\r\nak.fields(arrays)\r\n```\r\n\r\nGives me the error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nFile ~/CTU/reading_DAOD_PHYSLITE/errors.py:6, in <module>\r\n      4 t = f[\"CollectionTree\"]\r\n      5 arrays = t[\"AnalysisElectronsAuxDyn.trackParticleLinks\"].array(library=\"np\")\r\n----> 6 ak.fields(arrays)\r\n\r\nFile /opt/homebrew/Caskroom/miniconda/base/envs/latest_uproot/lib/python3.10/site-packages/awkward/operations/describe.py:263, in fields(array)\r\n    250 def fields(array):\r\n    251     \"\"\"\r\n    252     Extracts record fields or tuple slot numbers from `array` (many types\r\n    253     supported, including all Awkward Arrays and Records).\r\n   (...)\r\n    261     list.\r\n    262     \"\"\"\r\n--> 263     layout = ak.operations.convert.to_layout(\r\n    264         array, allow_record=True, allow_other=False\r\n    265     )\r\n    266     return layout.keys()\r\n\r\nFile /opt/homebrew/Caskroom/miniconda/base/envs/latest_uproot/lib/python3.10/site-packages/awkward/operations/convert.py:1902, in to_layout(array, allow_record, allow_other, numpytype)\r\n   1900 elif isinstance(array, (np.ndarray, numpy.ma.MaskedArray)):\r\n   1901     if not issubclass(array.dtype.type, numpytype):\r\n-> 1902         raise ValueError(\r\n   1903             f\"NumPy {array.dtype!r} not allowed\"\r\n   1904             + ak._util.exception_suffix(__file__)\r\n   1905         )\r\n   1906     return from_numpy(array, regulararray=True, recordarray=True, highlevel=False)\r\n   1908 elif (\r\n   1909     type(array).__module__.startswith(\"cupy.\") and type(array).__name__ == \"ndarray\"\r\n   1910 ):\r\n\r\nValueError: NumPy dtype('O') not allowed\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/1.8.0/src/awkward/operations/convert.py#L1904)\r\n```\r\n\r\nIt's not urgent or anything, but I'd like to promote uproot for reading DAOD_PHYSLITE files in my group, so it would be neat if that worked. If it's really a bug, and you think it reasonable, I'm happy to have a go at fixing it tonight?\r\n",
  "closed_at":"2022-04-26T08:55:47Z",
  "comments":1,
  "created_at":"2022-04-26T08:46:43Z",
  "id":1215617164,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5IdNiM",
  "number":588,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Reading DAOD_PHYSLITE files; issue with `ak.fields` on the returned array.",
  "updated_at":"2022-04-26T08:55:48Z",
  "user":"MDQ6VXNlcjEyOTk2NzYz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I use uproot on SWAN (software stack 97a, uproot 4.0.0, awkward1 1.0.0) for one of my FCC analysis, and I have an issue. Since the new version of the FCCAnalyses stuff, the conversion of my data from ROOT tree to Awkward array is impossible. I checked the C++ function behind my quantities but nothing seems different comparing to the previous version (when everything was good).\r\n\r\nWith the .show() function I seen that the problem come from the fact that my old ROOT::VecObs::RVec<float or int> was seen like std::vector<float or int> by uproot where my new ROOT::VecObs::RVec<float or int> are seen like ROOT::VecOps::RVec<float or int>. Because of that uproot is not able to interpret these quantities (it gives AsObjects(UnknownROOT\u2026)). I add that, by exploring my new and old .root with a TBrowser they seems identical.\r\n\r\nI attach two files in this report, new is the .root with the issue and old is the previous version of it (without any issue), we can see a slight difference of size between the two files.\r\n\r\n[new.txt](https://github.com/scikit-hep/uproot4/files/8632207/new.txt)\r\n[old.txt](https://github.com/scikit-hep/uproot4/files/8632208/old.txt)\r\n\r\n",
  "closed_at":"2022-05-11T20:10:44Z",
  "comments":8,
  "created_at":"2022-05-05T14:47:27Z",
  "id":1226775699,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5JHxyT",
  "number":589,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Uproot cannot read RVec",
  "updated_at":"2022-05-11T21:51:33Z",
  "user":"MDQ6VXNlcjczNDQzOTY4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.32.0 \u2192 v2.32.1](https://github.com/asottile/pyupgrade/compare/v2.32.0...v2.32.1)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-05-09T22:04:23Z",
  "comments":0,
  "created_at":"2022-05-09T19:52:49Z",
  "draft":false,
  "id":1230177361,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss43hs3S",
  "number":592,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-05-09T22:04:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-05-09T22:04:24Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It's just like the one for `std::vector`, but I didn't see any differences in how the two are encoded. If there are such differences, we should modify the new `RVec` code.",
  "closed_at":"2022-05-11T20:10:44Z",
  "comments":0,
  "created_at":"2022-05-11T19:53:37Z",
  "draft":false,
  "id":1233114869,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss43rQpH",
  "number":593,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-05-11T20:10:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add explicit interpreter for ROOT::VecOps::RVec.",
  "updated_at":"2022-05-11T20:10:46Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-05-11T20:58:34Z",
  "comments":0,
  "created_at":"2022-05-11T20:43:12Z",
  "draft":false,
  "id":1233166033,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss43rbN2",
  "number":594,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-05-11T20:58:34Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Recover from the HTTP error in #507 (with fallback).",
  "updated_at":"2022-05-11T20:58:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"(about 20 ms) by limiting damerau_levenshtein to 1000 strings.\r\n\r\nI seem to remember this being an issue for you, @kratsg, because something was using `try`-`except KeyInFileError` to determine whether a key exists in files with _lots_ of keys. The damerau_levenshtein algorithm is for helping users find a mistyped key, but we don't want it hurting automated processes.",
  "closed_at":"2022-05-11T21:44:33Z",
  "comments":0,
  "created_at":"2022-05-11T21:34:42Z",
  "draft":false,
  "id":1233207418,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss43rkK9",
  "number":595,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-05-11T21:44:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Put an upper limit on the time KeyInFileError takes to print itself",
  "updated_at":"2022-05-11T21:44:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Add ```to_dataframe``` to ```TTree``` for converting TTree to a ```pandas.DataFrame```.",
  "closed_at":"2022-05-17T14:26:42Z",
  "comments":4,
  "created_at":"2022-05-17T00:51:16Z",
  "draft":false,
  "id":1237909785,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4362Nw",
  "number":598,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add `to_dataframe` to `TTree`",
  "updated_at":"2022-05-17T14:26:43Z",
  "user":"MDQ6VXNlcjU3OTY2ODc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Just opening an issue to discuss feature 3 of the `uproot.dask()` as mentioned in #578 \r\n\r\n> Sometimes, just opening files is an expensive operation that we want to avoid on the Dask client (e.g. there are too many files). We want to delay the tasks of opening the files and getting TTree objects out of them, so that this is only done on distributed workers, not locally on the user's client. This would have some drawbacks: you can only know the names and dtypes of the TBranches if you've read at least one TTree metadata (and assume they all have the same names and dtypes), and you can only know the lengths and chunk sizes of the arrays if you've read all TTree metadatas. It would be pretty hard to do much without knowing the TBranch names and dtypes, but [Dask allows arrays with unknown chunk sizes](https://docs.dask.org/en/stable/array-chunks.html#unknown-chunks). How would you add a open_files=False option that (a) reads TTree metadata only from the first file, (b) assumes all files have the same names and dtypes, and (c) creates Dask arrays with unknown chunks that open files upon compute? Unlike (2), this goes beyond what uproot.lazy could do.\r\n\r\nI did give it a thought about how I could implement this. It looks like I'll have to wrap `uproot.open()` with a `dask.delayed()` decorator and then use `DelayedTTree[key].array()` as a delayed function call with `start` and  `stop` as parameters. This delayed array will then be fed to `dask.array.from_delayed` as already implemented.\r\n\r\nAs already discussed, unknown chunk sizes can be used here, but unknown chunk sizes seem to be an implicit paradigm in dask, with no clear way of passing info to `dask.array.from_delayed()` that we want to use unknown chunk sizes. Passing `(np.nan,)` or something like that might work. But I will have to test this.\r\n\r\nLuckily, `dask.array.concatenate()` does have a `allow_unknown_chunksizes: bool` parameter that will be super useful in concatenating individual dask arrays. That means I will only have to figure out how to indicate unknown chunk sizes to `dask.array.from_delayed()`, and everything after that is straightforward.",
  "closed_at":"2022-06-13T14:30:51Z",
  "comments":2,
  "created_at":"2022-06-02T17:13:07Z",
  "id":1258467646,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5LArE-",
  "number":602,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Delaying the opening of files in uproot.dask",
  "updated_at":"2022-06-13T14:30:51Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Solves #602 \r\nAlmost done with implementation, but tests are WIP.\r\n\r\nI'm not sure why pre-commit is failing (flake8) on a completely unrelated and unaltered file.",
  "closed_at":"2022-06-13T14:30:55Z",
  "comments":2,
  "created_at":"2022-06-03T18:05:56Z",
  "draft":false,
  "id":1260201939,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss45FYL-",
  "number":603,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-13T14:30:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Basic code for delay in opening files",
  "updated_at":"2022-06-13T14:31:33Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"If there is interest, it would be nice to add a [`CITATION.cff`](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files) especially as there is already a [Zenodo archive for `uproot`](https://doi.org/10.5281/zenodo.4340632). I would be happy to make the PR.\r\n",
  "closed_at":"2022-10-31T20:52:12Z",
  "comments":7,
  "created_at":"2022-06-06T22:41:40Z",
  "id":1262510696,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5LQGJo",
  "number":604,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add citation metadata wtih CITATION.cff",
  "updated_at":"2022-10-31T20:52:12Z",
  "user":"MDQ6VXNlcjUxNDIzOTQ="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"The documentation of `WritableTree.extend(data)` has a warning saying \"be sure that each call to [extend](https://uproot.readthedocs.io/en/latest/uproot.writing.writable.WritableTree.html#uproot-writing-writable-writabletree-extend) includes at least 100 kB per branch/array.\"\r\nI'm calling `extend` once per iteration inside a loop in my code. Unfortunately in quite some cases I can get very little data per iteration and it gets below the 100 kB limit. As a solution what I have to do now seems is to be that I have to create another array for each branch I'm filling that accumulate results of individual loops. Then somewhere in each iteration I have to check whether I have reached an acceptable size in the accumulated arrays and only if that is the case I call `extend`. This seems to be very complicated.\r\n\r\nInstead it would be very convenient if `extend` already had exactly this functionality inside and would keep around accumulated arrays internally, only doing the actual work once these are large enough. This would remove a lot of the work asked from the user and it would also remove the necessity of the warning inside the documentation.",
  "closed_at":null,
  "comments":2,
  "created_at":"2022-06-07T13:33:42Z",
  "id":1263313191,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5LTKEn",
  "number":605,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Want \"accumulator\" interface (context manager) to `extend` at `step_size` intervals, regardless of the group size in which data are provided",
  "updated_at":"2024-01-30T15:39:21Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hi,\r\n\r\nI'm trying to merge some large ntuples (between 400 MB to 4 GB, approximately) with a small friend ntuple.\r\n\r\nSince the friend tree is aligned with the main tree, there's no manual alignment required. I used `library='numpy'` to read branches chunk by chunk and extend the output tree:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n\r\nimport uproot\r\n\r\n\r\ndef getTreeSpec(tree):\r\n    raw = tree.typenames()\r\n    return {k: v.replace(\"_t\", \"\") for k, v in raw.items()}\r\n\r\n\r\nstepSize = 2500\r\n#  stepSize = 10000\r\naddBrName = 'probe_UBDT'\r\n\r\nmainInput = 'raw.root'\r\nfriendInput = 'friend.root'\r\noutputRootFile = uproot.recreate('merged.root')\r\n\r\nmainRootFile = uproot.open(mainInput)\r\ntrees = [t.replace(\";1\", \"\") for t in mainRootFile if \"DecayTree\" in t]\r\n\r\nfor t in trees:\r\n    mainSpec = getTreeSpec(mainRootFile[t])\r\n    mainSpec[addBrName] = 'float'\r\n    outputRootFile.mktree(t, mainSpec)\r\n\r\n    mainDF = uproot.iterate(\r\n        f\"{mainInput}:{t}\", step_size=stepSize, library=\"np\"\r\n    )\r\n    friendDF = uproot.iterate(\r\n        f\"{friendInput}:{t}\",\r\n        [addBrName],\r\n        step_size=stepSize,\r\n        library=\"np\",\r\n    )\r\n\r\n    for m, f in zip(mainDF, friendDF):\r\n        m[addBrName] = f[addBrName]\r\n        outputRootFile[t].extend(m)\r\n```\r\n\r\nBut I'd get the following error after a few chunks have been extended:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./test.py\", line 38, in <module>\r\n    outputRootFile[t].extend(m)\r\n  File \"/home/syp/misc/researches/lhcb-data_analysis/MuonBDTPid/.virtualenv/lib/python3.8/site-packages/uproot/writing/writable.py\", line 957, in __getitem__\r\n    return self._get_del_search(where, True)\r\n  File \"/home/syp/misc/researches/lhcb-data_analysis/MuonBDTPid/.virtualenv/lib/python3.8/site-packages/uproot/writing/writable.py\", line 916, in _get_del_search\r\n    step = step[item]\r\n  File \"/home/syp/misc/researches/lhcb-data_analysis/MuonBDTPid/.virtualenv/lib/python3.8/site-packages/uproot/writing/writable.py\", line 957, in __getitem__\r\n    return self._get_del_search(where, True)\r\n  File \"/home/syp/misc/researches/lhcb-data_analysis/MuonBDTPid/.virtualenv/lib/python3.8/site-packages/uproot/writing/writable.py\", line 950, in _get_del_search\r\n    return self._get(item, cycle)\r\n  File \"/home/syp/misc/researches/lhcb-data_analysis/MuonBDTPid/.virtualenv/lib/python3.8/site-packages/uproot/writing/writable.py\", line 987, in _get\r\n    raise TypeError(\r\nTypeError: WritableDirectory cannot view preexisting TTrees; open the file with uproot.open instead of uproot.recreate or uproot.update\r\n```\r\n\r\nAnd the output file `merged.root` would contain 25000 (`10*stepSize`) entries. \r\n\r\nIf I bump `stepSize = 10000`, then for the sample file (~440 MB), the merge would be successful. But for larger files, I got the same error, and at that point the merged file contains 100000 (`10*stepSize`) entries.\r\n\r\n### Sample files\r\n\r\nThe sample files can be (hopefully) accessed at [here](https://cernbox.cern.ch/index.php/s/d3NUexFAmvkjqtB)\r\n\r\n### System info\r\n\r\n- gcc: 10.3.0\r\n- Python: 3.8.9\r\n- `uproot`: 4.2.3\r\n- `numpy`: 1.20.3",
  "closed_at":"2022-08-12T00:31:40Z",
  "comments":2,
  "created_at":"2022-06-09T01:03:53Z",
  "id":1265466958,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5LbX5O",
  "number":606,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"\"WritableDirectory cannot view preexisting TTrees\" when extending a uproot-created TTree",
  "updated_at":"2022-08-12T00:31:40Z",
  "user":"MDQ6VXNlcjMzNzM4MTc2"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"```pycon\r\n>>> import uproot\r\n>>> uproot.__version__\r\n'4.2.2'\r\n```\r\n\r\nI'm trying to read objects with custom ROOT streamer collected in a TTree in [this file here](https://github.com/legend-exp/legend-testdata/blob/main/data/mgdo/gerda-run0050-20150826T170402Z-cal-ged-tier1.root). This is what I tried so far:\r\n```pycon\r\n>>> import uproot\r\n>>> events = uproot.open(\"gerda-run0050-20150826T170402Z-cal-ged-tier1.root:MGTree\")\r\n>>> events.show()\r\nname                 | typename                 | interpretation                \r\n---------------------+--------------------------+-------------------------------\r\nevent                | MGTEvent                 | AsObjects(AsDynamic(model=M...\r\n>>> events[\"event\"].interpretation\r\nAsObjects(AsDynamic(model=Model_MGTEvent))\r\n>>> events[\"event\"].arrays()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1059, in arrays\r\n    return self.parent.arrays(\r\n  File \"/usr/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1125, in arrays\r\n    _ranges_or_baskets_to_arrays(\r\n  File \"/usr/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3502, in _ranges_or_baskets_to_arrays\r\n    uproot.source.futures.delayed_raise(*obj)\r\n  File \"/usr/lib/python3.10/site-packages/uproot/source/futures.py\", line 36, in delayed_raise\r\n    raise exception_value.with_traceback(traceback)\r\n  File \"/usr/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3446, in basket_to_array\r\n    basket_arrays[basket.basket_num] = interpretation.basket_array(\r\n  File \"/usr/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 140, in basket_array\r\n    form = self.awkward_form(branch.file, index_format=\"i64\")\r\n  File \"/usr/lib/python3.10/site-packages/uproot/interpretation/objects.py\", line 120, in awkward_form\r\n    return self._model.awkward_form(\r\n  File \"/usr/lib/python3.10/site-packages/uproot/containers.py\", line 304, in awkward_form\r\n    parameters={\"uproot\": {\"as\": \"array\", \"header\": self._header}},\r\nAttributeError: 'AsDynamic' object has no attribute '_header'. Did you mean: 'header'?\r\n```\r\nIs this something expected or is it a bug? Where do I need to start to be able to decode this? Here's some (hopefully useful) information:\r\n```pycon\r\n>>> import ROOT\r\n>>> f = ROOT.TFile(\"gerda-run0050-20150826T170402Z-cal-ged-tier1.root\")\r\n>>> f.GetVersion()\r\n60410\r\n>>> f.ShowStreamerInfo()\r\nOBJ: TList\tTList\tDoubly linked list : 0\r\n\r\nStreamerInfo for class: TNamed, version=1, checksum=0xdfb74a3c\r\n  TObject        BASE            offset=  0 type=66 Basic ROOT object   \r\n  TString        fName           offset=  0 type=65 object identifier   \r\n  TString        fTitle          offset=  0 type=65 object title        \r\n\r\nStreamerInfo for class: TObject, version=1, checksum=0x901bc02d\r\n  unsigned int   fUniqueID       offset=  0 type=13 object unique identifier\r\n  unsigned int   fBits           offset=  0 type=15 bit field status word\r\n\r\nStreamerInfo for class: TList, version=5, checksum=0x69c5c3bb\r\n  TSeqCollection BASE            offset=  0 type= 0 Sequenceable collection ABC\r\n\r\nStreamerInfo for class: TSeqCollection, version=0, checksum=0xfc6c3bc6\r\n  TCollection    BASE            offset=  0 type= 0 Collection abstract base class\r\n\r\nStreamerInfo for class: TCollection, version=3, checksum=0x57e3cb9c\r\n  TObject        BASE            offset=  0 type=66 Basic ROOT object   \r\n  TString        fName           offset=  0 type=65 name of the collection\r\n  int            fSize           offset=  0 type= 3 number of elements in collection\r\n\r\nStreamerInfo for class: MGTEvent, version=9, checksum=0xed4b3be7\r\n  MGTDataObject  BASE            offset=  0 type= 0 MJ Data Object base class\r\n  MGVMemoryCheckable BASE            offset=  0 type= 0                     \r\n  MGEventType::EventType fEventType      offset=  0 type= 3 flag to identify e.g. events from pulser\r\n  double         fETotal         offset=  0 type= 8 sum of energies of Ge detector hit in this event\r\n  double         fTime           offset=  0 type= 8 time of the first Ge detector hit (since run start)\r\n  TClonesArray*  fWaveforms      offset=  0 type=64 TClonesArray of waveforms\r\n  TClonesArray*  fDigitizerData  offset=  0 type=64 TClonesArray of digitizer data\r\n  vector<bool>*  fActiveID       offset=  0 type=71 ,stl=41, ctype=21, Map of active IDs in the event\r\n  bool           fUseAuxWaveformArray offset=  0 type=18 flag to use or ignore auxiliary waveform array\r\n  TClonesArray*  fAuxWaveforms   offset=  0 type=64 Additional high frequency traces\r\n  int            fEventNumber    offset=  0 type= 3 Unique number pointing to event in file\r\n\r\nStreamerInfo for class: MGTDataObject, version=2, checksum=0xd3e7dd50\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n\r\nStreamerInfo for class: MGVMemoryCheckable, version=1, checksum=0x752eeea5\r\n\r\nStreamerInfo for class: TString, version=2, checksum=0x17419\r\n\r\nStreamerInfo for class: TClonesArray, version=4, checksum=0xb6c0ca63\r\n  TObjArray      BASE            offset=  0 type= 0 An array of objects \r\n\r\nStreamerInfo for class: TObjArray, version=3, checksum=0xa99e6552\r\n  TSeqCollection BASE            offset=  0 type= 0 Sequenceable collection ABC\r\n  int            fLowerBound     offset=  0 type= 3 Lower bound of the array\r\n  int            fLast           offset=  0 type= 3 Last element in array containing an object\r\n\r\nStreamerInfo for class: TParameter<int>, version=2, checksum=0xfe8557f8\r\n  TObject        BASE            offset=  0 type=66 Basic ROOT object   \r\n  TString        fName           offset=  0 type=65                     \r\n  int            fVal            offset=  0 type= 3                     \r\n\r\nStreamerInfo for class: MGTWaveform, version=5, checksum=0xf5508ea6\r\n  MGTDataObject  BASE            offset=  0 type= 0 MJ Data Object base class\r\n  MGWaveform     BASE            offset=  0 type= 0                     \r\n  MGVMemoryCheckable BASE            offset=  0 type= 0                     \r\n  TF1*           fWaveformFunction offset=  0 type=64                     \r\n  MGTWaveform::EWFEncScheme fWFEncScheme    offset=  0 type= 3                     \r\n\r\nStreamerInfo for class: MGWaveform, version=1, checksum=0x9b7a3848\r\n  double         fSampFreq       offset=  0 type= 8 sampling frequency  \r\n  double         fTOffset        offset=  0 type= 8 global time of sample 0\r\n  MGWaveform::EWFType fWFType         offset=  0 type= 3 waveform type       \r\n  vector<double> fData           offset=  0 type=300 ,stl=1, ctype=8, internal data array holding sample values\r\n  int            fID             offset=  0 type= 3 ID for storing, e.g., which detector / contact this wf comes from\r\n\r\nStreamerInfo for class: TF1, version=9, checksum=0x69241a7c\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n  TAttLine       BASE            offset=  0 type= 0 Line attributes     \r\n  TAttFill       BASE            offset=  0 type= 0 Fill area attributes\r\n  TAttMarker     BASE            offset=  0 type= 0 Marker attributes   \r\n  double         fXmin           offset=  0 type= 8 Lower bounds for the range\r\n  double         fXmax           offset=  0 type= 8 Upper bounds for the range\r\n  int            fNpar           offset=  0 type= 3 Number of parameters\r\n  int            fNdim           offset=  0 type= 3 Function dimension  \r\n  int            fNpx            offset=  0 type= 3 Number of points used for the graphical representation\r\n  int            fType           offset=  0 type= 3 (=0 for standard functions, 1 if pointer to function)\r\n  int            fNpfits         offset=  0 type= 3 Number of points used in the fit\r\n  int            fNDF            offset=  0 type= 3 Number of degrees of freedom in the fit\r\n  double         fChisquare      offset=  0 type= 8 Function fit chisquare\r\n  double         fMinimum        offset=  0 type= 8 Minimum value for plotting\r\n  double         fMaximum        offset=  0 type= 8 Maximum value for plotting\r\n  vector<double> fParErrors      offset=  0 type=300 ,stl=1, ctype=8, Array of errors of the fNpar parameters\r\n  vector<double> fParMin         offset=  0 type=300 ,stl=1, ctype=8, Array of lower limits of the fNpar parameters\r\n  vector<double> fParMax         offset=  0 type=300 ,stl=1, ctype=8, Array of upper limits of the fNpar parameters\r\n  vector<double> fSave           offset=  0 type=300 ,stl=1, ctype=8, Array of fNsave function values\r\n  bool           fNormalized     offset=  0 type=18 Normalization option (false by default)\r\n  double         fNormIntegral   offset=  0 type= 8 Integral of the function before being normalized\r\n  TFormula*      fFormula        offset=  0 type=64 Pointer to TFormula in case when user define formula\r\n  TF1Parameters* fParams         offset=  0 type=69 Pointer to Function parameters object (exusts only for not-formula functions)\r\n\r\nStreamerInfo for class: TAttLine, version=2, checksum=0x94074549\r\n  short          fLineColor      offset=  0 type= 2 line color          \r\n  short          fLineStyle      offset=  0 type= 2 line style          \r\n  short          fLineWidth      offset=  0 type= 2 line width          \r\n\r\nStreamerInfo for class: TAttFill, version=2, checksum=0xffd92a92\r\n  short          fFillColor      offset=  0 type= 2 fill area color     \r\n  short          fFillStyle      offset=  0 type= 2 fill area style     \r\n\r\nStreamerInfo for class: TAttMarker, version=2, checksum=0x291d8bec\r\n  short          fMarkerColor    offset=  0 type= 2 Marker color index  \r\n  short          fMarkerStyle    offset=  0 type= 2 Marker style        \r\n  float          fMarkerSize     offset=  0 type= 5 Marker size         \r\n\r\nStreamerInfo for class: TFormula, version=10, checksum=0x9cab775b\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n  vector<double> fClingParameters offset=  0 type=300 ,stl=1, ctype=8, parameter values    \r\n  bool           fAllParametersSetted offset=  0 type=18 flag to control if all parameters are setted\r\n  map<TString,int,TFormulaParamOrder> fParams         offset=  0 type=300  (nodelete) ,stl=4, ctype=61, list of  parameter names\r\n  TString        fFormula        offset=  0 type=65                     \r\n  vector<TObject*> fLinearParts    offset=  0 type=300  (nodelete) ,stl=1, ctype=63, vector of linear functions\r\n\r\nStreamerInfo for class: TF1Parameters, version=1, checksum=0xd703028e\r\n  vector<double> fParameters     offset=  0 type=300 ,stl=1, ctype=8, parameter values    \r\n  vector<string> fParNames       offset=  0 type=300 ,stl=1, ctype=61, parameter names     \r\n\r\nStreamerInfo for class: GETGERDADigitizerData, version=1, checksum=0xa48d9d0a\r\n  GETVGERDADigitizerData BASE            offset=  0 type= 0                     \r\n\r\nStreamerInfo for class: GETVGERDADigitizerData, version=2, checksum=0xcfc9fbe8\r\n  MGTVDigitizerData BASE            offset=  0 type= 0 DigitizerData class \r\n  double         fClockFrequency offset=  0 type= 8                     \r\n  int            fEventNumber    offset=  0 type= 3                     \r\n  unsigned long  fPretrigger     offset=  0 type=14                     \r\n  unsigned long  fTriggerNumber  offset=  0 type=14                     \r\n  unsigned int   fDecimalTimeStamp offset=  0 type=13                     \r\n  bool           fIsMuVetoed     offset=  0 type=18                     \r\n  unsigned int   fMuVetoSample   offset=  0 type=13                     \r\n  bool           fIsInverted     offset=  0 type=18                     \r\n  MGWaveformTag::EWaveformTag fWaveformTag    offset=  0 type= 3                     \r\n\r\nStreamerInfo for class: MGTVDigitizerData, version=1, checksum=0x1c64498c\r\n  MGTDataObject  BASE            offset=  0 type= 0 MJ Data Object base class\r\n  MGVDigitizerData BASE            offset=  0 type= 0                     \r\n\r\nStreamerInfo for class: MGVDigitizerData, version=1, checksum=0x640c47e7\r\n  double         fEnergy         offset=  0 type= 8                     \r\n  unsigned long  fTimeStamp      offset=  0 type=14                     \r\n  unsigned int   fID             offset=  0 type=13                     \r\n  unsigned long  fIndex          offset=  0 type=14                     \r\n\r\nStreamerInfo for class: TTree, version=19, checksum=0x58a396eb\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n  TAttLine       BASE            offset=  0 type= 0 Line attributes     \r\n  TAttFill       BASE            offset=  0 type= 0 Fill area attributes\r\n  TAttMarker     BASE            offset=  0 type= 0 Marker attributes   \r\n  Long64_t       fEntries        offset=  0 type=16 Number of entries   \r\n  Long64_t       fTotBytes       offset=  0 type=16 Total number of bytes in all branches before compression\r\n  Long64_t       fZipBytes       offset=  0 type=16 Total number of bytes in all branches after compression\r\n  Long64_t       fSavedBytes     offset=  0 type=16 Number of autosaved bytes\r\n  Long64_t       fFlushedBytes   offset=  0 type=16 Number of autoflushed bytes\r\n  double         fWeight         offset=  0 type= 8 Tree weight (see TTree::SetWeight)\r\n  int            fTimerInterval  offset=  0 type= 3 Timer interval in milliseconds\r\n  int            fScanField      offset=  0 type= 3 Number of runs before prompting in Scan\r\n  int            fUpdate         offset=  0 type= 3 Update frequency for EntryLoop\r\n  int            fDefaultEntryOffsetLen offset=  0 type= 3 Initial Length of fEntryOffset table in the basket buffers\r\n  int            fNClusterRange  offset=  0 type= 6 Number of Cluster range in addition to the one defined by 'AutoFlush'\r\n  Long64_t       fMaxEntries     offset=  0 type=16 Maximum number of entries in case of circular buffers\r\n  Long64_t       fMaxEntryLoop   offset=  0 type=16 Maximum number of entries to process\r\n  Long64_t       fMaxVirtualSize offset=  0 type=16 Maximum total size of buffers kept in memory\r\n  Long64_t       fAutoSave       offset=  0 type=16 Autosave tree when fAutoSave entries written or -fAutoSave (compressed) bytes produced\r\n  Long64_t       fAutoFlush      offset=  0 type=16 Autoflush tree when fAutoFlush entries written or -fAutoFlush (compressed) bytes produced\r\n  Long64_t       fEstimate       offset=  0 type=16 Number of entries to estimate histogram limits\r\n  Long64_t*      fClusterRangeEnd offset=  0 type=56 [fNClusterRange] Last entry of a cluster range.\r\n  Long64_t*      fClusterSize    offset=  0 type=56 [fNClusterRange] Number of entries in each cluster for a given range.\r\n  TObjArray      fBranches       offset=  0 type=61 List of Branches    \r\n  TObjArray      fLeaves         offset=  0 type=61 Direct pointers to individual branch leaves\r\n  TList*         fAliases        offset=  0 type=64 List of aliases for expressions based on the tree branches.\r\n  TArrayD        fIndexValues    offset=  0 type=62 Sorted index values \r\n  TArrayI        fIndex          offset=  0 type=62 Index of sorted values\r\n  TVirtualIndex* fTreeIndex      offset=  0 type=64 Pointer to the tree Index (if any)\r\n  TList*         fFriends        offset=  0 type=64 pointer to list of friend elements\r\n  TList*         fUserInfo       offset=  0 type=64 pointer to a list of user objects associated to this Tree\r\n  TBranchRef*    fBranchRef      offset=  0 type=64 Branch supporting the TRefTable (if any)\r\n\r\nStreamerInfo for class: TBranchObject, version=1, checksum=0x7706da6d\r\n  TBranch        BASE            offset=  0 type= 0 Branch descriptor   \r\n  TString        fClassName      offset=  0 type=65 Class name of referenced object\r\n\r\nStreamerInfo for class: TBranch, version=12, checksum=0x59108cb8\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n  TAttFill       BASE            offset=  0 type= 0 Fill area attributes\r\n  int            fCompress       offset=  0 type= 3 Compression level and algorithm\r\n  int            fBasketSize     offset=  0 type= 3 Initial Size of  Basket Buffer\r\n  int            fEntryOffsetLen offset=  0 type= 3 Initial Length of fEntryOffset table in the basket buffers\r\n  int            fWriteBasket    offset=  0 type= 3 Last basket number written\r\n  Long64_t       fEntryNumber    offset=  0 type=16 Current entry number (last one filled in this branch)\r\n  int            fOffset         offset=  0 type= 3 Offset of this branch\r\n  int            fMaxBaskets     offset=  0 type= 6 Maximum number of Baskets so far\r\n  int            fSplitLevel     offset=  0 type= 3 Branch split level  \r\n  Long64_t       fEntries        offset=  0 type=16 Number of entries   \r\n  Long64_t       fFirstEntry     offset=  0 type=16 Number of the first entry in this branch\r\n  Long64_t       fTotBytes       offset=  0 type=16 Total number of bytes in all leaves before compression\r\n  Long64_t       fZipBytes       offset=  0 type=16 Total number of bytes in all leaves after compression\r\n  TObjArray      fBranches       offset=  0 type=61 -> List of Branches of this branch\r\n  TObjArray      fLeaves         offset=  0 type=61 -> List of leaves of this branch\r\n  TObjArray      fBaskets        offset=  0 type=61 -> List of baskets of this branch\r\n  int*           fBasketBytes    offset=  0 type=43 [fMaxBaskets] Length of baskets on file\r\n  Long64_t*      fBasketEntry    offset=  0 type=56 [fMaxBaskets] Table of first entry in each basket\r\n  Long64_t*      fBasketSeek     offset=  0 type=56 [fMaxBaskets] Addresses of baskets on file\r\n  TString        fFileName       offset=  0 type=65 Name of file where buffers are stored (\"\" if in same file as Tree header)\r\n\r\nStreamerInfo for class: TLeafObject, version=4, checksum=0x26ba7c4c\r\n  TLeaf          BASE            offset=  0 type= 0 Leaf: description of a Branch data type\r\n  bool           fVirtual        offset=  0 type=18 Support for polymorphism, when set classname is written with object.\r\n\r\nStreamerInfo for class: TLeaf, version=2, checksum=0x6d1e8152\r\n  TNamed         BASE            offset=  0 type=67 The basis for a named object (name, title)\r\n  int            fLen            offset=  0 type= 3 Number of fixed length elements\r\n  int            fLenType        offset=  0 type= 3 Number of bytes for this data type\r\n  int            fOffset         offset=  0 type= 3 Offset in ClonesArray object (if one)\r\n  bool           fIsRange        offset=  0 type=18 (=kTRUE if leaf has a range, kFALSE otherwise)\r\n  bool           fIsUnsigned     offset=  0 type=18 (=kTRUE if unsigned, kFALSE otherwise)\r\n  TLeaf*         fLeafCount      offset=  0 type=64 Pointer to Leaf count if variable length (we do not own the counter)\r\n\r\nStreamerInfo for class: TBranchRef, version=1, checksum=0x8a9bd841\r\n  TBranch        BASE            offset=  0 type= 0 Branch descriptor   \r\n  TRefTable*     fRefTable       offset=  0 type=64 pointer to the TRefTable\r\n\r\nStreamerInfo for class: TRefTable, version=3, checksum=0x8c895b85\r\n  TObject        BASE            offset=  0 type=66 Basic ROOT object   \r\n  int            fSize           offset=  0 type= 3 dummy for backward compatibility\r\n  TObjArray*     fParents        offset=  0 type=64 array of Parent objects  (eg TTree branch) holding the referenced objects\r\n  TObject*       fOwner          offset=  0 type=64 Object owning this TRefTable\r\n  vector<string> fProcessGUIDs   offset=  0 type=300 ,stl=1, ctype=61, UUIDs of TProcessIDs used in fParentIDs\r\n OBJ: TList\tlistOfRules\tDoubly linked list : 0\r\n  OBJ: TObjString\ttype=read sourceClass=\"TTree\" targetClass=\"TTree\" version=\"[-16]\" source=\"\" target=\"fDefaultEntryOffsetLen\" code=\"{ fDefaultEntryOffsetLen = 1000; }\" \tCollectable string class : 0 at: 0x3e81670\r\n  OBJ: TObjString\ttype=read sourceClass=\"TTree\" targetClass=\"TTree\" version=\"[-18]\" source=\"\" target=\"fNClusterRange\" code=\"{ fNClusterRange = 0; }\" \tCollectable string class : 0 at: 0x3e98cc0\r\n  ```\r\n",
  "closed_at":"2022-08-11T22:09:14Z",
  "comments":5,
  "created_at":"2022-06-10T21:43:51Z",
  "id":1268048527,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5LlOKP",
  "number":607,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"`AttributeError` when calling `arrays()` on a branch holding objects with custom streamer",
  "updated_at":"2022-08-26T19:55:45Z",
  "user":"MDQ6VXNlcjIwMzU4MTky"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.32.1 \u2192 v2.34.0](https://github.com/asottile/pyupgrade/compare/v2.32.1...v2.34.0)\n- [github.com/pre-commit/pre-commit-hooks: v4.2.0 \u2192 v4.3.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.2.0...v4.3.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-06-13T21:24:46Z",
  "comments":0,
  "created_at":"2022-06-13T20:55:24Z",
  "draft":false,
  "id":1269945178,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss45lsGX",
  "number":608,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-13T21:24:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-06-13T21:24:47Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Usage commands:\r\n\r\n```python\r\nimport uproot\r\nimport skhep_testdata\r\nfrom pprint import pprint as pp\r\n\r\nfile1 = skhep_testdata.data_path(\"uproot-Zmumu.root\") + \":events\"\r\nfile2 = skhep_testdata.data_path(\"uproot-HZZ.root\") + \":events\"\r\n```\r\n\r\nOutputs:\r\n```python\r\n>>> pp(uproot.num_entries(file1))\r\n[(2304,)]\r\n>>> pp(uproot.num_entries([file1,file2]))\r\n[(2304,), (2421,)]\r\n```\r\n\r\nTests, docstring and cleanup: WIP",
  "closed_at":"2022-06-20T13:46:36Z",
  "comments":10,
  "created_at":"2022-06-14T16:29:25Z",
  "draft":false,
  "id":1271058715,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss45pZrw",
  "number":609,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-20T13:46:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add the uproot4.num_entries function",
  "updated_at":"2022-06-20T13:48:08Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-07-19T18:50:59Z",
  "comments":3,
  "created_at":"2022-06-14T19:26:45Z",
  "draft":false,
  "id":1271263943,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss45qCv7",
  "number":610,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Adding a AwkwardForth based ROOT reader to uproot4",
  "updated_at":"2022-07-19T18:51:04Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Instead of `index_format, header, tobject_header, breadcrumbs`.\r\n\r\nThis change makes it possible to add as many arguments to `awkward_form` as we need.",
  "closed_at":"2022-06-17T18:59:36Z",
  "comments":0,
  "created_at":"2022-06-17T18:14:49Z",
  "draft":false,
  "id":1275334257,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss453pA6",
  "number":611,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-17T18:59:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"awkward_form arguments are now (self, file, context).",
  "updated_at":"2022-06-17T18:59:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This PR just removes 2 tests.\r\n\r\nThe tests used to be:\r\n\r\n   1. put a TObjString in the ROOT file along with a TObjString streamer\r\n   2. update the file in ROOT (adding a histogram)\r\n   3. see that ROOT has added the histogram streamers in addition to the TObjString\r\n\r\nNow ROOT adds the histogram streamers, but removes the TObjString streamer. This is probably not considered an error because TObjString is a fundamental, built-in type. But still, we can't do our test now.",
  "closed_at":"2022-06-17T18:58:18Z",
  "comments":0,
  "created_at":"2022-06-17T18:49:00Z",
  "draft":false,
  "id":1275359417,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss453uZ-",
  "number":612,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-17T18:58:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Adjust for ROOT TStreamerInfo change.",
  "updated_at":"2022-06-17T18:58:18Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"pr #611 consolidated most arguments to `awkward_form()` into a single dictionary `context`. From the wording of the documentation:\r\n\r\n```python\r\ncontext (dict): Context for the Form-generation; defaults are\r\n                ``{\"index_format\": \"i64\", \"header\": False, \"tobject_header\": True, \"breadcrumbs\": ()}``.\r\n                See below for context argument descriptions.\r\n```\r\n\r\nthis seems to imply that context is optional, and that no other argument is required. If this is not the case, are callers of the function expected to provide `{}`, `None`, or as above `{\"index_format\": ...}` ?\r\n\r\nFrom the current callers perspective that use the defaults, it would be easiest if context is optional, as no changes downstream would be needed.\r\n\r\n(This issue became apparent with release 4.2.4.)",
  "closed_at":"2022-06-21T22:42:07Z",
  "comments":5,
  "created_at":"2022-06-21T17:45:51Z",
  "id":1278795452,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5MON68",
  "number":614,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"awkward_form() context arg is not optional",
  "updated_at":"2022-06-22T17:27:31Z",
  "user":"MDQ6VXNlcjMwODE4MjY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-06-21T21:53:17Z",
  "comments":0,
  "created_at":"2022-06-21T19:13:10Z",
  "draft":false,
  "id":1278929633,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46DhcK",
  "number":615,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-21T21:53:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Updating docs and test in response to the removal of uproot.lazy in Uproot5",
  "updated_at":"2022-06-21T21:58:33Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-06-21T22:45:04Z",
  "comments":0,
  "created_at":"2022-06-21T19:58:48Z",
  "draft":false,
  "id":1278988833,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46Duta",
  "number":616,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-21T22:45:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Completed the Forth based AsStrings reader.",
  "updated_at":"2022-06-21T22:45:04Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-06-21T21:56:18Z",
  "comments":0,
  "created_at":"2022-06-21T21:12:13Z",
  "draft":false,
  "id":1279098514,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46EHtT",
  "number":617,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-21T21:56:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"changed arguments for awkward_form",
  "updated_at":"2022-06-21T22:02:05Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"#617 went into `main`; this PR goes into `main-v4`.",
  "closed_at":"2022-06-21T22:02:04Z",
  "comments":0,
  "created_at":"2022-06-21T22:00:21Z",
  "draft":false,
  "id":1279157874,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46EVNb",
  "number":618,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-21T22:02:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"changed arguments for awkward_form (\u2192 main-v4)",
  "updated_at":"2022-06-22T12:10:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-07-08T22:47:03Z",
  "comments":11,
  "created_at":"2022-06-22T06:15:27Z",
  "draft":false,
  "id":1279605659,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46F5cE",
  "number":620,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-08T22:47:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Awkward v2 update",
  "updated_at":"2022-07-09T03:25:28Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-06-22T12:18:11Z",
  "comments":1,
  "created_at":"2022-06-22T12:16:05Z",
  "draft":false,
  "id":1280053081,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46Hav0",
  "number":621,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually pass user-specified 'awkward_form' arguments into context.",
  "updated_at":"2022-06-22T12:18:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-06-22T12:27:32Z",
  "comments":0,
  "created_at":"2022-06-22T12:19:13Z",
  "draft":false,
  "id":1280056575,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46HbgT",
  "number":622,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-22T12:27:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually pass user-specified 'awkward_form' arguments into context.",
  "updated_at":"2022-06-22T12:27:33Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-06-22T12:27:52Z",
  "comments":1,
  "created_at":"2022-06-22T12:27:01Z",
  "draft":false,
  "id":1280065736,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46Hdgn",
  "number":623,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually pass user-specified 'awkward_form' arguments into context.",
  "updated_at":"2022-06-22T12:28:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-06-22T14:30:54Z",
  "comments":1,
  "created_at":"2022-06-22T12:29:11Z",
  "draft":false,
  "id":1280068258,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46HeDi",
  "number":624,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-22T14:30:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually pass user-specified 'awkward_form' arguments into context.",
  "updated_at":"2022-06-22T14:30:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This went into `main-v4`; it should also go into `main`.",
  "closed_at":"2022-06-22T14:34:56Z",
  "comments":1,
  "created_at":"2022-06-22T14:26:38Z",
  "draft":false,
  "id":1280240835,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46ID0I",
  "number":625,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-22T14:34:56Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix annoying gaps in test files.",
  "updated_at":"2022-06-22T14:34:56Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"AsJagged was missing.\r\n\r\nAlso, I made sure that the docstrings reflect the arguments as they are.\r\n\r\nAnd we never create a dict and pass it in anymore; we let the default arguments do their work.\r\n\r\nThis will have to be cherry-picked and put onto `main` as well.",
  "closed_at":"2022-06-22T16:36:24Z",
  "comments":0,
  "created_at":"2022-06-22T16:26:36Z",
  "draft":false,
  "id":1280485161,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46I5K6",
  "number":627,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-22T16:36:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Cleanly ensure all Interpretation.awkward_form signatures have been reverted.",
  "updated_at":"2022-06-22T16:36:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-06-24T16:17:25Z",
  "comments":0,
  "created_at":"2022-06-23T17:20:52Z",
  "draft":false,
  "id":1282719918,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46Qo5u",
  "number":629,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-24T16:17:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Cleaning up string generation in streamers.py",
  "updated_at":"2022-06-24T16:17:26Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"cc. @jpivarski ",
  "closed_at":"2022-08-03T15:04:26Z",
  "comments":16,
  "created_at":"2022-06-28T15:06:36Z",
  "draft":false,
  "id":1287493812,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46gRli",
  "number":630,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-03T15:04:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Primitive Support for RNTuple",
  "updated_at":"2022-08-03T15:09:00Z",
  "user":"MDQ6VXNlcjUzMDYyMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Will help keep actions up to date.",
  "closed_at":"2022-06-29T12:13:43Z",
  "comments":1,
  "created_at":"2022-06-29T05:04:26Z",
  "draft":false,
  "id":1288176371,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46ie3Q",
  "number":631,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-29T12:13:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: add dependabot for actions",
  "updated_at":"2022-06-29T12:13:43Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [actions/checkout](https://github.com/actions/checkout) from 2 to 3.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v3.0.0</h2>\n<ul>\n<li>Updated to the node16 runtime by default\n<ul>\n<li>This requires a minimum <a href=\"https://github.com/actions/runner/releases/tag/v2.285.0\">Actions Runner</a> version of v2.285.0 to run, which is by default available in GHES 3.4 or later.</li>\n</ul>\n</li>\n</ul>\n<h2>v2.4.2</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Add set-safe-directory input to allow customers to take control. (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/770\">#770</a>) by <a href=\"https://github.com/TingluoHuang\"><code>@\u200bTingluoHuang</code></a> in <a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/776\">actions/checkout#776</a></li>\n<li>Prepare changelog for v2.4.2. by <a href=\"https://github.com/TingluoHuang\"><code>@\u200bTingluoHuang</code></a> in <a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/778\">actions/checkout#778</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v2...v2.4.2\">https://github.com/actions/checkout/compare/v2...v2.4.2</a></p>\n<h2>v2.4.1</h2>\n<ul>\n<li>Fixed an issue where checkout failed to run in container jobs due to the new git setting <code>safe.directory</code></li>\n</ul>\n<h2>v2.4.0</h2>\n<ul>\n<li>Convert SSH URLs like <code>org-&lt;ORG_ID&gt;@github.com:</code> to <code>https://github.com/</code> - <a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/621\">pr</a></li>\n</ul>\n<h2>v2.3.5</h2>\n<p>Update dependencies</p>\n<h2>v2.3.4</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/379\">Add missing <code>await</code>s</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/360\">Swap to Environment Files</a></li>\n</ul>\n<h2>v2.3.3</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/345\">Remove Unneeded commit information from build logs</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/326\">Add Licensed to verify third party dependencies</a></li>\n</ul>\n<h2>v2.3.2</h2>\n<p><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/320\">Add Third Party License Information to Dist Files</a></p>\n<h2>v2.3.1</h2>\n<p><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/284\">Fix default branch resolution for .wiki and when using SSH</a></p>\n<h2>v2.3.0</h2>\n<p><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/278\">Fallback to the default branch</a></p>\n<h2>v2.2.0</h2>\n<p><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/258\">Fetch all history for all tags and branches when fetch-depth=0</a></p>\n<h2>v2.1.1</h2>\n<p>Changes to support GHES (<a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/236\">here</a> and <a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/248\">here</a>)</p>\n<h2>v2.1.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/191\">Group output</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/199\">Changes to support GHES alpha release</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/184\">Persist core.sshCommand for submodules</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/163\">Add support ssh</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/179\">Convert submodule SSH URL to HTTPS, when not using SSH</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v3.0.2</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/770\">Add input <code>set-safe-directory</code></a></li>\n</ul>\n<h2>v3.0.1</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/762\">Fixed an issue where checkout failed to run in container jobs due to the new git setting <code>safe.directory</code></a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/744\">Bumped various npm package versions</a></li>\n</ul>\n<h2>v3.0.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/689\">Update to node 16</a></li>\n</ul>\n<h2>v2.3.1</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/284\">Fix default branch resolution for .wiki and when using SSH</a></li>\n</ul>\n<h2>v2.3.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/278\">Fallback to the default branch</a></li>\n</ul>\n<h2>v2.2.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/258\">Fetch all history for all tags and branches when fetch-depth=0</a></li>\n</ul>\n<h2>v2.1.1</h2>\n<ul>\n<li>Changes to support GHES (<a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/236\">here</a> and <a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/248\">here</a>)</li>\n</ul>\n<h2>v2.1.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/191\">Group output</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/199\">Changes to support GHES alpha release</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/184\">Persist core.sshCommand for submodules</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/163\">Add support ssh</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/179\">Convert submodule SSH URL to HTTPS, when not using SSH</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/157\">Add submodule support</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/144\">Follow proxy settings</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/141\">Fix ref for pr closed event when a pr is merged</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/128\">Fix issue checking detached when git less than 2.22</a></li>\n</ul>\n<h2>v2.0.0</h2>\n<ul>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/108\">Do not pass cred on command line</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/107\">Add input persist-credentials</a></li>\n<li><a href=\"https://github-redirect.dependabot.com/actions/checkout/pull/104\">Fallback to REST API to download repo</a></li>\n</ul>\n<h2>v2 (beta)</h2>\n<ul>\n<li>Improved fetch performance</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/2541b1294d2704b0964813337f33b291d3f8596b\"><code>2541b12</code></a> Prepare changelog for v3.0.2. (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/777\">#777</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/0ffe6f9c5599e73776da5b7f113e994bc0a76ede\"><code>0ffe6f9</code></a> Add set-safe-directory input to allow customers to take control. (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/770\">#770</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/dcd71f646680f2efd8db4afa5ad64fdcba30e748\"><code>dcd71f6</code></a> Enforce safe directory (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/762\">#762</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/add3486cc3b55d4a5e11c8045058cef96538edc7\"><code>add3486</code></a> Patch to fix the dependbot alert. (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/744\">#744</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/5126516654c75f76bca1de45dd82a3006d8890f9\"><code>5126516</code></a> Bump minimist from 1.2.5 to 1.2.6 (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/741\">#741</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/d50f8ea76748df49594d9b109b614f3b4db63c71\"><code>d50f8ea</code></a> Add v3.0 release information to changelog (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/740\">#740</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/2d1c1198e79c30cca5c3957b1e3b65ce95b5356e\"><code>2d1c119</code></a> update test workflows to checkout v3 (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/709\">#709</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/a12a3943b4bdde767164f792f33f40b04645d846\"><code>a12a394</code></a> update readme for v3 (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/708\">#708</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8f9e05e482293f862823fcca12d9eddfb3723131\"><code>8f9e05e</code></a> Update to node 16 (<a href=\"https://github-redirect.dependabot.com/actions/checkout/issues/689\">#689</a>)</li>\n<li>See full diff in <a href=\"https://github.com/actions/checkout/compare/v2...v3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=2&new-version=3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-06-29T12:35:01Z",
  "comments":1,
  "created_at":"2022-06-29T12:14:10Z",
  "draft":false,
  "id":1288633616,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46kAlI",
  "number":632,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-29T12:35:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bump actions/checkout from 2 to 3",
  "updated_at":"2022-06-29T12:35:02Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [actions/upload-artifact](https://github.com/actions/upload-artifact) from 2 to 3.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/upload-artifact/releases\">actions/upload-artifact's releases</a>.</em></p>\n<blockquote>\n<h2>v3.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update default runtime to node16 (<a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/293\">#293</a>)</li>\n<li>Update package-lock.json file version to 2 (<a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/302\">#302</a>)</li>\n</ul>\n<h3>Breaking Changes</h3>\n<p>With the update to Node 16, all scripts will now be run with Node 16 rather than Node 12.</p>\n<h2>v2.3.1</h2>\n<p>Fix for empty fails on Windows failing on upload <a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/281\">#281</a></p>\n<h2>v2.3.0 Upload Artifact</h2>\n<ul>\n<li>Optimizations for faster uploads of larger files that are already compressed</li>\n<li>Significantly improved logging when there are chunked uploads</li>\n<li>Clarifications in logs around the upload size and prohibited characters that aren't allowed in the artifact name or any uploaded files</li>\n<li>Various other small bugfixes &amp; optimizations</li>\n</ul>\n<h2>v2.2.4</h2>\n<ul>\n<li>Retry on HTTP 500 responses from the service</li>\n</ul>\n<h2>v2.2.3</h2>\n<ul>\n<li>Fixes for proxy related issues</li>\n</ul>\n<h2>v2.2.2</h2>\n<ul>\n<li>Improved retryability and error handling</li>\n</ul>\n<h2>v2.2.1</h2>\n<ul>\n<li>Update used actions/core package to the latest version</li>\n</ul>\n<h2>v2.2.0</h2>\n<ul>\n<li>Support for artifact retention</li>\n</ul>\n<h2>v2.1.4</h2>\n<ul>\n<li>Add Third Party License Information</li>\n</ul>\n<h2>v2.1.3</h2>\n<ul>\n<li>Use updated version of the <code>@action/artifact</code> NPM package</li>\n</ul>\n<h2>v2.1.2</h2>\n<ul>\n<li>Increase upload chunk size from 4MB to 8MB</li>\n<li>Detect case insensitive file uploads</li>\n</ul>\n<h2>v2.1.1</h2>\n<ul>\n<li>Fix for certain symlinks not correctly being identified as directories before starting uploads</li>\n</ul>\n<h2>v2.1.0</h2>\n<ul>\n<li>Support for uploading artifacts with multiple paths</li>\n<li>Support for using exclude paths</li>\n<li>Updates to dependencies</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/3cea5372237819ed00197afe530f5a7ea3e805c8\"><code>3cea537</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/327\">#327</a> from actions/robherley/artifact-1.1.0</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/849aa7758a428ee22be38de371b49c8bd57c4b9d\"><code>849aa77</code></a> nvm use 12 &amp; npm run release</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/4d3986961d0423ba9a593efb490a2960eb65f43b\"><code>4d39869</code></a> recompile with correct ncc version</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/2e0d362ec5cf81e334dda822c49c96dcd4b7df2c\"><code>2e0d362</code></a> bump <code>@\u200bactions/artifact</code> to 1.1.0</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/09a5d6a283da3e7c9f3253a5d4cdab2347712a66\"><code>09a5d6a</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/320\">#320</a> from actions/dependabot/npm_and_yarn/ansi-regex-4.1.1</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/189315d9106f43a2a8eb60836608bb96b1f69d77\"><code>189315d</code></a> Bump ansi-regex from 4.1.0 to 4.1.1</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/d159c2d80bf32e77611286e4d71bfe6d15208d88\"><code>d159c2d</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/297\">#297</a> from actions/dependabot/npm_and_yarn/ajv-6.12.6</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/c26a7ba4b5dbaecea906fec3b7d2c0c86f1ccaba\"><code>c26a7ba</code></a> Bump ajv from 6.11.0 to 6.12.6</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/6ed6c729229a623bcb1fdd75903dc6e436b3d0a7\"><code>6ed6c72</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/upload-artifact/issues/303\">#303</a> from actions/dependabot/npm_and_yarn/yargs-parser-13.1.2</li>\n<li><a href=\"https://github.com/actions/upload-artifact/commit/2aeee267b2cb1f938c861a763b9770ee6e921dc3\"><code>2aeee26</code></a> Bump yargs-parser from 13.1.1 to 13.1.2</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/upload-artifact/compare/v2...v3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/upload-artifact&package-manager=github_actions&previous-version=2&new-version=3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-06-29T12:47:27Z",
  "comments":0,
  "created_at":"2022-06-29T12:14:13Z",
  "draft":false,
  "id":1288633675,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46kAmA",
  "number":633,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-29T12:47:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bump actions/upload-artifact from 2 to 3",
  "updated_at":"2022-06-29T12:47:28Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.4.2 to 1.5.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pypa/gh-action-pypi-publish/releases\">pypa/gh-action-pypi-publish's releases</a>.</em></p>\n<blockquote>\n<h2>v1.5.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Added an action input <code>print_hash</code> for showing the hash values of files to be uploaded \u2014 by <a href=\"https://github.com/meowmeowmeowcat\"><code>@\u200bmeowmeowmeowcat</code></a> in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/87\">pypa/gh-action-pypi-publish#87</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/pllim\"><code>@\u200bpllim</code></a> made their first contribution in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/55\">pypa/gh-action-pypi-publish#55</a></li>\n<li><a href=\"https://github.com/meowmeowmeowcat\"><code>@\u200bmeowmeowmeowcat</code></a> made their first contribution in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/87\">pypa/gh-action-pypi-publish#87</a></li>\n</ul>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.4.2...v1.5.0\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.4.2...v1.5.0</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/717ba43cfbb0387f6ce311b169a825772f54d295\"><code>717ba43</code></a> Trim the trailing whitespaces in <code>print-hash.py</code></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/4992a00fb2ce867ab24eb17e1fe76738cabcc160\"><code>4992a00</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/87\">#87</a> from meowmeowmeowcat/show-hash-values</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/977d0675615f6a62b2da99c5d6cd6da339b38bd5\"><code>977d067</code></a> Fix a bug</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/5d18baa42c7d858441b701f9f8d1db08ba9be00e\"><code>5d18baa</code></a> Drop unnecessary <code>file_iterable</code> var</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/0575dc8eab29bdb32fdc059da3f8ac7a22a26fb7\"><code>0575dc8</code></a> Refactor the hash helper script to use pathlib and CLI args</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/8682135dac51a0c6d0b2b03eacc20cdb11f203f2\"><code>8682135</code></a> Correct the if-clause for printing the hashes</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/c83d37bdf05723c6eca6bd0df3c05e00cacfa961\"><code>c83d37b</code></a> Introduce print_hash in README</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/777bfc4346c57a31fdf7ec381ef3e92018960946\"><code>777bfc4</code></a> Fix the message</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/ca30c7da983a24caeddb2e73a5f6fe1022d880a2\"><code>ca30c7d</code></a> Show a message before printing hash values of files</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/06a2dd66854ee73931657bb8a4e1f261ef938a5f\"><code>06a2dd6</code></a> Fix bug</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.4.2...v1.5.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/gh-action-pypi-publish&package-manager=github_actions&previous-version=1.4.2&new-version=1.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-06-29T12:58:41Z",
  "comments":0,
  "created_at":"2022-06-29T12:14:16Z",
  "draft":false,
  "id":1288633748,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46kAnG",
  "number":634,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-29T12:58:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bump pypa/gh-action-pypi-publish from 1.4.2 to 1.5.0",
  "updated_at":"2022-06-29T12:58:42Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [actions/download-artifact](https://github.com/actions/download-artifact) from 2 to 3.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/download-artifact/releases\">actions/download-artifact's releases</a>.</em></p>\n<blockquote>\n<h2>v3.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update default runtime to node16 (<a href=\"https://github-redirect.dependabot.com/actions/download-artifact/pull/134\">actions/download-artifact#134</a>)</li>\n<li>Update package-lock.json file version to 2 (<a href=\"https://github-redirect.dependabot.com/actions/download-artifact/pull/136\">actions/download-artifact#136</a>)</li>\n</ul>\n<h3>Breaking Changes</h3>\n<p>With the update to Node 16, all scripts will now be run with Node 16 rather than Node 12.</p>\n<h2>v2.1.0 Download Artifact</h2>\n<ul>\n<li>Improved output &amp; logging</li>\n<li>Fixed issue where downloading all artifacts could cause display percentages to be over 100%</li>\n<li>Various small bug fixes &amp; improvements</li>\n</ul>\n<h2>v2.0.10</h2>\n<ul>\n<li>Retry on HTTP 500 responses from the service</li>\n</ul>\n<h2>v2.0.9</h2>\n<ul>\n<li>Fixes to proxy related issues</li>\n</ul>\n<h2>v2.0.8</h2>\n<ul>\n<li>Improvements to retryability if an error is encountered during artifact download</li>\n</ul>\n<h2>v2.0.7 download-artifact</h2>\n<ul>\n<li>Improved download retry-ability if a partial download is encountered</li>\n</ul>\n<h2>v2.0.6</h2>\n<p>Update actions/core NPM package that is used internally</p>\n<h2>v2.0.5</h2>\n<ul>\n<li>Add Third Party License Information</li>\n</ul>\n<h2>v2.0.4</h2>\n<ul>\n<li>Use the latest version of the <code>@actions/artifact</code> NPM package</li>\n</ul>\n<h2>v2.0.3</h2>\n<ul>\n<li>Misc improvements</li>\n</ul>\n<h2>v2.0.2</h2>\n<ul>\n<li>Support for tilde expansion</li>\n</ul>\n<h2>v2.0.1</h2>\n<ul>\n<li>Download path output</li>\n<li>Improved logging</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/download-artifact/commit/fb598a63ae348fa914e94cd0ff38f362e927b741\"><code>fb598a6</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/actions/download-artifact/issues/136\">#136</a> from actions/jtamsut/update-lockfile-version</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/a4a09c5d7eb5932e0e6c4e77a434738189a24f1b\"><code>a4a09c5</code></a> regenerate index.js</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/9acf51df7946118a04918663acc5d955f49de177\"><code>9acf51d</code></a> regenerate package lock</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/882107232564f8bc8c5083706e009246f11aa871\"><code>8821072</code></a> upgrade artifact version</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/b8bbd3b64f298f12cfabf7d85ee4e716714eae3b\"><code>b8bbd3b</code></a> regenerate lockfile</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/6ee3d963e5a7ed7dac02925e126c37e459c36aa6\"><code>6ee3d96</code></a> revert artifact version</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/d4793f4e27ec52069836c96d310f815ffa48176c\"><code>d4793f4</code></a> update docs for v3</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/2d338d2145c33c497f1f4f574ca1eb88e1061a8e\"><code>2d338d2</code></a> upgrade package to v3</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/360d0830b5796c983178d8073e39063e8d32bc46\"><code>360d083</code></a> update dependency on artifact lib</li>\n<li><a href=\"https://github.com/actions/download-artifact/commit/d9b73cccacd09ac21cc34b82578e6cbb1b4e2539\"><code>d9b73cc</code></a> update lock file</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/download-artifact/compare/v2...v3\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/download-artifact&package-manager=github_actions&previous-version=2&new-version=3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-06-29T13:03:01Z",
  "comments":0,
  "created_at":"2022-06-29T12:14:20Z",
  "draft":false,
  "id":1288633887,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46kApI",
  "number":635,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-06-29T13:03:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bump actions/download-artifact from 2 to 3",
  "updated_at":"2022-06-29T13:03:02Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-07-01T16:34:09Z",
  "comments":0,
  "created_at":"2022-06-30T16:14:05Z",
  "draft":false,
  "id":1290365249,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46p1gU",
  "number":636,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-01T16:34:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Forth based ROOT reader (revised)",
  "updated_at":"2022-07-01T16:34:10Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-07-01T17:00:49Z",
  "comments":1,
  "created_at":"2022-07-01T00:24:42Z",
  "draft":false,
  "id":1290759711,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46rKtF",
  "number":637,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-01T17:00:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Set up tests for AsObjects, for the AwkwardForth reader",
  "updated_at":"2022-07-01T17:00:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This was a dumb mistake, pointed out by Andrew Wightman (Notre Dame) with a file of 61944 histograms.\r\n\r\nSince names are not unique identifiers for objects in TDirectories, the `uproot.TDirectory.__getitem__` was iterating through the list, looking for matches. If you do that _n_ times, the time complexity is _O(n\u00b2)_.\r\n\r\nHowever, names are _almost_ unique identifiers for objects in TDirectories, so I added a `uproot.TDirectory._keys_lookup`, which is a hashmap from names to lists of matching indexes in `uproot.TDirectory._keys`. For a given name, the number of items to search through is much shorter, usually 1.\r\n\r\nThis reduces the time needed to read the 61944 from 206 seconds to 54 seconds. Most importantly, it's flat: both the first and the last 1000 histograms take 0.85 seconds, whereas before it was 0.85 seconds for the first 1000 histograms and 6.2 seconds for the last 1000 histograms. The time complexity to read _n_ histograms is _O(n)_.",
  "closed_at":"2022-07-02T18:18:39Z",
  "comments":1,
  "created_at":"2022-07-02T17:26:19Z",
  "draft":false,
  "id":1292101700,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46vnft",
  "number":638,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-02T18:18:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Iterate over objects in TDirectory in linear time.",
  "updated_at":"2022-07-02T18:18:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Copying PR #638 from `main` to `main-v4`.\r\n\r\n* Iterate over objects in TDirectory in linear time.\r\n\r\n* Remove the debug_counter.\r\n\r\n(cherry picked from commit 809cf8ec7923b490525fb977f7427348308ea05e)",
  "closed_at":"2022-07-02T19:47:37Z",
  "comments":0,
  "created_at":"2022-07-02T19:37:42Z",
  "draft":false,
  "id":1292127203,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss46vsby",
  "number":639,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-02T19:47:37Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Iterate over objects in TDirectory in linear time.",
  "updated_at":"2022-07-02T19:47:38Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/psf/black: 22.3.0 \u2192 22.6.0](https://github.com/psf/black/compare/22.3.0...22.6.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-07-08T22:04:51Z",
  "comments":0,
  "created_at":"2022-07-04T20:48:12Z",
  "draft":false,
  "id":1293558190,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss460YRs",
  "number":641,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-08T22:04:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-07-08T22:04:52Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"I've been able to create a `TTree` with the required branch and successfully read it back, so I believe there is something particular about this file that we're struggling to parse.\r\n\r\nROOT File:\r\n[pfTuple.root.txt](https://github.com/scikit-hep/uproot5/files/9049659/pfTuple.root.txt)\r\n\r\n\r\n```python\r\n>>> import uproot\r\n>>> uproot.__version__\r\n'4.3.3'\r\n```\r\n\r\n```python\r\nuproot.open(...)['ntuple0']['objects;1'].branches[3].array()\r\n```\r\nError:\r\n```pytb\r\nValueError: basket 0 in tree/branch /ntuple0/objects;1:pf has the wrong number of bytes (16938) for interpretation AsStridedObjects(Model_pair_3c_TLorentzVector_2c_int_3e__v1)\r\nin file ~/Downloads/pfTuple.root\r\n```\r\n",
  "closed_at":"2022-08-11T21:12:47Z",
  "comments":0,
  "created_at":"2022-07-05T21:00:05Z",
  "id":1294764287,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5NLIj_",
  "number":643,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Reading `vector<TLorentzVector, int>` fails for given file",
  "updated_at":"2022-08-11T21:12:47Z",
  "user":"MDQ6VXNlcjEyNDg0MTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-09-08T05:59:31Z",
  "comments":15,
  "created_at":"2022-07-06T18:42:21Z",
  "draft":false,
  "id":1296227338,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss469T5J",
  "number":644,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-08T05:59:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: Finalizing AwkwardForth reader for Uproot",
  "updated_at":"2022-09-08T05:59:33Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Add @aryan26roy as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/pull/610#issuecomment-1179467866)",
  "closed_at":"2022-07-09T03:21:40Z",
  "comments":0,
  "created_at":"2022-07-09T03:08:56Z",
  "draft":false,
  "id":1299556416,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss47Isnf",
  "number":645,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-09T03:21:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add aryan26roy as a contributor for code",
  "updated_at":"2022-07-09T03:21:40Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Add @kkothari2001 as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/pull/620#issuecomment-1179468042)",
  "closed_at":"2022-07-09T03:29:17Z",
  "comments":1,
  "created_at":"2022-07-09T03:10:21Z",
  "draft":false,
  "id":1299556592,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss47Isps",
  "number":646,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-09T03:29:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add kkothari2001 as a contributor for code",
  "updated_at":"2022-07-09T03:29:18Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Add @Moelf as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/pull/630#issuecomment-1179468157)",
  "closed_at":"2022-07-09T03:32:23Z",
  "comments":1,
  "created_at":"2022-07-09T03:11:15Z",
  "draft":false,
  "id":1299556742,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss47Isrn",
  "number":647,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-09T03:32:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add Moelf as a contributor for code",
  "updated_at":"2022-07-09T03:32:24Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.34.0 \u2192 v2.37.1](https://github.com/asottile/pyupgrade/compare/v2.34.0...v2.37.1)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-07-19T13:07:53Z",
  "comments":0,
  "created_at":"2022-07-11T20:27:45Z",
  "draft":false,
  "id":1301187072,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss47N_qh",
  "number":650,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-19T13:07:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-07-19T13:07:54Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"If I have a [`hist`](https://github.com/scikit-hep/hist) histogram with a [transformed](https://hist.readthedocs.io/en/latest/user-guide/axes.html?highlight=transform#regular-axis-transforms) `Regular` axis, `uproot` does not recognize the transformation and saves the wrong bin edges, as though they were spaced evenly. (There is no such problem for a `Variable` axis.)\r\n___\r\nReproducer (v4.3.3):\r\n```python\r\nimport hist\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport uproot\r\n\r\n# without uproot\r\nh_reg = hist.Hist(hist.axis.Regular(19, 0.1, 1e4, transform=hist.axis.transform.log))\r\nh_var = hist.Hist(hist.axis.Variable(np.logspace(-1, 4, 20)))\r\nh_reg.fill([0.15, 1.5, 15, 150, 1500, 15000])\r\nh_var.fill([0.15, 1.5, 15, 150, 1500, 15000])\r\nfig, ax = plt.subplots()\r\nh_reg.plot(ax=ax)\r\nh_var.plot(ax=ax)\r\nplt.xscale(\"log\")\r\nplt.savefig(\"without_uproot.pdf\")\r\n\r\n# with uproot\r\nwith uproot.recreate(\"test.root\") as f:\r\n    f[\"h_reg\"] = h_reg\r\n    f[\"h_var\"] = h_var\r\nwith uproot.open(\"test.root\") as f:\r\n    h_reg = f[\"h_reg\"].to_hist()\r\n    h_var = f[\"h_var\"].to_hist()\r\nfig, ax = plt.subplots()\r\nh_reg.plot(ax=ax)\r\nh_var.plot(ax=ax)\r\nplt.xscale(\"log\")\r\nplt.savefig(\"with_uproot.pdf\")\r\n\r\nprint(uproot.__version__)\r\n```\r\n[without_uproot.pdf](https://github.com/scikit-hep/uproot5/files/9121434/without_uproot.pdf)\r\n[with_uproot.pdf](https://github.com/scikit-hep/uproot5/files/9121435/with_uproot.pdf)\r\n\r\n",
  "closed_at":"2022-08-11T22:05:03Z",
  "comments":5,
  "created_at":"2022-07-15T14:04:56Z",
  "id":1306079729,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5N2THx",
  "number":651,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Support boost_histogram/hist's transformed axis",
  "updated_at":"2022-08-11T22:05:03Z",
  "user":"MDQ6VXNlcjE1Nzc0ODM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"@jpivarski @douglasdavis  please have a look\r\n\r\n\r\nUsage:\r\n```python\r\n>>> import uproot, skhep_testdata\r\n>>> \r\n>>> filename1 = skhep_testdata.data_path(\"uproot-Zmumu.root\") + \":events\"\r\n>>> filename2 = skhep_testdata.data_path(\"uproot-Zmumu-uncompressed.root\") + \":events\"\r\n>>> \r\n>>> uproot.dask(filename1, library='ak')\r\ndask.awkward<from-delayed, npartitions=1>\r\n>>> \r\n>>> uproot.dask(filename1, library='ak').compute()\r\n<Array [{Type: 'GT', Run: 148031, ...}, ...] type='2304 * {Type: string, Ru...'>\r\n>>> \r\n>>> uproot.dask(filename1, step_size='100 B',library='ak')\r\ndask.awkward<from-delayed, npartitions=2304>\r\n>>> uproot.dask(filename1, step_size='100 B',library='ak').compute()\r\n<Array [{Type: 'GT', Run: 148031, ...}, ...] type='2304 * {Type: string, Ru...'>\r\n>>> \r\n>>> uproot.dask(filename1, step_size=76,library='ak')\r\ndask.awkward<from-delayed, npartitions=31>\r\n>>> uproot.dask(filename1, step_size=76,library='ak').compute()\r\n<Array [{Type: 'GT', Run: 148031, ...}, ...] type='2304 * {Type: string, Ru...'>\r\n>>> \r\n>>> \r\n>>> uproot.dask([filename1,filename2], step_size=76,library='ak')\r\ndask.awkward<from-delayed, npartitions=62>\r\n>>> uproot.dask([filename1,filename2], step_size=76,library='ak').compute()\r\n<Array [{Type: 'GT', Run: 148031, ...}, ...] type='4608 * {Type: string, Ru...'>\r\n>>> \r\n>>> \r\n>>> uproot.dask([filename1,filename2],library='ak',open_files=True)\r\ndask.awkward<from-delayed, npartitions=2>\r\n>>> uproot.dask([filename1,filename2],library='ak', open_files=False)\r\ndask.awkward<from-delayed, npartitions=2>\r\n>>> uproot.dask([filename1,filename2],library='ak', open_files=False).compute()\r\n<Array [{Type: 'GT', Run: 148031, ...}, ...] type='4608 * {Type: string, Ru...'>\r\n```\r\n\r\nWIP:\r\nTests remain\r\nA few things to cleanup (move dask_awkward to extras, make awkward the default library to use)",
  "closed_at":"2022-08-11T05:17:41Z",
  "comments":3,
  "created_at":"2022-07-18T17:20:07Z",
  "draft":false,
  "id":1308272106,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss47ldFT",
  "number":652,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T05:17:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Dask awkward support for uproot.dask",
  "updated_at":"2022-08-17T22:33:11Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.37.1 \u2192 v2.37.2](https://github.com/asottile/pyupgrade/compare/v2.37.1...v2.37.2)\n- [github.com/asottile/setup-cfg-fmt: v1.20.1 \u2192 v1.20.2](https://github.com/asottile/setup-cfg-fmt/compare/v1.20.1...v1.20.2)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-07-25T21:10:54Z",
  "comments":0,
  "created_at":"2022-07-25T20:41:00Z",
  "draft":false,
  "id":1317344494,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48EQU9",
  "number":654,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-07-25T21:10:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-07-25T21:10:55Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.5.0 to 1.5.1.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pypa/gh-action-pypi-publish/releases\">pypa/gh-action-pypi-publish's releases</a>.</em></p>\n<blockquote>\n<h2>v1.5.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Fixed printing out the dist hashes when <code>packages_dir</code> is a wildcard value. \u2014 by <a href=\"https://github.com/meowmeowmeowcat\"><code>@\u200bmeowmeowmeowcat</code></a> in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/91\">pypa/gh-action-pypi-publish#91</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.0...v1.5.1\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.0...v1.5.1</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/37f50c210e3d2f9450da2cd423303d6a14a6e29f\"><code>37f50c2</code></a> Merge PR <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/91\">#91</a></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/9f0421c6c63e6834c88c90d39708f1e317f4dc82\"><code>9f0421c</code></a> Add #StandWithUkraine banner to README</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/c3fbd68c153b595e98c34c15ebfd0db1e144863d\"><code>c3fbd68</code></a> Remove quotes</li>\n<li>See full diff in <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.0...v1.5.1\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/gh-action-pypi-publish&package-manager=github_actions&previous-version=1.5.0&new-version=1.5.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-08-03T14:08:16Z",
  "comments":0,
  "created_at":"2022-08-01T09:46:41Z",
  "draft":false,
  "id":1324136972,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48aoTi",
  "number":656,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-03T14:08:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bump pypa/gh-action-pypi-publish from 1.5.0 to 1.5.1",
  "updated_at":"2022-08-03T14:08:16Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.37.2 \u2192 v2.37.3](https://github.com/asottile/pyupgrade/compare/v2.37.2...v2.37.3)\n- [github.com/asottile/setup-cfg-fmt: v1.20.2 \u2192 v2.0.0](https://github.com/asottile/setup-cfg-fmt/compare/v1.20.2...v2.0.0)\n- [github.com/asottile/yesqa: v1.3.0 \u2192 v1.4.0](https://github.com/asottile/yesqa/compare/v1.3.0...v1.4.0)\n- [github.com/PyCQA/flake8: 4.0.1 \u2192 5.0.4](https://github.com/PyCQA/flake8/compare/4.0.1...5.0.4)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-08-18T17:22:06Z",
  "comments":3,
  "created_at":"2022-08-01T21:26:06Z",
  "draft":false,
  "id":1325000566,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48dgeM",
  "number":657,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-18T17:22:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-08-18T17:22:07Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"ReadOnlyDirectory has a few attributes that usually get filled with meaningful values when `fSeekKeys != 0`. But in that special case:\r\n\r\nhttps://github.com/scikit-hep/uproot5/blob/914dd25ec03225c5a37da3c30d8d83d68d34fea4/src/uproot/reading.py#L1405-L1407\r\n\r\nthe `self._keys_lookup` and `self._len` attributes don't get set (any others? scroll down to check). They should be set in any case, possibly before that `if`-branch so that conditional initialization doesn't bite us again.",
  "closed_at":"2022-08-04T15:03:06Z",
  "comments":1,
  "created_at":"2022-08-03T13:59:58Z",
  "id":1327267749,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5PHH-l",
  "number":658,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"It's possible for a ReadOnlyDirectory to be created without all fields.",
  "updated_at":"2022-08-04T15:03:06Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello,\r\n\r\nI have been using uproot to save/load hist objects from root files. I have noticed that calling `to_hist()` on a `THn` object which contains a category axis yields a `ValueError: could not broadcast input array from shape (N,...) into shape (N+1,...)`. This snippet of code reproduces the issue:\r\n\r\n```python\r\nimport hist\r\nprint(f'{hist.__version__=}')\r\nimport uproot\r\nprint(f'{uproot.__version__=}')\r\nimport numpy\r\n\r\ncat_axis = hist.axis.IntCategory([1,2,3], label='Category')\r\nreg_axis = hist.axis.Regular(100,0,100, label='Random')\r\nh = hist.Hist(cat_axis)\r\nh2 = hist.Hist(cat_axis, reg_axis)\r\nh.fill(\r\n    numpy.random.randint(1,4,1000)\r\n)\r\nh2.fill(\r\n    numpy.random.randint(1,4,1000), numpy.random.normal(20,5,1000)\r\n)\r\n\r\nwith uproot.recreate(\"bug_output.root\") as f:\r\n    f['h'] = h\r\n    f['h2'] = h2\r\n\r\n    print(f['h'])\r\n    print(f['h2'])\r\n\r\nwith uproot.open(\"bug_output.root\") as f:\r\n    h_opened = f['h'] \r\n    h2_opened = f['h2']\r\n\r\nprint(h_opened)\r\nprint(h2_opened)\r\n\r\n#this fails \r\nprint(h_opened.to_hist())\r\nprint(h2_opened.to_hist())\r\n\r\n#this also fails\r\nprint(h_opened.to_numpy()) #works, but the bin edges are wrong\r\nprint(h2_opened.to_numpy()) #fails\r\n```\r\n\r\n\r\n```bash\r\n(gm2) jlab@SB3:~/github/g2_analysis/analysis$ python hist_uproot_category_bug.py \r\nhist.__version__='2.6.1'\r\nuproot.__version__='4.3.3'\r\n<TH1D (version 3) at 0x7fa5dc5650c0>\r\n<TH2D (version 4) at 0x7fa5db88e1a0>\r\n<TH1D (version 3) at 0x7fa5eb986710>\r\n<TH2D (version 4) at 0x7fa5eb793400>\r\nTraceback (most recent call last):\r\n  File \"/home/jlab/github/g2_analysis/analysis/hist_uproot_category_bug.py\", line 39, in <module>\r\n    print(h_opened.to_hist())\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/uproot/behaviors/TH1.py\", line 206, in to_hist\r\n    self.to_boost(metadata=boost_metadata, axis_metadata=boost_axis_metadata)\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/uproot/behaviors/TH1.py\", line 322, in to_boost\r\n    view.value = values\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/boost_histogram/_internal/view.py\", line 59, in fset\r\n    self[name] = value\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/boost_histogram/_internal/view.py\", line 39, in __setitem__\r\n    super().__setitem__(ind, value)  # type: ignore[no-untyped-call]\r\nValueError: could not broadcast input array from shape (4,) into shape (5,)\r\n```\r\n\r\nThe 2D `to_numpy()` call fails with:\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/jlab/github/g2_analysis/analysis/hist_uproot_category_bug.py\", line 40, in <module>\r\n    print(h2_opened.to_numpy())\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/uproot/behaviors/TH2.py\", line 96, in to_numpy\r\n    values = self.values(flow=flow)\r\n  File \"/home/jlab/miniconda3/envs/gm2/lib/python3.10/site-packages/uproot/behaviors/TH2.py\", line 52, in values\r\n    values = numpy.transpose(values.reshape(yaxis_fNbins + 2, xaxis_fNbins + 2))\r\nValueError: cannot reshape array of size 408 into shape (102,5)\r\n```\r\n\r\nI have tested this on uproot version `4.3.3` and hist version `2.6.1`. I think this is related to the handling of over/underflow bins discussed [here](https://github.com/scikit-hep/uproot5/pull/580). As far as I know ROOT doesn't have an exact analogue to the CategoryAxis, so should an error be raised when trying to write this object to a root file in the first place? \r\n\r\nThank you for the great deal of work which goes into maintaining this project!",
  "closed_at":"2022-08-11T19:53:22Z",
  "comments":0,
  "created_at":"2022-08-03T18:55:56Z",
  "id":1327654418,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5PImYS",
  "number":659,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Calling to_hist() and to_numpy() gives error when opening a CategoryAxis which has been saved to a root file",
  "updated_at":"2022-08-11T19:53:22Z",
  "user":"MDQ6VXNlcjEyNjE2NDU4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"As titled. Fixes #658. ",
  "closed_at":"2022-08-04T15:03:05Z",
  "comments":2,
  "created_at":"2022-08-03T19:30:18Z",
  "draft":false,
  "id":1327694729,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48mhe-",
  "number":660,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-04T15:03:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Set ReadOnlyDirectory attributes when fSeekKeys == 0",
  "updated_at":"2022-08-04T15:04:57Z",
  "user":"MDQ6VXNlcjEyNzk4MDEz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Backport of #660 to `main-v4`, fixes #658",
  "closed_at":"2022-08-04T15:03:39Z",
  "comments":2,
  "created_at":"2022-08-03T19:54:48Z",
  "draft":false,
  "id":1327717620,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48mmVV",
  "number":661,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-04T15:03:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[v4 backport] Set ReadOnlyDirectory attributes when fSeekKeys == 0",
  "updated_at":"2022-08-04T15:30:09Z",
  "user":"MDQ6VXNlcjEyNzk4MDEz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"See:\r\n- https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/specifications.md#stl-types-and-collections\r\n\r\nAnd similar existing tests for TTree:\r\n- https://github.com/scikit-hep/uproot5/blob/main/tests/test_0031-test-stl-containers.py\r\n- https://github.com/scikit-hep/uproot5/blob/main/tests/test_0033-more-interpretations-2.py",
  "closed_at":"2022-08-18T21:01:34Z",
  "comments":6,
  "created_at":"2022-08-03T23:08:05Z",
  "draft":false,
  "id":1327874457,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48nG1q",
  "number":662,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-18T21:01:34Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement stl containers for RNTuple",
  "updated_at":"2022-08-18T21:01:34Z",
  "user":"MDQ6VXNlcjUzMDYyMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Add @kakwok as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/pull/660#issuecomment-1205382929)",
  "closed_at":"2022-08-04T15:28:30Z",
  "comments":0,
  "created_at":"2022-08-04T15:04:54Z",
  "draft":false,
  "id":1328774962,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss48qGY3",
  "number":663,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-04T15:28:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add kakwok as a contributor for code",
  "updated_at":"2022-08-04T15:28:31Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjUzNjUwNTM4",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Currently, `library=\"pd\"` explodes ragged arrays and sets of ragged arrays to one or more DataFrames using MultiIndex, in a _reimplementation_ of [ak.to_pandas](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_pandas.html) (the reimplementation does not rely on `awkward` being installed). This has been a cause of confusion on multiple occasions, especially when the ragged arrays would have incompatible MultiIndexes; here's one occasion: #583.\r\n\r\nWith https://github.com/intake/awkward-pandas, it will be possible to simply wrap each ragged array as a `pd.Series`, which can always be a grouped into a single `pd.DataFrame`, regardless of the ragged structure. We should make this the new behavior in v5. It's backward-incompatible, but still possible to reproduce the old behavior via `library=\"ak\"` and `ak.to_dataframe` (see https://github.com/scikit-hep/awkward/issues/1546), and it will remove a lot of complex code.\r\n\r\nAlso, @kkothari2001 won't have to re-re-implement the explosion logic for `uproot.dask` with `library=\"pd\"`.",
  "closed_at":"2022-11-28T19:14:49Z",
  "comments":0,
  "created_at":"2022-08-10T16:51:52Z",
  "id":1334906414,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5PkQ4u",
  "number":668,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"The library=\"pd\" option for ragged arrays should return ragged arrays wrapped by awkward-pandas",
  "updated_at":"2023-02-15T19:10:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The following came up when trying to access this (ATLAS-restricted) ROOT file: `root://webdav.echo.stfc.ac.uk:1094/atlas:scratchdisk/rucio/user/lvozdeck/96/55/Wjets_l_Sh221_5M.root`. As the file contains a colon in the path, the usual way of accessing it is by wrapping the file name in a `pathlib.Path`. This however strips the double slash from the path (as discovered by @jpivarski):\r\n\r\n```python\r\n>>> import pathlib\r\n>>> pathlib.Path(\"root://what.ever.com:12345/some:where.root\")\r\nPosixPath('root:/what.ever.com:12345/some:where.root')\r\n```\r\n\r\nwhich results in the `uproot.open` to fail (since now the path is wrong). A workaround for this is to use another pattern that uproot supports, using a dict:\r\n```python\r\nuproot.open({\"root://webdav.echo.stfc.ac.uk:1094/atlas:scratchdisk/rucio/user/lvozdeck/96/55/Wjets_l_Sh221_5M.root\": None})\r\n```\r\nThis handles this specific case (and presumably others like it) fine.",
  "closed_at":"2022-08-11T18:53:31Z",
  "comments":0,
  "created_at":"2022-08-11T18:30:45Z",
  "id":1336339781,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Ppu1F",
  "number":669,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Accessing ROOT files with colons and double slashes in the path",
  "updated_at":"2022-08-11T18:53:31Z",
  "user":"MDQ6VXNlcjQ1MDA5MzU1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"So if a path from `pathlib.Path` _starts with_ \"http:/\" and _no second slash_ (also for \"file\", \"https\", \"root\" URL schemes, case insensitive), then a second slash will be added.\r\n\r\n`pathlib.Path` is our recommended way of saying, \"This really is a path, even though it has a colon in it,\" but we didn't foresee this issue with _URLs_ with colons in them.\r\n\r\nThere's another way of doing it with `{filename: None}` instead of `pathlib.Path(filename)`, which doesn't suffer from this, but enough people are probably doing the `pathlib.Path` thing that we need this small correction.",
  "closed_at":"2022-08-11T18:53:31Z",
  "comments":0,
  "created_at":"2022-08-11T18:37:41Z",
  "draft":false,
  "id":1336346258,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49DAMk",
  "number":670,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T18:53:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"pathlib.Path drops '//' (naturally), but it's sometimes used for URLs",
  "updated_at":"2022-08-11T18:53:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Doesn't fully support categorical axis round-trip from hist through TH*, but at least it gets the number of overflow bins right (fixing #659).",
  "closed_at":"2022-08-11T19:53:21Z",
  "comments":0,
  "created_at":"2022-08-11T19:37:22Z",
  "draft":false,
  "id":1336404243,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49DMvg",
  "number":671,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T19:53:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Gets the number of overflow bins for hist.axis.IntCategory, at least.",
  "updated_at":"2022-08-11T19:53:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjM1ODAzMjgw",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Inspired by #659 (@jlabounty). Currently, the boost-histogram/hist \u2192 ROOT TH* conversion takes a categorical axis with `n` categories as a continuous regular axis of `n` bins from `0` to `n-1` (inclusive). ROOT TH* objects have no notion of categorical axes, but they do have `fLabels`, which can be set to a list of strings. When this value is set to `n` strings, ROOT draws these strings under each tick, effectively simulating a categorical axis.\r\n\r\nThis feature request would be (1) to have boost-histogram/hist \u2192 ROOT TH* set `fLabels`, somewhere here (may have to be expanded to a regular `for` loop):\r\n\r\nhttps://github.com/scikit-hep/uproot5/blob/c7d728207878edaf9d017595d3aba864ad58ecf3/src/uproot/writing/identify.py#L320-L331\r\n\r\nAnd (2) to interpret a TAxis with `fLabels is not None and len(fLabels) != 0` as a boost-histogram/hist categorical axis when transforming the other way:\r\n\r\nhttps://github.com/scikit-hep/uproot5/blob/c7d728207878edaf9d017595d3aba864ad58ecf3/src/uproot/behaviors/TH1.py#L17-L40\r\n\r\nWe probably won't be able to preserve the int-ness of IntCategorical (`fLabels` are strictly strings), but maybe if all strings don't raise ValueError when cast as a Python `int`, that would be a good indicator.",
  "closed_at":"2022-11-02T20:13:47Z",
  "comments":0,
  "created_at":"2022-08-11T19:50:25Z",
  "id":1336416630,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5PqBl2",
  "number":672,
  "performed_via_github_app":null,
  "reactions":{
   "eyes":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Support boost_histogram/hist's categorical axes",
  "updated_at":"2023-02-15T19:10:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@aryan26roy, does this one get read properly through AwkwardForth, when this commit is ported to your branch?",
  "closed_at":"2022-08-11T21:12:46Z",
  "comments":0,
  "created_at":"2022-08-11T20:58:08Z",
  "draft":false,
  "id":1336483803,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49DdRs",
  "number":673,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T21:12:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Prevent std::pair from being AsStridedObjects.",
  "updated_at":"2022-08-11T21:12:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This fixes the direct error that #607 saw, though this data type is likely too complex to solve all of its issues. I see an infinite loop:\r\n\r\n```\r\nuproot.deserialization.DeserializationError: while reading\r\n\r\n    MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6286 bytes)\r\n        (base): <MGTDataObject (version 2) at 0x7f8c73766fa0>\r\n        (base): <MGVMemoryCheckable (version 1) at 0x7f8c73766b50>\r\n        fEventType: 16469\r\n        fETotal: -1.82467463945584e-05\r\n        fTime: 3.6780645929512914e+267\r\n        fWaveforms: None\r\n        fDigitizerData: None\r\n        MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (24441 bytes)\r\n            (base): <MGTDataObject (version 2) at 0x7f8c7371a160>\r\n            (base): <MGVMemoryCheckable (version 1) at 0x7f8c7371a1c0>\r\n            fEventType: 16608\r\n            fETotal: 1.0222966365301011e-196\r\n            fTime: 3.7243961167525673e+267\r\n            MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6868 bytes)\r\n                (base): <MGTDataObject (version 2) at 0x7f8c7371ae50>\r\n                (base): <MGVMemoryCheckable (version 1) at 0x7f8c7371adc0>\r\n                fEventType: 16611\r\n                fETotal: 1.1499381031852565e+253\r\n                fTime: 3.7309778849244594e+267\r\n                fWaveforms: None\r\n                fDigitizerData: None\r\n                MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6117 bytes)\r\n                    (base): <MGTDataObject (version 2) at 0x7f8c7371a910>\r\n                    (base): <MGVMemoryCheckable (version 1) at 0x7f8c7371a8b0>\r\n                    fEventType: 16555\r\n                    fETotal: -8.034678566710207e+212\r\n                    fTime: 3.7882262938416495e+267\r\n                    fWaveforms: None\r\n                    fDigitizerData: None\r\n                    MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6286 bytes)\r\n                        (base): <MGTDataObject (version 2) at 0x7f8c73713ca0>\r\n                        (base): <MGVMemoryCheckable (version 1) at 0x7f8c737139d0>\r\n                        fEventType: 16469\r\n                        fETotal: -1.82467463945584e-05\r\n                        fTime: 3.6780645929512914e+267\r\n                        fWaveforms: None\r\n                        fDigitizerData: None\r\n                        MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (24441 bytes)\r\n                            (base): <MGTDataObject (version 2) at 0x7f8c73712ca0>\r\n                            (base): <MGVMemoryCheckable (version 1) at 0x7f8c73712c40>\r\n                            fEventType: 16608\r\n                            fETotal: 1.0222966365301011e-196\r\n                            fTime: 3.7243961167525673e+267\r\n                            MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6868 bytes)\r\n                                (base): <MGTDataObject (version 2) at 0x7f8c73712550>\r\n                                (base): <MGVMemoryCheckable (version 1) at 0x7f8c737125b0>\r\n                                fEventType: 16611\r\n                                fETotal: 1.1499381031852565e+253\r\n                                fTime: 3.7309778849244594e+267\r\n                                fWaveforms: None\r\n                                fDigitizerData: None\r\n                                MGTEvent version 9 as uproot.dynamic.Model_MGTEvent_v9 (6117 bytes)\r\n                                    (base): <MGTDataObject (version 2) at 0x7f8c737122b0>\r\n                                    (base): <MGVMemoryCheckable (version 1) at 0x7f8c73712250>\r\n                                    fEventType: 16555\r\n                                    fETotal: -8.034678566710207e+212\r\n                                    fTime: 3.7882262938416495e+267\r\n                                    fWaveforms: None\r\n                                    fDigitizerData: None\r\nBase classes for MGTEvent: (MGTDataObject), (MGVMemoryCheckable)\r\nMembers for MGTEvent: (fEventType), (fETotal), (fTime), (fWaveforms), (fDigitizerData), fActiveID, fUseAuxWaveformArray, fAuxWaveforms, fEventNumber\r\n\r\nattempting to get bytes 3221179793:3221179799\r\noutside expected range 0:6296 for this Chunk\r\nin file gerda-run0050-20150826T170402Z-cal-ged-tier1.root\r\nin object /MGTree;1\r\n```\r\n\r\nThe `cursor` is not advancing forward, so it's trying to read the same class instance over and over again. Something evidently goes wrong before the first `fEventType` (that number is not a small `enum` value).",
  "closed_at":"2022-08-11T22:09:13Z",
  "comments":0,
  "created_at":"2022-08-11T21:11:46Z",
  "draft":false,
  "id":1336495358,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49Dfxh",
  "number":674,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T22:09:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"AsDynamic has no self._header.",
  "updated_at":"2022-08-11T22:09:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Because not implementing it means that users get the wrong data.",
  "closed_at":"2022-08-11T22:05:02Z",
  "comments":0,
  "created_at":"2022-08-11T21:50:50Z",
  "draft":false,
  "id":1336532630,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49DnxX",
  "number":675,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T22:05:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement transformed axis from boost-histogram/hist.",
  "updated_at":"2022-08-11T22:05:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is the `main-v4` version of #675.",
  "closed_at":"2022-08-11T22:06:48Z",
  "comments":0,
  "created_at":"2022-08-11T21:54:09Z",
  "draft":false,
  "id":1336535060,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49DoQk",
  "number":676,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-11T22:06:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement transformed axis from boost-histogram/hist (v4).",
  "updated_at":"2022-08-11T22:06:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-08-12T00:31:40Z",
  "comments":0,
  "created_at":"2022-08-12T00:16:21Z",
  "draft":false,
  "id":1336614254,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49D5GC",
  "number":677,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-12T00:31:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed TTree write_anew in a subdirectory (consistent caches).",
  "updated_at":"2022-08-12T00:31:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-08-12T00:33:30Z",
  "comments":0,
  "created_at":"2022-08-12T00:19:28Z",
  "draft":false,
  "id":1336615784,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49D5ZJ",
  "number":678,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-12T00:33:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed TTree write_anew in a subdirectory (consistent caches). (v4)",
  "updated_at":"2022-08-12T00:33:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-09-01T14:59:32Z",
  "comments":3,
  "created_at":"2022-08-12T04:47:35Z",
  "draft":false,
  "id":1336746073,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49EUWk",
  "number":679,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-01T14:59:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: `from_map` like optimization for dask arrays",
  "updated_at":"2022-09-01T14:59:33Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is addressing https://github.com/scikit-hep/uproot5/pull/652#discussion_r948495191 (@masonproffitt).\r\n\r\n@kkothari2001, please make sure that `uproot.extras.dask_awkward` is only called if `library != \"np\"` (i.e. `uproot.dask` with `library=\"np\"` requires Dask, but `uproot.dask` with `library=\"ak\"` requires Dask-Awkward). If Dask-Awkward strictly depends on `dask[complete]` (I haven't checked: please check it!), then the imports in the `dask_awkward()` function can be reduced to just `import dask_awkward`. We want to minimize the number of error messages that say, \"Stop what you're doing and go install some other library,\" but not require people to install things that they don't need. (Consider the example of `lz4` and `xxhash`, which are always needed together, so the error message for both says to install both.)\r\n\r\nI'm not sure what will be required for the `library=\"pd\"` case; quite possibly Awkward-Pandas. (If we no longer explode ragged data into a MultiIndex but wrap them using Awkward-Pandas, as described in #668, then every function with `library=\"pd\"` may need Awkward-Pandas.)",
  "closed_at":"2022-08-24T21:43:34Z",
  "comments":2,
  "created_at":"2022-08-18T12:40:14Z",
  "draft":true,
  "id":1343043625,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49Y7jn",
  "number":680,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Installation requirements and error text for dask/dask-awkward in extras.py",
  "updated_at":"2022-09-23T00:47:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is probably the last new pre-commit for `main-v4`, but I want to get it over the boundary because the flake8 v5 is a big change.",
  "closed_at":"2022-08-18T17:36:03Z",
  "comments":0,
  "created_at":"2022-08-18T17:10:46Z",
  "draft":false,
  "id":1343382678,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49aEOY",
  "number":681,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-18T17:36:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Apply #657 (pre-commit with flake8 v5) to main-v4.",
  "updated_at":"2022-08-18T17:36:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"```python\r\nakako@archlinux ~/D/g/uproot4 (RNTuple)> python -c 'from pprint import pprint; import uproot as up; import \r\nskhep_testdata; filename = skhep_testdata.data_path(\"test_ntuple_large_bit_int64.root\"); r = up.open(filena\r\nme)[\"ntuple\"]; pprint(r.arrays(entry_start=1, entry_stop=2).to_list())'\r\n[{'one_bit': True, 'two_int64': 1}]\r\n\r\nakako@archlinux ~/D/g/uproot4 (RNTuple)> python -c 'from pprint import pprint; import uproot as up; import \r\nskhep_testdata; filename = skhep_testdata.data_path(\"test_ntuple_large_bit_int64.root\"); r = up.open(filena\r\nme)[\"ntuple\"]; pprint(r.arrays(entry_start=11111112, entry_stop=11111113).to_list())'\r\n[{'one_bit': True, 'two_int64': 11111112},\r\n {'one_bit': True, 'two_int64': 11111113}]\r\n```\r\n\r\nthe `one_bit` field is not being read out correctly because it's actually bit not byte encoded in the serialization",
  "closed_at":"2022-08-21T20:34:42Z",
  "comments":5,
  "created_at":"2022-08-19T04:51:52Z",
  "draft":false,
  "id":1343939329,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49b6Fc",
  "number":682,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-21T20:34:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Multiple clusters support for RNTuple",
  "updated_at":"2022-08-21T20:34:42Z",
  "user":"MDQ6VXNlcjUzMDYyMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This should be faster.\r\n\r\nBefore:\r\n\r\n![1A64EE85-2392-4355-9410-76623C06D20C](https://user-images.githubusercontent.com/4616906/186325822-2a2a6bdb-a29b-4433-a01e-7fb90e5ce45b.jpeg)\r\n\r\n\r\nAfter:\r\n\r\n\r\n![B8E63BAA-AAFB-4EE4-863E-3EA0985397CF](https://user-images.githubusercontent.com/4616906/186325772-22b2131d-c077-4165-903b-55794bf951ef.jpeg)",
  "closed_at":"2022-08-24T20:13:44Z",
  "comments":3,
  "created_at":"2022-08-24T03:48:56Z",
  "draft":false,
  "id":1348813188,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49r86R",
  "number":683,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T20:13:44Z"
  },
  "reactions":{
   "rocket":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"ci: use mamba",
  "updated_at":"2022-08-24T20:13:44Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This should not be pulled from setuptools vendoring, it's a standalone package. And `importlib.metadata.version` is the correct way to get the version (or from the backport `importlib_metadata`).",
  "closed_at":"2022-08-24T19:31:40Z",
  "comments":2,
  "created_at":"2022-08-24T13:35:47Z",
  "draft":false,
  "id":1349462883,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49uHHH",
  "number":684,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T19:31:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: depend on packaging, not setuptools vendored packaging",
  "updated_at":"2022-08-24T19:55:51Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Saves some time for repeated pushes (including pre-commit fixes). Also allows Actions to run on a branch-to-branch PR, or manually.\n",
  "closed_at":"2022-08-24T19:48:57Z",
  "comments":0,
  "created_at":"2022-08-24T13:50:54Z",
  "draft":false,
  "id":1349484323,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49uLsh",
  "number":685,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T19:48:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: autocancel repeated runs",
  "updated_at":"2022-08-24T19:48:58Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-08-24T19:17:47Z",
  "comments":5,
  "created_at":"2022-08-24T14:21:12Z",
  "draft":false,
  "id":1349527901,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49uVAV",
  "number":686,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T19:17:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: Get test dependencies from one source",
  "updated_at":"2022-08-24T19:17:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Definitely for the `main` branch.\r\n\r\nAlso for the `main-v4` branch, and this means that Uproot v4 needs a new minor version number: 4.4.0. Which is fine.\r\n\r\nFYI @henryiii",
  "closed_at":"2022-10-31T20:51:30Z",
  "comments":1,
  "created_at":"2022-08-24T19:20:27Z",
  "id":1349915190,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5QdhI2",
  "number":687,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Drop support for Python 3.6.",
  "updated_at":"2022-10-31T20:51:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Mostly an automated move using `pipx run hatch new --init`. I cleaned up a tiny bit after that, moved pytest (and expanded using the dev pages guidelines) and isort, moved flake8 to it's own sad little file, and deleted things that are no longer needed. (I'm guessing `build-uproot4.sh` is not used anymore).\r\n",
  "closed_at":"2022-08-24T21:09:18Z",
  "comments":4,
  "created_at":"2022-08-24T20:11:21Z",
  "draft":false,
  "id":1349971472,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49v0fs",
  "number":688,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T21:09:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: move to hatchling",
  "updated_at":"2022-08-25T03:30:57Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is a total [crib](https://idioms.thefreedictionary.com/crib+from) from https://github.com/scikit-hep/awkward/pull/1615.",
  "closed_at":"2022-08-24T22:14:17Z",
  "comments":0,
  "created_at":"2022-08-24T21:29:39Z",
  "draft":false,
  "id":1350041783,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49wDfv",
  "number":689,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T22:14:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: Lint PR titles according to conventional commits",
  "updated_at":"2022-08-24T22:14:18Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This also addresses https://github.com/scikit-hep/uproot5/pull/652#discussion_r948495191, but is more up-to-date.\r\n\r\nIt _replaces_ #680, which should be closed.",
  "closed_at":"2022-08-24T22:54:40Z",
  "comments":0,
  "created_at":"2022-08-24T21:43:05Z",
  "draft":false,
  "id":1350054556,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49wGK6",
  "number":690,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-24T22:54:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: Installation requirements and error text for dask/dask-awkward in extras.py",
  "updated_at":"2022-08-24T22:54:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"The semantic-pr-title workflow does not currently run in a concurrency group. This means that subsequent pushes do not cancel in-progress actions. The following PR fixes this.",
  "closed_at":"2022-08-29T18:39:36Z",
  "comments":0,
  "created_at":"2022-08-25T16:08:57Z",
  "draft":false,
  "id":1351141789,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49zwQq",
  "number":691,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-29T18:39:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: use concurrency group for `semantic-pr-title`",
  "updated_at":"2022-08-29T18:39:36Z",
  "user":"MDQ6VXNlcjEyNDg0MTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2023-10-04T19:35:44Z",
  "comments":19,
  "created_at":"2022-08-25T18:53:14Z",
  "draft":true,
  "id":1351318334,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss490WTV",
  "number":692,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: fsspec source implementation",
  "updated_at":"2023-10-04T19:35:52Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"> If we were to do that, it would also be nice to drop the custom executor and futures implementation here and adopt the standard library one, now that python 2 is not supported.\r\n\r\n_Originally posted by @nsmith- in https://github.com/scikit-hep/uproot5/issues/692#issuecomment-1227669248_\r\n\r\nOne difference that most of the Uproot Executors have is that they manage a resource: the open file handle and the threads to read from that file are bound to each other, with the same lifetime. But I'm sure we could do that by subclassing the standard Python executors.\r\n\r\nWe'd still need a TrivialExecutor to use as a dummy when no parallel processing is desired (the default case).\r\n\r\nUnless there's a blocker I'm not seeing, @nsmith-, this would be a pure refactoring: replacing something with identical API because it's the Right Thing To Do (which it is: I'm not being sarcastic). We have other tasks in the countdown to v5 release that have visible effects. If this is pure refactoring, then it may be low on the priority list for a while.",
  "closed_at":null,
  "comments":0,
  "created_at":"2022-08-25T19:43:06Z",
  "id":1351371272,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5QjEoI",
  "number":693,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Remove custom executor and futures in favor of standards, now that Python 2 is dropped",
  "updated_at":"2022-11-28T20:56:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"dask-awkward assumes that `ak.Array((1, 2, 3))` makes an `ak.Array`, the same as `ak.Array([1, 2, 3])`, which is a sensible assumption.\r\n\r\nhttps://github.com/scikit-hep/awkward/pull/1614 accidentally changed that, and while one accidental consequence was for the better (`ak.from_iter({\"one\": 1, \"two\": 2, \"three\": 3})` no longer returns `ak.Array([\"one\", \"two\", \"three\"])`), it's reasonable to suppose that a _top-level_ tuple is intended to become an `ak.Array`, especially if passed to the `ak.Array` constructor.\r\n\r\nhttps://github.com/scikit-hep/awkward/pull/1642 fixes it (best of both worlds), but Uproot tests would fail until this comes through. Therefore, this fix removes the tests that trigger the incompatibility. It should be merged into any Uproot PRs that are failing because of it.\r\n\r\nRemoving the `len` tests doesn't decrease the power of the test: `assert_eq` would not be satisfied if the lengths were different. However, it does reduce coverage of the dask-awkward `__len__` code.",
  "closed_at":"2022-08-29T18:08:05Z",
  "comments":0,
  "created_at":"2022-08-29T17:32:27Z",
  "draft":false,
  "id":1354640429,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss49_R4b",
  "number":694,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-08-29T18:08:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Avoid triggering temporary dask-awkward/awkward incompatibility.",
  "updated_at":"2022-08-29T18:08:06Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"```python\r\nIn [1]: import uproot as up\r\n\r\nIn [2]: file = up.recreate(\"example.root\")\r\n\r\nIn [3]: file[\"hist\"] = [1,2,3], [0.1, 0.2, 0.3, 0.4]\r\n# or\r\nIn [5]: import array\r\n\r\nIn [6]: file[\"hist\"] = array.array('i', [1,2,3]), array.array('d', [0.1, 0.2, 0.3, 0.4])\r\n```\r\n\r\nboth end up with long error saying\r\n```python\r\n-> 1463             uproot.writing.identify.add_to_directory(v, name, directory, streamers)\r\n   1464 \r\n   1465         self._file._cascading.streamers.update_streamers(self._file.sink, streamers)\r\n\r\n/cvmfs/sft-nightlies.cern.ch/lcg/views/dev4/Mon/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/uproot/writing/identify.py in add_to_directory(obj, name, directory, streamers)\r\n    147 \r\n    148     else:\r\n--> 149         writable = to_writable(obj)\r\n    150 \r\n    151         for rawstreamer in writable.class_rawstreamers:\r\n\r\n/cvmfs/sft-nightlies.cern.ch/lcg/views/dev4/Mon/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/uproot/writing/identify.py in to_writable(obj)\r\n    630 \r\n    631     else:\r\n--> 632         raise TypeError(\r\n    633             \"unrecognized type cannot be written to a ROOT file: \" + type(obj).__name__\r\n    634         )\r\n\r\nTypeError: unrecognized type cannot be written to a ROOT file: tuple\r\n```\r\n\r\nit feels like we can be a bit smarter about this.",
  "closed_at":"2022-09-21T14:33:54Z",
  "comments":8,
  "created_at":"2022-08-30T04:03:27Z",
  "id":1355134367,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5QxbWf",
  "number":695,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"[FR] Support non-numpy array in writing",
  "updated_at":"2022-09-21T18:57:35Z",
  "user":"MDQ6VXNlcjUzMDYyMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"When saving a histogram in a ROOT file using Uproot, if the content of the last bin in the histogram is negative, ROOT will fail to plot it. The error message is \r\n```\r\nTCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects.\r\nTCanvas::ResizePad:0: RuntimeWarning: Canvas_1 height changed from 0 to 10\r\n```\r\nIf the last bin's content is non-negative, plotting works.\r\n\r\nTo reproduce, create the histogram\r\n```py\r\nimport numpy as np\r\nimport uproot\r\n\r\nwith uproot.recreate(\"test.root\") as f:\r\n    f[\"hist_fail\"] = (np.asarray([-3, -2, -1]), np.asarray([0, 1, 2, 3]))\r\n    f[\"hist_pass\"] = (np.asarray([-3, -2, +1]), np.asarray([0, 1, 2, 3]))\r\n```\r\nOpening `test.root` using `rootbrowser` (or just `root`, getting the histograms, and plotting them using `Draw()`) results in the `hist_pass` being drawn, while `hist_fail` won't be.\r\n\r\nFurthermore, even the `hist_pass` isn't drawn properly - the y-axis starts at 0. When creating the same histogram in ROOT, the range includes all the events.\r\n\r\nI think the issue is caused by the errors of the histogram bins - ROOT initializes them as `sqrt(abs(content))` while uproot uses `sqrt(content)`, leading to `nan`s for negative numbers. Not sure what is special about the last bin, though.\r\n\r\nUproot 4.3.4\r\nROOT 6.26/04\r\n",
  "closed_at":"2022-09-02T13:38:17Z",
  "comments":17,
  "created_at":"2022-09-01T13:47:06Z",
  "id":1358879616,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Q_tuA",
  "number":696,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Drawing of histograms created in uproot fails in ROOT",
  "updated_at":"2022-09-09T13:37:07Z",
  "user":"MDQ6VXNlcjIzMDUyMDU0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"See example below. The exact file used is <https://github.com/iris-hep/func_adl_uproot/blob/61b35593b4512dfaf3a75054aa13ffe2fbc602b6/tests/empty_branches_tree_file.root>. It's a perfectly valid tree; there are just no entries, so I expect to get empty arrays rather than an error.\r\n\r\n```python\r\n>>> import uproot\r\n>>> uproot.__version__\r\n'5.0.0rc2'\r\n>>> uproot.dask('tests/empty_branches_tree_file.root')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/_dask.py\", line 143, in dask\r\n    return _get_dak_array(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/_dask.py\", line 483, in _get_dak_array\r\n    ].basket_entry_start_stop(0)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 2112, in basket_entry_start_stop\r\n    raise IndexError(\r\nIndexError: branch 'int_branch' has 0 baskets; cannot get starting entry for basket 0\r\nin file tests/empty_branches_tree_file.root\r\n```",
  "closed_at":"2022-09-02T16:24:03Z",
  "comments":4,
  "created_at":"2022-09-01T15:43:07Z",
  "id":1359056046,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5RAYyu",
  "number":697,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"`uproot.dask` raises error on empty branches",
  "updated_at":"2022-09-02T16:24:03Z",
  "user":"MDQ6VXNlcjMyNzczMzA0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-02T13:38:16Z",
  "comments":0,
  "created_at":"2022-09-01T23:13:36Z",
  "draft":false,
  "id":1359513964,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-Pyd7",
  "number":698,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-02T13:38:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Do not write incorrect fSumw2 in histograms (v5).",
  "updated_at":"2022-09-02T13:38:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Equivalent of #698. This is an important bug-fix and must be back-ported.",
  "closed_at":"2022-09-02T13:38:21Z",
  "comments":0,
  "created_at":"2022-09-01T23:21:44Z",
  "draft":false,
  "id":1359523952,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-P0xw",
  "number":699,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-02T13:38:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Do not write incorrect fSumw2 in histograms (v4).",
  "updated_at":"2022-09-02T13:38:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Fixes #697 ",
  "closed_at":"2022-09-02T16:24:01Z",
  "comments":1,
  "created_at":"2022-09-02T03:13:18Z",
  "draft":false,
  "id":1359651529,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-QPtm",
  "number":700,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-02T16:24:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Fixes uproot.dask bug with empty branches",
  "updated_at":"2022-09-02T16:24:02Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This adds a tiny test on an existing sample ROOT file and increases the code coverage in `streamers.py` from 65% to 88%.",
  "closed_at":"2022-09-02T21:46:00Z",
  "comments":3,
  "created_at":"2022-09-02T20:42:54Z",
  "draft":false,
  "id":1360596627,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-TYZs",
  "number":701,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add a test for a custom interpreted branch with forth",
  "updated_at":"2022-09-02T21:46:00Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Documentation for `uproot.dask` incuding changes to the getting started guide.",
  "closed_at":"2022-11-28T20:59:46Z",
  "comments":4,
  "created_at":"2022-09-03T08:34:27Z",
  "draft":false,
  "id":1360797541,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-UAMd",
  "number":702,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-28T20:59:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: `uproot.dask` docs",
  "updated_at":"2023-02-15T19:10:51Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"This PR tackles 2 very similar things together:\r\n1. `from_map` optimisation for dask-numpy arrays with `open_files=False`.\r\n2. Tests for empty arrays with delayed open for dask-numpy and dask-awkward. I added this because the chunking mechanism for delayed-file-open calls is handled differently and might not match the behaviour discussed in #697. These tests increase coverage and assure us the chunks are as expected.\r\n\r\nThis is PR is ready for review @jpivarski ",
  "closed_at":"2022-09-05T14:13:44Z",
  "comments":2,
  "created_at":"2022-09-03T10:29:43Z",
  "draft":false,
  "id":1360818900,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-UEJS",
  "number":703,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-05T14:13:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Use `from_map` optimization for delayed numpy arrays and add tests with empty branches for the same",
  "updated_at":"2022-09-05T14:13:44Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello,\r\n\r\nI've tried to use uproot to parse *.root files; At the same time, I used c++ to verify.\r\n\r\nIn the same root file:\r\nFor Python: \r\n```python\r\nimport uproot\r\nuproot.__version__         # (4.0.11)\r\n\r\nCoins = uproot.open(input_file + ':Coincidences')\r\nprint(Coins.num_entries)\r\n```\r\nFor C++:\r\n```c++\r\n#include \"TFile.h\"\r\n#include \"TTree.h\"\r\n\r\nTFile *rootFile;\r\nrootFile = TFile::Open(root_filename.c_str());\r\nTTree *Coins = (TTree*)rootFile->Get(\"Coincidences\");\r\n\r\nint nevents = Coins->GetEntries();\r\nstd::cout << nevents << std::endl;\r\n```\r\n\r\n\r\nThe results:\r\n- Python: 34393000\r\n- C++    : 34393400\r\n\r\nWhy???\r\n\r\nBest regards,\r\n\r\nConnor,",
  "closed_at":"2022-09-20T20:25:05Z",
  "comments":13,
  "created_at":"2022-09-05T03:11:30Z",
  "id":1361360286,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5RJLWe",
  "number":704,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Which cycle ReadOnlyDirectory should return when not specified",
  "updated_at":"2022-09-20T20:25:05Z",
  "user":"MDQ6VXNlcjIyMDI2NTQ2"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2023-01-06T19:42:25Z",
  "comments":21,
  "created_at":"2022-09-05T14:48:49Z",
  "draft":false,
  "id":1362118139,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-YOua",
  "number":705,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2023-01-06T19:42:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: Infrastructure for writing of RNTuple (incomplete functionality)",
  "updated_at":"2023-11-12T11:55:48Z",
  "user":"MDQ6VXNlcjUzMDYyMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/psf/black: 22.6.0 \u2192 22.8.0](https://github.com/psf/black/compare/22.6.0...22.8.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-09-12T22:46:02Z",
  "comments":0,
  "created_at":"2022-09-05T21:34:47Z",
  "draft":false,
  "id":1362484887,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-ZfgD",
  "number":706,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-12T22:46:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-09-12T22:46:03Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"```py\r\n>>> uproot.__version__\r\n'4.3.4'\r\n>>> v = uproot.open(\"bb-pdf-cables-cables_all-Co60.root\")[\"NumberOfPrimariesEdep\"] # <Unknown TParameter<Long64_t> at 0x7fae30e27e50>\r\n>>> v.members\r\n{}\r\n```\r\nSo I cannot obviously ask for `fVal`. Bug? ([bb-pdf-cables-cables_all-Co60.root](https://github.com/scikit-hep/uproot5/files/9506174/bb-pdf-cables-cables_all-Co60.root.txt))\r\n\r\n",
  "closed_at":"2022-09-20T21:17:12Z",
  "comments":1,
  "created_at":"2022-09-07T12:36:19Z",
  "id":1364600636,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5RVic8",
  "number":707,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Cannot read `TParameter<Long64_t>`",
  "updated_at":"2022-09-20T21:17:12Z",
  "user":"MDQ6VXNlcjIwMzU4MTky"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Just added an image to `docs-img/diagrams`.\r\n\r\n@jpivarski Merging this will help me add the image to the Getting Started guide. I looked at the other images being used in the documentation, all of them are being fetched through `raw.githubusercontent.com`",
  "closed_at":"2022-09-08T14:01:54Z",
  "comments":0,
  "created_at":"2022-09-08T13:08:43Z",
  "draft":false,
  "id":1366296374,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-mRHw",
  "number":708,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-08T14:01:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: Add image for dask docs",
  "updated_at":"2022-09-08T14:01:55Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello, \r\n\r\nI am currently experiencing an issue related to `uproot.iterate` of streamed `.root` files.\r\n\r\nIt seems that the streamed file is not always kept open until all data is used up, leading to a `ValueError: I/O operation on closed file` error. There was no issue when reading the same file from a local directory.\r\nWith the setup as shown below, the error occurs in about 10% of the runs. It is likely that this number is dependent on the available memory of the machine. \r\nWhen we lowered the amount of data in each batch from 100 KB to just 10 KB, the issue happened in 100% of runs.\r\nAs the way, the events are processed is quite memory intensive, the small data batches (100 KB) are necessary.\r\n\r\nI am not sure if the issue lies with uproot, XRootD, the small size of the used data batches or the way the root file was created.\r\n\r\nBest regards,\r\nTim\r\n\r\n\r\n\r\nThe file used in the example:\r\nhttps://www.dropbox.com/s/ztw85ira3o8kz0z/2018_mt_emb_emb_datashard_fold0.root?dl=0\r\n\r\nThe issue was experienced with python 3.10, uproot 4.3.5 and XRootD 5.5.0\r\n\r\nThe testing script:\r\n```python\r\nimport uproot\r\nprint(uproot.__version__)\r\n\r\npath_local = \"2018_mt_emb_emb_datashard_fold0.root\"\r\npath_remote = \"root://cmsxrootd-kit.gridka.de//store/user/tvoigtlaender/uproot_issue/2018_mt_emb_emb_datashard_fold0.root\"\r\n\r\nvariables = [\"pt_1\", \"pt_2\", \"m_vis\", \"njets\", \"jpt_1\", \"jpt_2\"]\r\n\r\nprint(\"\\nTest with local file\")\r\nfor i, vals in enumerate(uproot.iterate(path_local, expressions=variables, library=\"np\", step_size=\"100 KB\")):\r\n    print(\"Events in batch {}: {}\".format(i, len(vals[variables[0]])))\r\n\r\nprint(\"\\nTest with remote file\")\r\nfor i, vals in enumerate(uproot.iterate(path_remote, expressions=variables, library=\"np\", step_size=\"100 KB\")):\r\n    print(\"Events in batch {}: {}\".format(i, len(vals[variables[0]])))\r\n```\r\nThe error:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/work/tvoigtlaender/uproot_issue/test.py\", line 14, in <module>\r\n    for i, vals in enumerate(uproot.iterate(path_remote, expressions=variables, library=\"np\", step_size=\"100 KB\")):\r\n  File \"/work/tvoigtlaender/uproot_issue/miniconda/envs/test_env/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 190, in iterate\r\n    for item in hasbranches.iterate(\r\n  File \"/work/tvoigtlaender/uproot_issue/miniconda/envs/test_env/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 1488, in iterate\r\n    _ranges_or_baskets_to_arrays(\r\n  File \"/work/tvoigtlaender/uproot_issue/miniconda/envs/test_env/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 3405, in _ranges_or_baskets_to_arrays\r\n    hasbranches._file.source.chunks(ranges, notifications=notifications)\r\n  File \"/work/tvoigtlaender/uproot_issue/miniconda/envs/test_env/lib/python3.10/site-packages/uproot/source/xrootd.py\", line 371, in chunks\r\n    status = self._resource.file.vector_read(\r\n  File \"/work/tvoigtlaender/uproot_issue/miniconda/envs/test_env/lib/python3.10/site-packages/XRootD/client/file.py\", line 236, in vector_read\r\n    return XRootDStatus(self.__file.vector_read(chunks, timeout, callback))\r\nValueError: I/O operation on closed file\r\n```",
  "closed_at":null,
  "comments":1,
  "created_at":"2022-09-12T13:23:12Z",
  "id":1369905655,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Rpxn3",
  "number":709,
  "performed_via_github_app":null,
  "reactions":{
   "+1":2,
   "total_count":2
  },
  "state":"open",
  "state_reason":null,
  "title":"Streamed .root file closed during `uproot.iterate`",
  "updated_at":"2023-07-26T11:55:40Z",
  "user":"MDQ6VXNlcjc0MTg4Njk5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-10-28T22:49:19Z",
  "comments":3,
  "created_at":"2022-09-13T13:43:15Z",
  "draft":false,
  "id":1371482134,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4-3dx_",
  "number":710,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-28T22:49:19Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"refactor: refactor Forth generation",
  "updated_at":"2022-10-28T22:49:20Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello everyone,\r\n\r\nWhen one wants to save a pandas array in a root file without having awkward library install, an incorrect/hard to understand error is raised.\r\n\r\nIn writing/identify.py, line 124 a break is triggered on import error leading to the else clause of the for loop not to be triggered line 141 and finally to a failure with \"unrecognized type cannot be written to a ROOT file: \\_\\_dict\\_\\_'\" on line 639.\r\nFrom this single raised error it is very difficult to understand that the awkward library is missing.\r\n\r\nI would advise to raise a more explicit error inviting the user to install awkward library.\r\n\r\nThanks for reading.",
  "closed_at":"2022-11-11T12:04:38Z",
  "comments":1,
  "created_at":"2022-09-13T14:12:10Z",
  "id":1371525432,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Rv9E4",
  "number":711,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Hidden error when saving pandas aaray to root file without awkward installed",
  "updated_at":"2023-02-15T19:10:51Z",
  "user":"MDQ6VXNlcjI4NDQwNzM3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"When using `uproot.num_entries` to read the number of entries for a lot of remote files, I eventually run into `RuntimeError: can't start new thread`. I cannot reproduce this with local files. This is tested with `uproot` version 4.3.5.\r\n```python\r\nimport uproot\r\nimport threading\r\n\r\nfor _ in range(10):\r\n    next(uproot.num_entries(\"https://github.com/scikit-hep/scikit-hep-testdata/\"\\\r\n            \"blob/main/src/skhep_testdata/data/uproot-HZZ.root?raw=true:events\"))\r\n    print(threading.active_count())\r\n```\r\noutput:\r\n```\r\n2\r\n3\r\n4\r\n5\r\n6\r\n7\r\n8\r\n9\r\n10\r\n11\r\n```",
  "closed_at":"2022-09-19T09:37:48Z",
  "comments":1,
  "created_at":"2022-09-16T20:14:21Z",
  "id":1376428750,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5SCqLO",
  "number":712,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Threads staying open after `uproot.num_entries`",
  "updated_at":"2022-09-19T09:37:48Z",
  "user":"MDQ6VXNlcjQ1MDA5MzU1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Long term I think we should be dealing with a per-process pool rather than a per-source pool, but that's a bigger task.\r\n\r\nFixes #712 \r\n\r\n@alexander-held would you be able to check that this works in your context w/o any changes to `HTTPSource.__del__`?",
  "closed_at":"2022-09-19T09:37:47Z",
  "comments":2,
  "created_at":"2022-09-17T08:26:35Z",
  "draft":false,
  "id":1376707102,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_I04U",
  "number":713,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-19T09:37:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: use ctx manager to ensure resources are freed",
  "updated_at":"2022-09-19T09:37:48Z",
  "user":"MDQ6VXNlcjEyNDg0MTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-18T15:36:53Z",
  "comments":6,
  "created_at":"2022-09-17T16:19:07Z",
  "draft":false,
  "id":1376813210,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_JIH2",
  "number":714,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-18T15:36:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: dask_awkward.test_utils moved in ContinuumIO/dask-awkward#76",
  "updated_at":"2022-09-18T15:36:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-20T20:25:04Z",
  "comments":5,
  "created_at":"2022-09-19T19:44:45Z",
  "draft":false,
  "id":1378443539,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_OZSk",
  "number":715,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T20:25:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: ReadOnlyDirectory should provide the largest abs(cycle) when cycle is unspecified, not the largest cycle.",
  "updated_at":"2022-09-20T20:25:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.37.3 \u2192 v2.38.0](https://github.com/asottile/pyupgrade/compare/v2.37.3...v2.38.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-09-20T21:20:35Z",
  "comments":1,
  "created_at":"2022-09-19T21:39:36Z",
  "draft":false,
  "id":1378554100,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_Ow3o",
  "number":716,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T21:20:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-09-20T21:20:36Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-20T21:17:11Z",
  "comments":3,
  "created_at":"2022-09-19T22:34:24Z",
  "draft":false,
  "id":1378600771,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_O6_T",
  "number":717,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T21:17:11Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: regularize ROOT type aliases to C fundamental type names.",
  "updated_at":"2022-09-20T21:17:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This PR is the \"v4\" version of #717, which ultimately fixes #707.",
  "closed_at":"2022-09-20T21:17:17Z",
  "comments":4,
  "created_at":"2022-09-19T22:39:29Z",
  "draft":false,
  "id":1378604067,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_O7tL",
  "number":718,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T21:17:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: regularize ROOT type aliases to C fundamental type names (v4).",
  "updated_at":"2022-09-20T21:17:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is needed for all PRs targeting `main`.\r\n\r\nIt should be fast-tracked into `main` so that it can be used in all those PRs.",
  "closed_at":"2022-09-20T16:26:22Z",
  "comments":2,
  "created_at":"2022-09-19T22:48:56Z",
  "draft":false,
  "id":1378610292,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_O9CG",
  "number":719,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T16:26:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"test: adjust for boost-histogram 1.3.2's _storage_type deprecation.",
  "updated_at":"2022-09-20T16:26:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is needed for all PRs targeting `main-v4`.\r\n\r\nIt should be fast-tracked into `main-v4` so that it can be used in all those PRs.",
  "closed_at":"2022-09-20T16:26:35Z",
  "comments":0,
  "created_at":"2022-09-19T22:51:30Z",
  "draft":false,
  "id":1378611940,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_O9YT",
  "number":720,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T16:26:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"test: adjust for boost-histogram 1.3.2's _storage_type deprecation (v4).",
  "updated_at":"2022-09-20T16:26:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is the \"v4\" version of #715.\r\n\r\nLike the other in-flight PRs, it will follow this procedure:\r\n\r\n  1. #720 gets approved and merged into `main-v4`.\r\n  2. This PR updates to `main-v4`.\r\n  3. The tests re-run and pass (again).\r\n  4. This PR gets approved and merged into `main-v4`.",
  "closed_at":"2022-09-20T19:33:38Z",
  "comments":2,
  "created_at":"2022-09-19T23:15:04Z",
  "draft":false,
  "id":1378626790,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_PAkx",
  "number":721,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-20T19:33:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: ReadOnlyDirectory should provide the largest abs(cycle) when cycle is unspecified, not the largest cycle (v4).",
  "updated_at":"2022-09-20T19:33:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I'm trying to read the histogram \"hist\" in this file [file.root.zip](https://github.com/scikit-hep/uproot5/files/9604957/file.root.zip) and I can indeed use `uproot.open`, but when trying to convert it to a boost histogram or a hist with `to_boost()` or `to_hist()` I get\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In [312], line 2\r\n      1 f = uproot.open(\"file.root\")\r\n----> 2 f['hist'].to_hist().plot()\r\n\r\nFile ~/opt/anaconda3/envs/ml/lib/python3.10/site-packages/uproot/behaviors/TH1.py:206, in Histogram.to_hist(self, metadata, axis_metadata)\r\n    195 def to_hist(self, metadata=boost_metadata, axis_metadata=boost_axis_metadata):\r\n    196     \"\"\"\r\n    197     Args:\r\n    198         metadata (dict of str \\u2192 str): Metadata to collect (keys) and\r\n   (...)\r\n    203     Converts the histogram into a ``hist`` object.\r\n    204     \"\"\"\r\n    205     return uproot.extras.hist().Hist(\r\n--> 206         self.to_boost(metadata=boost_metadata, axis_metadata=boost_axis_metadata)\r\n    207     )\r\n\r\nFile ~/opt/anaconda3/envs/ml/lib/python3.10/site-packages/uproot/behaviors/TH1.py:325, in TH1.to_boost(self, metadata, axis_metadata)\r\n    323     view.variance = sumw2\r\n    324 else:\r\n--> 325     view[...] = values\r\n    327 return out\r\n\r\nFile ~/opt/anaconda3/envs/ml/lib/python3.10/site-packages/boost_histogram/_internal/view.py:51, in View.__setitem__(self, ind, value)\r\n     49     super().__setitem__(ind, array)  # type: ignore[no-untyped-call]\r\n     50 else:\r\n---> 51     raise ValueError(\"Needs matching ndarray or n+1 dim array\")\r\n\r\nValueError: Needs matching ndarray or n+1 dim array\r\n```\r\nthe `to_numpy()` method however works just fine.\r\n\r\nBest,\r\nFrancesco\r\n",
  "closed_at":"2022-11-02T14:26:52Z",
  "comments":2,
  "created_at":"2022-09-20T07:17:00Z",
  "id":1378935802,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5SMOP6",
  "number":722,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Cannot convert `TH1` to hist via `.to_boost()`",
  "updated_at":"2023-02-15T19:10:52Z",
  "user":"MDQ6VXNlcjY2OTAzMDc3"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjUwNTc3ODA5",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Following up on #710, but as a new PR:\r\n\r\n- [x] Rename `GenHelper` to `ForthLevelStash` with docstring explaining how it's stashing code for just one level (as opposed to `ForthGenerator`, which descends all the way down and actually generates).\r\n- [x] Replace `helper_obj = uproot._awkward_forth.GenHelper(context)` constructor with `forth_stash = uproot._awkward_forth.forth_stash(context)` function that can return `None`; only making the `ForthLevelStash` if it's actually going to be generating Forth code. Then _all_ the `if helper_obj.is_forth()` become `if forth_stash is not None`.\r\n- [x] Non-forthable Models cancel Forth-generation. Need a \"cancel\" flag on ForthGenerator that AsObjects uses to `del context[\"forth\"]` at the end of an entry. Then the old, non-Forth path continues from there. (We also have a contingency to turn off broken Forth generation, if a user discovers it somewhere.)\r\n- [x] Add try-except logic to [this line](https://github.com/scikit-hep/uproot5/blob/20ebe9b81ae61b39157e5d725da0d67940a3e212/src/uproot/deserialization.py#L71) to catch `SyntaxError as err` and then `raise SyntaxError(class_code + \"\\n\\n\" + str(err)) from err`.\r\n- [x] Find out what went wrong in the indentation (8 spaces in most places) in streamers.py.",
  "closed_at":"2022-11-10T23:30:42Z",
  "comments":1,
  "created_at":"2022-09-20T15:00:33Z",
  "id":1379569709,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5SOpAt",
  "number":723,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Next (last) steps for Forth generation",
  "updated_at":"2023-02-15T19:10:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-20T15:01:31Z",
  "comments":1,
  "created_at":"2022-09-20T15:01:09Z",
  "id":1379570591,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5SOpOf",
  "number":724,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Replace `helper_obj = uproot._awkward_forth.GenHelper(context)` constructor with `forth_stash = uproot._awkward_forth.forth_stash(context)` function that can return `None`; only making the `ForthLevelStash` if it's actually going to be generating Forth code. Then all the `if helper_obj.is_forth()` become `if forth_stash is not None`.",
  "updated_at":"2022-09-20T15:01:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This PR shows how to add column projection to `uproot.dask` when `library=\"ak\"`. For this to work properly right now it would require the changes that are in ContinuumIO/dask-awkward#80 (still WIP). I've made this draft PR just to share the planned interface for making I/O column-project-able. Since `uproot.dask(..., library=\"ak\")` already uses `dask_awkward.from_map(fn: Callable, ...)`, all `fn` needs is a `project_columns` method.",
  "closed_at":"2022-11-09T14:57:13Z",
  "comments":1,
  "created_at":"2022-09-21T13:57:33Z",
  "draft":true,
  "id":1380981375,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_Wpnw",
  "number":725,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: (POC) Add column projection for reading to dask_awkward",
  "updated_at":"2023-02-15T19:10:54Z",
  "user":"MDQ6VXNlcjMyMDIwOTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Hi @jpivarski, @henryiii, @agoose77, @reikdas, @kkothari2001, @aryan26roy, @Moelf, @nsmith-, @chrisburr, @kratsg!\r\n\r\nI made this author list for Uproot by scanning through _all_ the Uproot 1-3 and Uproot 4-5 contributions and identifying those of you who have made major contributions. It's hard to put a cut-off on \"major\" and I definitely appreciate all of the community contributions. I think a good way to recognize them both is with a CITATION.cff _and_ an .all-contributorsrc.\r\n\r\nTake a look at your entry in the CITATIONS.cff file and let me know if something should be changed: email, institution, name/spelling, and @kkothari2001 and @aryan26roy, let me know if you have or get an ORCID (https://orcid.org).\r\n\r\nIf you think I've missed someone, I can consider adding one or two more names to the author list. Below are the notes that I took while scanning through all the contributions.\r\n\r\n### Uproot 1-3:\r\n\r\n- `plexoos`: devops and some interpretations (Double32)\r\n- `matthewfeickert`: devops\r\n- `tamasgal`: interpretations\r\n- `kreczko`: provenance\r\n- `oshadura`: ZSTD compression\r\n- `nbiederbeck`: HTTP authentication\r\n- `masonproffitt`: classname function and interpretation (long long)\r\n- `benkrikler`: entry numbering when iterating over Pandas\r\n- `guitargeek`: aligned Pandas output\r\n- `bfis`: File.update\r\n- `ast0815`: skip missing TTrees in iterate\r\n- `jrueb`: lax conformance between files\r\n- `HealthyPear`: file reporting in uproot.iterate\r\n\r\n### Uproot 4-5:\r\n\r\n- `veprbl`: devops, TDatime, TTable[^1]\r\n- `nikoladze`: XRootD bug-fixes[^1]\r\n- `jrueb`: WritableFile improvements\r\n- `ryuwd`: XRootD bug-fixes/work-arounds\r\n- `douglasdavis`: TArrayD.reshape\r\n- `kakwok`: ReadOnlyDirectory initialization bug\r\n- `pfackeldey`: memmap streamlining\r\n- `mpad`: AsDtypeInPlace\r\n- `btovar`: exception-handling for multithreaded\r\n- `duncanmmacleod`: devops (test suite in source dist)\r\n- `klieret`: docs[^1]\r\n- `dcervenkov`: XRootD version string handling[^1]\r\n- `beojan`: TGraph, RooCurve, RooHist behaviors[^1]\r\n- `cozzyd`: HTTP authentication\r\n- `HealthyPear`: TProfile reading bug\r\n- `tamasgal`: fix lazy\r\n- `andrzejnovak`: Damerau-Levenshtein distance for KeyNotFound reporting\r\n- `raymondEhlers`: histogram axis swap\r\n- `bendavid`: faster jagged header bytes removal\r\n\r\n[^1]: needs all-contributors\r\n",
  "closed_at":"2022-09-23T13:45:28Z",
  "comments":6,
  "created_at":"2022-09-22T19:08:21Z",
  "draft":false,
  "id":1382893716,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c8Bp",
  "number":726,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-23T13:45:28Z"
  },
  "reactions":{
   "+1":3,
   "heart":1,
   "total_count":4
  },
  "state":"closed",
  "state_reason":null,
  "title":"docs: add a CITATION.cff for Uproot.",
  "updated_at":"2022-09-23T13:55:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Hi, I was scanning through contributions to Uproot and realized that I missed some. I'll close this issue when all are included.",
  "closed_at":"2022-09-22T19:32:49Z",
  "comments":15,
  "created_at":"2022-09-22T19:14:43Z",
  "id":1382900866,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5SbWSC",
  "number":727,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Contributors who are missing from all-contributors",
  "updated_at":"2022-09-22T19:32:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @veprbl as a contributor for code, infra.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255445226)",
  "closed_at":"2022-09-22T19:15:44Z",
  "comments":0,
  "created_at":"2022-09-22T19:15:07Z",
  "draft":false,
  "id":1382901286,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c9pN",
  "number":728,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:15:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add veprbl as a contributor",
  "updated_at":"2022-09-22T19:15:44Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @nikoladze as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255447365)",
  "closed_at":"2022-09-22T19:17:38Z",
  "comments":0,
  "created_at":"2022-09-22T19:17:18Z",
  "draft":false,
  "id":1382903644,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c-Ja",
  "number":729,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:17:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add nikoladze as a contributor",
  "updated_at":"2022-09-22T19:17:39Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @klieret as a contributor for doc.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255448349)",
  "closed_at":"2022-09-22T19:18:34Z",
  "comments":0,
  "created_at":"2022-09-22T19:18:15Z",
  "draft":false,
  "id":1382904678,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c-Xk",
  "number":730,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:18:34Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add klieret as a contributor",
  "updated_at":"2022-09-22T19:18:35Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @dcervenkov as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255449230)",
  "closed_at":"2022-09-22T19:19:24Z",
  "comments":0,
  "created_at":"2022-09-22T19:19:05Z",
  "draft":false,
  "id":1382905600,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c-kJ",
  "number":731,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:19:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add dcervenkov as a contributor",
  "updated_at":"2022-09-22T19:19:24Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @beojan as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255450240)",
  "closed_at":"2022-09-22T19:20:18Z",
  "comments":0,
  "created_at":"2022-09-22T19:20:00Z",
  "draft":false,
  "id":1382906607,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_c-xg",
  "number":732,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:20:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add beojan as a contributor",
  "updated_at":"2022-09-22T19:20:19Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @agoose77 as a contributor for code, maintenance.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/issues/727#issuecomment-1255462518)",
  "closed_at":"2022-09-22T19:32:33Z",
  "comments":0,
  "created_at":"2022-09-22T19:32:14Z",
  "draft":false,
  "id":1382919686,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_dBh_",
  "number":733,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-22T19:32:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"add agoose77 as a contributor",
  "updated_at":"2022-09-22T19:32:33Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-11-28T19:14:48Z",
  "comments":6,
  "created_at":"2022-09-23T09:14:57Z",
  "draft":false,
  "id":1383515905,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_e9Xk",
  "number":734,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-28T19:14:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: Use awkward pandas, instead of the existing code that explodes Pandas Dataframes",
  "updated_at":"2023-02-15T19:10:54Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"This can't be merged until we have an `awkward==2.0.0rc0` out.",
  "closed_at":"2022-09-30T18:30:15Z",
  "comments":4,
  "created_at":"2022-09-26T14:16:58Z",
  "draft":true,
  "id":1386163948,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_nHnQ",
  "number":736,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: use the v2 main release",
  "updated_at":"2022-09-30T19:32:55Z",
  "user":"MDQ6VXNlcjEyNDg0MTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v2.38.0 \u2192 v3.1.0](https://github.com/asottile/pyupgrade/compare/v2.38.0...v3.1.0)\n- [github.com/psf/black: 22.8.0 \u2192 22.10.0](https://github.com/psf/black/compare/22.8.0...22.10.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-10-26T14:03:50Z",
  "comments":0,
  "created_at":"2022-09-26T21:47:14Z",
  "draft":false,
  "id":1386766596,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_pKzK",
  "number":737,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-26T14:03:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore(deps): update pre-commit hooks",
  "updated_at":"2022-10-26T14:03:51Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Uproot can open and read remote files, but AFAIK, it cannot write them - `recreate()` needs a local path only.\r\n\r\nDo you plan to support this? Or is there a reason why this can't work/is problematic?\r\n",
  "closed_at":"2022-09-28T19:23:32Z",
  "comments":3,
  "created_at":"2022-09-28T15:17:04Z",
  "id":1389543580,
  "labels":null,
  "locked":true,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5S0sCc",
  "number":738,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Writing remote files via XRootD",
  "updated_at":"2022-09-28T19:23:32Z",
  "user":"MDQ6VXNlcjIzMDUyMDU0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Starting by adapting to API changes and removing the \"`_v2`\" submodule.",
  "closed_at":"2022-10-26T13:51:44Z",
  "comments":5,
  "created_at":"2022-09-29T18:53:41Z",
  "draft":false,
  "id":1391343789,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_4ZYh",
  "number":741,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"refactor: prepare for Awkward 2.0.0rc1",
  "updated_at":"2022-10-26T13:51:48Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-09-30T20:18:49Z",
  "comments":3,
  "created_at":"2022-09-29T19:19:10Z",
  "draft":false,
  "id":1391374678,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss4_4gEH",
  "number":742,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-09-30T20:18:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: drop Python 3.6.",
  "updated_at":"2022-09-30T20:18:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Added in #742, was tracking https://github.com/actions/python-versions/pull/189, and fixed in https://github.com/actions/setup-python/issues/512.",
  "closed_at":"2022-10-03T19:00:42Z",
  "comments":0,
  "created_at":"2022-10-03T18:48:46Z",
  "draft":false,
  "id":1395171742,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AFCjT",
  "number":743,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-03T19:00:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: remove GHA workaround for macOS Python 3.11",
  "updated_at":"2022-10-03T19:00:43Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I've added a few cleanups based on `pipx run refurb src`. I didn't work on else after return (there's a lot of them), or on ones that were not clearly an improvement, but I liked these.\n\n- chore: remove extra returns\n- chore: using copy for dicts (better readability)\n- chore: nicer strings and comparisons\n- chore: use contextlib.suppress\n",
  "closed_at":"2022-10-05T18:07:31Z",
  "comments":0,
  "created_at":"2022-10-05T16:01:41Z",
  "draft":false,
  "id":1398033825,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AOi3N",
  "number":745,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-05T18:07:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: some cleanup inpsired by refurb",
  "updated_at":"2022-10-05T18:07:31Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"For all Interpretations other than AsMap, the non-memberwise case is implemented, and the memberwise case is implemented for only very few (and partially, at that). That's because when I tried making all combinations of STL containers, `std::map` consistently got serialized in a memberwise way, so I had no examples of what non-memberwise serialization looked like.\r\n\r\nEarlier this year, however, I found an example: #556, and earlier today, a user encountered it: #744. Apparently, maps of parameter names and values are serialized as memberwise `std::map` in TFormula, which is part of a TF1 that can be attached to a TH1 histogram. So adding this implementation enables reading histograms with attached fit functions.\r\n\r\nThere's no indication yet that memberwise `std::map` appears in TTrees, so it's not yet clear that we'll need an AwkwardForth implementation. Furthermore, the two examples (#556 and #744) are in histograms, not TTrees, so we wouldn't be able to test an AwkwardForth implementation.\r\n\r\nThe memberwise `std::map` turns out to be very simple, though: just\r\n\r\n   1. (4 bytes) length of map\r\n   2. deserialize one key\r\n   3. deserialize one value\r\n   4. GOTO 2, until end of map\r\n\r\nI also don't have any files that are small enough to add to scikit-hep-testdata, so no tests, unfortunately.",
  "closed_at":"2022-10-05T19:24:56Z",
  "comments":1,
  "created_at":"2022-10-05T18:40:34Z",
  "draft":false,
  "id":1398210459,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5APIxl",
  "number":746,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-05T19:24:56Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: implemented NON-memberwise deserialization for AsMap.",
  "updated_at":"2022-10-05T19:24:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Just like #746, but patching Uproot v4.",
  "closed_at":"2022-10-05T19:25:03Z",
  "comments":0,
  "created_at":"2022-10-05T18:48:49Z",
  "draft":false,
  "id":1398219481,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5APKs2",
  "number":747,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-05T19:25:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: implemented NON-memberwise deserialization for AsMap (v4).",
  "updated_at":"2022-10-05T19:25:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":null,
  "closed_at":"2022-11-06T09:49:36Z",
  "comments":7,
  "created_at":"2022-10-06T15:27:48Z",
  "draft":false,
  "id":1399866387,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AU2er",
  "number":749,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-06T09:49:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"refactor: final refactoring for Forth generation",
  "updated_at":"2023-02-15T19:10:55Z",
  "user":"MDQ6VXNlcjUwNTc3ODA5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I have written 2 .root files with uproot and both of them can be accessed perfectly fine individually:\r\n```\r\nIn [3]: egamma_b = uproot.open(\"./EGamma_B.root\")\r\n\r\nIn [4]: egamma_b['tout']['Electron_eta'].array()\r\nOut[4]: <Array [-0.656, -0.725, ... -1.67, 0.241] type='148 * float64'>\r\n\r\nIn [6]: egamma_c = uproot.open(\"./EGamma_C.root\")\r\n\r\nIn [7]: egamma_c['tout']['Electron_eta'].array()\r\nOut[7]: <Array [-0.613, 0.572, ... 0.957, -0.981] type='164 * float64'>\r\n\r\n```\r\n\r\nAfter hadding them like this:\r\n\r\n```\r\nhadd Data.root EGamma_B.root EGamma_C.root\r\n```\r\naccessing the resulting file \r\n```\r\nIn [8]: data = uproot.open(\"./Data.root\")\r\n\r\nIn [9]: data['tout']['Electron_eta'].array()\r\n\r\n```\r\n\r\nraises a deserialisation error:\r\n```\r\n---------------------------------------------------------------------------\r\nDeserializationError                      Traceback (most recent call last)\r\nCell In [9], line 1\r\n----> 1 data['tout']['Electron_eta'].array()\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:2210, in TBranch.array(self, interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library)\r\n   2204             for (\r\n   2205                 basket_num,\r\n   2206                 range_or_basket,\r\n   2207             ) in branch.entries_to_ranges_or_baskets(entry_start, entry_stop):\r\n   2208                 ranges_or_baskets.append((branch, basket_num, range_or_basket))\r\n-> 2210 _ranges_or_baskets_to_arrays(\r\n   2211     self,\r\n   2212     ranges_or_baskets,\r\n   2213     branchid_interpretation,\r\n   2214     entry_start,\r\n   2215     entry_stop,\r\n   2216     decompression_executor,\r\n   2217     interpretation_executor,\r\n   2218     library,\r\n   2219     arrays,\r\n   2220     False,\r\n   2221 )\r\n   2223 _fix_asgrouped(\r\n   2224     arrays, expression_context, branchid_interpretation, library, None\r\n   2225 )\r\n   2227 if array_cache is not None:\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3495, in _ranges_or_baskets_to_arrays(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\r\n   3492     pass\r\n   3494 elif isinstance(obj, tuple) and len(obj) == 3:\r\n-> 3495     uproot.source.futures.delayed_raise(*obj)\r\n   3497 else:\r\n   3498     raise AssertionError(obj)\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/source/futures.py:36, in delayed_raise(exception_class, exception_value, traceback)\r\n     32 def delayed_raise(exception_class, exception_value, traceback):\r\n     33     \"\"\"\r\n     34     Raise an exception from a background thread on the main thread.\r\n     35     \"\"\"\r\n---> 36     raise exception_value.with_traceback(traceback)\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3416, in _ranges_or_baskets_to_arrays.<locals>.chunk_to_basket(chunk, branch, basket_num)\r\n   3414 try:\r\n   3415     cursor = uproot.source.cursor.Cursor(chunk.start)\r\n-> 3416     basket = uproot.models.TBasket.Model_TBasket.read(\r\n   3417         chunk,\r\n   3418         cursor,\r\n   3419         {\"basket_num\": basket_num},\r\n   3420         hasbranches._file,\r\n   3421         hasbranches._file,\r\n   3422         branch,\r\n   3423     )\r\n   3424     original_index = range_original_index[(chunk.start, chunk.stop)]\r\n   3425     if update_ranges_or_baskets:\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/model.py:806, in Model.read(cls, chunk, cursor, context, file, selffile, parent, concrete)\r\n    801 if context.get(\"reading\", True):\r\n    802     self.hook_before_read_members(\r\n    803         chunk=chunk, cursor=cursor, context=context, file=file\r\n    804     )\r\n--> 806     self.read_members(chunk, cursor, context, file)\r\n    808     self.hook_after_read_members(\r\n    809         chunk=chunk, cursor=cursor, context=context, file=file\r\n    810     )\r\n    812 self.check_numbytes(chunk, cursor, context)\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/models/TBasket.py:275, in Model_TBasket.read_members(self, chunk, cursor, context, file)\r\n    272     cursor.skip(self._members[\"fKeylen\"])\r\n    274     self._raw_data = None\r\n--> 275     self._data = cursor.bytes(chunk, self.border, context)\r\n    277 else:\r\n    278     compressed_bytes = self._members[\"fNbytes\"] - self._members[\"fKeylen\"]\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/source/cursor.py:310, in Cursor.bytes(self, chunk, length, context, move)\r\n    308 if move:\r\n    309     self._index = stop\r\n--> 310 return chunk.get(start, stop, self, context)\r\n\r\nFile ~/miniconda3/envs/shep/lib/python3.10/site-packages/uproot/source/chunk.py:425, in Chunk.get(self, start, stop, cursor, context)\r\n    422             return self._raw_data[local_start:local_stop]\r\n    424         else:\r\n--> 425             raise uproot.deserialization.DeserializationError(\r\n    426                 \"\"\"attempting to get bytes {}:{}\r\n    427 outside expected range {}:{} for this Chunk\"\"\".format(\r\n    428                     start, stop, self._start, self._stop\r\n    429                 ),\r\n    430                 self,\r\n    431                 cursor.copy(),\r\n    432                 context,\r\n    433                 self._source.file_path,\r\n    434             )\r\n\r\nDeserializationError: while reading\r\n\r\n    TBasket version None as uproot.models.TBasket.Model_TBasket (? bytes)\r\n        fNbytes: 79\r\n        fObjlen: 0\r\n        fDatime: 1854743755\r\n        fKeylen: 79\r\n        fCycle: 0\r\n        fVersion: 3\r\n        fBufferSize: 32000\r\n        fNevBufSize: 8\r\n        fNevBuf: 0\r\n        fLast: 79\r\nMembers for TBasket: fNbytes?, fObjlen?, fDatime?, fKeylen?, fCycle?, fVersion?, fBufferSize?, fNevBufSize?, fNevBuf?, fLast?\r\n\r\nattempting to get bytes 101577:101577\r\noutside expected range 101419:101498 for this Chunk\r\nin file ./Data.root\r\n```\r\nROOT 6.26/06\r\nuproot 4.3.4\r\n\r\n[Data.root.txt](https://github.com/scikit-hep/uproot5/files/9726941/Data.root.txt)\r\n[EGamma_B.root.txt](https://github.com/scikit-hep/uproot5/files/9726942/EGamma_B.root.txt)\r\n[EGamma_C.root.txt](https://github.com/scikit-hep/uproot5/files/9726943/EGamma_C.root.txt)\r\n\r\n",
  "closed_at":"2022-10-06T19:53:34Z",
  "comments":3,
  "created_at":"2022-10-06T16:58:45Z",
  "id":1400021947,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5TcqO7",
  "number":750,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"DeserializationError after hadd ",
  "updated_at":"2022-10-06T19:53:34Z",
  "user":"MDQ6VXNlcjQ4MjgwNzYx"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The issue is that these files apparently don't have a second TKey. See https://github.com/scikit-hep/uproot5/issues/750#issuecomment-1270469267.",
  "closed_at":"2022-10-06T19:53:33Z",
  "comments":1,
  "created_at":"2022-10-06T18:06:14Z",
  "draft":false,
  "id":1400099524,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AVpzt",
  "number":751,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-06T19:53:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: avoid empty TBasket issue in embedded TBasket",
  "updated_at":"2022-10-06T19:54:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is the backport version of #751.",
  "closed_at":"2022-10-06T23:23:56Z",
  "comments":0,
  "created_at":"2022-10-06T18:08:39Z",
  "draft":false,
  "id":1400102267,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AVqZo",
  "number":752,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-06T23:23:56Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: avoid empty TBasket issue in embedded TBasket (v4)",
  "updated_at":"2022-10-06T23:23:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is a quick fix-up of #751, which shouldn't have been using Awkward in the test.\r\n\r\nIt's also interesting that it wasn't caught in `main`, only `main-v4`. In principle, there ought to be a test in our suite that doesn't install Awkward.",
  "closed_at":"2022-10-06T23:19:10Z",
  "comments":1,
  "created_at":"2022-10-06T23:11:00Z",
  "draft":false,
  "id":1400407114,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AWs6n",
  "number":753,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-06T23:19:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: don't use Awkward in test_0751 that doesn't need it",
  "updated_at":"2022-10-06T23:19:11Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"If they don't, make them the same.\r\n\r\nThe `\"uproot\"` parameters should be removed.\r\n\r\nSome of the `\"__record__\"` parameters have the C++ name; this is a good idea. We should make sure that all of them do.",
  "closed_at":"2022-11-30T16:31:09Z",
  "comments":0,
  "created_at":"2022-10-11T13:39:07Z",
  "id":1404660666,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5TuWu6",
  "number":754,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Ensure that the Forms produced by the AwkwardForth generation agree with the awkward_form methods.",
  "updated_at":"2023-02-15T19:10:56Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Include the `project_columns` method in the existing callable classes as described in #725.\r\n\r\nReady for review. cc @jpivarski @douglasdavis \r\nI wasn't sure how to test this though, any suggestions?",
  "closed_at":"2022-10-20T15:04:58Z",
  "comments":1,
  "created_at":"2022-10-11T16:33:46Z",
  "draft":false,
  "id":1404928363,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5AlgPZ",
  "number":755,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-20T15:04:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: Added column_projection optimization",
  "updated_at":"2022-10-20T15:05:00Z",
  "user":"MDQ6VXNlcjUzNjUwNTM4"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Each of the provided two .root files can be opened perfectly fine on their own:\r\n\r\n```\r\nIn [1]: import uproot\r\n\r\nIn [2]: f = uproot.open(\"./FD1F1FC5-0A2F-6445-B49F-BE0DE70B41B9_MA.root\")\r\n\r\nIn [3]: f['tout']['Muon_pt'].array()\r\nOut[3]: <Array [] type='0 * float64'>\r\n\r\nIn [4]: g = uproot.open(\"./FDF4838A-7644-014B-B2CD-1B2747CC43C3_MA.root\")\r\n\r\nIn [5]: g['tout']['Muon_pt'].array()\r\nOut[5]: <Array [32.5, 37.4, 34.1] type='3 * float64'>\r\n```\r\n\r\nafter \r\n```\r\nhadd` test.root FD1F1FC5-0A2F-6445-B49F-BE0DE70B41B9_MA.root FDF4838A-7644-014B-B2CD-1B2747CC43C3_MA.root\r\n```\r\nwhich generates the error `Error in <TBranch::AddBasket>: An out-of-order basket matches the entry number of an existing basket.`, \r\nthe TTree 'tout' of the resulting file is faulty:\r\n\r\n```\r\nIn [1]: import uproot\r\n\r\nIn [2]: f = uproot.open(\"./test.root\")\r\n\r\nIn [3]: f['tout']['Muon_pt'].array()\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In [3], line 1\r\n----> 1 f['tout']['Muon_pt'].array()\r\n\r\nFile ~/anaconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:2208, in TBranch.array(self, interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library)\r\n   2202             for (\r\n   2203                 basket_num,\r\n   2204                 range_or_basket,\r\n   2205             ) in branch.entries_to_ranges_or_baskets(entry_start, entry_stop):\r\n   2206                 ranges_or_baskets.append((branch, basket_num, range_or_basket))\r\n-> 2208 _ranges_or_baskets_to_arrays(\r\n   2209     self,\r\n   2210     ranges_or_baskets,\r\n   2211     branchid_interpretation,\r\n   2212     entry_start,\r\n   2213     entry_stop,\r\n   2214     decompression_executor,\r\n   2215     interpretation_executor,\r\n   2216     library,\r\n   2217     arrays,\r\n   2218     False,\r\n   2219 )\r\n   2221 _fix_asgrouped(\r\n   2222     arrays, expression_context, branchid_interpretation, library, None\r\n   2223 )\r\n   2225 if array_cache is not None:\r\n\r\nFile ~/anaconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3493, in _ranges_or_baskets_to_arrays(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\r\n   3490     pass\r\n   3492 elif isinstance(obj, tuple) and len(obj) == 3:\r\n-> 3493     uproot.source.futures.delayed_raise(*obj)\r\n   3495 else:\r\n   3496     raise AssertionError(obj)\r\n\r\nFile ~/anaconda3/envs/shep/lib/python3.10/site-packages/uproot/source/futures.py:36, in delayed_raise(exception_class, exception_value, traceback)\r\n     32 def delayed_raise(exception_class, exception_value, traceback):\r\n     33     \"\"\"\r\n     34     Raise an exception from a background thread on the main thread.\r\n     35     \"\"\"\r\n---> 36     raise exception_value.with_traceback(traceback)\r\n\r\nFile ~/anaconda3/envs/shep/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3463, in _ranges_or_baskets_to_arrays.<locals>.basket_to_array(basket)\r\n   3460 basket = None\r\n   3462 if len(basket_arrays) == branchid_num_baskets[branch.cache_key]:\r\n-> 3463     arrays[branch.cache_key] = interpretation.final_array(\r\n   3464         basket_arrays,\r\n   3465         entry_start,\r\n   3466         entry_stop,\r\n   3467         branch.entry_offsets,\r\n   3468         library,\r\n   3469         branch,\r\n   3470     )\r\n   3471     # no longer needed, save memory\r\n   3472     basket_arrays.clear()\r\n\r\nFile ~/anaconda3/envs/shep/lib/python3.10/site-packages/uproot/interpretation/numerical.py:88, in Numerical.final_array(self, basket_arrays, entry_start, entry_stop, entry_offsets, library, branch)\r\n     86     local_stop = stop - start\r\n     87     basket_array = basket_arrays[basket_num]\r\n---> 88     output[: stop - entry_start] = basket_array[local_start:local_stop]\r\n     90 elif start <= entry_stop <= stop:\r\n     91     local_start = 0\r\n\r\nValueError: could not broadcast input array from shape (0,) into shape (1,)\r\n```\r\n[FD1F1FC5-0A2F-6445-B49F-BE0DE70B41B9_MA.root.txt](https://github.com/scikit-hep/uproot5/files/9766610/FD1F1FC5-0A2F-6445-B49F-BE0DE70B41B9_MA.root.txt)\r\n[FDF4838A-7644-014B-B2CD-1B2747CC43C3_MA.root.txt](https://github.com/scikit-hep/uproot5/files/9766611/FDF4838A-7644-014B-B2CD-1B2747CC43C3_MA.root.txt)\r\n",
  "closed_at":null,
  "comments":4,
  "created_at":"2022-10-12T15:49:07Z",
  "id":1406442754,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5T1J0C",
  "number":756,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"hadd on files written with uproot creates a file with broken branches",
  "updated_at":"2023-04-06T16:34:27Z",
  "user":"MDQ6VXNlcjQ4MjgwNzYx"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [amannn/action-semantic-pull-request](https://github.com/amannn/action-semantic-pull-request) from 4 to 5.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/amannn/action-semantic-pull-request/releases\">amannn/action-semantic-pull-request's releases</a>.</em></p>\n<blockquote>\n<h2>v5.0.0</h2>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.6.0...v5.0.0\">5.0.0</a> (2022-10-11)</h2>\n<h3>\u26a0 BREAKING CHANGES</h3>\n<ul>\n<li>Enum options need to be newline delimited (to allow whitespace within them) (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/205\">#205</a>)</li>\n</ul>\n<h3>Features</h3>\n<ul>\n<li>Enum options need to be newline delimited (to allow whitespace within them) (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/205\">#205</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/c906fe1e5a4bcc61624931ca94da9672107bd448\">c906fe1</a>)</li>\n</ul>\n<h2>v4.6.0</h2>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.5.0...v4.6.0\">4.6.0</a> (2022-09-26)</h2>\n<h3>Features</h3>\n<ul>\n<li>Provide error messages as <code>outputs.error_message</code> (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/194\">#194</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/880a3c061c0dea01e977cefe26fb0e0d06b3d1a9\">880a3c0</a>)</li>\n</ul>\n<h2>v4.5.0</h2>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.4.0...v4.5.0\">4.5.0</a> (2022-05-04)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add <code>disallowScopes</code> option (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/179\">#179</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/6a7ed2d5046cf8a40c60494c83c962343061874a\">6a7ed2d</a>)</li>\n</ul>\n<h2>v4.4.0</h2>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.3.0...v4.4.0\">4.4.0</a> (2022-04-22)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add options to pass custom regex to conventional-commits-parser (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/177\">#177</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/956659ae00eaa0b00fe5a58dfdf3a3db1efd1d63\">956659a</a>)</li>\n</ul>\n<h2>v4.3.0</h2>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.2.0...v4.3.0\">4.3.0</a> (2022-04-13)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add <code>ignoreLabels</code> option to opt-out of validation for certain PRs (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/174\">#174</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/277c2303f965680aed7613eb512365c58aa92b6b\">277c230</a>)</li>\n</ul>\n<h2>v4.2.0</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/amannn/action-semantic-pull-request/blob/main/CHANGELOG.md\">amannn/action-semantic-pull-request's changelog</a>.</em></p>\n<blockquote>\n<h3><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v5.0.0...v5.0.1\">5.0.1</a> (2022-10-14)</h3>\n<h3>Bug Fixes</h3>\n<ul>\n<li>Upgrade GitHub Action to use Node v16 (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/207\">#207</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/6282ee339b067cb8eab05026f91153f873ad37fb\">6282ee3</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.6.0...v5.0.0\">5.0.0</a> (2022-10-11)</h2>\n<h3>\u26a0 BREAKING CHANGES</h3>\n<ul>\n<li>Enum options need to be newline delimited (to allow whitespace within them) (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/205\">#205</a>)</li>\n</ul>\n<h3>Features</h3>\n<ul>\n<li>Enum options need to be newline delimited (to allow whitespace within them) (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/205\">#205</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/c906fe1e5a4bcc61624931ca94da9672107bd448\">c906fe1</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.5.0...v4.6.0\">4.6.0</a> (2022-09-26)</h2>\n<h3>Features</h3>\n<ul>\n<li>Provide error messages as <code>outputs.error_message</code> (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/194\">#194</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/880a3c061c0dea01e977cefe26fb0e0d06b3d1a9\">880a3c0</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.4.0...v4.5.0\">4.5.0</a> (2022-05-04)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add <code>disallowScopes</code> option (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/179\">#179</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/6a7ed2d5046cf8a40c60494c83c962343061874a\">6a7ed2d</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.3.0...v4.4.0\">4.4.0</a> (2022-04-22)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add options to pass custom regex to conventional-commits-parser (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/177\">#177</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/956659ae00eaa0b00fe5a58dfdf3a3db1efd1d63\">956659a</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.2.0...v4.3.0\">4.3.0</a> (2022-04-13)</h2>\n<h3>Features</h3>\n<ul>\n<li>Add <code>ignoreLabels</code> option to opt-out of validation for certain PRs (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/174\">#174</a>) (<a href=\"https://github.com/amannn/action-semantic-pull-request/commit/277c2303f965680aed7613eb512365c58aa92b6b\">277c230</a>)</li>\n</ul>\n<h2><a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4.1.0...v4.2.0\">4.2.0</a> (2022-02-08)</h2>\n<h3>Features</h3>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/01d5fd8a8ebb9aafe902c40c53f0f4744f7381eb\"><code>01d5fd8</code></a> chore: Release 5.0.2 [skip ci]</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/91f4126c9e8625b9cadd64b02a03018fa22fc498\"><code>91f4126</code></a> fix: Upgrade <code>@actions/core</code> to avoid deprecation warnings (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/208\">#208</a>)</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/0a457e272673a33e52c9ade9318b3c115e566f60\"><code>0a457e2</code></a> ci: Fix branch name in dist check (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/209\">#209</a>)</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/570204e54c9030a6cb7ef781c492e76c1798d1c0\"><code>570204e</code></a> chore: Release 5.0.1 [skip ci]</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/6282ee339b067cb8eab05026f91153f873ad37fb\"><code>6282ee3</code></a> fix: Upgrade GitHub Action to use Node v16 (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/207\">#207</a>)</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/7c194c28652f0faf98ad437c6cf291406d387b43\"><code>7c194c2</code></a> docs: Use latest major [skip ci]</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/5369185dc9812f174fa58b03b13b79920b68f8e1\"><code>5369185</code></a> chore: Release 5.0.0 [skip ci]</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/c906fe1e5a4bcc61624931ca94da9672107bd448\"><code>c906fe1</code></a> feat!: Enum options need to be newline delimited (to allow whitespace within ...</li>\n<li><a href=\"https://github.com/amannn/action-semantic-pull-request/commit/b314c1bec341c714425c0aa43e142b35c12759a0\"><code>b314c1b</code></a> docs: Improve example for composing outputs (<a href=\"https://github-redirect.dependabot.com/amannn/action-semantic-pull-request/issues/206\">#206</a>)</li>\n<li>See full diff in <a href=\"https://github.com/amannn/action-semantic-pull-request/compare/v4...v5\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=amannn/action-semantic-pull-request&package-manager=github_actions&previous-version=4&new-version=5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-10-26T14:05:12Z",
  "comments":0,
  "created_at":"2022-10-17T09:35:06Z",
  "draft":false,
  "id":1411239556,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5A6Yp7",
  "number":757,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-26T14:05:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore(deps): bump amannn/action-semantic-pull-request from 4 to 5",
  "updated_at":"2022-10-26T14:05:13Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"uproot 4.3.7\r\n\r\nWhen opening a root file for writing, the call to `uproot.open(filename, mode=\"w\")` fails with this error message\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In [15], line 2\r\n      1 with uproot.open(\"output.root\", mode=\"w\") as f:\r\n----> 2     f.mktree(\"tree\", {\r\n      3         \"px\": \"var * float32\",\r\n      4     })\r\n      5     f[\"tree\"].show()\r\n\r\nAttributeError: 'ReadOnlyDirectory' object has no attribute 'mktree'\r\n```\r\nIt looks like `mode=\"w\"` is ignored. This is not pythonic. By providing `uproot.open` you are suggesting that you mimic the interface of the `open` command, which is used in several places in the Python stdlib (builtins open, gzip.open, lzma.open, ...). But then you should also mimics the signature of the stdlib version as much as possible. Calling uproot.open with mode=\"w\" should forward to uproot.recreate.\r\n\r\n `uproot.open(filename, \"w\")` fails with a different error, because the next positional argument after path is not `mode`, but `object_cache`. To fix this, `mode` should be added as the second argument after path or `uproot.open` should reject positional arguments after `path` with the signature `open(path, *, object_cache=...)`",
  "closed_at":null,
  "comments":5,
  "created_at":"2022-10-18T11:38:43Z",
  "id":1413064399,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5UOabP",
  "number":758,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"uproot.open(filename, \"w\") and uproot.open(filename, mode=\"w\") fail",
  "updated_at":"2022-10-19T22:11:54Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I want to write several variable length arrays that have the same length to an empty tree. https://uproot.readthedocs.io/en/latest/basic.html#extending-ttrees-with-large-datasets explains \r\n1) How to generate an empty tree with mktree, which can be `extend`ed later, I need this\r\n2) How to generate a tree with several arrays that share the length and already contain data, with awkward.zip\r\n\r\nWhat I am missing is the combination of the two. I want to start with an empty tree like in 1) that has branches which share the varlength. Then I want to extend this tree subsequently. Is this possible? If not, may I suggest the following intuitive API:\r\n\r\nInstead of {\"x\": \"var * float32\", \"y\": \"var * float32\"}, which generates two extra branches \"nx\" and \"ny\", please allow this declaration, where the counting branch is explicit:\r\n\r\n{\"n\": \"int32\", \"x\": \"n * float32\", \"y\": \"n * float32\"}\r\n\r\nAs the Python of Zen says, explicit is better than implicit.",
  "closed_at":null,
  "comments":3,
  "created_at":"2022-10-18T11:53:18Z",
  "id":1413083853,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5UOfLN",
  "number":759,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"How to create an empty tree with several var-length branches that share the var length",
  "updated_at":"2022-10-18T17:02:50Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"https://uproot.readthedocs.io/en/latest/uproot.writing.writable.WritableTree.html#extend\r\n\r\nThe link on this page [ak.types.Type](https://awkward-array.readthedocs.io/en/latest/ak.types.Type.html) is a dead link.",
  "closed_at":"2022-10-20T20:46:40Z",
  "comments":1,
  "created_at":"2022-10-18T12:49:56Z",
  "id":1413172446,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5UO0ze",
  "number":760,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Dead link in documentation",
  "updated_at":"2022-10-20T20:46:40Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjk3NTE4NzE=",
  "assignees":null,
  "author_association":"NONE",
  "body":"I have a tree with TLeafG type.\r\nWhen I try to process it, I get the following:\r\n\r\n```\r\nname                 | typename                 | interpretation                \r\n---------------------+--------------------------+-------------------------------\r\nrunNumber            | int32_t                  | AsDtype('>i4')\r\nsubrunNumber         | int32_t                  | AsDtype('>i4')\r\ntimestamp            | unknown                  | <UnknownInterpretation 'non...\r\n```\r\n\r\nWould it be possible to add the support for TLeafG type in identify.py?\r\n\r\nThanks, Yuri.\r\n\r\nWhat you're looking for might already be possible as a combination of existing functions, so these requests might get converted into requests for documentation (with a corresponding change in title).\r\n\r\nHere are some links to documentation, to help you in your search.\r\n\r\n   * [The tutorials site](https://uproot.readthedocs.io/)\r\n   * [StackOverflow: [uproot] tag](https://stackoverflow.com/questions/tagged/uproot)\r\n   * [Gitter: Scikit-HEP/uproot room](https://gitter.im/Scikit-HEP/uproot)\r\n",
  "closed_at":"2023-02-23T18:45:38Z",
  "comments":1,
  "created_at":"2022-10-21T20:57:28Z",
  "id":1418852955,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Ukfpb",
  "number":761,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Support for TLeafG",
  "updated_at":"2023-02-23T18:45:38Z",
  "user":"MDQ6VXNlcjQ4OTI3MzA2"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"I have noticed a problem when trying to write a `TList` of `TObjString` objects.\r\n\r\n**I woud like to reproduce the following file created by root**:\r\n\r\n```c++\r\nconst std::vector<const char*> strings = {\"this\", \"is\", \"a\", \"test\"};\r\n\r\nauto f = TFile::Open(\"list.root\", \"RECREATE\");\r\n\r\nauto l = new TList();\r\n\r\nfor (const auto& s: strings) {\r\n    l->Add(new TObjString(s));\r\n}\r\n\r\nl->Write(\"listOfStrings\", TObject::kSingleKey); // if TObject::kSingleKey is not specified, each item on the list is written as a key to the root file\r\n\r\nf->Close();\r\n```\r\n\r\n<details>\r\n  <summary>Opening the file with root:</summary>\r\n\r\n```\r\nroot@2a578f2dc0f6:~# root list.root\r\n   ------------------------------------------------------------------\r\n  | Welcome to ROOT 6.26/06                        https://root.cern |\r\n  | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |\r\n  | Built for linuxx8664gcc on Sep 25 2022, 12:37:00                 |\r\n  | From tags/v6-26-06@v6-26-06                                      |\r\n  | With c++ (Ubuntu 11.2.0-19ubuntu1) 11.2.0                        |\r\n  | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q'       |\r\n   ------------------------------------------------------------------\r\n\r\nroot [0]\r\nAttaching file list.root as _file0...\r\n(TFile *) 0x5572bae81430\r\nroot [1] .ls\r\nTFile**         list.root\r\n TFile*         list.root\r\n  KEY: TList    listOfStrings;1 Doubly linked list\r\nroot [2] listOfStrings->Print(nullptr)\r\nCollection name='TList', class='TList', size=4\r\n TObjString = this\r\n TObjString = is\r\n TObjString = a\r\n TObjString = test\r\nroot [3]\r\n```\r\n</details>\r\n\r\nMy attempt to do this using `uproot` makes use of the `uproot.writing.identify.to_TList` method which according to its description should be able to write a `TList` of root objects into a root file.\r\n\r\nPython to write `TList` into file:\r\n\r\n```python\r\nimport uproot\r\nprint(f\"{uproot.__version__=}\")\r\n\r\nstrings = [\"this\", \"is\", \"a\", \"test\"]\r\n\r\nlistOfStrings = uproot.writing.identify.to_TList([uproot.writing.identify.to_TObjString(s) for s in strings])\r\n# listOfStrings = uproot.writing.identify.to_TList([]) # this works\r\n\r\nprint(f\"{listOfStrings=}\")\r\n\r\nfilename = \"list.root\"\r\nkey = \"listOfStrings\"\r\n\r\nwith uproot.recreate(filename) as f:\r\n    f[key] = listOfStrings\r\n```\r\n\r\n```\r\nuproot.__version__='5.0.0rc4'\r\nlistOfStrings=<TList of 4 items at 0x7f3b987d8eb0>\r\n```\r\n\r\n<details>\r\n  <summary>Reading the file with root does not work:</summary>\r\n\r\n\r\n```\r\nroot@2a578f2dc0f6:~# root list.root\r\n   ------------------------------------------------------------------\r\n  | Welcome to ROOT 6.26/06                        https://root.cern |\r\n  | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |\r\n  | Built for linuxx8664gcc on Sep 25 2022, 12:37:00                 |\r\n  | From tags/v6-26-06@v6-26-06                                      |\r\n  | With c++ (Ubuntu 11.2.0-19ubuntu1) 11.2.0                        |\r\n  | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q'       |\r\n   ------------------------------------------------------------------\r\n\r\nroot [0]\r\nAttaching file list.root as _file0...\r\n(TFile *) 0x557bde1ff7a0\r\nroot [1] .ls\r\nTFile**         list.root\r\n TFile*         list.root\r\n  KEY: TList    listOfStrings;1\r\nroot [2] listOfStrings\r\nError in <TExMap::Remove>: key 90432 not found at 396\r\nWarning in <TBufferFile::CheckObject>: reference to object of unavailable class TObject, offset=90432 pointer will be 0\r\nError in <TExMap::Remove>: key 2424831 not found at 371\r\nWarning in <TBufferFile::CheckObject>: reference to object of unavailable class TObject, offset=2424831 pointer will be 0\r\nError in <TRint::HandleTermInput()>: std::length_error caught: basic_string::_M_replace_aux\r\nroot [3] listOfStrings->Print(nullptr)\r\nError in <TExMap::Remove>: key 90432 not found at 396\r\nWarning in <TBufferFile::CheckObject>: reference to object of unavailable class TObject, offset=90432 pointer will be 0\r\nError in <TExMap::Remove>: key 2424831 not found at 371\r\nWarning in <TBufferFile::CheckObject>: reference to object of unavailable class TObject, offset=2424831 pointer will be 0\r\nError in <TRint::HandleTermInput()>: std::length_error caught: basic_string::_M_replace_aux\r\nroot [4]\r\n```\r\n\r\n</details>\r\n\r\nReading with uproot does not work either:\r\n\r\n```python\r\nimport uproot\r\nprint(f\"{uproot.__version__=}\")\r\n\r\nfilename = \"list.root\"\r\nkey = \"listOfStrings\"\r\n\r\nwith uproot.open(filename) as f:\r\n    print(f\"keys: {f.keys()}\")\r\n    print(f\"list: {f[key]}\")\r\n```\r\n\r\n<details>\r\n  <summary>error when reading with `uproot` the file generated using `uproot`:</summary>\r\n\r\n```\r\nuproot.__version__='5.0.0rc4'\r\nkeys: ['listOfStrings;1']\r\nTraceback (most recent call last):\r\n  File \"/root/t.py\", line 9, in <module>\r\n    print(f\"list: {f[key]}\")\r\n  File \"/usr/local/lib/python3.10/dist-packages/uproot/reading.py\", line 2107, in __getitem__\r\n    return self.key(where).get()\r\n  File \"/usr/local/lib/python3.10/dist-packages/uproot/reading.py\", line 2510, in get\r\n    out = cls.read(chunk, cursor, context, self._file, selffile, parent)\r\n  File \"/usr/local/lib/python3.10/dist-packages/uproot/model.py\", line 877, in read\r\n    self.check_numbytes(chunk, cursor, context)\r\n  File \"/usr/local/lib/python3.10/dist-packages/uproot/model.py\", line 952, in check_numbytes\r\n    uproot.deserialization.numbytes_check(\r\n  File \"/usr/local/lib/python3.10/dist-packages/uproot/deserialization.py\", line 167, in numbytes_check\r\n    raise DeserializationError(\r\nuproot.deserialization.DeserializationError: while reading\r\n\r\n    TList version 5 as uproot.models.TList.Model_TList (176 bytes)\r\n        (base): <TObject None None at 0x7f74785d4160>\r\n        fName: ''\r\n        fSize: 4\r\nBase classes for TList: TObject?\r\nMembers for TList: fName?, fSize?\r\n\r\nexpected 176 bytes but cursor moved by -11251723 bytes (through TList)\r\nin file list.root\r\nin object /listOfStrings;1\r\n```\r\n</details>\r\n\r\n**uproot works when reading the file written using root though**:\r\n\r\n```python\r\nimport uproot\r\nprint(f\"{uproot.__version__=}\")\r\n\r\nfilename = \"list.root\"\r\nkey = \"listOfStrings\"\r\n\r\nwith uproot.open(filename) as f:\r\n    print(f\"keys: {f.keys()}\")\r\n    print(f\"list: {f[key]}\")\r\n    print(f\"list as json: {f[key].tojson()}\")\r\n    for i, s in enumerate(f[key]):\r\n        print(f\"string {i}: {s}\")\r\n```\r\n\r\n```\r\nuproot.__version__='5.0.0rc4'\r\nkeys: ['listOfStrings;1']\r\nlist: <TList of 4 items at 0x7f05c3c546a0>\r\nlist as json: {'_typename': 'TList', 'name': 'TList', 'arr': [{'_typename': 'TObjString', 'fUniqueID': 0, 'fBits': 50331648}, {'_typename': 'TObjString', 'fUniqueID': 0, 'fBits': 50331648}, {'_typename': 'TObjString', 'fUniqueID': 0, 'fBits': 50331648}, {'_typename': 'TObjString', 'fUniqueID': 0, 'fBits': 50331648}], 'opt': []}\r\nstring 0: this\r\nstring 1: is\r\nstring 2: a\r\nstring 3: test\r\n```\r\n\r\nI have tried writing a single `TObjString` into a root file and this works fine.",
  "closed_at":"2022-10-28T22:45:23Z",
  "comments":1,
  "created_at":"2022-10-24T08:20:54Z",
  "id":1420423788,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5UqfJs",
  "number":762,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Problem writing TList of TObjString",
  "updated_at":"2022-10-28T22:45:23Z",
  "user":"MDQ6VXNlcjM1ODAzMjgw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Closes https://github.com/scikit-hep/uproot5/issues/762.\r\n\r\nThis PR was motivated because of problems serializing `TList`. \r\n\r\n- `TList` serialization was fixed in 4da653fee0f28789fbb20abcad3a4541acd6701a.\r\n\r\nA few other minor improvements were done along the way:\r\n\r\n- `TObject` should now correctly serialize `fUniqueID` member (previously it was using only 0).\r\n- `TObject` `__repr__` is fixed.\r\n- A method `Model_TObject.empty` has been added as override to avoid using its parent method in order to simplify code.\r\n- `TObjString` now correctly initializes its `bases` with a `TObject` with all its members.\r\n- Updated some `tojson` calls of above mentined classes.\r\n- Added / Updated tests for writing and reading `TObjString` and `TList`.\r\n\r\n\r\n",
  "closed_at":"2022-10-28T22:45:22Z",
  "comments":14,
  "created_at":"2022-10-24T12:17:50Z",
  "draft":false,
  "id":1420737783,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5BaOcK",
  "number":763,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-28T22:45:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: working TList serialization",
  "updated_at":"2022-10-29T00:00:51Z",
  "user":"MDQ6VXNlcjM1ODAzMjgw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Closes https://github.com/scikit-hep/uproot5/issues/672.\r\n\r\nThe logic for setting the `fLabels` on the axis is pretty straightforward, however to achieve this we need to serialize `THashList` which is not currently implemented.\r\n\r\nWhile working on this I found out a problem when serializing `TList` (which `THashList` inherits directly from), which is pointed out in https://github.com/scikit-hep/uproot5/issues/762 and is fixed by https://github.com/scikit-hep/uproot5/pull/763.\r\n\r\nAnother issue related to weighted histograms was also found and fixed at https://github.com/scikit-hep/uproot5/pull/774.\r\n\r\nSummary of changes:\r\n- Implement `THashList` serialization and `to_HashList` factory method.\r\n- Add tests for `THashList` writing. Compare serialization (bytes) to `TList` as they should be the same except for class name.\r\n- The name (`fName`) of all axes is now `xaxis`, `yaxis` or `zaxis` regardless of user definition, as this field should not be modified by the user since it causes problems on histogram drawing. (The text of the axis is `fTitle`). Tests have been updated accordingly.\r\n- Add tests for histograms with categorical axes.",
  "closed_at":"2022-11-02T20:13:46Z",
  "comments":13,
  "created_at":"2022-10-24T21:01:20Z",
  "draft":false,
  "id":1421442770,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5BcmfR",
  "number":764,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-02T20:13:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: support categorical axes on boost histograms",
  "updated_at":"2023-02-15T19:10:57Z",
  "user":"MDQ6VXNlcjM1ODAzMjgw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This PR won't pass tests until Awkward 2.0.0rc1 is actually released on PyPI.",
  "closed_at":"2022-10-26T18:44:51Z",
  "comments":6,
  "created_at":"2022-10-25T19:32:36Z",
  "draft":false,
  "id":1422967878,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5BhtFb",
  "number":765,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-26T18:44:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: update Uproot to require Awkward 2.0.0rc1.",
  "updated_at":"2022-10-26T18:44:52Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Committed via https://github.com/asottile/all-repos",
  "closed_at":"2022-10-26T20:17:21Z",
  "comments":3,
  "created_at":"2022-10-26T14:47:31Z",
  "draft":false,
  "id":1424181387,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5Blv-r",
  "number":766,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-26T20:17:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: update to Python 3.11 final",
  "updated_at":"2022-10-26T20:17:22Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"But this issue is going to remove it entirely: https://github.com/scikit-hep/awkward/issues/1843\r\n\r\nIt will have to be coordinated between Awkward and Uproot, though it's apparently an error that doesn't affect the tests.",
  "closed_at":"2022-10-31T20:49:42Z",
  "comments":1,
  "created_at":"2022-10-27T17:39:32Z",
  "id":1426036585,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5U_5dp",
  "number":768,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Form.has_identifier is misspelled in the Uproot codebase as \"has_identifiers\" (plural)",
  "updated_at":"2022-10-31T20:49:42Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"As much of the `AsObjects` deserialization as possible is done with AwkwardForth now, but there's a fallback path for any data types that can't be implemented in Forth. This fallback path is what Uproot v4 did. Since the fallback is not being tested, there are Awkward1isms still hidden in it, like this one found by @lgray.\r\n\r\n```python\r\nelif isinstance(form, awkward.forms.RecordForm):\r\n            print(form.contents)\r\n            contents = {\r\n                k: awkward_form_remove_uproot(awkward, v)\r\n>               for k, v in form.contents.items()\r\n                if not k.startswith(\"@\")\r\n            }\r\nE           AttributeError: 'list' object has no attribute 'items'\r\n```\r\n\r\nI (or one of us) should\r\n\r\n  1. find all of the tests that run a `ForthMachine` (by putting an exception in that call)\r\n  2. parameterize them with pytest to run with and without AwkwardForth, by setting the flag on `AsObjects` that disables it\r\n  3. work through the Awkward1isms in the fallback path",
  "closed_at":"2022-11-11T15:10:41Z",
  "comments":0,
  "created_at":"2022-10-27T18:01:24Z",
  "id":1426066964,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5VAA4U",
  "number":769,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"The deserialization fallback path is not being tested",
  "updated_at":"2023-02-15T19:10:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The tests for this PR should pass after scikit-hep/awkward#1845 has been added to a release (probably 2.0.0rc2).",
  "closed_at":"2022-10-29T16:59:25Z",
  "comments":4,
  "created_at":"2022-10-28T21:42:11Z",
  "draft":false,
  "id":1427869481,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5ByEAu",
  "number":770,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-29T16:59:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore: remove Identifier and `\"uproot\"` parameter.",
  "updated_at":"2022-10-29T16:59:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @lobis as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/uproot5/pull/763#issuecomment-1295589480)\n\n[skip ci]",
  "closed_at":"2022-10-28T22:47:04Z",
  "comments":0,
  "created_at":"2022-10-28T22:46:27Z",
  "draft":false,
  "id":1427927119,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5ByQli",
  "number":771,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-10-28T22:47:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add lobis as a contributor for code",
  "updated_at":"2022-10-28T22:47:05Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Here's the problem (nano_dy.root has 1499 branches):\r\n\r\n```python\r\n>>> import uproot\r\n>>> import time\r\n>>> starttime = time.time(); tree = uproot.open(\"nano_dy.root:Events\"); time.time() - starttime\r\n0.4795074462890625\r\n>>> starttime = time.time(); dask_tree = uproot.dask({\"nano_dy.root\": \"Events\"}); time.time() - starttime\r\n2.7875990867614746\r\n```\r\n\r\nWhy does `uproot.dask` take so much more time to process metadata? (Neither of the above actually read any arrays.)\r\n\r\nThe problem is that there are _O(n\u00b2)_ walks over TBranches to check their names. One of these is for simple name-lookup, which affects non-Dask as well as Dask, and the other is that the Dask implementation is using public API functions that do more regularization tests on the given list of TBranch names than is necessary (by construction, the list we provide is in the proper internal format).",
  "closed_at":"2022-11-10T04:28:16Z",
  "comments":5,
  "created_at":"2022-10-31T18:35:50Z",
  "draft":false,
  "id":1430307261,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5B6Idp",
  "number":772,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-10T04:28:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"perf: streamline metadata handling for TBranch name lookup and uproot.dask",
  "updated_at":"2023-02-15T19:10:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v3.1.0 \u2192 v3.2.0](https://github.com/asottile/pyupgrade/compare/v3.1.0...v3.2.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-11-01T17:40:08Z",
  "comments":0,
  "created_at":"2022-10-31T22:05:49Z",
  "draft":false,
  "id":1430556368,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5B6-by",
  "number":773,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-01T17:40:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-11-01T17:40:09Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Currently the `fSumw2` (weights) are not being correctly read/written when performing conversion to/from `hist`/`boost` histograms.\r\n\r\nThis is causing issues in https://github.com/scikit-hep/uproot5/issues/672 and solving this will also close https://github.com/scikit-hep/uproot5/issues/722.\r\n\r\n- We now use `hist` `storage_type` property to check wether it's a weighted histogram or not, instead of the `variances` which is always defined and was cuasing false positives.\r\n- Add two new tests, to check the conversion with a histogram with weights and another one without weights.\r\n- Updated slicing of values / variances for categorical axes.\r\n- Refactored `weighted` property and `to_boost` method to use inheritance.\r\n- Write test for 2D, 3D histograms with weights / labels.",
  "closed_at":"2022-11-02T14:26:50Z",
  "comments":3,
  "created_at":"2022-10-31T22:12:04Z",
  "draft":false,
  "id":1430563319,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5B6_9h",
  "number":774,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-02T14:26:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: histogram weights not handled correctly in hist / boost conversion",
  "updated_at":"2023-02-15T19:11:00Z",
  "user":"MDQ6VXNlcjM1ODAzMjgw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I am using uproot 4.3.7\r\n\r\n```python\r\n>>> import uproot\r\n>>> uproot.__version__\r\n```\r\n\r\nI'm using PI (3.1415...) in my expressions, but in some cases it works, other is not\r\n\r\nI am using this file (I hope the link works since I have some problems)\r\n\r\n```python\r\nfn = \"https://cernbox.cern.ch/s/nrNUJTfBLHltfDy:analysis\"\r\n```\r\n\r\nThis is working\r\n\r\n``` python\r\nuproot.concatenate([fn], [\"phiModCalo\"], \r\naliases={\"phiModCalo\": \"where(abs(el_cl_eta) <= 1.425, abs(el_cl_phiCalo) % (PI / 512), abs(el_cl_phiCalo) % (PI / 384))\"}, library='pd')\r\n\r\n```\r\n\r\nThis is not working\r\n```python\r\n uproot.concatenate([fn], [ 'DeltaPhiTG3'],\r\n aliases={'DeltaPhiTG3': 'abs(2.0 * PI + el_cl_phi) % (PI / 32.0) - PI / 64.0'}, library='pd')\r\n```\r\n\r\nIn both I am using `PI`, but I have no idea why the second is failing.\r\n\r\n```\r\nKeyInFileError: not found: 'PI'\r\nin file /home/turra/cernbox/user.turra.900333.PG_single_electron_egammaET.MVACalib_el_offline.e8453_s3873_r13830_v2_ANALYSIS.root/user.turra.30650965._000001.ANALYSIS.root\r\nin object /analysis;1\r\n```\r\n\r\nadding `{'PI': 3.1415}` to the aliases makes both working, but I not sure why one is working... the only difference is the usage of `where`. Is this triggering anything?",
  "closed_at":"2022-11-03T17:34:49Z",
  "comments":5,
  "created_at":"2022-11-02T17:13:52Z",
  "id":1433506296,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5VcZH4",
  "number":775,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Warn about name conflict between aliases and TBranch names",
  "updated_at":"2022-11-03T17:34:49Z",
  "user":"MDQ6VXNlcjE0MzM4OQ=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I normally dislike warnings, but if we made this case an exception, then there would be reasonable-to-do things that wouldn't be possible to do. So, okay, a warning.",
  "closed_at":"2022-11-03T17:34:48Z",
  "comments":5,
  "created_at":"2022-11-02T23:13:39Z",
  "draft":false,
  "id":1433902994,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5CGOWQ",
  "number":776,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-03T17:34:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: warn about TBranch name, alias name conflict.",
  "updated_at":"2022-11-04T13:57:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I'm a newbie to uproot and encountered some problems when trying to use uproot. Sorry for possible misunderstandings of the usage, though I think my expectation might be reasonable. \r\n\r\nCreate a jagged array\r\n\r\n```python\r\nimport uproot\r\nimport awkward as ak\r\narray = ak.Array({'a': [[1.1, 2.2, 3.3], [], [4.4, 5.5]], 'b': [[1.1, 2.2, 3.3], [], [4.4, 5.5]], 'c': [1, 2, 3]})\r\n```\r\n\r\nand save it to a ROOT file\r\n```python\r\nwith uproot.recreate('data.root') as output_file:\r\n    output_file['tree'] = array\r\n```\r\n\r\nI expect that the saved tree has 3 branches\r\n> name                 | typename                 | interpretation                \r\n> ---------------------+--------------------------+-------------------------------\r\n> a                    | double[]                 | AsJagged(AsDtype('>f8'))\r\n> b                    | double[]                 | AsJagged(AsDtype('>f8'))\r\n> c                    | int64_t                  | AsDtype('>i8')\r\n\r\nbut actually I got errors\r\n> TypeError: fields of a record must be NumPy types, though the record itself may be in a jagged array\r\n> \r\n> field 'a' has type var * float64\r\n\r\nThis situation easily happens when reading a TTree with variable length arrays and then saving it back after some manipulations. ",
  "closed_at":null,
  "comments":2,
  "created_at":"2022-11-03T11:17:15Z",
  "id":1434491798,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5VgJuW",
  "number":777,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"open",
  "state_reason":null,
  "title":"Want to write TTree with an Awkward record array, rather than a dict of non-record arrays",
  "updated_at":"2024-01-30T15:36:02Z",
  "user":"MDQ6VXNlcjM3OTU1ODQ5"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is a reminder to sweep through and label the obviously keyword-only arguments as such. The codebase doesn't have any keyword-only arguments because it once supported Python 2, but that rationale is long gone. This change is backward-incompatible (in a small way, easy to work around), so it should be done before the release.",
  "closed_at":"2022-11-30T00:29:31Z",
  "comments":0,
  "created_at":"2022-11-10T19:14:22Z",
  "id":1444430229,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5WGEGV",
  "number":778,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Some arguments should be keyword-only.",
  "updated_at":"2023-02-15T19:11:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is a change in policy. Now when anyone does\r\n\r\n```python\r\nwith uproot.recreate(\"file.root\") as file:\r\n    file[\"something\"] = {\"key\": value}\r\n```\r\n\r\nit will _always_ attempt to interpret the `{\"key\": value}` Mapping (any kind of Mapping) as a TTree. If any `value` cannot be interpreted as an array, it raises an error message that highlights the `\"key\"` name.\r\n\r\nThe old behavior was to give up on interpreting `{\"key\": value}` as a TTree, but keep open the possibility that it might be some other kind of writable data. In practice, there are no other types of writable data associated with Mapping, so the error message would be `\"unrecognized type cannot be written to a ROOT file: __dict__'\"`.\r\n\r\nWhat's worse, this error message depended on the state of the environment: if `awkward` is not installed, then Uproot can't check non-NumPy `value` to see if it might be interpretable as an Awkward Array (with `ak.from_iter`), so it failed with the above complaint about not recognizing the dict type, instead of saying that `awkward` needs to be pip-installed.",
  "closed_at":"2022-11-11T12:04:37Z",
  "comments":1,
  "created_at":"2022-11-11T00:02:51Z",
  "draft":false,
  "id":1444727314,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5CqjPP",
  "number":779,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-11T12:04:37Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: any Mapping assigned to a WritableDirectory is interpreted as a TTree or failure, no fall-through.",
  "updated_at":"2022-11-11T12:04:38Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Swapped for loops for pytest fixtures, so that the with-AwkwardForth code path and the without-AwkwardForth code path are fully tested.\r\n\r\nSwitching the order with-AwkwardForth and without-AwkwardForth in `test_00` revealed a bug in the fallback path that hadn't been tested (also fixed in this PR).\r\n\r\nThis PR also removes \"FIXME\" messages for the old path: it won't be removed because it's a fallback.\r\n\r\nI'll ask @aryan26roy to check this over.",
  "closed_at":"2022-11-11T15:10:40Z",
  "comments":1,
  "created_at":"2022-11-11T01:28:57Z",
  "draft":false,
  "id":1444792682,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5CqxAG",
  "number":780,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-11T15:10:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: ensure AwkwardForth fallback path is tested without history.",
  "updated_at":"2022-11-11T15:10:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The `_libraries_lazy` dict was the set of libraries (and their names) that could be used with `uproot.lazy`, which is now gone.\r\n\r\nThe `_libraries` dict is now the only such dict.\r\n\r\nAfter #734 is done, I'll look around to see if there's any more dead code that can be removed.",
  "closed_at":"2022-11-11T01:43:21Z",
  "comments":2,
  "created_at":"2022-11-11T01:34:25Z",
  "draft":false,
  "id":1444796127,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5CqxvL",
  "number":781,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"refactor: remove now-unused lazy libraries dict (no uproot.lazy).",
  "updated_at":"2022-11-11T01:43:24Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":null,
  "closed_at":"2022-11-11T15:46:50Z",
  "comments":1,
  "created_at":"2022-11-11T05:30:56Z",
  "draft":false,
  "id":1444955463,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5CrUFt",
  "number":782,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-11T15:46:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: fix TRef.py doc urls",
  "updated_at":"2022-11-15T19:32:59Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v3.2.0 \u2192 v3.2.2](https://github.com/asottile/pyupgrade/compare/v3.2.0...v3.2.2)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-11-15T22:30:02Z",
  "comments":0,
  "created_at":"2022-11-14T22:12:44Z",
  "draft":false,
  "id":1448842124,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5C4U72",
  "number":783,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-15T22:30:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: pre-commit autoupdate",
  "updated_at":"2022-11-15T22:30:03Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is taking over a function from Coffea\u2014adding `TBranch.title` to the `__doc__` parameter of Awkward Arrays\u2014in a centralized way. The only file that is affected to add that feature is library.py (the `Awkward` singleton). Let me know, @lgray, if it works as needed.\r\n\r\nAll the rest of the changes are to propagate the option down. We don't want to _always_ do this; Coffea just needs a hook to be able to enable it. The `interp_options` mechanism enables us to pass more of these options in in the future.",
  "closed_at":"2022-11-20T03:52:46Z",
  "comments":7,
  "created_at":"2022-11-18T20:59:42Z",
  "draft":false,
  "id":1455796317,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5DPsTr",
  "number":784,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-20T03:52:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: add 'interp_options' mechanism and ak_add_doc.",
  "updated_at":"2022-11-20T03:52:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Please add a property `title` to the WriteableTree that users can set.",
  "closed_at":null,
  "comments":4,
  "created_at":"2022-11-24T13:09:59Z",
  "id":1463325026,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5XOJFi",
  "number":785,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":"reopened",
  "title":"WritableTree does not allow to set title",
  "updated_at":"2022-11-25T14:22:23Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I'm going to fast-track this, adding\r\n\r\n```diff\r\n@@ -50,7 +50,8 @@ def test_write_pyroot_TLorentzVector(tmp_path):\r\n     with uproot.recreate(newfile, compression=None) as fout:\r\n         fout[\"something\"] = ROOT.TLorentzVector(1, 2, 3, 4)\r\n \r\n-    with uproot.open(newfile) as fin:\r\n+    classes = dict(uproot.classes)\r\n+    with uproot.open(newfile, custom_classes=classes) as fin:\r\n         uproot_vec = fin[\"something\"]\r\n         assert uproot_vec.member(\"fP\").member(\"fX\") == 1\r\n         assert uproot_vec.member(\"fP\").member(\"fY\") == 2\r\n```\r\n\r\nIt's always legal to add `custom_classes` to [uproot.open](https://uproot.readthedocs.io/en/latest/uproot.reading.open.html). Doing so in this case prevents a test from modifying a global variable, `uproot.classes`, which makes the test fail offline. Maybe all `uproot.open` calls in the test suite should have their own `custom_classes` so that it's 100% thread-safe (instead of 99% \u00b1 1% thread-safe), but that can be a PR for another day.\r\n\r\nOr more ambitiously, maybe we can find the right place to put a lock on the updating of `uproot.classes` so that it can always be modified in parallel threads.\r\n\r\nBy \"fast-track,\" I mean that I'm going to enable auto-merge without a review, and my next PR (addressing #778, a much bigger PR) can assume that this will be ready in `main`. We may need to formalize when \"fast-tracking\" is allowed and by whom, but however we formalize that, a case like this one would be allowed.",
  "closed_at":"2022-11-28T23:27:33Z",
  "comments":0,
  "created_at":"2022-11-28T23:01:57Z",
  "draft":false,
  "id":1467207264,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5D19_6",
  "number":786,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-28T23:27:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"test: make tests parallelizable (custom_classes in uproot.open).",
  "updated_at":"2022-11-28T23:27:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is similar to https://github.com/scikit-hep/awkward/pull/1905, but for Uproot.\r\n\r\nMulti-array-fetching functions (`HasBranches.arrays`, `HasBranches.iterate`, `uproot.iterate`, `uproot.concatenate`, `uproot.dask`) can take `expressions` and `cut` as positional, but `filter_name` onward are all keyword-only. Similarly, `common_entry_offsets` takes `filter_name` onward as keyword-only (no positional arguments).\r\n\r\nThe single-array fetching function (`TBranch.array`) can take `interpretation`, `entry_start`, and `entry_stop` as positional, but `decompression_executor` onward are all keyword-only.\r\n\r\n`uproot.open` and `ReadOnlyFile` can take `file_path` as positional, but the rest are keyword-only.\r\n\r\n`ReadOnlyDirectory` and `HasBranches` (`TTree` and `TBranch`) have mapping-like functions (`keys`, `values`, `items`, `iterkeys`, `itervalues`, `iteritems`, and the special `classnames`, `iterclassnames`, `typenames`, `itertypenames`), which take a bunch of boolean flag arguments, all now keyword-only.\r\n\r\n`WritableDirectory.mkdir` takes a positional `name`, but keyword-only `initial_directory_bytes`.\r\n\r\n`WritableDirectory.mktree` takes positional `name`, `branch_types`, and `title`, but all of the advanced options are now keyword-only.\r\n\r\n`HasBranches.show` and `WritableTTree.show` now have no positional arguments; all arguments from `filter_name` onward are keyword-only.",
  "closed_at":"2022-11-30T00:29:30Z",
  "comments":7,
  "created_at":"2022-11-28T23:07:09Z",
  "draft":false,
  "id":1467212092,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5D1_DO",
  "number":787,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-30T00:29:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: made 'very optional' arguments keyword-only",
  "updated_at":"2022-11-30T00:29:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEyNDg0MTM=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The tests in this PR will fail until the change in https://github.com/scikit-hep/awkward/pull/1919 makes its way into a release, 2.0.0rc5 (probably). Once that happens, these tests will pass and all others will fail.\r\n\r\nFollow the plan described in https://github.com/scikit-hep/awkward/pull/1919#pullrequestreview-1196679809.",
  "closed_at":"2022-12-06T22:38:49Z",
  "comments":2,
  "created_at":"2022-11-28T23:22:33Z",
  "draft":false,
  "id":1467227817,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5D2Ciz",
  "number":788,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-06T22:38:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"feat: adjust for name change in scikit-hep/awkward#1919.",
  "updated_at":"2023-02-15T19:11:01Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/pre-commit/pre-commit-hooks: v4.3.0 \u2192 v4.4.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.3.0...v4.4.0)\n- [github.com/PyCQA/flake8: 5.0.4 \u2192 6.0.0](https://github.com/PyCQA/flake8/compare/5.0.4...6.0.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-11-29T01:27:01Z",
  "comments":0,
  "created_at":"2022-11-28T23:32:44Z",
  "draft":false,
  "id":1467234462,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5D2D9M",
  "number":789,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-29T01:27:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-11-29T01:27:02Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Quoting #754,\r\n\r\n> If they don't, make them the same.\r\n\r\nThey are now; the differences were only minor and some of the errors were in the _non-Forth_ implementation.\r\n\r\n> The `\"uproot\"` parameters should be removed.\r\n\r\nThey were already gone before I started.\r\n\r\n> Some of the `\"__record__\"` parameters have the C++ name; this is a good idea. We should make sure that all of them do.\r\n\r\nThey all do now.\r\n\r\nA user-visible difference is that we're excluding all of the TObject header and numbytes_version header stuff (used to be marked with `@`, now gone). It's still possible to get them back, but you have to run a non-Forth read and pass non-default parameters to the `awkward_forth` method. I don't think we'll ever need it.",
  "closed_at":"2022-11-30T16:31:08Z",
  "comments":2,
  "created_at":"2022-11-30T00:16:20Z",
  "draft":false,
  "id":1468871198,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5D7kS_",
  "number":790,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-11-30T16:31:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: all AwkwardForth Forms now agree with awkward_form method output.",
  "updated_at":"2022-11-30T16:31:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I'm not 100% sure if this is a problem in Uproot or dask-awkward, but the error is at least coming from Uproot. The exact file I'm using is https://github.com/iris-hep/func_adl_uproot/blob/fb9cd8607739fce4c70c72ef395301effc3a2692/tests/scalars_tree_file.root, but I don't think this is file specific.\r\n\r\n```python\r\n>>> import uproot, dask_awkward as dak\r\n>>> uproot.__version__\r\n'5.0.0rc6'\r\n>>> dak.__version__\r\n'2022.12a1'\r\n>>> da = uproot.dask('tests/scalars_tree_file.root:tree')\r\n>>> da.layout\r\n<RecordArray is_tuple='false' len='??'>\r\n    <content index='0' field='int_branch'>\r\n        <NumpyArray dtype='int32' len='??'>[?? ... ??]</NumpyArray>\r\n    </content>\r\n    <content index='1' field='long_branch'>\r\n        <NumpyArray dtype='int64' len='??'>[?? ... ??]</NumpyArray>\r\n    </content>\r\n    <content index='2' field='float_branch'>\r\n        <NumpyArray dtype='float32' len='??'>[?? ... ??]</NumpyArray>\r\n    </content>\r\n    <content index='3' field='double_branch'>\r\n        <NumpyArray dtype='float64' len='??'>[?? ... ??]</NumpyArray>\r\n    </content>\r\n    <content index='4' field='bool_branch'>\r\n        <NumpyArray dtype='bool' len='??'>[?? ... ??]</NumpyArray>\r\n    </content>\r\n</RecordArray>\r\n>>> da[da.int_branch < 0].compute()\r\nTraceback (most recent call last):\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 378, in free_symbols\r\n    return list(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 90, in _walk_ast_yield_symbols\r\n    yield from _walk_ast_yield_symbols(x, keys, aliases, functions, getter)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 94, in _walk_ast_yield_symbols\r\n    yield from _walk_ast_yield_symbols(x, keys, aliases, functions, getter)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 90, in _walk_ast_yield_symbols\r\n    yield from _walk_ast_yield_symbols(x, keys, aliases, functions, getter)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 90, in _walk_ast_yield_symbols\r\n    yield from _walk_ast_yield_symbols(x, keys, aliases, functions, getter)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 73, in _walk_ast_yield_symbols\r\n    raise KeyError(node.id)\r\nKeyError: 'less'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/base.py\", line 315, in compute\r\n    (result,) = compute(self, traverse=False, **kwargs)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/base.py\", line 600, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/threaded.py\", line 89, in get\r\n    results = get_async(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/local.py\", line 511, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/local.py\", line 319, in reraise\r\n    raise exc\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/local.py\", line 224, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/optimization.py\", line 990, in __call__\r\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/core.py\", line 149, in get\r\n    result = _execute_task(task, cache)\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*(_execute_task(a, cache) for a in args))\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/_dask.py\", line 526, in __call__\r\n    return self.hasbranches[i].arrays(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 919, in arrays\r\n    arrays, expression_context, branchid_interpretation = _regularize_expressions(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 2986, in _regularize_expressions\r\n    _regularize_expression(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/behaviors/TBranch.py\", line 2854, in _regularize_expression\r\n    for symbol in language.free_symbols(\r\n  File \"/home/user/miniconda3/envs/func_adl_uproot_rc/lib/python3.10/site-packages/uproot/language/python.py\", line 384, in free_symbols\r\n    raise uproot.KeyInFileError(\r\nuproot.exceptions.KeyInFileError: not found: 'less'\r\nin file tests/scalars_tree_file.root\r\nin object /tree;1\r\n```\r\n\r\nThe non-dask version of this works as expected:\r\n\r\n```python\r\n>>> a = uproot.open('tests/scalars_tree_file.root:tree').arrays()\r\n>>> a[a.int_branch < 0]\r\n<Array [{int_branch: -1, ...}] type='1 * {int_branch: int32, long_branch: i...'>\r\n```\r\n\r\nIt even works with dask-awkward if I start from the Awkward array itself, which maybe further suggests that the above problem is in Uproot:\r\n\r\n```python\r\n>>> da2 = dak.from_awkward(a, 1)\r\n>>> da2[da2.int_branch < 0].compute()\r\n<Array [{int_branch: -1, ...}] type='1 * {int_branch: int32, long_branch: i...'>\r\n```",
  "closed_at":"2022-12-15T17:59:53Z",
  "comments":1,
  "created_at":"2022-12-03T14:21:49Z",
  "id":1474061795,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5X3GXj",
  "number":791,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Slicing a Dask RecordArray from Uproot raises a key error",
  "updated_at":"2022-12-15T17:59:53Z",
  "user":"MDQ6VXNlcjMyNzczMzA0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.5.1 to 1.6.1.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pypa/gh-action-pypi-publish/releases\">pypa/gh-action-pypi-publish's releases</a>.</em></p>\n<blockquote>\n<h2>v1.6.1</h2>\n<h2>What's happened?!</h2>\n<p>There was a sneaky bug in v1.6.0 which caused Twine to be outside the import path in the Python runtime. It is fixed in v1.6.1 by updating <code>$PYTHONPATH</code> to point to a correct location of the user-global <code>site-packages/</code> directory.</p>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.0...v1.6.1\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.0...v1.6.1</a></p>\n<h2>v1.6.0</h2>\n<h2>Anything's changed?</h2>\n<p>The only update is that the Python runtime has been upgraded from 3.9 to 3.11. There are no functional changes in this release.</p>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.2...v1.6.0\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.2...v1.6.0</a></p>\n<h2>v1.5.2</h2>\n<h2>What's Improved</h2>\n<ul>\n<li>Implemented the Twine transitive dependency tree pinning using pip-tools-generated constraint files. See <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/107\">pypa/gh-action-pypi-publish#107</a> and <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/101\">pypa/gh-action-pypi-publish#101</a> for details.</li>\n</ul>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.1...v1.5.2\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.1...v1.5.2</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/5d1679fa6b895587c6eb10c3fe82205b440a580e\"><code>5d1679f</code></a> Use py3.11 user-global site-packages in PYTHONPATH</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/d2a2496a01f8b4b773ccd9cae8f2151589de5b62\"><code>d2a2496</code></a> Switch the runtime from Python 3.9 to Python 3.11</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/d7edd4c95736a5bc1260d38b5523f5d24338bc25\"><code>d7edd4c</code></a> Add user-global site-packages to <code>$PYTHONPATH</code></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/8d5f27cca4a50790668fae0c4211d3f380213dad\"><code>8d5f27c</code></a> Install Twine in the user-global site-packages</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/b0dc178d8e9955153bdd91f7aeaca24951330289\"><code>b0dc178</code></a> Disable pip cache dir with an env var</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/bbf6e0b2f09b6ddd8a439374509c868678be1630\"><code>bbf6e0b</code></a> Copy requirements to corresponding dir @ container</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/0b69a8c2dfa166206a4007a228ec3306ac63d1d0\"><code>0b69a8c</code></a> Document broken <code>pkginfo==1.9.0</code> transitive dep</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/c54db9c2b7aa2a20b80134f0f154359c73bbdf0b\"><code>c54db9c</code></a> Integrate pip-tools-generated constraint files</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/480ec4ed586e715b06c3d3a5fcdfa4834246d7e2\"><code>480ec4e</code></a> Inherit <code>yamllint</code> config from the default preset</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/5fb2f047e26679d7846a8370de1642ff160b9025\"><code>5fb2f04</code></a> Drop <code>__token__</code> from README code usage snippets</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.5.1...v1.6.1\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/gh-action-pypi-publish&package-manager=github_actions&previous-version=1.5.1&new-version=1.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-12-05T15:10:49Z",
  "comments":0,
  "created_at":"2022-12-05T09:06:02Z",
  "draft":false,
  "id":1476066226,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5EUOMg",
  "number":792,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-05T15:10:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore(deps): bump pypa/gh-action-pypi-publish from 1.5.1 to 1.6.1",
  "updated_at":"2022-12-05T15:10:50Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v3.2.2 \u2192 v3.3.0](https://github.com/asottile/pyupgrade/compare/v3.2.2...v3.3.0)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-12-05T23:07:25Z",
  "comments":0,
  "created_at":"2022-12-05T22:22:49Z",
  "draft":false,
  "id":1477577452,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5EZhEv",
  "number":793,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-05T23:07:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-12-05T23:07:26Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It works offline with dask-awkward from its `main` branch, but the tests will still fail until a dask-awkward release is made containing dask-contrib/dask-awkward#119. We just need a dask-awkward 2022.12a3, @douglasdavis.\r\n\r\nI'm impressed that the `parse_version(\"1\") < parse_version(awkward.__version__) < parse_version(\"2\")` line survived this long in Uproot v5. I simply misunderstood what \"`< parse_version(\"2\")` meant: I must have thought that it excluded all the 2.0.0rcX pre-releases, but that's not how version ordering works. Okay. The version range has been fixed, and it no longer has an upper cap. (We have no reason to believe that there will be an Awkward 3.x, or that it might be disruptive.)\r\n\r\nThe other \"fix\", twiddling how the tests get data out of an Awkward Array, side-steps the bug that is fixed in scikit-hep/awkward#1993 (and now there's an Awkward test for it, so we don't rely on Uproot's test).\r\n\r\nUproot 5.0.0 can't be released until this is merged and this can't be merged until dask-awkward 2022.12a3 exists. But we don't need scikit-hep/awkward#1993; this PR is independent of that reaching a release. That's the order of dependencies.",
  "closed_at":"2022-12-10T03:45:31Z",
  "comments":1,
  "created_at":"2022-12-10T01:58:59Z",
  "draft":false,
  "id":1487786926,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5E9nTY",
  "number":795,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-10T03:45:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: Uproot tests now work with Awkward 2.0.0.",
  "updated_at":"2023-02-15T19:11:02Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Bumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.6.1 to 1.6.4.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/pypa/gh-action-pypi-publish/releases\">pypa/gh-action-pypi-publish's releases</a>.</em></p>\n<blockquote>\n<h2>v1.6.4</h2>\n<h2>oh, boi! again?</h2>\n<p>This is the last one tonight, promise! It fixes this embarrassing bug that was actually caught by the CI but got overlooked due to the lack of sleep.\nTL;DR GH passed <code>$HOME</code> from the external env into the container and that tricked the Python's <code>site</code> module to think that the home directory is elsewhere, adding non-existent paths to the env vars. See <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/115\">#115</a>.</p>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.3...v1.6.4\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.3...v1.6.4</a></p>\n<h2>v1.6.3</h2>\n<h1>Another Release!? Why?</h1>\n<p>In <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/112#issuecomment-1340133013\">pypa/gh-action-pypi-publish#112</a>, it was discovered that passing a <code>$PATH</code> variable even breaks the shebang. So this version adds more safeguards to make sure it keeps working with a fully broken <code>$PATH</code>.</p>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.2...v1.6.3\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.2...v1.6.3</a></p>\n<h2>v1.6.2</h2>\n<h2>What's Fixed</h2>\n<ul>\n<li>Made the <code>$PATH</code> and <code>$PYTHONPATH</code> environment variables resilient to broken values passed from the host runner environment, which previously allowed the users to accidentally break the container's internal runtime as reported in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/issues/112\">pypa/gh-action-pypi-publish#112</a></li>\n</ul>\n<h2>Internal Maintenance Improvements</h2>\n<ul>\n<li>Added a devpi-based smoke-test GitHub Actions CI/CD workflow by <a href=\"https://github.com/sesdaile-varmour\"><code>@\u200bsesdaile-varmour</code></a> in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/111\">pypa/gh-action-pypi-publish#111</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/sesdaile-varmour\"><code>@\u200bsesdaile-varmour</code></a> made their first contribution in <a href=\"https://github-redirect.dependabot.com/pypa/gh-action-pypi-publish/pull/111\">pypa/gh-action-pypi-publish#111</a></li>\n</ul>\n<p><strong>Full Diff</strong>: <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.1...v1.6.2\">https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.1...v1.6.2</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/c7f29f7adef1a245bd91520e94867e5c6eedddcc\"><code>c7f29f7</code></a> \ud83d\udc1b Override <code>$HOME</code> in the container with <code>/root</code></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/644926c9722664f88c9f456a1c367031ffb065f8\"><code>644926c</code></a> \ud83e\uddea Always run smoke testing in debug mode</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/e71a4a4c1d3837e77d0353f9229be9217526a2c4\"><code>e71a4a4</code></a> Add support for verbose bash execusion w/ <code>$DEBUG</code></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/e56e8212f48a2dd7d76d426d4bcab2f5ce15277d\"><code>e56e821</code></a> \ud83d\udc1b Make <code>id</code> always available in <code>twine-upload</code></li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/c879b84594122637ac80295111bfd478444c7983\"><code>c879b84</code></a> \ud83d\udc1b Use full path to <code>bash</code> in shebang</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/57e7d53102237d3c8f3e745ed8be27cc0e543819\"><code>57e7d53</code></a> \ud83d\udc1bEnsure the default <code>$PATH</code> value is pre-loaded</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/ce291dce5b39b74daf2a1a0dcb652314e3263edb\"><code>ce291dc</code></a> \ud83c\udfa8\ud83d\udc1bFix the branch @ pre-commit.ci badge links</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/102d8ab13f40a06246caac2b1008617a8d4673cc\"><code>102d8ab</code></a> \ud83d\udc1b Rehardcode devpi port for GHA srv container</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/3a9eaef3ef4ec31b99bda836b8b667475e6ee532\"><code>3a9eaef</code></a> \ud83d\udc1bUse different ports in/out of GHA containers</li>\n<li><a href=\"https://github.com/pypa/gh-action-pypi-publish/commit/a01fa7442e281f2856175aee1545561a54c01d6c\"><code>a01fa74</code></a> \ud83d\udc1b Use <code>localhost</code> @ GHA outside the containers</li>\n<li>Additional commits viewable in <a href=\"https://github.com/pypa/gh-action-pypi-publish/compare/v1.6.1...v1.6.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/gh-action-pypi-publish&package-manager=github_actions&previous-version=1.6.1&new-version=1.6.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
  "closed_at":"2022-12-12T14:32:10Z",
  "comments":0,
  "created_at":"2022-12-12T09:05:26Z",
  "draft":false,
  "id":1491361949,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5FKezc",
  "number":797,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-12T14:32:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"chore(deps): bump pypa/gh-action-pypi-publish from 1.6.1 to 1.6.4",
  "updated_at":"2022-12-12T14:32:11Z",
  "user":"MDM6Qm90NDk2OTkzMzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"A test in coffea results in:\r\n```\r\nValueError: 'skip beyond' in AwkwardForth runtime: tried to skip beyond the bounds of an input (0 or length)\r\n```\r\nwhen awkward forth is used, and passes when forcing the pure-python interpretation paths to be used.\r\nThese tests involve iterating over arrays and fully validating the data contained, so the arrays produced within the test are correct (and in fact the same data-wise as uproot4/awkward1).\r\n\r\nTo reproduce this:\r\n```\r\n$ pip install 'git+https://github.com/CoffeaTeam/coffea.git@awkward2_dev'\r\n$ python -c 'from coffea.nanoevents import NanoEventsFactory, PHYSLITESchema; NanoEventsFactory.from_root(\"https://github.com/CoffeaTeam/coffea/blob/master/tests/samples/DAOD_PHYSLITE_21.2.108.0.art.pool.root?raw=true\", treepath=\"CollectionTree\", schemaclass=PHYSLITESchema, use_ak_forth=False).events()'\r\n$ python -c 'from coffea.nanoevents import NanoEventsFactory, PHYSLITESchema; NanoEventsFactory.from_root(\"https://github.com/CoffeaTeam/coffea/blob/master/tests/samples/DAOD_PHYSLITE_21.2.108.0.art.pool.root?raw=true\", treepath=\"CollectionTree\", schemaclass=PHYSLITESchema, use_ak_forth=True).events()'\r\n```",
  "closed_at":"2023-03-11T12:28:26Z",
  "comments":2,
  "created_at":"2022-12-12T16:13:35Z",
  "id":1492243277,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5Y8dNN",
  "number":798,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"DAOD_PHYSLITE works in pure python interpretation, not in awkward-forth (uproot 5.0.0)",
  "updated_at":"2023-03-11T12:28:26Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/asottile/pyupgrade: v3.3.0 \u2192 v3.3.1](https://github.com/asottile/pyupgrade/compare/v3.3.0...v3.3.1)\n- [github.com/psf/black: 22.10.0 \u2192 22.12.0](https://github.com/psf/black/compare/22.10.0...22.12.0)\n- [github.com/PyCQA/isort: 5.10.1 \u2192 5.11.1](https://github.com/PyCQA/isort/compare/5.10.1...5.11.1)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-12-12T23:45:03Z",
  "comments":0,
  "created_at":"2022-12-12T23:08:26Z",
  "draft":false,
  "id":1492953803,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5FQDDn",
  "number":799,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-12T23:45:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-12-12T23:45:04Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"In the [getting started guide](https://uproot.readthedocs.io/en/latest/basic.html#nested-data-structures) it says that nested structures will automatically be flattened into a DataFrame with MultiIndex when importing using Pandas. This does not seem to be the case any more:\r\n\r\n```python\r\ndf = structured_tree.arrays([\"NMuon\", \"Muon_Px\", \"Muon_Py\", \"Muon_Pz\"], library=\"pd\")\r\nprint(df)\r\n```\r\n\r\n```\r\n      NMuon  ...                                   Muon_Pz\r\n0         2  ...  [-8.16079330444336, -11.307581901550293]\r\n1         1  ...                      [20.199968338012695]\r\n2         2  ...   [11.168285369873047, 36.96519088745117]\r\n3         2  ...   [403.84844970703125, 335.0942077636719]\r\n4         2  ...  [-89.69573211669922, 20.115053176879883]\r\n...     ...  ...                                       ...\r\n2416      1  ...                      [61.715789794921875]\r\n2417      1  ...                       [160.8179168701172]\r\n2418      1  ...                      [-52.66374969482422]\r\n2419      1  ...                       [162.1763153076172]\r\n2420      1  ...                       [54.71943664550781]\r\n```\r\n\r\nSo I guess that should be updated and maybe an example given how to use the awkward accessor on the structured columns. Assuming that that is the intended way of going about things.",
  "closed_at":"2022-12-14T19:50:25Z",
  "comments":1,
  "created_at":"2022-12-14T17:18:22Z",
  "id":1497072609,
  "labels":null,
  "locked":true,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5ZO4Ph",
  "number":800,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Reading data into Pandas in Uproot 5; awkward-pandas versus MultiIndex",
  "updated_at":"2022-12-14T19:50:25Z",
  "user":"MDQ6VXNlcjU4ODQwNjU="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"When computing Dask graphs with a operations inside a `__getitem__`,\r\n\r\n```python\r\nda = uproot.dask(skhep_testdata.data_path(\"uproot-issue-791.root\") + \":tree\")\r\nda[da.int_branch < 0].compute()\r\n```\r\n\r\nUproot is receiving names like \"less-06b0b18209c65504e8506df9da02f75d\" as branch names in `project_columns`. The strings we get in `project_columns` should be a strict subset of the strings in the input set of columns. This PR selects that subset, but it shouldn't be happening on the dask-awkward end.\r\n\r\nI'm using a version of dask-awkward from git... `7fe448a1d448fa30f09693be0b14634c7968161a` from December 9, 2022.",
  "closed_at":"2022-12-15T17:59:52Z",
  "comments":0,
  "created_at":"2022-12-14T17:51:36Z",
  "draft":false,
  "id":1497121254,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5FeeLO",
  "number":801,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-15T17:59:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: protect Uproot's 'project_columns' from Dask node names.",
  "updated_at":"2022-12-15T17:59:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This fixes #800, but I'm going to convert it into a Discussion, rather than closing the issue.\r\n\r\nIt's now Discussion #803.",
  "closed_at":"2022-12-15T17:54:39Z",
  "comments":0,
  "created_at":"2022-12-14T19:47:25Z",
  "draft":false,
  "id":1497277342,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5FfAdx",
  "number":802,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-15T17:54:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: update documentation about Pandas; we don't do MultiIndex anymore.",
  "updated_at":"2022-12-15T17:54:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"The link https://github.com/scikit-hep/uproot gets forwarded to https://github.com/scikit-hep/uproot3\r\n\r\nIs this intentional or should it go to https://github.com/scikit-hep/uproot5 now?",
  "closed_at":"2022-12-15T17:12:27Z",
  "comments":1,
  "created_at":"2022-12-15T14:33:18Z",
  "id":1498548633,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"I_kwDOD6Q_ss5ZUgmZ",
  "number":804,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"scikit-hep/uproot still gets forwarded to uproot3",
  "updated_at":"2022-12-15T17:12:27Z",
  "user":"MDQ6VXNlcjU4ODQwNjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"In `uproot.dask`'s `project_columns` implementations we need to make sure `branches` is not `None` before looping over the argument. (The optimization in `dask-awkward` will run project_columns with `None` branches if the the optimization determines that all original branches are necessary). more info at https://github.com/dask-contrib/dask-awkward/issues/134 and https://github.com/dask-contrib/dask-awkward/pull/131",
  "closed_at":"2022-12-18T03:39:02Z",
  "comments":1,
  "created_at":"2022-12-17T00:33:47Z",
  "draft":false,
  "id":1501050548,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5Fr4CU",
  "number":806,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-18T03:39:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: uproot.dask: Protect against `branches=None` in `project_columns`",
  "updated_at":"2022-12-18T03:39:02Z",
  "user":"MDQ6VXNlcjMyMDIwOTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/PyCQA/isort: 5.11.1 \u2192 v5.11.3](https://github.com/PyCQA/isort/compare/5.11.1...v5.11.3)\n<!--pre-commit.ci end-->",
  "closed_at":"2022-12-22T20:44:29Z",
  "comments":0,
  "created_at":"2022-12-19T22:39:31Z",
  "draft":false,
  "id":1503710769,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5F0s6w",
  "number":807,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-22T20:44:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2022-12-22T20:44:30Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"AwkwardForth doesn't read class members like `@instance_version`, `@fBits`, ... because they're not data; they're internal ROOT metadata. `AsObjects.awkward_form` was made to agree with the Forms of the as-built Awkward Arrays (in #790), but `AsStridedObjects.awkward_form` was still sneaking this information in.\r\n\r\nIt wasn't that the `header` and `tobject_header` flags were somehow being unset from their default values (the default value of `False` means to exclude these \"`@`\" members). The issue was that the list of member names was being taken from `Model._members`, which includes everything.\r\n\r\nNow the accumulation of `_strided_awkward_form` excludes the \"`@`' members if the `header` and `tobject_header` flags say we should.",
  "closed_at":"2022-12-22T18:39:33Z",
  "comments":3,
  "created_at":"2022-12-22T01:41:14Z",
  "draft":false,
  "id":1507126264,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5GAEqP",
  "number":808,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2022-12-22T18:39:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: AsStridedObjects.awkward_form was still including the '@' members.",
  "updated_at":"2022-12-22T19:51:33Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"<!--pre-commit.ci start-->\nupdates:\n- [github.com/PyCQA/isort: v5.11.3 \u2192 5.11.4](https://github.com/PyCQA/isort/compare/v5.11.3...5.11.4)\n<!--pre-commit.ci end-->",
  "closed_at":"2023-01-26T19:29:21Z",
  "comments":0,
  "created_at":"2022-12-26T23:43:44Z",
  "draft":false,
  "id":1511313010,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"PR_kwDOD6Q_ss5GOLFM",
  "number":810,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2023-01-26T19:29:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ci: [pre-commit.ci] pre-commit autoupdate",
  "updated_at":"2023-01-26T19:29:23Z",
  "user":"MDM6Qm90NjY4NTMxMTM="
 }
]