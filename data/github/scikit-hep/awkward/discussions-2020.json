[
 {
  "author":{
   "login":"rw"
  },
  "body":"I'm interested in using this library (when it's ready) from Rust and Golang.\r\n\r\nAre there plans for this? I think it would mean directly using the C++ headers, and skipping anything that uses Python.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Actually, all the array transformations are put under an `extern \"C\"` interface (\"layer 4\") precisely so that other language implementions can be written. The FFI only expresses C concepts, not C++. The Numba implementation can be seen as the first language to use this, beyond C++.\r\n\r\nWhile possible, it should be clear that this is a big task. A new \"layer 3\" in Rust or golang would be responsible for defining array types, allocating, tracking ownership, and deleting array memory. When Rust or golang call the \"layer 4\" functions, the arrays already have to be made\u2014the shared code only _fills_ preallocated arrays.\r\n\r\nIf Rust or golang have C++ bindings (i.e. _not_ FFI, but something more specific, an equivalent of pybind11 or Cxx.jl), then less work would have to be done. You could put a Rust or golang wrapper over \"layer 3\" the same way that it's done in Awkward with pybind11.\r\n\r\nIn most languages, though, that's not an option. FFI is there common denominator, not any C++ interface.",
     "createdAt":"2020-02-01T14:22:02Z",
     "number":166590,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Oh, a couple of other things\u2014while there would be less to write if building a new \"layer 2\" (on top of C++, equivalent to pybind11 or Cxx.jl) than a new \"layer 3\" (on top of the `extern \"C\"` interface), you would have to link the target language's reference counts with `std::shared_ptr` reference counts. The price of inheriting the array-ownership code is having to interface with it. Arrays can be created by the target language (NumPy in the Python case) or by Awkward Array (in C++ or in Numba), and both types need to deleted exactly once.\r\n\r\nThe other thing is that you don't need to wait for Awkward to be ready. It's not ready for general data analysis users, but it's sufficiently well-defined to start building new interfaces. We're at the stage where all the array types have been defined for general use (though a few more will be needed for interface with ROOT files and Arrow buffers) and we're writing functions on all of these types. `__getitem__` was a major project, but it's finished, and it's a good starting point for a new language wrapper. (It's where I started when adding Numba.)\r\n\r\nWe can discuss the particulars, but there's no need to wait.",
     "createdAt":"2020-02-01T14:39:20Z",
     "number":166591,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"rw"
     },
     "body":"@jpivarski This is great news! Thanks for planning this out and giving so much detail.\r\n\r\nFor Rust, I'd probably try to use the new [cxx library](https://github.com/dtolnay/cxx) to do type-safe interop between C++ and Rust.",
     "createdAt":"2020-02-01T19:44:17Z",
     "number":166592,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I'd like to see how this works out! To help with your planning, I can point out exactly which parts of C++ memory management we use.\r\n\r\nAll of the arrays of primitive numbers and booleans, that which is directly shared with NumPy, are in `std::shared_ptr<T>` for integer types that have to be interpreted on the C++ side (only `int8_t`, `int32_t`, `uint32_t`, and `int64_t` now and in the foreseeable future) or `std::shared_ptr<void>` (for the numerical data that _don't_ need to be interpreted on the C++ side, like the contents of NumpyArray). If these buffers are created on the C++ side, we use an [array_deleter](https://github.com/scikit-hep/awkward-1.0/blob/f9620cf6150b468de7955bb088e0249b7ea2e6fb/include/awkward/util.h#L30-L36) and if they're created on the Python side, we use a [pyobject_deleter](https://github.com/scikit-hep/awkward-1.0/blob/f9620cf6150b468de7955bb088e0249b7ea2e6fb/src/pyawkward.cpp#L42-L53), which connects C++ reference counts to Python reference counts.\r\n\r\nIt's often the case that multiple array nodes use the same buffer, so they share the `shared_ptr`. Since they might be viewing a subinterval of that buffer, they have an `offset` and `length`, but they have to share the same base pointer to properly count references.\r\n\r\nInteger arrays that the C++ needs to understand to do its work (e.g. the `starts` and `stops` in a ListArray) all have an [Index](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/Index.h) type. Indexes are usually passed around by value, but they contain a `std::shared_ptr` to the actual buffer, so really we're just copying that reference count table, `offset` and `length`.\r\n\r\nAll leaves of the nested structure are either [NumpyArray](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/array/NumpyArray.h) (intended for Python, but can be used in C++) or [RawArray](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/array/RawArray.h) (only intended for C++; a templated and header-only class). These carry `std::shared_ptr<void>` or `std::shared_ptr<T>` but are themselves carried around as `std::shared_ptr<Content>`, as all array nodes are.\r\n\r\nAll array nodes are passed around as `std::shared_ptr<Content>` so that we can mix them dynamically at runtime. (The `Content` class is full of virtual methods.) Arbitrary data structures do not require recompilation.\r\n\r\nEach of these nodes can optionally carry [Identities](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/Identities.h), which are two-dimensional arrays fulfilling a similar role to Pandas indexes. They're optional (the `std::shared_ptr<Identities>` _can_ point to `nullptr`) and only a few functions will use them (SQL-like joins), but all functions pass them through. An \"identity\" is a unique marker on all logical list/record/numbers. There are only two flavors of Identities: 32-bit and 64-bit; the specialization and possibility of `nullptr` are the reasons it's passed by pointer.\r\n\r\nEach array node also passes through a string \u2192 JSON mapping that indicates how it should be interpreted in the high-level interface. For instance, internally, strings are just ListOffsetArrays of 8-bit NumpyArrays, but they carry a parameter `\"__class__\": \"\\\"string\\\"\"` that the high-level view uses to present them as strings, rather than lists of numbers.\r\n\r\nThe identities and parameters are the only mutable attributes that the array nodes have. All the rest are immutable, and the data in the arrays themselves should be regarded as immutable. Actually, there's one exception to that: RecordArray will have mutable `contents` as requested by #103. It hasn't happened yet, but it's coming. So three\u2014three immutable attributes.\r\n\r\nTo make structures, we build them up with an append-only [FillableArray](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/fillable/FillableArray.h), which is dynamically typed. It discovers the type of the data as it's being filled. Faster filling when the type is known or partially known in advance will be special cases, not filled with FillableArray (see [root.h](https://github.com/scikit-hep/awkward-1.0/blob/master/include/awkward/io/root.h) for a first example of filling data when it's known to be `vector^N<number>`).\r\n\r\n`std::unique_ptr` is not used anywhere. I thought at first that I might be using it, but the similarity of `std::shared_ptr` to the Python memory model made it much more convenient. One of the planned array node types, RedirectArray, will be using `std::weak_ptr`, but that's about it. I use only a few memory features of C++, most of them old (not even `std::move`), because all of the performance concerns are in \"layer 4,\" under the `extern \"C\"` interface. The idea is that a typical dataset would have only a few dozen array nodes at most (representing the array _type_), but billions of array elements (the array _values_). All of the loops in C++ (except in FillableArray) walk over array _type_ and not array _values_.\r\n\r\nI don't know how well this memory model maps onto Rust, however: maybe some kind of `Box`? It should map onto golang well, since that's a garbage collected language.",
     "createdAt":"2020-02-01T20:25:12Z",
     "number":166593,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"On second thought, `__setitem__` is not going to be mutable (in development in #107), and `setidentities` and `setparameters` will eventually become immutable, too. The high-level `ak.Array` in Python is a thin wrapper around everything, and it can have a mutable `__setitem__` that replaces its `self._layout` in place so that it looks to data analysts like they're changing these things in place, but in C++ I'm moving toward complete immutability.\r\n\r\nSince these nodes are lightweight handles pointing to large arrays (shared wherever possible), there's no performance advantage to modifying things in place. There can be a conceptual advantage to high-level users (\"I just want to add this one field!\"), but that mutability can be concentrated in a layer that's easy to debug.",
     "createdAt":"2020-02-04T14:00:18Z",
     "number":166594,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This isn't any less relevant, but it's not a to-do item and I'd like to close it to see the list of remaining work more clearly.\r\n\r\nIf you're planning to build other-language versions on top of either the C layer or the C++ layer, you don't have to wait for me. Awkward 1.0 is \"doneish\" right now (and it will become more \"doneish\" as time goes on).",
     "createdAt":"2020-02-25T21:29:19Z",
     "number":166595,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":6
  },
  "createdAt":"2020-02-01T03:30:00Z",
  "number":104,
  "title":"Non-Python implementations of Awkward Array (e.g. Rust, Go)",
  "url":"https://github.com/scikit-hep/awkward/discussions/104"
 },
 {
  "author":{
   "login":"DraTeots"
  },
  "body":"Dear Jim, David, Peter and other awkward developers. \r\n\r\nLet me cite an example from the awkward array presentation:\r\n\r\n> For events with at least three leptons (electrons or muons) and a same-flavor opposite-sign lepton pair, find the same-flavor opposite-sign lepton pair with a mass closest to 91.2 GeV;\r\n\r\nI can't figure out an effective way of doing it with uproot, awkward arrays and pandas. How one does it without PartiQL? \r\n\r\nIn sequential event-by-event world is kind of easy. Somewhere I found an example with numba accelerated for loops with event by event processing. It is slow (even with numba) and I believe there might be more effective way. Maybe not as elegant as with PartiQL but still? There are cross and choose, but they kind of effective on that 2 muons example and hard to scale. \r\n\r\nLet me put simplified version of question here:\r\n\r\nImagine one has Pythia output (or any other generator) with particles parameters as sub arrays for each event. So we have some awkward arrays with something like `pdg, px, py, pz, E`. \r\n\r\nHow one selects one particle with some cuts, other particle with other cuts and builds an effective mass of  combinations? \r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This is a rather open-ended question. I'll start by ruling out Pandas, since it simply want designed for this sort of question and that's why we're developing Awkward. Also, uproot is just for reading the data.\r\n\r\nAre you asking about solving Benchmark 8 with only array-at-a-time primitives? (That's the problem you quoted.) Or about applying cuts and combinatorics in general? The latter is a broad subject in need of a tutorial, and the former was held up as an example of why array-at-a-time operations shouldn't be the _only_ way to work. Even if someone finds a clever solution or we add more primitives to make that problem easier, busy physicists shouldn't be forced to solve puzzles or find the magic primitive when they have real work to do. PartiQL is conceptually event-at-a-time (though may be implemented as array-at-a-time: see AwkwardQL), and Numba is imperative.\r\n\r\nHow recently have you tried operating on Awkward Arrays in Numba, and with what version? A week or two ago, I rewrote the Numba lowering of Awkward 1.0 to be much more lightweight. I haven't had the chance to do any performance tests on it, but in principle, it should be many times faster. (I noticed that the old version was scaling with the size of the data structure, and that's because it was pass-by-value. I've since reworked it as a cursor object that navigates over the structure but copies nothing, reading only on demand.)",
     "createdAt":"2020-03-09T11:29:21Z",
     "number":166564,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This question may just be asking for better documentation, which is definitely in our plans. Should it remain open now?",
     "createdAt":"2020-03-10T21:25:08Z",
     "number":166565,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"DraTeots"
     },
     "body":"1. Jim, thank you! Yes, this question is basically about a better documentation. And please, close the ticket if this is convenient for you. \r\n\r\n2. Could I also ask about this \"Benchmark 8\" and where it is located? (I searched scikit-hep). Or for now maybe you have your older/newer presentations with some examples? \r\n\r\n3. To clarify what we are trying to achieve. \r\n\r\nI'm one of the core software developers for Electron Ion Collider (EIC) at Jefferson Lab.  \r\n\r\nWe created a framework which consist of C++ chunks (such as geant4, track reconstruction, etc) glued together with python. So one can easily configure and run everything in python and jupyter lab (with widgets GUI and stuff like that). The data exchange (and output) between those C++ parts is made with flattened root files. One of our requirements for that files actually is that it should be possible to process them with uproot as convenient as possible. \r\n\r\nFor many years there where just a small number of people, doing analysis and work for upcoming EIC (mainly in Jefferson Lab and BNL). But recently it has been changed. There was an announcement about the CD0 for EIC, along with the beginning of Yellow Report studies initiated by EIC user group, where a lot of new users from universities and other labs will try to make their analysis on EIC physics and detectors. Result: ~150 new users are trying to tame our software for their first time. \r\n\r\nSo it is actually we (our team) - who desperately need to fill the gap in the documentation and examples. There are a lot of analysis that can be done directly from those flattened root files. And we stuck with a number of questions like: \"Can we analyze that in Jupyer? How we analyse this?\". And as I said before, I can't find a good answer to some questions. So any new information, talks, examples which could satisfy our users could be very appreciated. \r\n\r\nWould you or maybe other developers be interested in giving a talk for Electron Ion Collider User Group? \r\n\r\nI also talked with one of the EIC UG conveners and JLab management today and there is full green light to any activities and collaboration to advocate for new tools for Nuclear Physics community at JLab and EIC which also could be discussed. \r\n\r\nIf you be interested, my email is romanov@jlab.org\r\n",
     "createdAt":"2020-03-11T03:50:15Z",
     "number":166566,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"One of the IRIS-HEP projects was to develop a suite of typical analysis problems to test the expressiveness of new domain-specific languages. Awkward isn't exactly a language (at best, you could call it an embedded DSL), but the benchmarks applied. Most of them were quite easy, but number 8 was especially hard. Here's the full list:\r\n\r\nhttps://github.com/iris-hep/adl-benchmarks-index\r\n\r\n(That site also has solutions in various languages.)\r\n\r\nMy take-away from that is that the array-at-a-time interface is generally useful but not one-size-fits-all. There have to be multiple ways to solve a problem using the same data structures with as little switching overhead (i.e. hoops for the user to jump through) as possible. PartiQL was one idea of how this can be done, and @lgray is interested enough to develop that into a real product, AwkwardQL. Numba is another. They're complementary: AwkwardQL is declarative and Numba is imperative.\r\n\r\nI'd be very interested in presenting this to the EIC user group. I started giving tutorial-style talks at the LPC when Uproot was first introduced, which I think has helped a lot because it sets the context for where to look for solutions, and a community of people in close proximity who can lead each other in the right direction. Documentation is still necessary, but documentation without context is limited.\r\n\r\nI'll follow-up by email, but the most significant variable is \"when?\" Awkward 1 isn't complete, but it's very close and there are some early adopters tinkering with it. The combinatorics functions haven't been written, but I'd estimate that it would take a few days to write them, rounding up to a week. So now is an interesting time\u2014would a tutorial be entirely about the new version, it would it pragmatically include the old version?\r\n\r\nFor reference, the most recent tutorial I gave on columnar analysis is this one:\r\n\r\nhttps://github.com/jpivarski/2019-07-29-dpf-python\r\n\r\nwhich covers NumPy (on its own), Uproot, and the original Awkward.",
     "createdAt":"2020-03-11T12:07:36Z",
     "number":166567,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"audiya"
     },
     "body":"hi, im a root newbie, im interested in you topic on how one selects one particle with some cuts, other particle with other cuts and builds an effective mass of combinations?\r\n\r\nare there any tutorials available for this topic? i found one tutorial which uses rdataframe, but im rather instrested if theres a tutorial for this using standard root\r\nthanks!",
     "createdAt":"2020-10-04T06:23:47Z",
     "number":166568,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Perhaps this:\r\n\r\nhttps://github.com/jpivarski-talks/2020-04-08-eic-jlab/blob/master/2020-04-08-eic-jlab-EVALUATED.ipynb\r\n\r\nOr this:\r\n\r\nhttps://github.com/jpivarski-talks/2020-06-08-uproot-awkward-columnar-hats/blob/master/evaluated/02-columnar-analysis-awkward-array.ipynb\r\n\r\nOr this:\r\n\r\nhttps://github.com/jpivarski-talks/2020-07-13-pyhep2020-tutorial/blob/master/tutorial-EVALUATED.ipynb",
     "createdAt":"2020-10-04T14:05:42Z",
     "number":166569,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"DraTeots"
     },
     "body":"To help a bit. The video of the first tutorial is located here:\r\nhttps://www.youtube.com/watch?v=FoxNS6nlbD0\r\n\r\nThe video of PyHEP tutorial is here:\r\nhttps://www.youtube.com/watch?v=ea-zYLQBS4U&feature=youtu.be\r\n\r\nAnd the full time table of PyHEP (with videos) is here:\r\nhttps://indico.cern.ch/event/882824/timetable/#20200713.detailed",
     "createdAt":"2020-10-04T19:47:15Z",
     "number":166570,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":7
  },
  "createdAt":"2020-03-09T10:25:03Z",
  "number":153,
  "title":"How to deal with complex combinatorics?",
  "url":"https://github.com/scikit-hep/awkward/discussions/153"
 },
 {
  "author":{
   "login":"luk-f-a"
  },
  "body":"Hi! I took an indexed array from the tests and tried to apply a jitted function. \r\n\r\n```python\r\ncontent = awkward1.layout.NumpyArray(numpy.array([0.0, 1.1, 2.2, 3.3, 4.4]))\r\n\r\nind = numpy.array([0,0,0,0,1,2,3,4,4,4,4,4,], dtype=numpy.int64)\r\nindex = awkward1.layout.Index64(ind)\r\narray = awkward1.layout.IndexedArray64(index, content)\r\n\r\n\r\n@njit\r\ndef foo(x):\r\n    return x[1]\r\n\r\nfoo.py_func(array) #works\r\nfoo(array) #fails\r\n```\r\n\r\nwith error\r\n\r\n`Invalid use of Function(<built-in function getitem>) with argument(s) of type(s): (awkward1.IndexedArrayType(array(int64, 1d, C), awkward1.NumpyArrayType(array(float64, 1d, A), none, {}), none, {}), Literal[int](1))`\r\n\r\nThis is using version 0.2.19, and numba 0.49.1rc1",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The reason is that only high-level [ak.Array](https://awkward-array.readthedocs.io/en/latest/_auto/ak.Array.html) objects can be passed into (and out of) a Numba-compiled function. (By design: the high-level arrays are the ones that users are supposed to interact with primarily; the layout objects you're creating, such as IndexedArray, are part of the \"internals\". Also, behaviors such as \"this array of variable-length lists is actually an array of strings\" are defined at the ak.Array level and not the layout level.)\r\n\r\nTo make your example work, you only need to wrap your `array` as an `ak.Array`:\r\n\r\n```python\r\n>>> array2 = awkward1.Array(array)\r\n>>> foo(array2) #works\r\n0.0\r\n```\r\n\r\nThe limitations of what is supported inside the lowered code need to be listed prominently, as it is for Numba itself ([Supported Python features](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html) and [Supported NumPy features](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html)). PR #268 adds subs for where this would go, just under \"Converting arrays\" and \"Creating arrays\", visible without scrolling on a regular-sized screen.",
     "createdAt":"2020-05-15T13:05:03Z",
     "number":166549,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2020-05-15T12:17:06Z",
  "number":267,
  "title":"Passing layout nodes into Numba-JITted functions",
  "url":"https://github.com/scikit-hep/awkward/discussions/267"
 },
 {
  "author":{
   "login":"prockenschaub"
  },
  "body":"## Problem\r\nI am looking into efficient ways to represent multi-subject, multi-variate time series of arbitrary length and sampling frequency. For example, I have data on 100 patients in hospital (=subjects) for whom I collect data on heart rate and body temperature (multi-variate). The measurements are taken at random times (i.e. whenever the nurse happens to check on or the other) and the length of observation for each patient depends on their length of stay. \r\n\r\nIn a perfect world, I would represent such a structure as a 3D pandas dataframe, where rows correspond to patients, columns to variables, and the 3rd dimension is made up of timestamp-value pairs. Ideally this structure would also be performant (it can currently be approximated by having a \"nested\" dataframe where each cell is again a pandas series but can be fairly awkward - pun not intended - and slow).\r\n\r\n## Necessary operators\r\nThe most important operation on such a structure would be efficient slicing in time. For example, I often want to select all measurements taken within the first hour after admission to hospital. In a highly regular case where each measurement is taken let's say every minute for 24 hours, the above example could be represented as a 3D numpy array with dimensions 100 patients x 2 variables (heart rate and temperature) x 1440 minutes and slicing for the first hour could be performed as `arr[:, :, :60]`.\r\n\r\n## Question\r\nCan such a datastructure be represented in awkward1?\r\n\r\nawkward array seems like an ideal choice to provide a performant solution to this and can now also be embedded in pandas dataframes. \r\n\r\nIn pre-1.0 awkward implementation, something like the above could be approximated by using `SparseArray`s nested within two `JaggedArray`s (one for each variable) and treating the indexes of the `SparseArray` as the timestamp (e.g. seconds), although printing wasn't ideal since all intermediate values (which for the most part are missing) were also printed. \r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"## Suggestion\r\n\r\nHow about the following?\r\n\r\n```python\r\ndataset = [\r\n    {\"patient_name\": \"Bob\",\r\n     \"room_number\": 104,\r\n     \"data\": [{\"time\": 1591360416,\r\n               \"heart_rate\": 60,\r\n               \"temperature\": 101},\r\n              {\"time\": 1591360476,\r\n               \"heart_rate\": 70,\r\n               \"temperature\": 102},\r\n              {\"time\": 1591360536,\r\n               \"heart_rate\": 50,\r\n               \"temperature\": 99},\r\n              {\"time\": 1591360716,\r\n               \"heart_rate\": 60,\r\n               \"temperature\": 98},\r\n              {\"time\": 1591360776,\r\n               \"heart_rate\": 60,\r\n               \"temperature\": 99}]},\r\n    {\"patient_name\": \"Sally\",\r\n     \"room_number\": 102,\r\n     \"data\": [{\"time\": 1591359404,\r\n               \"heart_rate\": 130,\r\n               \"temperature\": 98},\r\n              {\"time\": 1591359464,\r\n               \"heart_rate\": 120,\r\n               \"temperature\": 98},\r\n              {\"time\": 1591359524,\r\n               \"heart_rate\": 110,\r\n               \"temperature\": 99},\r\n              {\"time\": 1591359644,\r\n               \"heart_rate\": 90,\r\n               \"temperature\": 98}]}]\r\n\r\narray = ak.Array(dataset)\r\n<Array [{patient_name: 'Bob', ... ] type='2 * {\"patient_name\": string, \"room_num...'>\r\n```\r\n\r\nI've assumed that the timestamps start their lives as the number of seconds since 1970. If most of your queries are going to be relative to the first time, you could preserve the absolute offset yet make the times relative to the starting time with\r\n\r\n```python\r\narray[\"data\", \"first_time\"] = array[\"data\", \"time\", :, 0]\r\narray[\"data\", \"time\"] = array[\"data\", \"time\"] - array[\"data\", \"first_time\"]\r\n```\r\n\r\n(I have assumed that the times within each subarray are sorted, or at the very least that index `0` corresponds to the first. This deep assignment is a feature recently added by @nikoladze and I like how it's immediately useful beyond its original domain!)\r\n\r\nSwitching to attribute access because it's more convenient (square bracket access is necessary for _assignment_; see #273), we can select times relative to the first with NumPy-style selectors. If we didn't have relative times, this would just be a little more complicated (we'd have to subtract time zero from each of the `array.data.time` expressions).\r\n\r\n```python\r\narray.data.heart_rate[array.data.time < 150]\r\n<Array [[60, 70, 50], [130, 120, 110]] type='2 * var * int64'>\r\n\r\narray.data.temperature[array.data.time < 150]\r\n<Array [[101, 102, 99], [98, 98, 99]] type='2 * var * int64'>\r\n```\r\n\r\nThese expressions have lost metadata (patient name, room number). You could keep the metadata by doing all of the operations in place, like the absolute \u2192 relative time conversion, but it's probably safer bookkeeping to create new arrays with the metadata \"zipped\" in.\r\n\r\n```python\r\nak.zip({\"room_number\": array.room_number,\r\n        \"heart_rate\": array.data.heart_rate[array.data.time < 150]})\r\n<Array [[{room_number: 104, ... ] type='2 * var * {\"room_number\": int64, \"heart_...'>\r\n```\r\n\r\nIn general, you should think of projecting columns out (e.g. `array.data.heart_rate`) and zipping columns together (e.g. the above) as quick operations. Because the data are internally columnar, all of this projecting and zipping is `_O(1)_` (does not scale with the size of the dataset).\r\n\r\n## The main thing that's different\r\n\r\nI see that you're thinking of time as part of the index. That is a Pandas way of thinking\u2014I get it\u2014but that's going against the grain in NumPy/Awkward. In Pandas terms, we've made the time a column. Whether that matters for performance depends on what you're doing with it. As an index, searching through a huge number of times can take _O(log(N))_ time, rather than _O(N)_ time, but that's assuming you're looking for one time or one time interval, not one time per patient. How much this matters depends on the relative scales of the number of patients and the number of measurements.\r\n\r\nAs a column, you have some more flexibility: inequalities like `array.data.time < 150` don't require the times to be sorted. The `array.data.time[:, 0]` used an assumption that the time at index `0` of each patient (the `:` slice), but if the times were unsorted and you couldn't assume that, you could have found the minimum for each patient with\r\n\r\n```python\r\nak.min(array.data.time, axis=1)\r\n<Array [1591360416, 1591359404] type='2 * ?int64'>\r\n```\r\n\r\nSparseArray from Awkward 0 approximates the access-via-index way of thinking from Pandas, but\r\n\r\n   * it's different enough from other types of arrays that it's hard to integrate into the operations (like ChunkedArray, which I restricted in Awkward 1 because of similar issues)\r\n   * SparseArray doesn't give you much Pandas-like indexing anyway, since array indexes always have to be integers. What would happen if you get millisecond times from some instrument?\r\n\r\nIf you didn't like seeing the zeros between time points with measurements, then SparseArray wasn't the right data structure for you. Passing around two arrays of the same length, one with time values, the other with measurements at those times, is a very common way to work in the NumPy world, and it's probably not uncommon to have \"time\" as a column in a Pandas DataFrame.\r\n\r\n## Getting data into this (or a similar) form\r\n\r\nDepending on how large your dataset is, turning it into JSON or Python objects and passing them into the ak.Array constructor might be prohibitive. (The scale where that might start to matter is 10's to 100's of GB.) When you've decided what form you want your data to have, by playing around with small samples, I can help you with a large scale conversion if the scale is large enough to matter and if I know what form it's starting in.\r\n\r\n## Involving Pandas\r\n\r\nI'm not sure how much this would involve Pandas. Awkward 1 is Pandasable by default because it seemed like that would be a good idea, though I find it hard to see how the suite of operations Pandas provides mix well with Awkward's view of the world.\r\n\r\nYou can put these things into Pandas with\r\n\r\n```python\r\npd.DataFrame({\"everything\": array})\r\n                                          everything\r\n0  ... temperature: 98}, {time: 1591360776, heart...\r\n1  ... temperature: 99}, {time: 1591359644, heart...\r\n```\r\n\r\nbut I don't see what can be done with it in such an opaque form. Maybe this?\r\n\r\n```python\r\npd.DataFrame({\"patient_name\": array.patient_name,\r\n              \"room_number\": array.room_number,\r\n              \"heart_rate\": array.data.heart_rate,\r\n              \"temperature\": array.data.temperature})\r\n  patient_name room_number            heart_rate             temperature\r\n0          Bob         104  [60, 70, 50, 60, 60]  [101, 102, 99, 98, 99]\r\n1        Sally         102   [130, 120, 110, 90]        [98, 98, 99, 98]\r\n```\r\n\r\nWe'd like to do\r\n\r\n```python\r\ndf.temperature[:, 0]\r\n```\r\n\r\nbut Pandas complains because it believes the data in each column is a scalar. (\"Can only tuple-index with a MultiIndex.\")\r\n\r\nWe could go \"full Pandas\" with something like\r\n\r\n```python\r\nak.pandas.df(array)\r\n               patient_name room_number        data data data\r\nentry subentry                                               \r\n0     0                  66         104  1591360416   60  101\r\n      1                 111         104  1591360476   70  102\r\n      2                  98         104  1591360536   50   99\r\n1     0                  83         102  1591359404  130   98\r\n      1                  97         102  1591359464  120   98\r\n      2                 108         102  1591359524  110   99\r\n      3                 108         102  1591359644   90   98\r\n```\r\n\r\n(Those last three columns are wrong: looks like a bug. They ought to be MultiIndex (\"data\", \"time\"), (\"data\", \"heart_rate\"), (\"data\", \"temperature\").)\r\n\r\nThen you'd be able to get the first time for each patient with\r\n\r\n```python\r\ndf.xs(0, level=1)\r\n      patient_name room_number        data data data\r\nentry                                               \r\n0               66         104  1591360416   60  101\r\n1               83         102  1591359404  130   98\r\n```\r\n\r\nand then get relative times with\r\n\r\n```python\r\ndf.iloc[:, 2] - df.iloc[:, 2].xs(0, level=1)\r\nentry  subentry\r\n0      0             0\r\n       1            60\r\n       2           120\r\n1      0             0\r\n       1            60\r\n       2           120\r\n       3           240\r\nName: (data,), dtype: int64\r\n```\r\n\r\nwhich you can use for the same kind of time-slicing I did above with Awkward Arrays. You might be able to do your whole analysis in Pandas. The thing is that Pandas only recognizes its own structures: there are operations for dealing with jagged arrays as a MultiIndex, but not when they're in a column.\r\n\r\n(When I talk about Awkward vs Pandas to physicists, I point out the fact that physics datasets have a lot of different nested jagged arrays, but a Pandas DataFrame can have only one MultiIndex, so physicists would be forced to use multiple DataFrames with frequent JOINs. It looks to me like your dataset has only one jagged array, so I think MultiIndex is an option for you.)\r\n\r\n@martindurant might have other suggestions on using Awkward and Pandas together. I thought it was important to take the initial step of making Awkward Arrays a column type, but I don't know where to go from there\u2014I don't know what would be the most useful way to use them in Pandas.\r\n\r\n## Closing this issue\r\n\r\nI'm open to continuing conversation! I'm closing it now because I think it's done and I want to avoid a situation like that in the previous repo where issues remain open because they _might_ not be done. It's for bookkeeping.",
     "createdAt":"2020-06-05T13:59:10Z",
     "number":166543,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"prockenschaub"
     },
     "body":"This is amazing, thanks for the incredibly thorough answer. I will go through it in detail over the weekend and have a look at how much this already covers my usual use cases. \r\n\r\n`df.temperature[:, 0]` would be closest in spirit to what I am ultimately aiming for (a pandas-like strcture with a ragged third dimension) but as you mentioned pandas is quite unhappy with anything 3D. ",
     "createdAt":"2020-06-05T14:14:44Z",
     "number":166544,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2020-06-05T07:14:25Z",
  "number":289,
  "title":"Representing time series (timestamp-value pairs)",
  "url":"https://github.com/scikit-hep/awkward/discussions/289"
 },
 {
  "author":{
   "login":"ChristianMichelsen"
  },
  "body":"Hi,\r\n\r\nFirst and foremost thanks for a really useful tool! \r\n\r\nI am having trouble specifying the dtype for awkward arrays. For simple arrays it works well, e.g:\r\n```python\r\nimport numpy as np\r\nimport awkward1 as ak\r\n\r\nx = np.arange(5, dtype=np.int8)\r\n\r\nak.Array(x)\r\nak.from_numpy(x)\r\n```\r\nHere both methods preserve the dtype: `<Array [0, 1, 2, 3, 4] type='5 * int8'>` (compared to e.g. `ak.from_iter(x)`: `<Array [0, 1, 2, 3, 4] type='5 * int64'>`. )\r\n\r\nMy problem is that I have to create nested lists (or, preferably, ragged arrays) of specific dtype (to reduce memory). \r\nRight now I make the nested lists in numba:\r\n\r\n```python\r\n\r\nN = 5\r\nnested_list = initialize_nested_lists(2, dtype=np.int8) \r\nfor i in range(N):\r\n    rand_int = np.random.randint(2)\r\n    nested_list[rand_int].append(i)\r\n```\r\nwhich gives the following output:\r\n```python\r\nListType[ListType[int8]]([[1, 2, 3], [0, 4]])\r\n```\r\n\r\nHow do I convert such a nested list to an awkward array while still keeping the correct dtype? \r\n\r\nI have tried a few different things:\r\n\r\n### 1.\r\nIn:\r\n```python \r\nak.Array(nested_list)\r\n```\r\nOut:\r\n```python \r\n<Array [[1, 2, 3], [0, 4]] type='2 * var * int64'>\r\n```\r\n\r\n\r\n### 2.\r\nIn:\r\n```python \r\nx = ak.Array(np.array(nested_list[0], dtype=np.int8))\r\ny = ak.Array(np.array(nested_list[1], dtype=np.int8))\r\nak.concatenate((x, y))\r\n```\r\nOut:\r\n```python \r\n<Array [[1, 2, 3], [0, 4]] type='2 * var * int64'>\r\n```\r\n\r\n\r\n### 3.\r\nIn:\r\n```python \r\nb = ak.ArrayBuilder()\r\nfor x in nested_list:\r\n    b.append(np.array(x, dtype=np.int8))\r\n```\r\nOut:\r\n```python \r\n<Array [[1, 2, 3], [0, 4]] type='2 * var * int64'>\r\n```\r\n\r\nAs I see it, the ArrayBuilder would be the way to go, since I then don't have to create the nested list in Numba and then convert it to an awkward-array, however, looking at the [documentation](https://awkward-array.readthedocs.io/en/latest/_auto/ak.ArrayBuilder.html) of it I fail to see how one specify the dtype (other than int/float/bool/etc.).\r\n\r\nDo you have any suggestions about which way to go about creating ragged arrays of specific dtypes - either directly with awkward and the ArrayBuilder or by converting the nested lists to awkward arrays? \r\n\r\nThanks a lot!\r\n\r\nCheers,\r\nChristian",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"You're right to start with the high-level functions (`ak.Array`, `ak.ArrayBuilder`, etc.), but what you want to do doesn't have a high-level function. You can, however, do it by accessing a lower level. (If this is needed _frequently enough_, it should get a convenience function at the high-level, but let's see how common usage plays out.)\r\n\r\nThe `ak.Array` type is a wrapper providing conveniences like ufunc-handling to a suite of layout classes, which are the structure of the data. For instance,\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> ak.Array([[1, 2, 3], [0, 4]])\r\n<Array [[1, 2, 3], [0, 4]] type='2 * var * int64'>\r\n```\r\n\r\nis laid out in memory as\r\n\r\n```python\r\n>>> ak.Array([[1, 2, 3], [0, 4]]).layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 3 5]\" offset=\"0\" length=\"3\" at=\"0x55b581801c80\"/></offsets>\r\n    <content><NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 0 4\" at=\"0x55b581803c90\"/></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nThese classes, ListOffsetArray, Index, NumpyArray, etc., are [documented here](https://awkward-array.readthedocs.io/en/latest/ak.layout.Content.html). They're part of the public API (hence, no underscores), but not what you'd usually use in analysis.\r\n\r\nYou want to build something just like this but with 8-bit integers instead of 64-bit integers. You can use the layout classes' constructors directly:\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> content = ak.layout.NumpyArray(np.array([1, 2, 3, 0, 4], np.int8))\r\n>>> index = ak.layout.Index32(np.array([0, 3, 5], np.int32))\r\n>>> listoffsetarray = ak.layout.ListOffsetArray32(index, content)\r\n>>> listoffsetarray\r\n<ListOffsetArray32>\r\n    <offsets><Index32 i=\"[0 3 5]\" offset=\"0\" length=\"3\" at=\"0x55b581345b30\"/></offsets>\r\n    <content><NumpyArray format=\"b\" shape=\"5\" data=\"0x 01020300 04\" at=\"0x55b581313990\"/></content>\r\n</ListOffsetArray32>\r\n```\r\n\r\n(Note: integer types for Index and the classes that use Indexes are fairly limited: 32-bit, unsigned 32-bit, and 64-bit. `Index8` is for tags in a UnionArray, which are always small. These choices were made to be compatible with Arrow (mostly 32-bit and now some 64-bit) and ROOT (unsigned 32-bit). NumpyArrays can in principle have any dtype, though you'll encounter unimplemented features if you stray beyond signed and unsigned int 8, 16, 32, 64-bit and float 32, 64-bit, as mentioned below.)\r\n\r\nThe ListOffsetArray object won't do all the things you'd like to do:\r\n\r\n```python\r\n>>> np.square(listoffsetarray)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: unsupported operand type(s) for *: 'awkward1._ext.NumpyArray' and 'awkward1._ext.NumpyArray'\r\n```\r\n\r\nbut you can wrap this up in an `ak.Array` to use it. (The `ak.Array` constructor takes layout objects as well as the usual iterables and NumPy arrays.)\r\n\r\n```python\r\n>>> array = ak.Array(listoffsetarray)\r\n>>> array\r\n<Array [[1, 2, 3], [0, 4]] type='2 * var * int8'>\r\n>>> np.square(array)\r\n<Array [[1, 4, 9], [0, 16]] type='2 * var * int8'>\r\n```\r\n\r\n(Working through this example, taking square roots of `int8` in the first version, revealed that I haven't considered `float16`, NumPy's format `\"e\"`, but I don't know if you'll be needing that. Handling `float16` is something we should keep in mind, as well as complex types. They should probably all be added in a one-time effort once we know the complete set of such things.)\r\n\r\nI hope this answers your question; if it's satisfactory, I'd like to close this issue because in the old repo I ended up with a lot of old open-but-not-active issues and I'd like to restrict the open issues to just the ones that require some action. Do you need anything more than the above?",
     "createdAt":"2020-07-10T13:02:45Z",
     "number":166503,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ChristianMichelsen"
     },
     "body":"Thanks for the very quick and detailed answer! \r\n\r\nYour solution with `ListOffsetArray32` could definitely work for now, however, this would also mean that I can only convert a final nested list to ragged array (which is still a great improvement compared to before!). \r\n\r\nIs there any way of appending new rows (lists) to the array while still preserving the dtype? ",
     "createdAt":"2020-07-10T13:14:37Z",
     "number":166504,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Awkward arrays are immutable objects; the `ak.ArrayBuilder` is different in that it has append-only semantics (and `snapshot` creates `ak.Arrays` that _view_ the data in an `ak.ArrayBuilder`, so that is a good way to make a growable dataset), but as you've seen, it's limited to 64-bit numbers.\r\n\r\nIf it's okay to grow your dataset in chunks, you could use [ak.concatenate](https://awkward-array.readthedocs.io/en/latest/_auto/ak.concatenate.html) to merge them. That's a copy, though, as it makes a new physically contiguous array. Depending on your performance needs, you might not want that.\r\n\r\nAnother alternative (also assuming you can grow your dataset in chunks) is to use a [PartitionedArray](https://awkward-array.readthedocs.io/en/latest/_auto/ak.partition.PartitionedArray.html). PartitionedArray is a layout type, and unlike the others, it can only be applied at the root of a structure. It allows you to logically join physically disjoint arrays, and thus build up a dataset from chunks without copying. The cost is a little indirection when you access it, and operations involving any PartitionedArrays might need to implicitly repartition to ensure that all arrays have the same partitioning. If your calculations are all derived from a single partitioned array, they'll generally be partitioned the same way (especially if you use [masking](https://awkward-array.readthedocs.io/en/latest/_auto/ak.mask.html) rather than filtering with boolean arrays, as this maintains the length of the array while crossing out the element you don't want to use).\r\n\r\nThere is a high-level function for constructing a partitioned array, [ak.partitioned](https://awkward-array.readthedocs.io/en/latest/_auto/ak.partitioned.html), though I'm unsure if it has the right interface. (It asks for a function to generate partitions and a number of partitions; it might be more natural to just take a list of arrays, as a \"soft\" alternative to `ak.concatenate`, though one that can only ever act at `axis=0`. If you have suggestions for the name and interface of such a function, I'd take those suggestions.)",
     "createdAt":"2020-07-10T13:36:39Z",
     "number":166505,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ChristianMichelsen"
     },
     "body":"Okay, I guess I'll just continue creating the nested lists in numba and then convert them to ragged arrays in the end. I'll try to look into partitioned arrays as you mention, but for now I think I'll just use the following small helper function (written below in case others might need something similar).\r\n\r\nThanks a lot for the detailed, quick answers! You may close the topic now :) \r\n\r\n```python\r\n@njit\r\ndef flatten_nested_list(nested_list):\r\n    res = List()\r\n    for lst in nested_list:\r\n        for x in lst:\r\n            res.append(x)\r\n    return np.asarray(res)\r\n\r\n@njit\r\ndef get_cumulative_indices(nested_list, index_dtype=np.int32):\r\n    index = np.zeros(len(nested_list)+1, index_dtype)\r\n    for i, lst in enumerate(nested_list):\r\n        index[i+1] = index[i] + len(lst)\r\n    return index\r\n\r\ndef nested_list_to_awkward_array(nested_list, index_dtype=np.int32):\r\n    content = ak.layout.NumpyArray(flatten_nested_list(nested_list))\r\n    index = ak.layout.Index32(get_cumulative_indices(nested_list, index_dtype))\r\n    listoffsetarray = ak.layout.ListOffsetArray32(index, content)\r\n    array = ak.Array(listoffsetarray)\r\n    return array\r\n```",
     "createdAt":"2020-07-10T13:52:15Z",
     "number":166506,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I think this is a good solution. Using Numba to make pieces of an Awkward array or indexes to slice an Awkward array is more performant than using `ak.ArrayBuilder` in the jit-compiled function (because `ak.ArrayBuilder` has to be dynamically typed). Since you're interested in 8-bit integers to save space, performance is something that you're thinking about, so the trade-off for a little complexity (19 lines of code above) makes sense.\r\n\r\nGood luck in your project!",
     "createdAt":"2020-07-10T14:06:44Z",
     "number":166507,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"You might be interested in the `ak.numbers_to_type` added in #346 and #377, which I'm going to add to a new release (0.2.28) in a few minutes. It would let you create the array with its default int64 type, then convert to int8. That might not be helpful if the goal was to stay under a memory footprint (since you'd be creating the int64 temporarily), but maybe it would be if you're creating a lot of arrays (do the conversion one at a time; the largest footprint is a single int64 array).",
     "createdAt":"2020-08-07T14:09:14Z",
     "number":166508,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ChristianMichelsen"
     },
     "body":"Oh, cool, I'll look into that! ",
     "createdAt":"2020-08-10T07:05:39Z",
     "number":166509,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":7
  },
  "createdAt":"2020-07-10T10:11:45Z",
  "number":328,
  "title":"Building arrays of a specified dtype",
  "url":"https://github.com/scikit-hep/awkward/discussions/328"
 },
 {
  "author":{
   "login":"ChristianMichelsen"
  },
  "body":"Hi!\r\n\r\nI have a short question about what's the preferred method of saving awkward 1.0 arrays? Is it by first converting it to awkward0 arrays (`ak.to_awkward0`) and then saving it with `awkward0.save(filename, array0, mode=\"w\")` or how? \r\n\r\nCheers!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The currently implemented ways to read and write Awkward 1 arrays are:\r\n\r\n   * convert to Awkward 0 and use Awkward 0's persistence (\"save/load\", \"hdf5\", \"to/fromarrow\", \"to/fromparquet\")\r\n   * use Awkward 1's [ak.to_arrow](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_arrow.html) and [ak.from_arrow](https://awkward-array.readthedocs.io/en/latest/_auto/ak.from_arrow.html)\r\n   * read from ROOT files with [Uproot 4](https://github.com/scikit-hep/uproot4).\r\n\r\nSince Awkward 1 can read and write Arrow, reading and writing Parquet is low-hanging fruit (discussed in #303). I (or someone else) would only need to port the [Awkward 0 \u2194 Arrow \u2194 Parquet chain](https://github.com/scikit-hep/awkward-array/blob/6cd32929f2ff7c219eb974a44b6f90e29ae9cf06/awkward/arrow.py#L450-L578). All the pieces are in place to do that, especially PartitionedArrays and VirtualArrays (because we usually want to view a Parquet file lazily), so the differential \"work to do\" over \"benefit\" (_dW/dB_) is small and it ought to be a high-priority item.\r\n\r\nLess low-hanging is the idea of making Awkward Array a Zarr v3 protocol extension (discussed in zarr-developers/zarr-specs#62). That's a thread I'd like to follow, but it will take some time.\r\n\r\nI'm not 100% sure it's a good idea to reimplement Awkward 0's custom format, the `.awkd` files (which were really just ZIP files with the flat-array components as binary blobs within the file) and the layer on HDF5 (which was the same thing, but it used HDF5 as a place to store flat arrays). The motivation for `.awkd` files was so that there would be at least one format that could save and retrieve Awkward arrays with 100% fidelity, but Arrow's [custom application metadata and/or extension types](https://arrow.apache.org/docs/format/Columnar.html#custom-application-metadata) could make it possible to express the extra information so that an Awkward array can losslessly round-trip to that format. Also, 1:1 parity between the object in memory and on disk is not always desirable: scikit-hep/awkward-array#246 is an example where a user was expecting an array to be smaller on disk after filtering out events, but it wasn't because slicing an Awkward array doesn't recursively compact all of its contents, and a 1:1 view of that uncompacted data on disk isn't any smaller. What that user really wanted was only the accessible elements to be saved, so he _did_ want the file-writing to be lossy, in a sense.\r\n\r\nIf all of the logical data (everything that meaningfully affects the interpretation of the array) can be saved in Arrow and therefore Parquet files, then we have no business inventing a new file format and maybe the `.awkd` files should be retired. As for the HDF5 version, a user receiving those files without knowing that they're supposed to view them through the Awkward HDF5 layer might get very confused about what they're supposed to mean. Unlike ZIP, HDF5 is a high-level format that people expect to be able to understand without extra software.",
     "createdAt":"2020-07-12T16:03:27Z",
     "number":166524,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ChristianMichelsen"
     },
     "body":"Hi again and thanks for your answer!\r\n\r\nI'm converting the awkward1 arrays to awkward0 for now and saving them as hdf5-files, since this seems to be the easiest for me and others who need to be able to also read the code. \r\n\r\nI'm looking forward to being able to save and load directly to parquet files from awkward1 at some point. \r\n\r\nOne last question; is it on purpose that awkward1 arrays are immutable (compared to awkward0 arrays)?",
     "createdAt":"2020-07-15T14:22:20Z",
     "number":166525,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> One last question; is it on purpose that awkward1 arrays are immutable (compared to awkward0 arrays)?\r\n\r\nIt's on purpose. It allows for references and values to be treated equally, which means that outputs of operations can share most of their internal data (\"structural sharing\").\r\n\r\nAwkward 0 arrays were immutable apart from their properties\u2014starts, stops, content, mask, index, etc.\u2014as a user convenience. Now the layout nodes, which have these properties, are hidden inside `ak.Array` as an \"experts only\" feature (you have to say `array.layout` to access them), so the user convenience of setting \"content\" after a node has been created is not as important. (Experts can create nodes with the constructor.) This also makes it impossible to build cyclic references, which is good because cyclic references are not supported by C++ `std::shared_ptr` and operations are not, in general, recursion-ready and raise segfaults when the stack overflows. Preventing this case as a side-effect of syntax is good for preventing errors downstream. (Cyclic references will have to be built a different way: scikit-hep/awkward-1.0#178.)\r\n\r\nNote that `ak.Array` is mutable in one particular way: you can assign fields to records. This replaces the immutable layout within the `ak.Array`, but the `ak.Array` itself is changed in-place to have the new field. (See scikit-hep/awkward-1.0#273.)",
     "createdAt":"2020-07-15T14:50:09Z",
     "number":166526,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ChristianMichelsen"
     },
     "body":"Hm, so it wouldn't be possible to implement e.g. a counter as a jagged awkward array? \r\n\r\nTo be more precise, I'll shortly explain my use case. I need to be able to iterate over particles in each list (where all lists are combined as a jagged awkward array) [[particle1, particle2, particle3], [particle4, particle5], ...] . I need to be able to set some of the particles to be invalid which I used to do by just setting the value to \"-1\" (an unphysical value for this variable) and then only iterate over the \"good\" particles. I guess a masked array could also work, however, I do not have any experience with the combination of awkward1, numba, and masked arrays. Do you have any tips for this sort of use case?\r\n\r\nThanks a lot!\r\n\r\n",
     "createdAt":"2020-07-16T09:03:16Z",
     "number":166527,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"That's right: if you mean a counter that both increases integers in nested lists and appends to those nested lists, the ListArray and ListOffsetArray in the Awkward library are not good data structures: appending to the first list would move (i.e. reallocate and copy) all the subsequent lists. There's not a fundamental problem with increasing a fixed-length set of integers (no appending), but that could be a flat array that later gets wrapped as jagged.\r\n\r\nData structures with good mutation properties, such as the counter you mentioned, hash-maps, B-trees indexes for databases, etc., are a large, open set that extend beyond the data structures covered by Awkward Array. Awkward's data structures are covering a more focused problem: viewing arbitrarily shaped input data. Since the goal is to view data that have already been made, immutability is a natural choice.\r\n\r\nIt is possible, however, for a momentary state of a dynamic data structure to be viewed as an Awkward Array. The \"snapshots\" of [ak.ArrayBuilder](https://awkward-array.readthedocs.io/en/latest/_auto/ak.ArrayBuilder.html) are an example of that: the ArrayBuilder is a dynamic data structure in that it grows by allocating blocks, filling them until they reach their limit, then replacing them with larger blocks (i.e. the `std::vector` algorithm); then when you call `snapshot()`, those blocks are viewed within an immutable `ak.Array` (while the ArrayBuilder might continue growing).\r\n\r\nOther dynamic data structures _could_ be viewed that way, and the `snapshot()` might be a lightweight view or a heavyweight copy, depending on the data structure. A counter with nested lists whose lengths do not change would be easy to wrap:\r\n\r\n```python\r\n>>> class Counter:\r\n...     def __init__(self, offsets, content):\r\n...         self.offsets, self.content = offsets, content\r\n...     def __getitem__(self, i):\r\n...         return self.content[self.offsets[i]:self.offsets[i + 1]]\r\n...     def snapshot(self):\r\n...         offsets = ak.layout.Index64(self.offsets)\r\n...         content = ak.layout.NumpyArray(self.content)\r\n...         listarray = ak.layout.ListOffsetArray64(offsets, content)\r\n...         return ak.Array(listarray)\r\n... \r\n>>> counter = Counter(np.array([0, 3, 3, 5, 10]), np.zeros(10, int))\r\n>>> counter.snapshot()\r\n<Array [[0, 0, 0], [], ... 0], [0, 0, 0, 0, 0]] type='4 * var * int64'>\r\n>>> counter[0][2] += 1\r\n>>> counter.snapshot()\r\n<Array [[0, 0, 1], [], ... 0], [0, 0, 0, 0, 0]] type='4 * var * int64'>\r\n>>> counter[3][1] += 1\r\n>>> counter[3][1] += 1\r\n>>> counter[3][1] += 1\r\n>>> counter.snapshot()\r\n<Array [[0, 0, 1], [], ... 0], [0, 3, 0, 0, 0]] type='4 * var * int64'>\r\n```\r\n\r\n(Actually, in this implementation, the originally snapshotted array would see all updates because it views the data that are changing in place. ArrayBuilder escapes that by only making changes that are beyond the view of previously snapshotted arrays.)\r\n\r\nIf we want to append to inner lists, we'd have to have blocks that can be replaced, so the Awkward snapshot would need a layer of indirection, which can be implemented by [ak.IndexedArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.IndexedArray.html).\r\n\r\nSo, things can be done, but the conceptual constraint is that Awkward Arrays are _views_ of data, not general-purpose data structures.",
     "createdAt":"2020-07-16T13:31:06Z",
     "number":166528,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Actually, this \"counter\" that you speak of sounds a lot like a histogram with a sparse axis. Perhaps this is something that's happening in boost-histogram or hist? (@HDembinski, @henryiii)",
     "createdAt":"2020-07-16T13:34:33Z",
     "number":166529,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"(The reason this closed yesterday is because I implemented Parquet reading and writing. That might help with your original problem.)",
     "createdAt":"2020-07-17T13:08:51Z",
     "number":166530,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":7
  },
  "createdAt":"2020-07-12T13:58:55Z",
  "number":329,
  "title":"How to save Awkward Arrays? (Parquet in specific)",
  "url":"https://github.com/scikit-hep/awkward/discussions/329"
 },
 {
  "author":{
   "login":"ramankhurana"
  },
  "body":"Dear Experts \r\n\r\nI try to make a ak.zip of two existing zips and ran into broadcasting error. \r\n\r\nLooking at the structure/dimension of these two input zips everything seems consistent and there should be no issue while creating these zips. \r\n\r\nI attached my code to this page for reference. \r\n\r\nDo you have some suggestions to debug this or fix this? \r\n\r\nhttps://github.com/ramankhurana/test/blob/main/test.py\r\n\r\nError: \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 87, in <module>\r\n    print (\"ele_mu\", ak.zip ({  \"ele\":ele_, \"mu\":mu_  }))\r\n  File \"/afs/cern.ch/work/k/khurana/EXOANALYSIS/CMSSW_11_0_2/src/bbDMNanoAOD/analyzer/dependencies/lib/python3.6/site-packages/awkward1/operations/structure.py\", line 348, in zip\r\n    out = awkward1._util.broadcast_and_apply(layouts, getfunction, behavior)\r\n  File \"/afs/cern.ch/work/k/khurana/EXOANALYSIS/CMSSW_11_0_2/src/bbDMNanoAOD/analyzer/dependencies/lib/python3.6/site-packages/awkward1/_util.py\", line 972, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/afs/cern.ch/work/k/khurana/EXOANALYSIS/CMSSW_11_0_2/src/bbDMNanoAOD/analyzer/dependencies/lib/python3.6/site-packages/awkward1/_util.py\", line 745, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/afs/cern.ch/work/k/khurana/EXOANALYSIS/CMSSW_11_0_2/src/bbDMNanoAOD/analyzer/dependencies/lib/python3.6/site-packages/awkward1/_util.py\", line 786, in apply\r\n    nextinputs.append(x.broadcast_tooffsets64(offsets).content)\r\nValueError: in ListOffsetArray64, cannot broadcast nested list\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.3.1/src/cpu-kernels/operations.cpp#L778)\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"You're not going to like this answer, but \"You can zip two zips unless they're unbroadcastable.\" (My assessment of the error is the same as the error message.) It's up to you to understand what's broadcastable and what's not.\r\n\r\nYour reproducer is not minimal; even if I managed to access the file on EOS, there's a lot of analysis code to pick through to find the actual error. And anyway, I think it would be more useful to look at this in a generic case. Consider two zips of a shallow array and two different deep arrays:\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> shallow = ak.Array([1.1, 2.2, 3.3, 4.4, 5.5])\r\n>>> deep1 = ak.Array([[1, 2, 3], [], [4, 5], [6, 7, 8], [9]])\r\n>>> deep2 = ak.Array([[\"a\", \"b\"], [\"c\"], [\"d\", \"e\", \"f\"], [], [\"g\"]])\r\n>>> x = ak.zip({\"x1\": shallow, \"x2\": deep1})\r\n>>> y = ak.zip({\"y1\": shallow, \"y2\": deep2})\r\n```\r\n\r\nThe shallow array is like your event-level variables, \"nMuLoose\" etc., and the deep arrays are like your collections of particles. Be aware of what [ak.zip](https://awkward-array.readthedocs.io/en/latest/_auto/ak.zip.html) is doing: it's duplicating each shallow value to match all of the corresponding deep values. To see that, let's print them out. Notice how the single `1.1` appears in three records of `x` and two records of `y`. Also notice that if you have any empty lists, the corresponding shallow values are lost entirely.\r\n\r\n```python\r\n>>> x.type\r\n5 * var * {\"x1\": float64, \"x2\": int64}\r\n>>> y.type\r\n5 * var * {\"y1\": float64, \"y2\": string}\r\n>>> x.tolist()\r\n[[{'x1': 1.1, 'x2': 1}, {'x1': 1.1, 'x2': 2}, {'x1': 1.1, 'x2': 3}],\r\n [],\r\n [{'x1': 3.3, 'x2': 4}, {'x1': 3.3, 'x2': 5}],\r\n [{'x1': 4.4, 'x2': 6}, {'x1': 4.4, 'x2': 7}, {'x1': 4.4, 'x2': 8}],\r\n [{'x1': 5.5, 'x2': 9}]]\r\n>>> y.tolist()\r\n[[{'y1': 1.1, 'y2': 'a'}, {'y1': 1.1, 'y2': 'b'}],\r\n [{'y1': 2.2, 'y2': 'c'}],\r\n [{'y1': 3.3, 'y2': 'd'}, {'y1': 3.3, 'y2': 'e'}, {'y1': 3.3, 'y2': 'f'}],\r\n [],\r\n [{'y1': 5.5, 'y2': 'g'}]]\r\n```\r\n\r\nMaybe you didn't want that. Maybe you wanted the event-level variables to stay separate from the particles by limiting how deeply they get zipped (`depth_limit`):\r\n\r\n```python\r\n>>> maybe = ak.zip({\"x1\": shallow, \"x2\": deep1}, depth_limit=1)\r\n>>> maybe.type\r\n5 * {\"x1\": float64, \"x2\": var * int64}\r\n>>> maybe.tolist()\r\n[{'x1': 1.1, 'x2': [1, 2, 3]},\r\n {'x1': 2.2, 'x2': []},\r\n {'x1': 3.3, 'x2': [4, 5]},\r\n {'x1': 4.4, 'x2': [6, 7, 8]},\r\n {'x1': 5.5, 'x2': [9]}]\r\n```\r\n\r\nIn general, the results of a zip can be used in another zip, though it makes records of records.\r\n\r\n```python\r\n>>> zip_of_zip = ak.zip({\"x\": x, \"deep1\": deep1})\r\n>>> zip_of_zip.type\r\n5 * var * {\"x\": {\"x1\": float64, \"x2\": int64}, \"deep1\": int64}\r\n>>> zip_of_zip.tolist()\r\n[[{'x': {'x1': 1.1, 'x2': 1}, 'deep1': 1}, {'x': {'x1': 1.1, 'x2': 2}, 'deep1': 2}, {'x': {'x1': 1.1, 'x2': 3}, 'deep1': 3}],\r\n [],\r\n [{'x': {'x1': 3.3, 'x2': 4}, 'deep1': 4}, {'x': {'x1': 3.3, 'x2': 5}, 'deep1': 5}],\r\n [{'x': {'x1': 4.4, 'x2': 6}, 'deep1': 6}, {'x': {'x1': 4.4, 'x2': 7}, 'deep1': 7}, {'x': {'x1': 4.4, 'x2': 8}, 'deep1': 8}],\r\n [{'x': {'x1': 5.5, 'x2': 9}, 'deep1': 9}]]\r\n```\r\n\r\nBut the `x` and the `y` that we've just created can't be zipped because they can't be broadcasted:\r\n\r\n```python\r\n>>> ak.zip({\"x\": x, \"y\": y})\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/operations/structure.py\", line 348, in zip\r\n    out = awkward1._util.broadcast_and_apply(layouts, getfunction, behavior)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 975, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 745, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 786, in apply\r\n    nextinputs.append(x.broadcast_tooffsets64(offsets).content)\r\nValueError: in ListOffsetArray64, cannot broadcast nested list\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.3.2/src/cpu-kernels/awkward_ListArray_broadcast_tooffsets.cpp#L27)\r\n```\r\n\r\nThis is not because they're zips of zips, but because the original `deep1` and `deep2` are unbroadcastable due to having different numbers of elements in their lists.\r\n\r\n```python\r\n>>> ak.zip({\"deep1\": deep1, \"deep2\": deep2})\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/operations/structure.py\", line 348, in zip\r\n    out = awkward1._util.broadcast_and_apply(layouts, getfunction, behavior)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 975, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 745, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 786, in apply\r\n    nextinputs.append(x.broadcast_tooffsets64(offsets).content)\r\nValueError: in ListOffsetArray64, cannot broadcast nested list\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.3.2/src/cpu-kernels/awkward_ListArray_broadcast_tooffsets.cpp#L27)\r\n```\r\n\r\nYou can see that with [ak.num](https://awkward-array.readthedocs.io/en/latest/_auto/ak.num.html), which tells you the number of elements in each list. If they differ, like the different numbers of electrons, muons, and jets in each event, then fields from one can't be put into fields of another because there are too many of some values and not enough of others.\r\n\r\n```python\r\n>>> ak.num(deep1), ak.num(deep2)\r\n(<Array [3, 0, 2, 3, 1] type='5 * int64'>,\r\n <Array [2, 1, 3, 0, 1] type='5 * int64'>)\r\n>>> ak.num(x), ak.num(y)\r\n(<Array [3, 0, 2, 3, 1] type='5 * int64'>,\r\n <Array [2, 1, 3, 0, 1] type='5 * int64'>)\r\n```\r\n\r\nBut maybe you never meant to try to put them all in common lists. Maybe you only wanted to shallowly zip them:\r\n\r\n```python\r\n>>> maybe2 = ak.zip({\"x\": x, \"y\": y}, depth_limit=1)\r\n>>> maybe2.type\r\n5 * {\"x\": var * {\"x1\": float64, \"x2\": int64}, \"y\": var * {\"y1\": float64, \"y2\": string}}\r\n>>> maybe2.tolist()\r\n[{'x': [{'x1': 1.1, 'x2': 1}, {'x1': 1.1, 'x2': 2}, {'x1': 1.1, 'x2': 3}],\r\n  'y': [{'y1': 1.1, 'y2': 'a'}, {'y1': 1.1, 'y2': 'b'}]},\r\n {'x': [],\r\n  'y': [{'y1': 2.2, 'y2': 'c'}]},\r\n {'x': [{'x1': 3.3, 'x2': 4}, {'x1': 3.3, 'x2': 5}],\r\n  'y': [{'y1': 3.3, 'y2': 'd'}, {'y1': 3.3, 'y2': 'e'}, {'y1': 3.3, 'y2': 'f'}]},\r\n {'x': [{'x1': 4.4, 'x2': 6}, {'x1': 4.4, 'x2': 7}, {'x1': 4.4, 'x2': 8}],\r\n  'y': []},\r\n {'x': [{'x1': 5.5, 'x2': 9}],\r\n  'y': [{'y1': 5.5, 'y2': 'g'}]}]\r\n```\r\n\r\nOr maybe you never meant to broadcast the event-level variables (\"shallow\" things like \"nMuLoose\") in the first zip, anyway.\r\n\r\nBasically, you need to be aware of the data structures you're making, the difference between zipping \"all the way down\" to the particle attributes, duplicating any event-level variables to match, and zipping down to some depth with `depth_limit`. You might also not want to make records of records, since that will determine how you extract them later\u2014or maybe you do\u2014that's personal choice.\r\n\r\nIt's much easier to get this awareness if you develop your analysis interactively on a Python prompt, in IPython, or in Jupyter. As you see above, it was instructive to print out the types of each object and the first few samples with `tolist` (slice your data with `events[:2]` so that you don't print too much!). Awkward, like NumPy, was made for interactive development, and as soon as it gets moderately complex, you _have to_ develop interactively (like NumPy: indexing can be complicated). From your test.py, I'm guessing that you are developing by adding some code to the script and re-running the script, like an edit-compile-run cycle in C++. That's an uphill battle: as your script gets longer, debugging will get slower and slower\u2014it's unproductive in the long run.\r\n\r\nBy the end, you may want everything wrapped up in a script that you can run in a push-button way, not a notebook that you have to engage interactively. For that, I usually experiment in an interactive terminal/IPython/Jupyter and copy each bit into a script as soon as it works. The notebooks are not final products, but an essential step.",
     "createdAt":"2020-10-08T13:24:00Z",
     "number":166472,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ramankhurana"
     },
     "body":"Thanks a lot Jim for quick and detailed reply. I was in the mean time following this documentation [1] again and seems I did not understood the zipping properly. I am reading your reply and following the tutorial and check what suits in my case. \r\n\r\nThanks again for advise to use the jupyter, I will try that for quick debugging, indeed I was so far using [:10] to see the print of a few events. Ofcourse jupyter will will help in fasten the debugging,. \r\n\r\nRegards. \r\n\r\n[1]\r\nhttps://mybinder.org/v2/gh/jpivarski/2020-07-13-pyhep2020-tutorial.git/1.1?urlpath=lab/tree/tutorial.ipynb",
     "createdAt":"2020-10-08T13:55:05Z",
     "number":166473,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"For my part, I need to translate explanations like the above into formal documentation on [https://awkward-array.org](https://awkward-array.org). The trouble is that everybody needs to know something different: in your case it was the `depth_limit` parameter. If this has been helpful, go ahead and close the issue now. (Though that means it will be harder for others to find! That's the trouble with GitHub Issues for \"how do I?\" type questions.)",
     "createdAt":"2020-10-08T14:17:39Z",
     "number":166474,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ramankhurana"
     },
     "body":"Indeed, It was issue of depth_limit. I was aware of depth_limit and did it right at first step and then forgot it because I was using awkward1 for the first time. It was so silly to spend to much time debugging myself and then yours.  \r\n\r\nWhat should i use next time to ask some question if I don't find it in the documentation? ",
     "createdAt":"2020-10-08T14:42:26Z",
     "number":166475,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> What should i use next time to ask some question if I don't find it in the documentation?\r\n\r\nFor a \"how do I?\" question, the best place is StackOverflow with the `[awkward-array]` tag. Then I can provide an answer like the above and when it's done, it will continue to be visible. In GitHub Issues, when something's done, it has to be closed so that I can tell what still needs to be fixed. (If everything was left open, I'd have to keep track of issues elsewhere.)",
     "createdAt":"2020-10-08T14:57:59Z",
     "number":166476,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"ramankhurana"
     },
     "body":"I understand, I will use stackoverflow in future. ",
     "createdAt":"2020-10-08T15:02:51Z",
     "number":166477,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":6
  },
  "createdAt":"2020-10-08T09:29:54Z",
  "number":486,
  "title":"Broadcasting the results of two ak.zips",
  "url":"https://github.com/scikit-hep/awkward/discussions/486"
 },
 {
  "author":{
   "login":"EnginEren"
  },
  "body":"Dear colleagues, \r\n\r\nI'm sorry beforehand if this question has been asked already.. Or the answer is hidden in the tutorials. I have tried my best to find an answer but could not find it. \r\n\r\nJust imagine you have an event loop and getting information one by one \r\n\r\n```\r\nfor i in event:\r\n    x = i.getPositionX()\r\n    e = i.getEnergy()\r\n    ## would like to accumulate these information \r\n\r\n```\r\n\r\nInstead of appending the information to python lists, I would like to append them into Jagged / numpy arrays inside the loop. \r\n\r\nCheers,\r\nEngin\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This is the conceptual shift that Awkward Array represents: you _don't_ iterate over events and you _don't_ accumulate results like appending to a loop. The reason is that these would be inefficient in Python, and NumPy-like idioms are generally more concise, too.\r\n\r\nFor instance, if you have some data (that came out of Uproot 4, for instance) like this:\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> events = ak.Array([{\"x\": 1.1, \"energy\": 10},\r\n...                    {\"x\": 2.2, \"energy\": 15},\r\n...                    {\"x\": 3.3, \"energy\": 20},\r\n...                    {\"x\": 4.4, \"energy\": 12},\r\n...                    {\"x\": 5.5, \"energy\": 17}])\r\n... \r\n>>> events\r\n<Array [{x: 1.1, energy: 10, ... energy: 17}] type='5 * {\"x\": float64, \"energy\":...'>\r\n```\r\n\r\nextracting just the `x` positions or `energy` values is\r\n\r\n```python\r\n>>> events.x\r\n<Array [1.1, 2.2, 3.3, 4.4, 5.5] type='5 * float64'>\r\n>>> events.energy\r\n<Array [10, 15, 20, 12, 17] type='5 * int64'>\r\n>>> events[\"energy\"]    # if the name of the field is not a legal identifier\r\n<Array [10, 15, 20, 12, 17] type='5 * int64'>\r\n```\r\n\r\nThe performance considerations are all different in this framework: you should consider projections like this to be essentially \"free\" because it's just rearranging metadata. For instance, if a projection takes ~30 \u03bcs on an array with 5 elements, it will take ~30 \u03bcs on an array with 5 billion elements, because it's not actually doing anything to the underlying data buffers. (The 30 \u03bcs is parsing the string `\"energy\"` and rearranging the metadata.)\r\n\r\nThis is also true if the objects are structured, like nested lists.\r\n\r\n```python\r\n>>> events = ak.Array([[{\"x\": 1.1, \"energy\": 10}, {\"x\": 2.2, \"energy\": 15}, {\"x\": 3.3, \"energy\": 20}],\r\n...                    [],\r\n...                    [{\"x\": 4.4, \"energy\": 12}, {\"x\": 5.5, \"energy\": 17}]])\r\n... \r\n>>> events.x\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5]] type='3 * var * float64'>\r\n>>> events.energy\r\n<Array [[10, 15, 20], [], [12, 17]] type='3 * var * int64'>\r\n```\r\n\r\nThat said, it is possible to do this using for loops and it can be efficient if it is compiled by [Numba](https://numba.pydata.org/).\r\n\r\n```python\r\n>>> import numba as nb\r\n>>> @nb.jit\r\n... def this_will_be_compiled(builder, events):\r\n...     for event in events:\r\n...         builder.begin_list()\r\n...         for particle in event:\r\n...             builder.append(particle.energy)\r\n...         builder.end_list()\r\n...     return builder\r\n... \r\n>>> this_will_be_compiled(ak.ArrayBuilder(), events).snapshot()\r\n<Array [[10, 15, 20], [], [12, 17]] type='3 * var * int64'>\r\n```\r\n\r\nThe documentation for [ArrayBuilder is here](https://awkward-array.readthedocs.io/en/latest/_auto/ak.ArrayBuilder.html); even though it is compiled, it can be a performance bottleneck because it has to discover the data type (e.g. how many levels of nested lists do you have?), but it is the most general way to make an Awkward Array from a for loop. Preallocating a NumPy array and filling it, if you can do that, is faster.\r\n\r\nBut I think you'll agree that if your task is as simple as projecting out `\"x\"` or `\"energy\"`, you'll want to do it with the array-at-a-time function, not a for loop.",
     "createdAt":"2020-10-28T17:50:12Z",
     "number":166449,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"EnginEren"
     },
     "body":"Hi Jim,\r\n\r\nthank you very much for your detailed answer. It was helpful. \r\n\r\nThe reason I need a loop is that we have a big `event` file (not a `root` file!) and we need to read events as batches/chunks. That is how I/O is set in this particular file. However, in the final end, I would like to transform this file into `hdf5` so that I can feed into my machine learning system. That means I dont know how to escape from looping. \r\n\r\nmaybe `numba` is a solution. Alternatively, I tried to accumulate all events with `pandas` data frame. However, I'm not sure about the performance. \r\n\r\nCheers,\r\nEngin\r\n",
     "createdAt":"2020-10-29T07:48:44Z",
     "number":166450,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"If you have to convert a rowwise source (all the data for one event is stored together, data for the next event is elsewhere, like JSON) into columnar (all data for a field, across all events, is stored together\u2014ROOT TTree, Awkward Array, Apache Arrow, Parquet are all examples), then you have to loop. This is what `ak.ArrayBuilder` is for, and it's used internally for all of these conversions: Python \u2192 Awkward in `ak.from_iter`, JSON \u2192 Awkward in `ak.from_json`, etc.\r\n\r\nSo if your data source is like that, you'll have to use a for loop and either fill a preallocated NumPy array if your data are flat or regular, or use `ak.ArrayBuilder` if they are not. The performance loss is inescapable because of the nature of the problem (the nature of rowwise data). If it's possible to iterate over your data source in Numba, that can help, but Numba only recognizes a limited set of types\u2014it only recognizes Awkward Arrays because I wrote extensions for that.\r\n\r\nOutside of Numba (because of limitations in Numba), `ak.ArrayBuilder` has a `with`-statement syntax:\r\n\r\n```python\r\nwith builder.list():\r\n    builder.append(x)\r\n    builder.append(y)\r\n    builder.append(z)\r\n```\r\n\r\ninstead of\r\n\r\n```python\r\nbuilder.begin_list()\r\nbuilder.append(x)\r\nbuilder.append(y)\r\nbuilder.append(z)\r\nbuilder.end_list()\r\n```\r\n\r\nand that's nice. (Imbalanced begin/end can be disastrous\u2014you'll likely run out of memory while building the wrong result).",
     "createdAt":"2020-10-29T12:27:06Z",
     "number":166451,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I think this is done. If not, let me know!",
     "createdAt":"2020-10-30T23:00:07Z",
     "number":166452,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"EnginEren"
     },
     "body":"Dear Jim,\r\n\r\nSorry for the late response. I was trying to digest what you suggested. I think I've managed to do it with `ak.ArrayBuilder`. However, I'll bother you if I need any optimization in the future.\r\n\r\nthanks for the help,\r\nEngin\r\n",
     "createdAt":"2020-11-04T11:35:48Z",
     "number":166453,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":5
  },
  "createdAt":"2020-10-28T13:22:48Z",
  "number":500,
  "title":"Accumulating Awkward and NumPy arrays in a loop (in and out of Numba)",
  "url":"https://github.com/scikit-hep/awkward/discussions/500"
 },
 {
  "author":{
   "login":"HDembinski"
  },
  "body":"When writing generic transforms from awkward arrays to numpy arrays, it is necessary to get the dtype of the awkward array, in order to construct a matching numpy array. I could not find out how to get the dtype for an existing awkward array. I also need a way to get the dtype in Numba-compiled Python.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I'm also in a discussion about that here: https://github.com/data-apis/consortium-feedback/discussions/6 (the common array API development).\r\n\r\nFor arrays that can be converted to NumPy (i.e. [ak.to_numpy](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_numpy.html) does not raise an exception), it would be possible to talk about its `dtype` and `shape`, but not in the general case. I don't like the idea of a property that can raise exceptions\u2014that would look like a bug, though it wouldn't be one in this case.\r\n\r\nSince conversion to NumPy is zero-copy when it's not an error, `np.asarray(awkward_array).dtype` wouldn't be a performance hit.\r\n\r\nI'm not sure what would be the right interface for this. Maybe `ak.to_dtype(awkward_array.type)`? Then such a function, `ak.to_dtype` could also raise exceptions, so it's not clearly better than `np.asarray(awkward_array).dtype`.",
     "createdAt":"2020-11-12T15:11:44Z",
     "number":166359,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"`ak.to_dtype` is fine if you cannot have a property on the array (I don't understand, but I trust that you have a better overview, awkward1 is so general, it is difficult to reason about from my layman's perspective). `np.asarray(awkward_array).dtype` seems very inelegant. Would it work in numba?",
     "createdAt":"2020-11-12T18:25:25Z",
     "number":166360,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"https://github.com/data-apis/consortium-feedback/discussions/6 seems to suggest that `.dtype` should be present when the represented data structure has a dtype.",
     "createdAt":"2020-11-12T18:30:35Z",
     "number":166361,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"We're having that conversation. The array API depends crucially on `.dtype` and `.shape` properties, but it's not obvious that Awkward arrays should have them. There are several interface possibilities:\r\n\r\n   0. Awkward Array doesn't get involved in the array API effort.\r\n   1. Defining a subset of the array API that doesn't need `.dtype` and `.shape`, though this cuts deep into functionality.\r\n   2. Add `.dtype` and `.shape` to Awkward arrays and let them raise exceptions when they don't make sense. I'm afraid that asking for a property and getting an exception would look like a bug, even though it's intended to be important feedback to the user about the structure of their data.\r\n   3. Add `.dtype` and `.shape` to Awkward arrays and have them mean what the array would look like if forced into a rectilinear array, either by padding or `dtype=\"O\"`. This would require corresponding changes to [ak.to_numpy](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_numpy.html) (a.k.a. `__array__`) to perform that forcing. I was surprised to learn that's what pyarrow does\u2014I think it's very unsafe. Not only are `dtype=\"O\"` arrays slow, but they lack all the slicing features. I don't want users to end up mixing them and getting confused when things don't work. (That happened a lot with Uproot 3 ObjectArrays.)\r\n\r\nSo at the moment, I'm not sure what the best course of action is.",
     "createdAt":"2020-11-12T19:40:29Z",
     "number":166362,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"What I want to do is take a ListOffsetArray, make a numpy array with the same length as the total size of ListOffsetArray (by which I mean len of layout.content) and the same dtype, which I then fill with computed content from the original ListOffsetArray. I need to write array transforms like this and I cannot assume that my ListOffsetArrays are all storing double. The transform must also work with Awkward arrays that store floats, too, and they should then also produce corresponding numpy arrays with the same dtype.\r\n\r\nI think you need different layers of abstractions. Perhaps on the highest-level of abstraction only a subset of the numpy interface can exist, for example no dtype. But lower levels, such as ListOffsetArray, should have dtype.\r\n\r\n I know very well from designing Boost Histogram how difficult it is to balance an abstraction that is very general and offers a very uniform interface over a large range of specific implementations. But as pointed out above, abstractions can be layered. An example are the different classes of iterators in C++, you can have random-access ones, bidirectional ones, unidirectional ones, and those which only allow either reading or writing. Together they form a hierarchy. As you go up in the abstraction hierarchy, fewer and fewer common operations are supported.",
     "createdAt":"2020-11-13T10:37:37Z",
     "number":166364,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"We might be using words in different ways: the following ListOffsetArray can't have a dtype.\r\n\r\n```python\r\n>>> array = ak.Array([[{\"x\": 1.1, \"y\": [1]}, {\"x\": 2.2, \"y\": [1, 2]}], [], [{\"x\": 3.3, \"y\": [1, 2, 3]}]])\r\n>>> print(array)\r\n[[{x: 1.1, y: [1]}, {x: 2.2, y: [1, 2]}], [], [{x: 3.3, y: [1, 2, 3]}]]\r\n>>> array.type\r\n3 * var * {\"x\": float64, \"y\": var * int64}\r\n>>> array.layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 2 2 3]\" offset=\"0\" length=\"4\" at=\"0x555b16c4f880\"/></offsets>\r\n    <content><RecordArray>\r\n        <field index=\"0\" key=\"x\">\r\n            <NumpyArray format=\"d\" shape=\"3\" data=\"1.1 2.2 3.3\" at=\"0x555b16c51890\"/>\r\n        </field>\r\n        <field index=\"1\" key=\"y\">\r\n            <ListOffsetArray64>\r\n                <offsets><Index64 i=\"[0 1 3 6]\" offset=\"0\" length=\"4\" at=\"0x555b16c538a0\"/></offsets>\r\n                <content><NumpyArray format=\"l\" shape=\"6\" data=\"1 1 2 1 2 3\" at=\"0x555b16c558b0\"/></content>\r\n            </ListOffsetArray64>\r\n        </field>\r\n    </RecordArray></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nListOffsetArrays can contain any other node type as their `content`. In this case, records. NumPy dtypes can say that `\"x\"` has `float64` type and `\"y\"` has `int64` type (i.e. `dtype=[(\"x\", np.float64), (\"y\", np.int64)]`), but how do we say that `\"y\"` contains _lists_ of integers and `\"x\"` contains non-lists of floats? Different parts of the array have different numbers of dimensions.\r\n\r\nI think you might mean \"ListOffsetArray whose `content` is NumpyArray,\" which is very much a corner case. Users posting on Uproot and Awkward's GitHub Issues frequently need more than that. If you have an application where you know that you only ever have this structure, you can build on that, but _if_ I'm going to add `dtype` as a property on `ak.Array`, _then_ I'll need to deal with the consequences of full generality.\r\n\r\nSome libraries are designed as you've described: with layered abstractions as different types, such as C++'s basic iterators, random-access ones, bidirectional ones, etc. Making all of the node types visible in Awkward 0 (as well as using plain NumPy arrays when no structure was needed) was a mistake because it exposes details that are not relevant to analyzers doing data analysis. For instance, these two arrays have different layouts, but identical meaning from a data analysis point of view:\r\n\r\n```python\r\n>>> one = ak.Array([[1, 2, 3], [999], [], [123, 123], [3, 4]])[[0, 2, 4]]\r\n>>> two = ak.Array([[1, 2, 3], [], [3, 4]])\r\n>>> one\r\n<Array [[1, 2, 3], [], [3, 4]] type='3 * var * int64'>\r\n>>> two\r\n<Array [[1, 2, 3], [], [3, 4]] type='3 * var * int64'>\r\n>>> one.layout\r\n<ListArray64>\r\n    <starts><Index64 i=\"[0 4 6]\" offset=\"0\" length=\"3\" at=\"0x557adb2f1dd0\"/></starts>\r\n    <stops><Index64 i=\"[3 4 8]\" offset=\"0\" length=\"3\" at=\"0x557adb2f1e10\"/></stops>\r\n    <content><NumpyArray format=\"l\" shape=\"8\" data=\"1 2 3 999 123 123 3 4\" at=\"0x557adb2ed880\"/></content>\r\n</ListArray64>\r\n>>> two.layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 3 3 5]\" offset=\"0\" length=\"4\" at=\"0x557adb2f20e0\"/></offsets>\r\n    <content><NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 3 4\" at=\"0x557adb2f6110\"/></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nThe only thing that happened differently is that `one` was sliced and `two` was not. In Awkward 0, users accessed these nodes (or NumPy arrays as leaf nodes) directly, and frequently made mistakes with them because these differences have nothing to do with the fact that they both represent `[[1, 2, 3], [], [4, 5]]`. ListArray vs ListOffsetArray is a good illustration of the abstraction-layering that you described: ListArray is more general than ListOffsetArray, with more capabilities, just like bidirectional vs unidirectional iterators.\r\n\r\nBut whereas C++ users are encouraged to think about how much generality they need for a given algorithm, Python users are not encouraged to think about that: lists, tuples, sequences, and iterables fly around among duck-typed functions that someone wrote while thinking about a very different problem than how much abstraction they need. NumPy made a good design choice in presenting only one type, `np.ndarray`, without making users worry about whether they're C-contiguous, Fortran-contiguous, or something else, for normal usage (without also making it impossible to get at this information, when needed). Awkward 1 is following the same model: all non-scalars are `ak.Array` instances, `type` is a generalization of `dtype` and `shape`, and `layout` is a generalization of `shape` and `strides`.",
     "createdAt":"2020-11-13T16:34:50Z",
     "number":166365,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"TTree has VARLEN arrays, which map to [[1, 2, 3,], [4], [5, 6]]. In my LHCb analysis, we exclusively use TTrees with this data structure. So for us it is not a corner case, it is the standard case. We build our whole analysis on the simplest hierarchical TTree in which each \"event\" contains values and VARLEN arrays. Processing them with uproot (not uproot4) worked very well. It is a little frightening that you consider us a corner case.",
     "createdAt":"2020-11-17T15:26:12Z",
     "number":166366,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"I obviously don't understand the new awkward library as well as you do, so yes, I was not aware that there are ListOffsetArrays which can contain other ListOffsetArrays as \"dtype\". This nesting property is of course very nice and makes this super general.\r\n\r\nI merely want to be able to get the dtype for a ListOffsetArray that contains a NumpyArray. My needs would be satisfied if there was a `ak.dtype` function that yielded the appropriate dtype for this special case and returns None or raises an exception (as you see fit) if the ListOffsetArray does not contain a NumpyArray. This function should ideally work from within numba-compiled code.\r\n\r\nEdit: I would prefer if it returned `None` instead of raising exceptions.",
     "createdAt":"2020-11-17T15:37:38Z",
     "number":166367,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I shouldn't have used the word \"corner case\" because that word implies an unimportant case. That's not what I meant. This is an important case, but it's not more important than many of the others that have come up in issues. It's definitely not \"on the fringe,\" but it's also not so overwhelmingly more central that other cases have to work around it.\r\n\r\nDefining `dtype` in such a way that it means the `Numbers` in an `Array[List[Numbers]]` would make it unclear how to define it for an `Array[List[List[Numbers]]]` or an `Array[Record[{x: Numbers1, y: Numbers2}]]` (or an `Array[Union[Numbers1, Numbers2]]`, though unions are treated as second-class citizens\u2014they can't be used in Numba, for instance\u2014unions are a \"corner case,\" partly supported).\r\n\r\nThe big problem here is that NumPy started a convention of defining the types of arrays in terms of what is like a product of two descriptors, the `shape` and the `dtype`. Rectilinear arrays can be factorized into these two descriptors, but non-rectilinear arrays are not factorizable in this way. The whole project of \"applying Numpy-like idioms to JSON-like data\" (Awkward Array's reason for being) requires a non-factorized way of expressing types. [Datashape](https://datashape.readthedocs.io/) was invented for this purpose (for the now-defunct DyND project, which was essentially what Awkward Array is), so we use that.\r\n\r\nKnowing only the depth of your arrays, the following should always be able to get the content `dtype`, and it's a metadata-only operation (_O(1)_ in the length of the array):\r\n\r\n```python\r\n>>> def get_dtype(one_level_deep):\r\n...     return np.asarray(one_level_deep[0:0]).dtype\r\n... \r\n>>> get_dtype(ak.Array([[1, 2, 3], [], [4, 5]]))\r\ndtype('int64')\r\n>>> get_dtype(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]))\r\ndtype('float64')\r\n```\r\n\r\nThe advantage of this is that it does not rely on any details of the layout (ListArray/ListOffsetArray/IndexedArray), only your knowledge that it's one level deep. Since an empty array is sliced, it will always be rectilinear and never raise exceptions. Come to think of it, this would also work on deeper arrays because slicing length zero forces all sub and sub-sub lists to also have length zero, and hence it's always rectilinear. It won't work for records, missing data, or other structures, though. If it were a function in the Awkward Array library, it would have to have qualifications to explain all of that.\r\n\r\nThe trick is getting that to work in Numba, which relies on scikit-hep/awkward-1.0#509 and (transitively) [Numba Discourse 338](https://numba.discourse.group/t/extending-numba-with-a-convertible-to-type/338). From what I currently understand, I can see how to make an explicit `np.asarray(\u00b7)` work, but not the implicit ones.\r\n\r\nThis will work, though it is strictly limited to functions that are exactly one level deep and non-empty:\r\n\r\n```python\r\n>>> @nb.njit\r\n... def get_dtype(one_level_deep):\r\n...     for nested_list in one_level_deep:\r\n...         for item in nested_list:\r\n...             return np.array(item).dtype\r\n...     raise ValueError(\"it's empty!\")\r\n... \r\n>>> get_dtype(ak.Array([[1, 2, 3], [], [4, 5]]))\r\ndtype('int64')\r\n>>> get_dtype(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]))\r\ndtype('float64')\r\n```\r\n\r\nand it can be used in other Numba functions without the entry/exit cost:\r\n\r\n```python\r\n>>> @nb.njit\r\n... def another_function(one_level_deep):\r\n...     dt = get_dtype(one_level_deep)\r\n...     return np.zeros(10, dt)\r\n... \r\n>>> another_function(ak.Array([[1, 2, 3], [], [4, 5]]))\r\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\r\n>>> another_function(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]))\r\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\r\n```\r\n\r\nIt is important for the `get_dtype` to raise an exception in the empty case because dtypes are Numba constants that can't be unified with each other. An exception has bottom type, which can be unified with anything.\r\n\r\nOnce I've implemented `np.asarray(Awkward Array)` in Numba, then this explicit\r\n\r\n```python\r\n>>> @nb.njit\r\n... def get_dtype(one_level_deep):\r\n...     return np.asarray(one_level_deep).dtype\r\n```\r\n\r\nwill work (it doesn't yet), and that open question on Numba's Discourse is about getting it to work implicitly.",
     "createdAt":"2020-11-17T16:12:38Z",
     "number":166368,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I'm losing track of the conversation between #528, #530 (this issue), and #532, but I think the following resolves everything we've talked about: in the master branch, you can now use `np.array` (always copies, exception if not rectilinear) and `np.asarray` (always views, only applies to 1D flat arrays) on Awkward Arrays in Numba-compiled functions. The `np.asarray` allows for mutability.\r\n\r\nFor example,\r\n\r\n```python\r\n>>> @nb.njit\r\n... def change(array):\r\n...     for subarray in array:\r\n...         np_view = np.asarray(subarray)\r\n...         np_view *= 10\r\n... \r\n>>> array = ak.Array([[1, 2, 3], [], [4, 5]])\r\n>>> change(array)\r\n>>> array\r\n<Array [[10, 20, 30], [], [40, 50]] type='3 * var * int64'>\r\n>>> change(array)\r\n>>> array\r\n<Array [[100, 200, 300], [], [400, 500]] type='3 * var * int64'>\r\n```\r\n\r\nThe cast to a NumPy array has to be explicit (I'm still working on how to do implicit casts in Numba, if it's even possible), and the new array is a writable view that does not own the data:\r\n\r\n```python\r\n>>> nparray.flags\r\n  C_CONTIGUOUS : True\r\n  F_CONTIGUOUS : True\r\n  OWNDATA : False\r\n  WRITEABLE : True\r\n  ALIGNED : True\r\n  WRITEBACKIFCOPY : False\r\n  UPDATEIFCOPY : False\r\n>>> nparray.base is None\r\nTrue\r\n```\r\n\r\nI think it could segfault if you hold onto a reference of the NumPy array (outside of Numba; i.e. you return it) and the original Awkward Array gets garbage collected. I think that's in general true of NumPy arrays wrapping a pointer that they do not own (and don't have a convenient Python object to assign to the NumPy array's `base`). These should be used for short excursions\u2014I'll explain that in the documentation.\r\n\r\nIncidentally, the same code above works outside of Numba:\r\n\r\n```python\r\n>>> array = ak.Array([[1, 2, 3], [], [4, 5]])\r\n>>> for subarray in array:\r\n...     np_view = np.asarray(subarray)\r\n...     np_view *= 10\r\n... \r\n>>> print(array)\r\n[[10, 20, 30], [], [40, 50]]\r\n```\r\n\r\nBut outside of Numba, I don't have the technical issue setting the `base`, so this array is safe.\r\n\r\n```python\r\n>>> np_view.flags\r\n  C_CONTIGUOUS : True\r\n  F_CONTIGUOUS : True\r\n  OWNDATA : False\r\n  WRITEABLE : True\r\n  ALIGNED : True\r\n  WRITEBACKIFCOPY : False\r\n  UPDATEIFCOPY : False\r\n\r\n>>> np_view.base\r\n<memory at 0x7fee9ef9cf40>\r\n```\r\n\r\nThat `memory` is the Awkward NumpyArray.",
     "createdAt":"2020-11-18T03:38:32Z",
     "number":166371,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":10
  },
  "createdAt":"2020-11-12T14:12:15Z",
  "number":530,
  "title":"Awkward Array dtypes and mutating data in-place (in and out of Numba)",
  "url":"https://github.com/scikit-hep/awkward/discussions/530"
 },
 {
  "author":{
   "login":"HDembinski"
  },
  "body":"What is the intended use case for `ak.flatten`? If it converts an arbitrarily complex awkward array into a flat 1d array, then I think it should return a numpy array, not a 1D awkward array. I wanted to call some of my array transforms, e.g.\r\n```\r\ndef pt_eta(px, py, pz): ...\r\n```\r\nwith `ak.flatten` instead of `np.asarray(array.layout.content)`, but that still does not work in my code, since neither the type returned by ak.flatten nor by array.layout.content has the `dtype` property.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"In other words, I don't understand why awkward arrays do not transform into numpy arrays when the result is representable as a numpy array. Requiring the developer to do the conversion explicitly with np.asarray seems not user-friendly.",
     "createdAt":"2020-11-12T19:18:56Z",
     "number":166256,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The opposite\u2014mixing Awkward-brand and NumPy-brand arrays in return values\u2014was a problem that we wanted to fix from Awkward 0. Not every flatten would return a flat array:\r\n\r\n```python\r\n>>> array = ak.Array([[[0, 1, 2], []], [], [[3, 4]], [[5], [6, 7, 8, 9]]])\r\n>>> array\r\n<Array [[[0, 1, 2], []], ... 5], [6, 7, 8, 9]]] type='4 * var * var * int64'>\r\n\r\n>>> ak.flatten(array)\r\n<Array [[0, 1, 2], [], ... [5], [6, 7, 8, 9]] type='5 * var * int64'>\r\n\r\n>>> ak.flatten(ak.flatten(array))\r\n<Array [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] type='10 * int64'>\r\n```\r\n\r\nHaving return types (`ak.Array` vs `np.ndarray`) depend on values (the structure within the input `ak.Array`) makes it difficult for developers and data analysts to use a library. Knowing that you always have to `np.asarray` is better than knowing that you sometimes have to `np.asarray`. (This function, [ak.to_numpy](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_numpy.html), is also `ak.Array.__array__`, so any API that expects an array-like should be calling `__array__` to get a NumPy-brand array.)\r\n\r\nFor normal data analysis, though, you shouldn't be extracting things from `layout`. The node structure of the array was hidden in there for this same reason: users were confused about sometimes getting a JaggedArray, sometimes an IndexedArray, sometimes a ChunkedArray, etc. in Awkward 0. We need all of these different node types to construct the abstraction, but then we deliberately hide them all inside a single type, `ak.Array`, with a fixed set of properties and methods. Those properties do not (yet?) include `dtype`, but the rule is this: you _always_ `np.asarray(\u00b7).dtype` to get the `dtype`. Then there's no guessing.",
     "createdAt":"2020-11-12T19:56:54Z",
     "number":166257,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"Sorry Jim, but you are closing issues so fast that I feel like you are ending a discussion one-sidedly. \r\n\r\nIn numpy, flatten always reduces to 1D, so if `ak.flatten` does not do that, then that's a break in similarity. The awkward behavior of flatten is certainly very unexpected.",
     "createdAt":"2020-11-13T09:21:52Z",
     "number":166258,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I only closed this one and a duplicate (which was resolved with the requested feature, by the way). That's because in this one, you're asking for something that is way outside the design of the library\u2014returning different Python types depending on array type was the bug we fixed with this redesign.\r\n\r\nIn all of these, you are coming from a different point of view: I think your needs are simpler. You have reason to believe that your arrays are ListOffsetArrays of one level deep. If that's always the case, it's less onerous to work with the nodes and indexes directly (including mutation) and you don't need the full abstraction. This redesign was motivated by the problems people were having with more complex cases, Earth missing values, unions, and chunking. There are good reasons to have multiple ways of expressing the same array, with and without an IndexedArray, for instance (which delays rearrangement), but those reasons are technical and would be very distracting in a data analysis. However, this is a difference in layout that could make the difference between an Awkward Array and a NumPy array.\r\n\r\nFinally, we do make sure that any function with the same name as NumPy has the same behavior. However, NumPy doesn't have a `np.flatten` function. The semantics of `ak.flatten` (flattening only one level) come from functional programming: LISP, Scala, and Spark, for instance.",
     "createdAt":"2020-11-13T12:31:36Z",
     "number":166259,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"HDembinski"
     },
     "body":"I thank you for the explanation, but I am talking about another aspect.\r\n\r\nFirstly, you are right, numpy does not have a free function called `flatten`, but it has a method called `flatten` on each array. Whether it is a free function or a method does not really matter, right?\r\n\r\nThe primary point is what you think `ak.flatten` should do. In numpy, it converts an N-dimensional array to a one-dimensional array. By default the order of the items in the returned array is the order in memory, so that this operation is O(1). This is very useful in practicle, because after processing I usually reach a point where I can ignore substructures and just pass all the numbers into a histogram. This is not what `ak.flatten` does, which only seems to remove one layer of the nested structure instead of all of them. I am merely telling you that I didn't expect this and I find the name misleading if it does not do what the numpy equivalent does. The word \"flatten\" indicates removal of all substructure in my ears.\r\n\r\nMy interest in this is purely practical and based on the analysis that my group does in LHCb. I argue that this is a very useful function and it could just do the same for (some) awkward arrays. Whether `ak.flatten` returns a numpy array or an awkward array is a secondary point, although I don't understand why you don't return a data structure that is representable as a numpy array as a numpy array. I don't see how that can cause problems. You have a NumpyArray class in awkward, after all.",
     "createdAt":"2020-11-17T16:00:51Z",
     "number":166260,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I think of methods vs free functions as being a different interface, though that's a matter of definition. Awkward Arrays don't have `sum`, `max`, etc. methods on purpose because they were interfering with the user-defined methods. NumPy's use of both methods and free functions with similar meanings is often described as a mistake, and I agree. New languages, like Julia, are going the route of only free functions, but the choice we made here was to use the distinction as a dividing line: nearly all generic functionality is in Awkward free functions, leaving most of the method-space available for user-defined functions.\r\n\r\nSo by \"generalizing NumPy,\" we mean \"generalizing a subset of NumPy's free functions.\" Since `np.flatten` isn't one of them, I didn't think `ak.flatten` is constrained.\r\n\r\nThe feature you want is `ak.flatten` with `axis=None`. That eliminates all structure, no matter how many levels, and eliminates all field distinctions among records. It's usually too much; that's why the _default_ is `axis=1`.\r\n\r\nOne of the unpleasant consequences of generalizing NumPy is that reducers like `ak.sum` and `ak.max` must have `axis=None` as a default. Most of the time, we want `axis=1`, but we were constrained by NumPy and it complicates analysis code to have to always insert the `axis=1`.\r\n\r\nIs the argument here that the default `ak.flatten` axis should be `None`?\r\n\r\nAs for its performance characteristics, `ak.flatten` is _O(1)_ when it can be (e.g. ListOffsetArray), _O(n)_ when it can't (e.g. ListArray, IndexedArray, etc.). I think I could cook up a NumPy example that can't be _O(1)_. Here's one that must copy:\r\n\r\n```python\r\n>>> base = np.arange(2*3*5).reshape(2, 3, 5)\r\n>>> base\r\narray([[[ 0,  1,  2,  3,  4],\r\n        [ 5,  6,  7,  8,  9],\r\n        [10, 11, 12, 13, 14]],\r\n\r\n       [[15, 16, 17, 18, 19],\r\n        [20, 21, 22, 23, 24],\r\n        [25, 26, 27, 28, 29]]])\r\n>>> sliced = base[::-1, ::2, 1:-1]\r\n>>> sliced\r\narray([[[16, 17, 18],\r\n        [26, 27, 28]],\r\n\r\n       [[ 1,  2,  3],\r\n        [11, 12, 13]]])\r\n>>> result = sliced.flatten()\r\n>>> result\r\narray([16, 17, 18, 26, 27, 28,  1,  2,  3, 11, 12, 13])\r\n>>> result.base\r\n```\r\n\r\nNon-contiguous ListArrays are the moral equivalent of that.",
     "createdAt":"2020-11-17T17:05:32Z",
     "number":166261,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"agoose77"
     },
     "body":"I'm just adding to this issue now that we're a little further along the line, in case new users discover this discussion. \r\n\r\nAwkward now has `ak.ravel`, which overloads `np.ravel` via the `__array_function__` mechanism. This function, like its NumPy counterpart, fully flattens the array. Given that Awkward only intends to maintain compatibility via the module API and not the array object itself, this is a reasonable level of compatibility.",
     "createdAt":"2021-09-02T11:32:56Z",
     "number":1271527,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":7
  },
  "createdAt":"2020-11-12T19:16:28Z",
  "number":532,
  "title":"Returning Awkward Arrays vs returning NumPy arrays from Awkward functions",
  "url":"https://github.com/scikit-hep/awkward/discussions/532"
 },
 {
  "author":{
   "login":"Superharz"
  },
  "body":"Let ```a``` and ```b``` be some jagged arrays of same outer (axis = 0) lengths.\r\nIt is possible to do:\r\n```\r\nindex = ak.argcartesian({\"x\": a, \"y\": b}, axis = 1, nested = False)\r\nx       = a[index['x']]\r\ny       = b[index['y']]\r\n```\r\nHowever, it would also be nice to have this working with ```nested = True```\r\nAt the moment, this results in:\r\n```\r\nValueError: too many jagged slice dimensions for array\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"Superharz"
     },
     "body":"This is motivated by the idea of having some ```a1```, ```a2``` and ```a3``` that are identical in shape, only different in values. And having some ```b1```, ```b2``` and ```b3``` that are also identical in shape (but different from the ```a``` ones), only different in values.\r\nI need:\r\n```\r\na1_b1 = ak.cartesian({\"x\": a1, \"y\": b1}, axis = 1, nested = True)\r\nx1    = a1_b1['x']\r\ny1    = a1_b1['y']\r\na2_b2 = ak.cartesian({\"x\": a2, \"y\": b2}, axis = 1, nested = True)\r\nx2    = a2_b2['x']\r\ny2    = a2_b2['y']\r\na3_b3 = ak.cartesian({\"x\": a3, \"y\": b3}, axis = 1, nested = True)\r\nx3    = a3_b3['x']\r\ny3    = a3_b3['y']\r\n```\r\n\r\nThat works but seems slow and I hope to be faster by doing:\r\n```\r\nindex = ak.argcartesian({\"x\": a1, \"y\": b1}, axis = 1, nested = True)\r\nx1 = a1[index['x']]\r\ny1 = b1[index['y']]\r\nx2 = a2[index['x']]\r\ny2 = b2[index['y']]\r\nx3 = a3[index['x']]\r\ny3 = b3[index['y']]\r\n```\r\nWhich doesn't work (for me).",
     "createdAt":"2020-12-07T14:38:25Z",
     "number":166173,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This doesn't work for `nested=True` because of what `nested=True` means:\r\n\r\n```python\r\n>>> a = ak.Array([[1, 2, 3], [], [4, 5]])\r\n>>> b = ak.Array([[\"a\", \"b\"], [\"c\"], [\"d\", \"e\"]])\r\n>>> index1 = ak.argcartesian({\"x\": a, \"y\": b}, nested=False)\r\n>>> index2 = ak.argcartesian({\"x\": a, \"y\": b}, nested=True)\r\n>>> index1.tolist()\r\n[[{'x': 0, 'y': 0},\r\n  {'x': 0, 'y': 1},\r\n  {'x': 1, 'y': 0},\r\n  {'x': 1, 'y': 1},\r\n  {'x': 2, 'y': 0},\r\n  {'x': 2, 'y': 1}],\r\n [],\r\n [{'x': 0, 'y': 0},\r\n  {'x': 0, 'y': 1},\r\n  {'x': 1, 'y': 0},\r\n  {'x': 1, 'y': 1}]]\r\n>>> index2.tolist()\r\n[[[{'x': 0, 'y': 0}, {'x': 0, 'y': 1}],\r\n  [{'x': 1, 'y': 0}, {'x': 1, 'y': 1}],\r\n  [{'x': 2, 'y': 0}, {'x': 2, 'y': 1}]],\r\n [],\r\n [[{'x': 0, 'y': 0}, {'x': 0, 'y': 1}],\r\n  [{'x': 1, 'y': 0}, {'x': 1, 'y': 1}]]]\r\n>>> index1[\"x\"].tolist()\r\n[[0, 0, 1, 1, 2, 2], [], [0, 0, 1, 1]]\r\n>>> index2[\"x\"].tolist()\r\n[[[0, 0], [1, 1], [2, 2]], [], [[0, 0], [1, 1]]]\r\n```\r\n\r\n`index2[\"x\"]` doesn't have the same \"shape\" (in an extended-beyond-NumPy sense) as `a`. We could explicitly broadcast `a` to get the same shape:\r\n\r\n```python\r\n>>> ak.broadcast_arrays(a, index2[\"x\"])[0].tolist()\r\n[[[1, 1], [2, 2], [3, 3]], [], [[4, 4], [5, 5]]]\r\n>>> ak.broadcast_arrays(a, index2[\"x\"])[0].tolist()\r\n[[[1, 1], [2, 2], [3, 3]], [], [[4, 4], [5, 5]]]\r\n>>> index2[\"x\"].tolist()\r\n[[[0, 0], [1, 1], [2, 2]], [], [[0, 0], [1, 1]]]\r\n```\r\n\r\nbut it still doesn't work:\r\n\r\n```python\r\n>>> ak.broadcast_arrays(a, index2[\"x\"])[0][index2[\"x\"]]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward/highlevel.py\", line 946, in __getitem__\r\n    return ak._util.wrap(self._layout[where], self._behavior)\r\nValueError: in ListArray64 attempting to get 2, index out of range\r\n```\r\n\r\nbecause, for example, the `2` in `[2, 2]` is beyond all the indexes in the corresponding `[3, 3]` in the broadcasted `a` (there's only `0` and `1`). The indexes refer to positions in the dimension one level higher: we've nested them more deeply than they were intended by broadcasting those arrays.",
     "createdAt":"2020-12-07T14:38:52Z",
     "number":166174,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"An easier way to deal with this conceptually, with possibly better performance as well, is to `ak.zip` all your \"a\" arrays into one package and all your \"b\" arrays into another, then do a single `ak.cartesian` on both groups.\r\n\r\n```python\r\n>>> many_a = ak.zip({\"a1\": a, \"a2\": a, \"a3\": a})\r\n>>> many_b = ak.zip({\"b1\": b, \"b2\": b, \"b3\": b})\r\n>>> ak.cartesian({\"x\": many_a, \"y\": many_b}).tolist()\r\n[[{'x': {'a1': 1, 'a2': 1, 'a3': 1}, 'y': {'b1': 'a', 'b2': 'a', 'b3': 'a'}},\r\n  {'x': {'a1': 1, 'a2': 1, 'a3': 1}, 'y': {'b1': 'b', 'b2': 'b', 'b3': 'b'}},\r\n  {'x': {'a1': 2, 'a2': 2, 'a3': 2}, 'y': {'b1': 'a', 'b2': 'a', 'b3': 'a'}},\r\n  {'x': {'a1': 2, 'a2': 2, 'a3': 2}, 'y': {'b1': 'b', 'b2': 'b', 'b3': 'b'}},\r\n  {'x': {'a1': 3, 'a2': 3, 'a3': 3}, 'y': {'b1': 'a', 'b2': 'a', 'b3': 'a'}},\r\n  {'x': {'a1': 3, 'a2': 3, 'a3': 3}, 'y': {'b1': 'b', 'b2': 'b', 'b3': 'b'}}],\r\n [],\r\n [{'x': {'a1': 4, 'a2': 4, 'a3': 4}, 'y': {'b1': 'd', 'b2': 'd', 'b3': 'd'}},\r\n  {'x': {'a1': 4, 'a2': 4, 'a3': 4}, 'y': {'b1': 'e', 'b2': 'e', 'b3': 'e'}},\r\n  {'x': {'a1': 5, 'a2': 5, 'a3': 5}, 'y': {'b1': 'd', 'b2': 'd', 'b3': 'd'}},\r\n  {'x': {'a1': 5, 'a2': 5, 'a3': 5}, 'y': {'b1': 'e', 'b2': 'e', 'b3': 'e'}}]]\r\n```\r\n\r\nBeyond that, Numba is generally faster than these array-at-a-time functions, though the array-at-a-time functions are generally more convenient. The second thing to try would be Numba.",
     "createdAt":"2020-12-07T14:44:33Z",
     "number":166175,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"Superharz"
     },
     "body":"Thank you for the fast response.\r\nCould this be related to #555 ?",
     "createdAt":"2020-12-07T14:45:40Z",
     "number":166176,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"#555 is about adding a way to create new arrays-of-lists. It's something one can already do from the low level (directly manipulating layouts), but it would provide a high-level way to do it, motivated by `JaggedArray.fromcounts` in Awkward 0.x. I don't personally see the connection to this.\r\n\r\nI've relabeled this issue as a question, because I think it was about technique, not new functionality. Zipping all of your arrays would let you do a single `ak.cartesian`, which might solve your speed problem. If this is a promising avenue, please close the issue. Thanks!",
     "createdAt":"2020-12-07T14:55:41Z",
     "number":166177,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"Superharz"
     },
     "body":"Okay, thank you for the clarification.\r\nYour idea of zipping the 3 arrays works like a charm and is about 5 times faster.\r\nHowever, a new speed problem arrives:\r\n\r\n```\r\neta_cross = ak.cartesian({\"x\": eta, \"y\": eta}, axis = 1, nested = True)\r\nphi_cross = ak.cartesian({\"x\": phi, \"y\": phi}, axis = 1, nested = True)\r\net_cross  = ak.cartesian({\"x\": et , \"y\": et }, axis = 1, nested = True)\r\n```\r\nThe above takes ```15s```\r\n```\r\neta_diff  = eta_cross['y'] - eta_cross['x']\r\nphi_diff  = phi_cross['y'] - phi_cross['x']\r\n```\r\nThe above  takes ```1s```\r\nNow the new approach:\r\n\r\n```\r\neta_phi_et = ak.zip({\"eta\": eta, \"phi\": phi, \"et\": et})\r\neta_phi_et_cross = ak.cartesian({\"x\": eta_phi_et, \"y\": eta_phi_et}, axis = 1, nested = True)\r\n```\r\nThe above  takes ```3s```\r\n```\r\neta_phi_et_x, eta_phi_et_y = ak.unzip(eta_phi_et_cross)\r\neta_x, phi_x, _  = ak.unzip(eta_phi_et_x)\r\neta_y, phi_y, et = ak.unzip(eta_phi_et_y)\r\n```\r\nThe above  takes almost no time.\r\n```\r\neta_diff  = eta_y - eta_x\r\nphi_diff  = phi_y - phi_x\r\n```\r\nThe above suddenly takes ```11s```\r\n\r\nThe new approach is faster in crossing but for some reason way slower in calculating the difference, which doesn't make sense to me as ```eta_y``` and ```eta_x``` should be identical to ```eta_cross['y']``` and ```eta_cross['x']```",
     "createdAt":"2020-12-08T00:01:18Z",
     "number":166178,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The trade-off is due to a difference in technique. When computing the Cartesian product (as well as several other operations) of records, we don't descend through every field of the record, computing the Cartesian product of each field. We create an [IndexedArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.IndexedArray.html) of those records. I'll demonstrate.\r\n\r\nFor the Caresian product of two record arrays,\r\n\r\n```python\r\n>>> one = ak.Array([[{\"x\": 1}, {\"x\": 2}, {\"x\": 3}], [], [{\"x\": 4}, {\"x\": 5}]])\r\n>>> two = ak.Array([[{\"y\": 1}, {\"y\": 2}], [{\"y\": 3}], [{\"y\": 4}, {\"y\": 5}]])\r\n>>> ak.cartesian([one, two]).tolist()\r\n[[({'x': 1}, {'y': 1}),\r\n  ({'x': 1}, {'y': 2}),\r\n  ({'x': 2}, {'y': 1}),\r\n  ({'x': 2}, {'y': 2}),\r\n  ({'x': 3}, {'y': 1}),\r\n  ({'x': 3}, {'y': 2})],\r\n [],\r\n [({'x': 4}, {'y': 4}),\r\n  ({'x': 4}, {'y': 5}),\r\n  ({'x': 5}, {'y': 4}),\r\n  ({'x': 5}, {'y': 5})]]\r\n```\r\n\r\nThe result is a [ListOffsetArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListOffsetArray.html) of [RecordArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.RecordArray.html) of [IndexedArrays](https://awkward-array.readthedocs.io/en/latest/ak.layout.IndexedArray.html), with the unduplicated data inside the IndexedArrays.\r\n\r\n```python\r\n>>> ak.cartesian([one, two]).layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 6 6 10]\" offset=\"0\" length=\"4\" at=\"0x562c068de5d0\"/></offsets>\r\n    <content><RecordArray>\r\n        <field index=\"0\">\r\n            <IndexedArray64>\r\n                <index><Index64 i=\"[0 0 1 1 2 2 3 3 4 4]\" offset=\"0\" length=\"10\" at=\"0x562c06903df0\"/></index>\r\n                <content><RecordArray>\r\n                    <field index=\"0\" key=\"x\">\r\n                        <NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x562c069f74e0\"/>\r\n                    </field>\r\n                </RecordArray></content>\r\n            </IndexedArray64>\r\n        </field>\r\n        <field index=\"1\">\r\n            <IndexedArray64>\r\n                <index><Index64 i=\"[0 1 0 1 0 1 3 4 3 4]\" offset=\"0\" length=\"10\" at=\"0x562c068e3ee0\"/></index>\r\n                <content><RecordArray>\r\n                    <field index=\"0\" key=\"y\">\r\n                        <NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x562c06a3e660\"/>\r\n                    </field>\r\n                </RecordArray></content>\r\n            </IndexedArray64>\r\n        </field>\r\n    </RecordArray></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nThe `index` of the IndexedArray has the duplication for the Cartesian product (`0 0 1 1 2 2 3 3 4 4` and `0 1 0 1 0 1 3 4 3 4`)\u2014essentially what you were using the `argcartesian` for earlier\u2014and the data within that are the original `1 2 3 4 5`. Whenever you access a field of the new record, it goes through this IndexedArray indirection.\r\n\r\nBy contrast, if you did a Cartesian product of non-record arrays:\r\n\r\n```python\r\n>>> ak.cartesian([ak.Array([[1, 2, 3], [], [4, 5]]), ak.Array([[1, 2], [3], [4, 5]])]).layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 6 6 10]\" offset=\"0\" length=\"4\" at=\"0x562c06a43ef0\"/></offsets>\r\n    <content><RecordArray>\r\n        <field index=\"0\">\r\n            <NumpyArray format=\"l\" shape=\"10\" data=\"1 1 2 2 3 3 4 4 5 5\" at=\"0x562c0688a7d0\"/>\r\n        </field>\r\n        <field index=\"1\">\r\n            <NumpyArray format=\"l\" shape=\"10\" data=\"1 2 1 2 1 2 4 5 4 5\" at=\"0x562c068e3ee0\"/>\r\n        </field>\r\n    </RecordArray></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nthere are no IndexedArrays and the innermost [NumpyArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.NumpyArray.html) data are duplicated.\r\n\r\nAdding this IndexedArray layer to most operations with RecordArrays was a performance upgrade this summer: issue #204, PR #261. However, as you point out, it is a tradeoff. If you have records with few fields and frequently access the results (in most or all fields), then you'd rather do `ak.cartesian` separately and then `ak.zip` (for no IndexedArray). If you have records with many fields and access the results infrequently or only access a small subset of the results, then you'd rather `ak.zip` and then `ak.cartesian` together (to get an IndexedArray).\r\n\r\nWe were motivated to make the change because (1) many physics records are wide, and a given analysis typically doesn't use all of those fields and (2) it's also fairly common for records to contain [VirtualArrays](https://awkward-array.readthedocs.io/en/latest/ak.layout.VirtualArray.html) for lazy-reading of data. The IndexedArray indirection not only delays duplication, it also prevents unaccessed fields from being eagerly read. So we were seeing cases in which dozens of fields were \"Cartesianed\" and then ignored, as well as cases in which fields were unnecessarily read from disk, \"Cartesianed,\" and ignored.\r\n\r\nWhat you're seeing in your examples is just illustrating that you have to pay the price eventually: either up front or upon access. Since you will be using all of the fields of your record, there's not a strong advantage to one case or the other. We could imagine complicating the interface, adding compute-once caches to the IndexedArrays, but there's diminishing returns in that: the array-at-a-time interface is a balance of fast and convenient (at least, faster than Python loops and more convenient than writing a function in Numba). If you really need speed for a given application, you should probably turn to Numba. That avoids the whole intermediate arrays that duplicate the data: a traditional for loop will win on a CPU. (It's not as clear on a GPU, but the GPU implementations are far from ready.) This is the same reason Numba usually beats NumPy.\r\n\r\nBut this isn't a concession: the ability to mix Awkward Array operations with the occasional Numba-accelerated loop was [part of the plan](https://docs.google.com/document/d/1lj8ARTKV1_hqGTh0W_f01S6SsmpzZAXz9qqqWnEB3j4/edit?usp=sharing). It enables \"non-premature optimization\": you try it in Awkward operations because they're the most convenient, then replace just the hot-spots with Numba, leaving everything else intact.",
     "createdAt":"2020-12-08T00:42:32Z",
     "number":166179,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":7
  },
  "createdAt":"2020-12-07T14:17:14Z",
  "number":575,
  "title":"ak.argcartesian and performance of record arrays vs non-record arrays in ak.cartesian",
  "url":"https://github.com/scikit-hep/awkward/discussions/575"
 },
 {
  "author":{
   "login":"tamasgal"
  },
  "body":"This issue arose in https://github.com/scikit-hep/awkward-1.0/issues/572\r\n\r\nI have difficulties with a recursive function using `awkward.Array`s. The following example simply traverses an array with an `ndim>=2` and produces an array with `ndim-1` which contains a boolean entry for each sub-array which starts and ends with the given `start` and `end` integers. It works fine without `njit` but fails in the Numba context as seen below.\r\n\r\n```python\r\ndef mask_startend(arr, start, end):\r\n    builder = ak.ArrayBuilder()\r\n    _mask_startend(arr, start, end, builder)\r\n    return builder.snapshot()\r\n\r\n@nb.njit  # raises \r\ndef _mask_startend(arr, start, end, builder):\r\n    if arr.ndim == 2:  # recursion stop\r\n        for el in arr:\r\n            if len(el) > 0 and el[0] == start and el[-1] == end:\r\n                builder.boolean(True)\r\n            else:\r\n                builder.boolean(False)\r\n        return\r\n    \r\n    for subarray in arr:\r\n        builder.begin_list()\r\n        _mask_startend(subarray, start, end, builder)\r\n        builder.end_list()\r\n```\r\n\r\nThis gives without `@nb.njit` (only `[1, 2, 3]` and `[1, 3]` start with 1 and 3):\r\n\r\n```\r\n>>> mask_startend(ak.Array([[[1,2,3], [1,2]], [[1, 3]], [[1, 2], [3, 4]]]), 1, 3).tolist()\r\n[[True, False], [True], [False, False]]\r\n```\r\n\r\nBut gives an error when JITted. It seems that the `eq` function from `el[0] == start` is failing due to type inference. `el[0]` should report its type as a simple `int64` but somehow it's that array view which of course doesn't have an `==` implementation.\r\nI guess that this is coming from type inference confusion caused by the iterator interface, but I am not sure.\r\n\r\nAny hints or ideas are appreciated!\r\n\r\n```\r\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\r\nNo implementation of function Function(<built-in function eq>) found for signature:\r\n\r\n >>> eq(ak.ArrayView(ak.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), int64)\r\n\r\nThere are 32 candidate implementations:\r\n      - Of which 30 did not match due to:\r\n      Overload of function 'eq': File: <numerous>: Line N/A.\r\n        With argument(s): '(ak.ArrayView(ak.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), int64)':\r\n       No match.\r\n      - Of which 2 did not match due to:\r\n      Operator Overload in function 'eq': File: unknown: Line unknown.\r\n        With argument(s): '(ak.ArrayView(ak.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), int64)':\r\n       No match for registered cases:\r\n        * (bool, bool) -> bool\r\n        * (int8, int8) -> bool\r\n        * (int16, int16) -> bool\r\n        * (int32, int32) -> bool\r\n        * (int64, int64) -> bool\r\n        * (uint8, uint8) -> bool\r\n        * (uint16, uint16) -> bool\r\n        * (uint32, uint32) -> bool\r\n        * (uint64, uint64) -> bool\r\n        * (float32, float32) -> bool\r\n        * (float64, float64) -> bool\r\n        * (complex64, complex64) -> bool\r\n        * (complex128, complex128) -> bool\r\n\r\nDuring: typing of intrinsic-call at <ipython-input-8-00220a4074bc> (10)\r\n\r\nFile \"<ipython-input-8-00220a4074bc>\", line 10:\r\ndef _mask_startend(arr, start, end, builder):\r\n    <source elided>\r\n        for el in arr:\r\n            if len(el) > 0 and el[0] == start and el[-1] == end:\r\n            ^\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Without knowing your specific problem, I put a note about recursion in the other issue: https://github.com/scikit-hep/awkward-1.0/issues/572#issuecomment-740789151\r\n\r\nI was actually in a Numba developer's meeting, but we ran overtime and I didn't get to ask about recursion.\r\n\r\nAlso, because I hadn't investigated it before, I checked to see if there's any documentation on it. There is:\r\n\r\nhttps://numba.pydata.org/numba-doc/latest/proposals/typing_recursion.html\r\n\r\nThe last note on that page about \"limitations\" seems to be about what I found in the code (see above comment) about the call stack.\r\n\r\nI'm going to see if I can cast your problem in the form that has been implemented. Failing that, I'll close this issue because it's actually a Numba issue.",
     "createdAt":"2020-12-08T17:53:17Z",
     "number":166048,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Yes thanks! Saw it already `:)`\r\n\r\nBtw. I also found the NBEP 6, but could not figure out how to use type annotation with complex structures like these awkward arrays. If you have any examples for that, that would be very helpful! I already worked with type annotated Numba-JIT functions before, but only with primitive types and NumPy arrays.",
     "createdAt":"2020-12-08T17:58:35Z",
     "number":166049,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The first quick thing is that if `array.ndim == 2`, then\r\n\r\n```python\r\nel[0] == start\r\n```\r\n\r\nwould be an array comparison, which would return an array of booleans (is the first element of `el[0]` equal to `start`? is the second? is the third?), which can't be used as a predicate, anyway. You don't see _that_ error message because \"`np.equal(`Awkward Array, number`)`\" hasn't been implemented. That's what I was asking about in the meeting: I want to implement all of these by taking advantage of Numba's existing ufuncs (such as `np.equal`) and I was getting hints on how to do that.\r\n\r\nSo as a first step, you either want something different from\r\n\r\n```python\r\nel[0] == start and el[-1] == end\r\n```\r\n\r\nor perhaps you instead wanted this case to be `ndim == 1`:\r\n\r\n```python\r\nif arr.ndim == 1:  # recursion stop\r\n```",
     "createdAt":"2020-12-08T18:01:06Z",
     "number":166050,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Ah, that's actually a doubly nested `for`-loop (which is in fact the lowest dimension to be supported), so `el` is a sub-array. The variable names are a bit misleading, sorry \ud83d\ude48. So `el` is a subarray and then I am looking for the first and last element if those are equal to `start` and `end`.\r\n\r\nSo if I understood correctly, the problem is that if a higher dimensional (`arr.ndim > 2`) is passed in, the `if arr.ndim == 2` is not skipped because there is no logic resolution of the code at that stage, so it goes further and still tries to find `len(el) > 0` which is then in fact a higher dimensional one (and actually doesn't make sense in the algorithm) and does not implement equality (we wouldn't need them anyways but it still tries to).\r\nThe main problem therefore is that that specific part of the code is only valid for `arr.ndim == 2` but cannot be hidden for higher dimns.\r\n\r\n```\r\n    if arr.ndim == 2:  # recursion stop\r\n        for el in arr:\r\n            if len(el) > 0 and el[0] == start and el[-1] == end:\r\n                builder.boolean(True)\r\n            else:\r\n                builder.boolean(False)\r\n        return\r\n```",
     "createdAt":"2020-12-08T18:06:47Z",
     "number":166051,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I should still think about the Numba recursion problem, but you know, this can be solved entirely by Awkward Array primitives, too.\r\n\r\nStarting with an example of integer endpoints like\r\n\r\n```python\r\n>>> import awkward as ak\r\n>>> example = ak.Array([[[0, 1, 2], []], [[3, 4]], [], [[5], [6, 7, 8, 9]]])\r\n>>> example\r\n<Array [[[0, 1, 2], []], ... 5], [6, 7, 8, 9]]] type='4 * var * var * int64'>\r\n```\r\n\r\nSome of these are empty, so part of the solution will involve avoiding accessing the first or last element of an empty array.\r\n\r\n```python\r\n>>> ak.num(example, axis=-1)\r\n<Array [[3, 0], [2], [], [1, 4]] type='4 * var * int64'>\r\n>>> nonempty = ak.num(example, axis=-1) > 0\r\n>>> nonempty\r\n<Array [[True, False], ... [True, True]] type='4 * var * bool'>\r\n```\r\n\r\nIf we used this as a cut, it would reduce the length of the inner lists, which would make the final result hard to apply to arrays of the original length. So instead of a standard boolean slice, we'll use a [mask-slice](https://awkward-array.readthedocs.io/en/latest/_auto/ak.mask.html):\r\n\r\n```python\r\n>>> example.mask[nonempty]\r\n<Array [[[0, 1, 2], None], ... [6, 7, 8, 9]]] type='4 * var * option[var * int64]'>\r\n```\r\n\r\nWe want to pick out the first and last elements of each remaining list at the deepest level, whatever that is. As in NumPy, we can use ellipsis (`...`):\r\n\r\n```python\r\n>>> example.mask[nonempty][..., 0]\r\n<Array [[0, None], [3], [], [5, 6]] type='4 * var * ?int64'>\r\n>>> example.mask[nonempty][..., -1]\r\n<Array [[2, None], [4], [], [5, 9]] type='4 * var * ?int64'>\r\n```\r\n\r\nFor a given `start` and `stop`, like `6` and `9`,\r\n\r\n```python\r\n>>> start, stop = 6, 9\r\n>>> example.mask[nonempty][..., 0] == start\r\n<Array [[False, None], ... [False, True]] type='4 * var * ?bool'>\r\n>>> example.mask[nonempty][..., -1] == stop\r\n<Array [[False, None], ... [False, True]] type='4 * var * ?bool'>\r\n```\r\n\r\nWe need both of those to be true:\r\n\r\n```python\r\n>>> good = ((example.mask[nonempty][..., 0] == start) &\r\n...         (example.mask[nonempty][..., -1] == stop))\r\n>>> good\r\n<Array [[False, None], ... [False, True]] type='4 * var * ?bool'>\r\n```\r\n\r\nWe still have `None` values in the output. We could use this as a slice, but it's probably not what you want:\r\n\r\n```python\r\n>>> example[good]\r\n<Array [[None], [], [], [[6, 7, 8, 9]]] type='4 * var * option[var * int64]'>\r\n```\r\n\r\nWe don't want to pick out the empty arrays as `None`; we want them to go away, which is what `False` would do. So just replace `None` \u2192 `False`:\r\n\r\n```python\r\n>>> ak.fill_none(good, False)\r\n<Array [[False, False], ... [False, True]] type='4 * var * bool'>\r\n```\r\n\r\nPutting it all together,\r\n\r\n```python\r\n>>> def mask_startstop(arr, start, stop):\r\n...     nonempty = ak.num(arr, axis=-1) > 0\r\n...     good = ((arr.mask[nonempty][..., 0] == start) &\r\n...             (arr.mask[nonempty][..., -1] == stop))\r\n...     return ak.fill_none(good, False)\r\n...\r\n>>> mask_startstop(example, 0, 2)\r\n<Array [[True, False], ... [False, False]] type='4 * var * bool'>\r\n>>> mask_startstop(example, 5, 5)\r\n<Array [[False, False], ... [True, False]] type='4 * var * bool'>\r\n```\r\n\r\nBut I'll think about the Numba thing, too, because I want to understand what Numba can and can't do, and why.",
     "createdAt":"2020-12-08T18:23:15Z",
     "number":166052,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Thanks for the nice example, that's also very helpful. I already had a somewhat similar solution but wanted to squeeze out the last bits of performance since we need to apply this to very large datasets and I wanted to avoid allocation as much as possible. I will review your workflow and compare it with the current implementation, which contains just hardcoded functions for a few dimensions.",
     "createdAt":"2020-12-08T18:33:54Z",
     "number":166053,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Keep in mind that `ak.ArrayBuilder` is not super-fast. It's compiled, but dynamically typed. Someday, we'll need to have a \"TypedArrayBuilder\" that takes a type as a constructor argument to build array structures without having to discover the type at runtime.",
     "createdAt":"2020-12-08T18:39:13Z",
     "number":166054,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Oh OK, I did not know that. I'll definitely compare the performance with your approach anyways and report back!",
     "createdAt":"2020-12-08T18:40:38Z",
     "number":166055,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I struggled with Numba recursion for a while and decided that I don't understand their call-stack restriction. But anyway, you're not going to get the most speed from that because of `ArrayBuilder`. The absolutely fastest way to do this is to unwrap the array until you're down to just the part that the Numba-compiled function applies to, then wrap the result.\r\n\r\nI have an open issue (#516) to make a public interface that would let you write fully general functions like this. Perhaps I should prioritize that. Meanwhile, here's what it would look like, fully written out. The `ak.to_layout(x)` and `x.layout` parts extract a layout from an array (the latter _only_ works for `ak.Array`) and the `ak.Array` constructors reverse that process. The `.purelist_depth` is the low-level layout name for `ndim`. (It's hard to keep names consistent: we're only careful about naming conventions at the high-level `ak.Array` interface.)\r\n\r\n```python\r\nimport awkward as ak\r\nimport numpy as np\r\nimport numba as nb\r\n\r\n@nb.njit\r\ndef base_case(arr, start, stop):\r\n    out = np.empty(len(arr), np.bool_)\r\n    for i, el in enumerate(arr):\r\n        out[i] = len(el) > 0 and el[0] == start and el[-1] == stop\r\n    return out\r\n\r\ndef mask_startstop(arr, start, stop):\r\n    def recurse(layout):\r\n        if layout.purelist_depth == 2:\r\n            np_array = base_case(ak.Array(layout), start, stop)\r\n            return ak.layout.NumpyArray(np_array)\r\n\r\n        elif isinstance(layout, (\r\n            ak.layout.ListArray32,\r\n            ak.layout.ListArrayU32,\r\n            ak.layout.ListArray64,\r\n        )):\r\n            content = recurse(layout.content)\r\n            return type(layout)(layout.starts, layout.stops, content)\r\n\r\n        elif isinstance(layout, (\r\n            ak.layout.ListOffsetArray32,\r\n            ak.layout.ListOffsetArrayU32,\r\n            ak.layout.ListOffsetArray64,\r\n        )):\r\n            content = recurse(layout.content)\r\n            return type(layout)(layout.offsets, content)\r\n\r\n        elif isinstance(layout, ak.layout.RegularArray):\r\n            content = recurse(layout.content)\r\n            return ak.layout.RegularArray(content, layout.size)\r\n\r\n        else:\r\n            raise NotImplementedError(repr(arr))\r\n\r\n    layout = ak.to_layout(arr, allow_record=True, allow_other=False)\r\n    return ak.Array(recurse(layout))\r\n```\r\n\r\nWhat #516 would do is replace the `if` statements identifying layout node types with a functional callback, like the one I use internally, but with a guaranteed public interface. (One of the tasks I set for myself today is to _change_ that callback\u2014my internal function is _not_ a stable API, though one should be built on top of it.)\r\n\r\nThis will be the fastest implementation because\r\n\r\n   * it does not recreate the `offsets` or `starts`/`stops` at all levels above `ndim == 2` (I was wrong in my earlier comment: the base case _is_ `ndim == 2`); it reuses the old ones\u2014no allocation and no copying.\r\n   * it also doesn't create intermediate arrays in the `len(el) > 0 and el[0] == start and el[-1] == stop`, which my pure high-level Awkward solution did.\r\n\r\nIt will generally be true that unwrapping/reuse + Numba for the fixed-type things that return **NumPy arrays** will be the fastest for this combination of reasons, so there isn't really a reason to get Numba recursion to work.",
     "createdAt":"2020-12-08T19:18:29Z",
     "number":166056,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Here is a quick comparison, it seems that the Numba version (`mask`) is still much faster than the awkward whole-meal appraoch (`mask_alt`). The `f.events.tracks.rec_stages` is coming from `uproot4`, I can dig out the sample file from `skhep-testdata` later!\r\n\r\n```python\r\n>>> arr2d = f.events.tracks.rec_stages[0]\r\n\r\n>>> arr3d = f.events.tracks.rec_stages\r\n\r\n>>> arr2d\r\n<Array [[1, 3, 5, 4], [1, 3, ... [1], [1], [1]] type='56 * var * int64'>\r\n\r\n>>> arr3d\r\n<Array [[[1, 3, 5, 4], [1, ... 1], [1], [1]]] type='10 * var * var * int64'>\r\n\r\n>>> %timeit km3io.tools.mask(arr2d, startend=(1, 3))\r\n155 \u00b5s \u00b1 3.45 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n\r\n>>> %timeit km3io.tools.mask(arr3d, startend=(1, 3))\r\n197 \u00b5s \u00b1 18.8 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n\r\n>>> %timeit km3io.tools.mask_alt(arr2d, 1, 3)\r\n3.54 ms \u00b1 65.7 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n\r\n>>> %timeit km3io.tools.mask_alt(arr3d, 1, 3)\r\n7.04 ms \u00b1 2.54 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n```",
     "createdAt":"2020-12-08T19:19:35Z",
     "number":166057,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I think these samples are too small to be conclusive as performance tests. There are two things that could be quantified: the time spent rearranging metadata (like those layout nodes in my previous comment) and the time spent iterating over arrays. If you do a test with a small dataset over and over (100\u201210000 times, above), you're mostly measuring the time spent rearranging metadata. In real applications, that `mask_alt` function is only going to be called _O(1)_ times\u2014like once, or a hundred times, or something small like that\u2014an anyone can wait 100 \u00b5s \u00d7 a hundred times or 7.04 ms \u00d7 a hundred times.\r\n\r\nTherefore, you want your performance test to run over a large dataset a small number of times. The first number out of `%timeit` should be at least seconds.",
        "createdAt":"2020-12-08T19:30:34Z",
        "number":166147
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Yes you are of course right! However, this will be part of an iterative pipeline where each \"event\" is read-in one-by-one or chunk-wise (depending on the available memory and the type of the processing chain). I will talk to the users to find a realistic use-case and do the performance checks on that. I also need to study your comment at https://github.com/scikit-hep/awkward-1.0/discussions/580#discussioncomment-166056 which I overlooked since it was posted the same time I answered `;)`",
        "createdAt":"2020-12-08T20:18:39Z",
        "number":166873
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Here is a quick comparison of `mask` and `mask_alt`. To quickly recap, the `mask` uses Numba and is currently hardcoded to only work with 2 and 3 dimensions (btw. the actual `mask` function we use implements also other condition checking mechanisms, this is a simplified version which only implements the `startend`-check and is compared to the awkward-slicing-magic `mask_alt` approach provided by Jim):\r\n\r\n```python\r\ndef mask(arr, start, end):\r\n    builder = ak.ArrayBuilder()\r\n    # Numba has limited recursion support, so this is hardcoded\r\n    if arr.ndim == 2:\r\n        _mask2d(arr, builder, start, end)\r\n    else:\r\n        _mask3d(arr, builder, start, end)\r\n    return builder.snapshot()\r\n\r\n@nb.njit\r\ndef _mask3d(arr, builder, start, end):\r\n    for subarray in arr:\r\n        builder.begin_list()\r\n        _mask2d(subarray, builder, start, end)\r\n        builder.end_list()\r\n\r\n@nb.njit\r\ndef _mask2d(arr, builder, start, end):\r\n    for els in arr:\r\n        if len(els) > 0 and els[0] == start and els[-1] == end:\r\n            builder.boolean(True)\r\n        else:\r\n            builder.boolean(False)\r\n```\r\n\r\nAnd the `mask_alt` using awkward-only high-level functions:\r\n\r\n```python\r\ndef mask_alt(arr, start, end):\r\n    nonempty = ak.num(arr, axis=-1) > 0\r\n    mask = ((arr.mask[nonempty][..., 0] == start) & (arr.mask[nonempty][..., -1] == end))\r\n    return ak.fill_none(mask, False)\r\n```\r\n\r\nThe benchmark is dead simple:\r\n\r\n```python\r\nfrom collections import defaultdict\r\nimport awkward as ak\r\nimport numpy as np\r\nimport uproot\r\nimport matplotlib.pyplot as plt\r\nfrom skhep_testdata import data_path\r\n\r\n# This is a large file with 143381 events, each containing a 128 element\r\n# array which consists of up ~10 elements of `int64`\r\n# An example file with 10 events is available via\r\n# f = uproot.open(data_path(\"uproot-issue431b.root\"))\r\nf = uproot.open(\"datav5.40.jorcarec.aanet.00006614.root\")\r\narr = f[\"E/Evt/trks/trks.rec_stages\"].array()  # takes 3-4 minutes and 8GB mem to load\r\n\r\nns = 2 ** np.arange(18)\r\nbenchmarks = defaultdict(list)\r\nfor n in ns:\r\n    print(f\"{n}\")\r\n    bm_numba = %timeit -o km3io.tools.mask(arr[0:n], startend=(1, 3))\r\n    bm_awkward = %timeit -o km3io.tools.mask_alt(arr[0:n], 1, 3)\r\n    benchmarks[\"numba\"].append(bm_numba)\r\n    benchmarks[\"awkward\"].append(bm_awkward)\r\n\r\nfig, ax = plt.subplots()\r\nfor lib, benchmark in benchmarks.items():\r\n    ax.scatter(ns, [b.average for b in benchmark], label=lib)\r\nax.legend();\r\nax.set_xlabel(\"number of arrays\")\r\nax.set_ylabel(\"average execution time / us\")\r\nax.grid()\r\n```\r\n\r\nThe overhead seems to be negligible and Numba seems to be ~3 times faster:\r\n\r\n![numba_vs_awkward](https://user-images.githubusercontent.com/1730350/101551167-e7263400-39b0-11eb-8040-71379dc320b8.png)\r\n",
     "createdAt":"2020-12-08T22:56:18Z",
     "number":170022,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Great! This avoids the overhead (constant-time with respect to array size) effects, and therefore I think the horizontal axis should be labeled \"size of array\" rather than \"number of arrays.\"\r\n\r\nI'm not surprised that the Numba implementation is faster, and in fact I'm rather happy that the one based entirely on high-level functions (which is supposed to be the most convenient) is only 3\u00d7 worse.\r\n\r\nThe two cases studied here don't include the one I wrote in https://github.com/scikit-hep/awkward-1.0/discussions/580#discussioncomment-166056, which ought to be the fastest of the three.",
        "createdAt":"2020-12-08T23:19:30Z",
        "number":170351
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Yes indeed, factor 3 is quite impressive (and it works for arbitrary dimensions)! \"size of arrays\" is more descriptive and correct, I agree.\r\n\r\n> The two cases studied here don't include the one I wrote in #580 (comment), which ought to be the fastest of the three.\r\n\r\nAh, let me add that quickly...\r\n\r\n",
        "createdAt":"2020-12-08T23:25:48Z",
        "number":170588
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Ahm, yes, the `numba_jim` version which is not using the builder is the clear winner for an array size of arround 8000 and above `:)` I also checked if the results are the same and they are.\r\n\r\n![image](https://user-images.githubusercontent.com/1730350/101553980-0a071700-39b6-11eb-960a-454f71d296b5.png)\r\n![image](https://user-images.githubusercontent.com/1730350/101553990-0e333480-39b6-11eb-97cd-9a9ccbbad92d.png)\r\n",
        "createdAt":"2020-12-08T23:34:51Z",
        "number":170671
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"The reason the `numba_jim` version is flat with respect to \"size of array\" is because it is computing it for all elements every time. (That is, the \"size of array\" is always maximal; slicing `arr[0:n]` doesn't remove data from the layout.)\r\n\r\nI've fixed the implementation so that it ignores inaccessible data on the high side (scales appropriately for `arr[:n]` but not `arr[-n:]`). The changed lines are labeled \"`FIX`\". The main benefit is that it makes the plot right.\r\n\r\n```python\r\n@nb.njit\r\ndef base_case(arr, start, stop):\r\n    out = np.empty(len(arr), np.bool_)\r\n    for i, el in enumerate(arr):\r\n        out[i] = len(el) > 0 and el[0] == start and el[-1] == stop\r\n    return out\r\n\r\ndef mask_startstop(arr, start, stop):\r\n    def recurse(layout):\r\n        if layout.purelist_depth == 2:\r\n            np_array = base_case(ak.Array(layout), start, stop)\r\n            return ak.layout.NumpyArray(np_array)\r\n\r\n        elif isinstance(layout, (\r\n            ak.layout.ListArray32,\r\n            ak.layout.ListArrayU32,\r\n            ak.layout.ListArray64,\r\n        )):\r\n            if len(layout.stops) == 0:                                   # FIX\r\n                content = recurse(layout.content)                         # FIX\r\n            else:                                                         # FIX\r\n                content = recurse(layout.content[:np.max(layout.stops)])  # FIX\r\n            return type(layout)(layout.starts, layout.stops, content)\r\n\r\n        elif isinstance(layout, (\r\n            ak.layout.ListOffsetArray32,\r\n            ak.layout.ListOffsetArrayU32,\r\n            ak.layout.ListOffsetArray64,\r\n        )):\r\n            content = recurse(layout.content[:layout.offsets[-1]])        # FIX\r\n            return type(layout)(layout.offsets, content)\r\n\r\n        elif isinstance(layout, ak.layout.RegularArray):\r\n            content = recurse(layout.content)\r\n            return ak.layout.RegularArray(content, layout.size)\r\n\r\n        else:\r\n            raise NotImplementedError(repr(arr))\r\n\r\n    layout = ak.to_layout(arr, allow_record=True, allow_other=False)\r\n    return ak.Array(recurse(layout))\r\n```",
        "createdAt":"2020-12-08T23:49:44Z",
        "number":170792
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"OK, I thought it was some other overhead. I\u2019ll rerun it tomorrow! Thanks already, I learned a lot.",
        "createdAt":"2020-12-09T00:02:36Z",
        "number":171112
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"I confirm, it's linear now and the fastest:\r\n\r\n![image](https://user-images.githubusercontent.com/1730350/101607493-f767fe80-3a04-11eb-8465-134c04f1a20a.png)\r\n\r\n![image](https://user-images.githubusercontent.com/1730350/101607718-2f6f4180-3a05-11eb-81d6-0a4438094b72.png)\r\n",
        "createdAt":"2020-12-09T08:59:17Z",
        "number":176158
       }
      ],
      "totalCount":6
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"I think we can close this, thanks Jim for the fruitful discussion and lots of input (including the final implementation prototype)!\r\n\r\nEDIT: ah, I just realised it's now a Q&A ;)",
     "createdAt":"2020-12-09T10:50:25Z",
     "number":177071,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I've migrated the issue into a Discussion, which doesn't need to be closed. It gets to remain available to help other users without confusing me about what work needs to be done. That's why I used to recommend StackOverflow, but since GitHub Discussions are all under one roof, I can convert Issues into Discussions, like this one.",
        "createdAt":"2020-12-09T14:54:34Z",
        "number":179123
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Yes! I guess I should have started the https://github.com/scikit-hep/awkward-1.0/discussions/584 also in stackoverflow. I can move it if you want to!",
        "createdAt":"2020-12-09T14:57:37Z",
        "number":179131
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Btw. what I do not like in StackOverflow is that there is no easy back-and-forth communication. Maybe we can simply copy over a condensed version of the discussion here to SO after an answer has been figured out `;)`",
        "createdAt":"2020-12-09T15:38:58Z",
        "number":179327
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"If GitHub Discussions work for us, I'll stop recommending StackOverflow. I'm already promoting them on an equal level (with GitHub Discussions first). The ability to turn Issues into Discussions is a big plus\u2014the problem had been that people put the wrong types of questions on Issues and StackOverflow, and then it was stuck there. (\"Wrong\" meaning \"that which should stay open after being answered, to help other users\" versus \"that which should be closed after the issue has been fixed.\") On the other hand, consolidating everything into the hands of one company because it's easier is a slippery slope toward monopoly (remembering that GitHub is owned by Microsoft).\r\n\r\nBeyond just the advantage of being under one roof, GitHub Discussions approached the problem of back-and-forth differently: there are no upvotes to change the order, so it stays mostly linear, and it has this two-level hierarchy of nesting instead of StackOverflow's tiny comment boxes (tiny because they're discouraged). On the one hand, that might make it easier to find the right answer in StackOverflow because the right stuff is sifted up and the wrong or less useful stuff is sifted down, but if there's any kind of back-and-forth to be had, GitHub Discussions is better. In Awkward Array and Uproot questions, back-and-forth has generally been useful. (There aren't so many \"how do I append to a list?\" questions.)",
        "createdAt":"2020-12-09T17:42:28Z",
        "number":180807
       }
      ],
      "totalCount":4
     }
    }
   ],
   "totalCount":12
  },
  "createdAt":"2020-12-08T17:02:30Z",
  "number":580,
  "title":"Numba recursion, ArrayBuilder performance, and writing functions that descend to an an arbitrary list depth",
  "url":"https://github.com/scikit-hep/awkward/discussions/580"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"This might be a good replacement for StackOverflow, especially if I can transfer GitHub Issues to Discussions and vice-versa.",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2020-12-08T19:23:26Z",
  "number":581,
  "title":"Awkward Discussions!",
  "url":"https://github.com/scikit-hep/awkward/discussions/581"
 },
 {
  "author":{
   "login":"tamasgal"
  },
  "body":"I have some problems understanding how to \"flatten\" nested arrays/records when applying masks.\r\n\r\nI think it's best explained with an actual use-case (with reduced complexity). Given a set of events (in this case 3), each event contains a variable lengths of particle tracks where I want to pick exactly one with the highest likelihood (`lik`).\r\n\r\n```python\r\nfrom skhep_testdata import data_path\r\nimport uproot\r\nimport awkward as ak\r\n\r\nf = uproot.open(data_path(\"uproot-issue431b.root\"))\r\n# grab the tracks of the first three events and only the lik-parameter for simplicity\r\ntracks = f[\"E/Evt/trks\"].arrays([\"lik\"], aliases={\"lik\": \"trks.lik\"})[:3]\r\n```\r\n\r\n`tracks` now is an array of records, which is basically a list of dictionaries:\r\n\r\n```python\r\n>>> tracks.tolist()  # truncated output\r\n[{'lik': [294.64, 294.64, ..., 67.77, 67.77]},\r\n {'lik': [96.75, 96.75, ..., 39.18, 38.87]},\r\n {'lik': [560.27, 560.27, ..., 118.72, 117.80]}]\r\n```\r\n\r\nI create an integer-`mask` for the tracks with the highest likelihood (in this example it's always the first, but it's not generally the case). I have to use `keepdims=True` to match the nested scheme (maybe that's where I enter the one-way route?):\r\n\r\n```python\r\nmask = ak.argmax(tracks.lik, axis=-1, keepdims=True)\r\n# <Array [[0], [0], [0]] type='3 * var * ?int64'>\r\n```\r\n\r\nand use that mask to actually select the tracks:\r\n\r\n```python\r\nselected_tracks = tracks[mask]\r\n# <Array [{lik: [295]}, ... 96.8]}, {lik: [560]}] type='3 * {\"lik\": var * ?float64}'>\r\n```\r\n\r\nAs seen above, the masking works fine but it is nested. This is expected since the mask with `[[0], [0], [0]]` has `ndim==2` and since it's an integer mask, it will not change the dimensions. However, I cannot find a way to flatten the resulting array of records since one obviously cannot flatten a record. This means that we need to put `[0]` after each attribute to access the value, although we know that each element is a single record (with single entries for each field):\r\n\r\n```python\r\nselected_tracks.lik\r\n# <Array [[295], [96.8], [560]] type='3 * var * ?float64'>\r\nak.flatten(selected_tracks.lik)  # this is the desired output but there are dozens of fields\r\n# <Array [295, 96.8, 560] type='3 * ?float64'>\r\n\r\n# or when accessing single entries:\r\nselected_tracks[0].lik\r\n# <Array [295] type='1 * ?float64'>\r\nselected_tracks[0].lik[0]\r\n# 295\r\n```\r\n\r\nIs there a better approach to reduce the dimensions of the fields of nested records, so that `selected_tracks.ATTRIBUTES` returns a flat list without the need to flatten them explicitly?\r\n\r\nI am pretty sure it's kind of an corner-case but unfortunately many of our files are structured like this and I am trying to wrap all this into a low-level user-library which needs to be high-performant and user-friendly at the same time.\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"It's not such a corner case\u2014other users might not encounter exactly this case, but probably a similar-enough one.\r\n\r\nSince you know each list returned by `ak.argmax` with `keepdims=True` has exactly one element (even if that element is None), you can use `[:, 0]` as a slice to remove the dimension by picking the first (and only) element:\r\n\r\n```python\r\n>>> tracks[mask].tolist()\r\n[{'lik': [294.6407542676734]}, {'lik': [96.75133289411137]}, {'lik': [560.2775306614813]}]\r\n>>> tracks[mask][:, 0].tolist()\r\n[{'lik': 294.6407542676734}, {'lik': 96.75133289411137}, {'lik': 560.2775306614813}]\r\n```\r\n\r\nI did a quick check to verify that this also works with empty lists (missing values in the `mask`).\r\n\r\n```python\r\n>>> fewer_tracks = tracks[tracks.lik > 100]\r\n>>> ak.num(fewer_tracks)\r\n<Array [{lik: 20}, {lik: 0}, {lik: 55}] type='3 * {\"lik\": int64}'>\r\n>>> mask = ak.argmax(fewer_tracks.lik, axis=1, keepdims=True)\r\n>>> mask\r\n<Array [[0], [None], [0]] type='3 * var * ?int64'>\r\n>>> fewer_tracks[mask].tolist()\r\n[{'lik': [294.6407542676734]}, {'lik': [None]}, {'lik': [560.2775306614813]}]\r\n>>> fewer_tracks[mask][:, 0].tolist()\r\n[{'lik': 294.6407542676734}, {'lik': None}, {'lik': 560.2775306614813}]\r\n```\r\n\r\nWhat the `[:, 0]` slice is taking advantage of is the fact that \"slicing columns\" (record fields selected by string names) commutes with \"slicing rows\" (such as `:` for everything in the first dimension and `0` for the first in each list of the second dimension).\r\n\r\n```python\r\n>>> deep = ak.Array([[{\"x\": {\"a\": 1}, \"y\": [{\"b\": 2}]}]])\r\n>>> deep.type\r\n1 * var * {\"x\": {\"a\": int64}, \"y\": var * {\"b\": int64}}\r\n>>> deep[:, 0].tolist()\r\n[{'x': {'a': 1}, 'y': [{'b': 2}]}]\r\n>>> deep[0, 0].tolist()\r\n{'x': {'a': 1}, 'y': [{'b': 2}]}\r\n>>> deep[0, 0, \"x\"].tolist()\r\n{'a': 1}\r\n>>> deep[0, \"x\", 0].tolist()\r\n{'a': 1}\r\n>>> deep[\"x\", 0, 0].tolist()\r\n{'a': 1}\r\n>>> deep[0, 0, \"y\"].tolist()\r\n[{'b': 2}]\r\n>>> deep[0, 0, \"y\", 0].tolist()\r\n{'b': 2}\r\n>>> deep[0, \"y\", 0, 0].tolist()\r\n{'b': 2}\r\n>>> deep[\"y\", 0, 0, 0].tolist()\r\n{'b': 2}\r\n```\r\n\r\nTo be fully correct, this is Commutivity with a Caveat (I wish I had a better word): column-string selections can move anywhere to the _left_ (shallower) than a deepest position, but not to the _right_, as illustrated by this failure:\r\n\r\n```python\r\n>>> deep[0, 0, 0, \"y\"].tolist()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward/highlevel.py\", line 943, in __getitem__\r\n    return ak._util.wrap(self._layout[where], self._behavior)\r\nValueError: in NumpyArray, too many dimensions in slice\r\n```\r\n\r\nbecause the first `[0, 0, 0` can't be applied to the `\"x\"` field.",
     "createdAt":"2020-12-09T16:54:38Z",
     "number":180232,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"Ah dear, of course I know the `[:, 0]` syntax but I have no idea why I have not came up with it in this case. I somehow thought it's special since those are `Records` \ud83e\udd26  Maybe too much coding the last few days...\r\n\r\nYes, this all make sense, I can wrap the `[:, 0]` thing in the high-level accessors where I know that the result contains one element.\r\n\r\nBtw. it's a bit funny since I am pretty sure that this behaviour was a bit different in past. At least I have some unit-tests which at some point failed but I cannot put together the exact uproot/awkward versions anymore, so I have no idea where the slicing behaviour changed, but it was at some point returning single elements. I know that it was a combination of uproot3 and an earlier awkward1 version, probably around `0.3.x` or early `0.4.x`.",
     "createdAt":"2020-12-09T17:00:41Z",
     "number":180278,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Uproot 3 can't be combined with Awkward 1, unless you do `ak.from_awkward0`.\r\n\r\nIt _is_ the case that Awkward 0's `argmax` returned a jagged array of indexes so that it could be used as a slice without the extra `[:, 0]`, but this was in conflict with NumPy's behavior for the same inputs, and Awkward 1 is constrained to only generalize NumPy, not change it.\r\n\r\n```python\r\n>>> import awkward as ak\r\n>>> import awkward0\r\n>>> ak.argmax(ak.from_iter([[1, 2, 3], [], [4, 5]]), axis=1)\r\n<Array [2, None, 1] type='3 * ?int64'>\r\n>>> awkward0.fromiter([[1, 2, 3], [], [4, 5]]).argmax()\r\n<JaggedArray [[2] [] [1]] at 0x7fe4ba0b4e20>\r\n```\r\n\r\nThese are two different ways of expressing missing values: numbers with None on the one hand and lists of zero or one elements on the other hand, and different languages prefer one or the other. [In Scala](https://alvinalexander.com/scala/using-scala-option-some-none-idiom-function-java-null/), for instance, missing values in data of type `Option[X]`, which are also called `None`, are equivalent to empty lists, and the non-missing values, `Some(x)`, are equivalent to non-missing lists.\r\n\r\nSo Awkward 1 has ways to switch between the two representations:\r\n\r\n```python\r\n>>> a = ak.argmax(ak.from_iter([[1, 2, 3], [], [4, 5]]), axis=1)\r\n>>> ak.singletons(a)\r\n<Array [[2], [], [1]] type='3 * var * int64'>\r\n>>> ak.firsts(ak.singletons(a))\r\n<Array [2, None, 1] type='3 * ?int64'>\r\n```\r\n\r\nThese were introduced to make use of the output of `ak.argmax` and #203 is an open issue to make that easier. However, @nsmith- noticed that it's much simpler to pass `keepdims=True` and slice with `[:, 0]`.",
        "createdAt":"2020-12-09T17:34:35Z",
        "number":180778
       },
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"Yep, we used `ak.from_awkward0`.\r\n\r\nYes, makes sense, thanks! I also agree that `keepdims=True` and `[:, 0]` is a good choice.",
        "createdAt":"2020-12-09T17:37:26Z",
        "number":180786
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"tamasgal"
     },
     "body":"This is the first job which failed: https://git.km3net.de/km3py/km3io/-/jobs/104059 with\r\n\r\n```\r\nawkward==1.0.0rc2\r\nawkward0==0.15.0\r\nuproot3==3.14.1\r\nuproot3-methods==0.10.0\r\n```\r\n\r\nAnd the last which worked https://git.km3net.de/km3py/km3io/-/jobs/101157 with\r\n\r\n```\r\nawkward==0.14.0\r\nawkward1==0.4.3\r\nuproot==3.13.0\r\nuproot-methods==0.8.0\r\n```\r\n\r\nSo somewhere between these things have suddenly failed, which were using `awkward1` arrays:\r\n\r\n```\r\n>       assert best.rec_stages[0].tolist() == [1, 3, 5, 4]\r\nE       AssertionError: assert [[1, 3, 5, 4]] == [1, 3, 5, 4]\r\n```",
     "createdAt":"2020-12-09T17:09:05Z",
     "number":180320,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"tamasgal"
        },
        "body":"...anyways, it's not so important since the `[:, 0]` is fine `;)`",
        "createdAt":"2020-12-09T17:16:21Z",
        "number":180364
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":3
  },
  "createdAt":"2020-12-09T12:54:05Z",
  "number":584,
  "title":"Masking and flattening (using an argmax as a integer-array slice)",
  "url":"https://github.com/scikit-hep/awkward/discussions/584"
 },
 {
  "author":{
   "login":"Superharz"
  },
  "body":"Allow ```ak.flatten(array, axis= 0)```. As of ```awkward 0.4.5``` I get:\r\n```\r\nValueError: axis=0 not allowed for flatten\r\n```\r\nThis would make it possible to pass already flat arrays (it would just return the array as is was) and you wouldn't have to worry about the depth of ```array```.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I couldn't exactly reproduce this, even going back to 0.4.5. If you pass `axis=0` to `ak.flatten`, the case is handled in Python code and you don't get this error message that comes from C++. Tinkering with it, I did find an unhandled corner-case: if you pass the negative axis that is equivalent to `axis=0` (such as `axis=-2` for a singly jagged array or `axis=-1` for a flat array), it missed the check for `axis == 0` and went into C++. As far as I can see, that's the only way to encounter this error message.\r\n\r\n(The C++ code was written under the assumption that `axis == 0` would never be allowed, but it made sense to add that case, though its behavior is entirely different from any other `axis` value. Since `axis == 1` flattens a possibly jagged two-dimensional array into a one-dimensional array, `axis == 0` does not change the dimension of _any_ array. However, all flattening operations remove None values, so `axis == 0` only removes None from the top level. This is the only behavior that's consistent with the pattern set by all other `axis` values.)\r\n\r\nThe only way to express \"flatten if not already flat\" without exceptions is `axis=None`:\r\n\r\n```python\r\n>>> ak.flatten(ak.Array([[1, 2, 3], [], [4, 5]]), axis=None)\r\n<Array [1, 2, 3, 4, 5] type='5 * int64'>\r\n>>> ak.flatten(ak.Array([1, 2, 3, 4, 5]), axis=None)\r\n```\r\n\r\nBe sure it's what you want, though. Unlike a single-axis flatten, it flattens all levels of depth:\r\n\r\n```python\r\n>>> ak.flatten(ak.Array([[[1, 2], [], [3]], [], [[4, 5]]]), axis=None)\r\n<Array [1, 2, 3, 4, 5] type='5 * int64'>\r\n```\r\n\r\nand even flattens records:\r\n\r\n```python\r\n>>> ak.flatten(ak.Array([{\"x\": 1.1, \"y\": [1]}, {\"x\": 2.2, \"y\": [1, 2]}]), axis=None)\r\n<Array [1.1, 2.2, 1, 1, 2] type='5 * float64'>\r\n```",
     "createdAt":"2020-12-09T17:22:32Z",
     "number":180660,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Oh, I also meant to say that you can also just\r\n\r\n```python\r\n>>> ak.Array([[1, 2, 3], [], [4, 5]]).ndim\r\n2\r\n>>> ak.Array([1, 2, 3, 4, 5]).ndim\r\n1\r\n```\r\n\r\nif you don't want something quite as drastic as `ak.flatten` with `axis=None`.",
        "createdAt":"2020-12-09T17:24:22Z",
        "number":180715
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"Superharz"
     },
     "body":"Thank you for the explanation.\r\nYou are right, the error arrived with ```axis=-1``` and an already flat array.\r\n\r\nI have to admit that I never actually tried ```axis=0``` and only assumed that it wouldn't work with it because it didn't work with ```axis=-1``` on a flat array.",
     "createdAt":"2020-12-09T18:57:43Z",
     "number":181394,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2020-12-09T13:51:25Z",
  "number":585,
  "title":"Flattening without having to worry about current depth",
  "url":"https://github.com/scikit-hep/awkward/discussions/585"
 },
 {
  "author":{
   "login":"Duchstf"
  },
  "body":"Hello,\r\n\r\nso suppose that I want to do this with an awkward array:\r\n\r\n```\r\na[a>4000] = 4000\r\n```\r\n\r\nHow would I do this? Is there any current support for this operation?\r\n\r\nThanks!!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"In-place assignment isn't supported as a design choice. There are two corners of \"parameter space\" we could have chosen:\r\n\r\n   * allow in-place assignment and defensively copy arrays in complex operations, so that assignments don't lead to surprising long-distance consequences;\r\n   * forbid in-place assignment and view, rather than copy, for most operations.\r\n\r\nI chose the latter (after initial experience with an early version that _did_ allow in-place assignment). Defensive copies would be prohibitive for large data structures, such as records with many fields (which are common). The choice to make everything immutable was made _for performance_ (both speed and memory), which might sound surprising, considering that in-place mutations are used in NumPy for performance reasons (both speed and memory).\r\n\r\nNumPy has this problem, too, but not as acutely. Some operations cause views, some cause copies:\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> original = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9])\r\n>>> sliced = original[::2]\r\n>>> advanced = original[[0, 2, 4, 6, 8]]\r\n>>> sliced\r\narray([1.1, 3.3, 5.5, 7.7, 9.9])\r\n>>> advanced\r\narray([1.1, 3.3, 5.5, 7.7, 9.9])\r\n>>> original[6] = 999\r\n>>> sliced     # this is a view; it has changed\r\narray([  1.1,   3.3,   5.5, 999. ,   9.9])\r\n>>> advanced   # this is a copy; it has NOT changed\r\narray([1.1, 3.3, 5.5, 7.7, 9.9])\r\n```\r\n\r\n(I think PyTorch has taken a positive step by making all the view operations have a different naming convention from the copy ones.)\r\n\r\nThis is a bit of an issue in NumPy because you have to be careful to check for view-vs-copy. It's endemic in Pandas (search for \"SettingwithCopyWarning\"). But it's harder in Awkward Array because rather than having one buffer that might be a view or might be a copy, almost all operations give you a tree with buffers attached to all the nodes of that tree in which some nodes are views and other nodes are new buffers. Which are views and which are new buffers is subject to change. [This PR](https://github.com/scikit-hep/awkward-1.0/pull/261), for example.\r\n\r\nTherefore, the Awkward Array library itself does not include any operations that change the values of these buffers in place. You can do this kind of assignment in place:\r\n\r\n```python\r\n>>> import awkward as ak\r\n>>> original = ak.Array([{\"x\": 1}, {\"x\": 2}, {\"x\": 3}])\r\n>>> original[\"y\"] = 10\r\n>>> original\r\n<Array [{x: 1, y: 10}, ... {x: 3, y: 10}] type='3 * {\"x\": int64, \"y\": int64}'>\r\n```\r\n\r\nbut that's actually not changing any _buffers_ in place: it's creating a new tree structure with the new buffer (`y = 10`) added. If you have any other references to parts of `original` elsewhere, they are unharmed.\r\n\r\nThe other exception is that while Awkward Array doesn't define any in-place operations, nothing is stopping you from casting an Awkward Array (or part of one) as a NumPy array and changing it in place. This can potentially have long-range consequences, so if you do this, you'll have to be aware of its history. For example, it's fine to change in place an array that you have just created\u2014you know exactly where it's been.\r\n\r\nIn the online documentation, [Mutability of Awkward Arrays from NumPy](https://awkward-array.org/how-to-convert-numpy.html#mutability-of-awkward-arrays-from-numpy) and [Mutability of Awkward Arrays converted to NumPy](https://awkward-array.org/how-to-convert-numpy.html#mutability-of-awkward-arrays-converted-to-numpy) discusses how to do this and what the issues are. Note that you can also cast Awkward Arrays as NumPy arrays in Numba and assign to them (PR #550).",
     "createdAt":"2020-12-18T19:32:04Z",
     "number":224113,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I also should have given you a direct answer to your question:\r\n\r\n```python\r\n>>> a = ak.Array([1000, 2000, 3000, 4000, 5000, 6000])\r\n>>> a\r\n<Array [1000, 2000, 3000, 4000, 5000, 6000] type='6 * int64'>\r\n>>> np.asarray(a)[a > 4000] = 4000\r\n>>> a\r\n<Array [1000, 2000, 3000, 4000, 4000, 4000] type='6 * int64'>\r\n```",
     "createdAt":"2020-12-18T19:34:11Z",
     "number":224123,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Here's an example of how it gets confusing quickly.\r\n\r\nThis `a` is a [ListOffsetArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListOffsetArray.html), for which the [ak.flatten](https://awkward-array.readthedocs.io/en/latest/_auto/ak.flatten.html) operation passes through a view:\r\n\r\n```python\r\n>>> a = ak.Array([[1, 2, 3], [], [4, 5]])\r\n>>> np.asarray(ak.flatten(a))[2:] = 10\r\n>>> a\r\n<Array [[1, 2, 10], [], [10, 10]] type='3 * var * int64'>\r\n```\r\n\r\nThis `b` is a [ListArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListArray.html), for which the [ak.flatten](https://awkward-array.readthedocs.io/en/latest/_auto/ak.flatten.html) returns a new buffer. When you change that new buffer in place, the original array is not changed in place.\r\n\r\n```python\r\n>>> b = ak.Array([[1, 2, 3], [], [4, 5]])[[0, 1, 2]]\r\n>>> np.asarray(ak.flatten(b))[2:] = 10\r\n>>> b\r\n<Array [[1, 2, 3], [], [4, 5]] type='3 * var * int64'>\r\n```\r\n\r\nIn general, if you want to know whether a change in-place is going to change other arrays, such as whether changing this flattened array would change the original, you have to know about the array's layout. Most data analysis should be done at a high-level where you can ignore these differences.\r\n\r\nThe flattened [ListOffsetArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListOffsetArray.html) has a [NumpyArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.NumpyArray.html) with the same base pointer because flattening a [ListOffsetArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListOffsetArray.html) can be efficiently implemented by just passing or range-slicing its `content`:\r\n\r\n```python\r\n>>> a.layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 3 3 5]\" offset=\"0\" length=\"4\" at=\"0x5609caa3af30\"/></offsets>\r\n    <content><NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x5609caa4d050\"/></content>\r\n</ListOffsetArray64>\r\n>>> ak.flatten(a).layout\r\n<NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x5609caa4d050\"/>\r\n```\r\n\r\nThe flattened [ListArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListArray.html) has to, in general, create a new content buffer:\r\n\r\n```python\r\n>>> b.layout\r\n<ListArray64>\r\n    <starts><Index64 i=\"[0 3 3]\" offset=\"0\" length=\"3\" at=\"0x5609ca963990\"/></starts>\r\n    <stops><Index64 i=\"[3 3 5]\" offset=\"0\" length=\"3\" at=\"0x5609ca8f71d0\"/></stops>\r\n    <content><NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x5609caa34590\"/></content>\r\n</ListArray64>\r\n>>> ak.flatten(b).layout\r\n<NumpyArray format=\"l\" shape=\"5\" data=\"1 2 3 4 5\" at=\"0x5609ca460f30\"/>\r\n```\r\n\r\nWhy is that? Because [ListArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListArray.html) `starts` and `stops` don't have to be contiguous and abutting:\r\n\r\n```python\r\n>>> c = ak.Array(ak.layout.ListArray64(\r\n...     ak.layout.Index64(np.array([4, 99, 1])),\r\n...     ak.layout.Index64(np.array([7, 99, 3])),\r\n...     ak.layout.NumpyArray(np.array([1000, 4.4, 5.5, 1000, 1.1, 2.2, 3.3, 1000]))\r\n... ))\r\n>>> c\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5]] type='3 * var * float64'>\r\n```\r\n\r\nis a totally legal [ListArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListArray.html), and\r\n\r\n```python\r\n>>> ak.flatten(c)\r\n<Array [1.1, 2.2, 3.3, 4.4, 5.5] type='5 * float64'>\r\n>>> ak.flatten(c).layout\r\n<NumpyArray format=\"d\" shape=\"5\" data=\"1.1 2.2 3.3 4.4 5.5\" at=\"0x5609caa0b710\"/>\r\n```\r\n\r\ncan only make a flattened version of it by cutting pieces out of the original array. (It's not even guaranteed to be _smaller_, since the `starts` and `stops` of [ListArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.ListArray.html) are allowed to _overlap_!)\r\n\r\nA future performance optimization might identify ListArrays that are regular enough to be ListOffsetArrays and have [ak.flatten](https://awkward-array.readthedocs.io/en/latest/_auto/ak.flatten.html) return a view. Code that assumes that some operation is a view or a copy can easily be broken by updates in Awkward Array, and that's why I recommend against it.",
        "createdAt":"2020-12-18T19:55:49Z",
        "number":224174
       },
       {
        "author":{
         "login":"lukasheinrich"
        },
        "body":"I tried following this explanation but get `ListOffsetArray` in both cases. Has something changed since the answer?\r\n\r\n![image](https://user-images.githubusercontent.com/2318083/115154023-17759180-a079-11eb-9f66-75c1d2718082.png)\r\n",
        "createdAt":"2021-04-18T17:06:03Z",
        "number":627049
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Whether an operation returns a ListArray or a ListOffsetArray is an implementation detail. I can take a closer look later, though.",
        "createdAt":"2021-04-18T21:24:14Z",
        "number":627605
       },
       {
        "author":{
         "login":"lukasheinrich"
        },
        "body":"I was mainly curious/studying up on forms vs types vs layouts and was curious to find any operation that returns a `ListArray` - not high priority",
        "createdAt":"2021-04-19T00:49:10Z",
        "number":627965
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"The types\u2014whether it's a list of not, and whether the list has variable length or a fixed length\u2014is a predictable property of an operation. The form (or for a specific array, the layout) specifies exactly how data are arranged in memory, and that is chosen to optimize performance. It's stable for a given version of Awkward Array, but it's not guaranteed to start the same between versions. (As an example of that, some rearrangements of RecordArrays were made lazy by wrapping them in IndexedArrays.) ListArray and ListOffsetArray differ by whether the list elements of consecutive lists are known to be contiguous in memory. When an operation creates a new output array, it would be a ListOffsetArray, because you might as well make it contiguous, but when a list array is rearranged, it becomes a ListArray because the rearrangement can remain lazy at that level\u2014we can pass through the original `content` with a new `starts` and `stops` to avoid copying (which is why Awkward Arrays aren't mutable in-place).",
        "createdAt":"2021-04-19T12:45:09Z",
        "number":630035
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I just ran it on a computer and it's true: the operation on `b` has changed so that it's now operating in place. This is the sort of thing that makes it dangerous to _rely_ on the mutability through conversion to NumPy\u2014memory layout in Awkward Array is an implementation detail that can change like this.",
        "createdAt":"2021-04-19T14:05:04Z",
        "number":630458
       }
      ],
      "totalCount":6
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2020-12-18T18:48:30Z",
  "number":609,
  "title":"In-place assignment for awkward  array?",
  "url":"https://github.com/scikit-hep/awkward/discussions/609"
 },
 {
  "author":{
   "login":"maxgalli"
  },
  "body":"Hi,\r\nfirst of all, thank you for the awesome job you're doing. I recently started using Awkward and I find it suitable and easy to use for most of the operations I usually perform during analysis.\r\nI have a question regarding the possibility to get substructures from complex arrays.\r\nLet's say I have an array whose type is the following:\r\n```python\r\n22838 * {\r\n\"Muon_pt_1\": {\"Nominal\": float64, \"Up\": float64, \"Down\": float64}, \r\n\"Muon_pt_2\": {\"Nominal\": float64, \"Up\": float64, \"Down\": float64}, \r\n\"Electron_pt_1\": {\"Nominal\": float64, \"Up\": float64, \"Down\": float64}, \r\n\"Electron_pt_2\": {\"Nominal\": float64, \"Up\": float64, \"Down\": float64}, \r\n\"PV_x\": float64, \r\n\"PV_y\": float64, \r\n\"PV_z\": float64\r\n}\r\n```\r\nIs there a simple way to get an array containing e.g. all the ```Up``` values from the fields that have it?\r\nSomething like \r\n```python\r\nmy_array['*']['Up']\r\n```\r\nI took a look at the documentation but I wasn't able to find anything like this. Sorry if it's there and I missed it.\r\n\r\nThank you,\r\n\r\nMassimiliano",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"You're right: there isn't an operation for that! There are a lot of ways to slice _rows_ within rows, but this is a column within a column. Perhaps the following\r\n\r\n```python\r\nmy_array[[\"Muon_pt_1\", \"Muon_pt_2\", \"Electron_pt_1\", \"Electron_pt_2\"], \"Up\"]\r\n```\r\n\r\n_should_ be defined in such a way as to select the inner field `\"Up\"` from all four outer field names, by analogy with\r\n\r\n```python\r\nanother_array[:, 1]\r\n```\r\n\r\nfor rows. It could be implemented here:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/5625722d7da1e4c826783cf466c19e47bea15835/src/libawkward/array/RecordArray.cpp#L1621-L1630\r\n\r\nInstead of applying the `getitem_fields` (slicing by `[\"Muon_pt_1\", \"Muon_pt_2\", \"Electron_pt_1\", \"Electron_pt_2\"]`, which returns a new record of only these fields) and then applying the next tuple item (`\"Up\"`) to the record that consists of those fields, the new feature would apply the rest of the tuple items (just `\"Up\"` in this case) to each of the fields (`\"Muon_pt_1\"`, `\"Muon_pt_2\"`, etc.) and then wrap the result of that up as a new record. It would be _almost_ like moving the closing parenthesis of the `getitem_fields` call so that it includes the `getitem_next`, though it's not quite that simple.\r\n\r\nSo it could be done and it could be a [new feature that you can request](https://github.com/scikit-hep/awkward-1.0/issues/new?assignees=&labels=feature&template=feature-request.md&title=). The hard part is figuring out how to do the deprecation cycle: if people are relying on the current behavior, how do tell them that it's going to change so that they can fix their scripts?\r\n\r\nUsually, new features are new function names or argument names, so they can't break any old code. When I want to change a named function or argument, I usually have to come up with a new name, so that the new name does the new thing and the old name has a deprecation warning and is eventually removed. (For example, renaming `ak.from_arrayset` \u2192 `ak.from_buffers` in #592.) But since this is a \"`__getitem__`\" thing, there's no name to change.\r\n\r\nThis `my_array[[\"Muon_pt_1\", \"Muon_pt_2\", \"Electron_pt_1\", \"Electron_pt_2\"], \"Up\"]` would be a nice feature to have, and it would be more consistent with the way that `my_array[\"Muon_pt_1\", \"Up\"]` works. I like it! But I think it would have to have a long deprecation cycle:\r\n\r\n   * in the first phase, uses of a multi-field selection followed by anything with a field or multi-field selection should raise a `FutureWarning` indicating when the change in behavior is going to happen and how to change code to keep the old behavior (users will need two square bracket selectors, one after the other);\r\n   * once the targeted date is reached, the new behavior becomes available for the first time. You wouldn't be able to use it until that day comes, because it would interfere with the old behavior.\r\n\r\nThat's not as nice as introducing a new name that people can use now, and it certainly doesn't help your short term problem of how to do it in your analysis. To do it now, you have to do it longhand:\r\n\r\n```python\r\nak.zip({field: my_array[field, \"Up\"] for field in ak.fields(my_array) if \"Up\" in ak.fields(my_array[field])})\r\n```\r\n\r\n(Note: the above would run in constant time, independent of the size of `my_array`, so it's not a performance problem. A `for` loop over columns is not slow like a `for` loop over rows, since we assume that arrays have no more than thousands of columns but can have billions of rows.)\r\n\r\nAbout the `\"*\"` syntax, I'd rather not introduce something like that because there are no constraints on field names; `\"*\"` might be a valid field, and then how would you select it? Even with the above-described feature, you'd either have to know which fields might contain an `\"Up\"` or select them with\r\n\r\n```python\r\n[x for x in ak.fields(my_array) if \"Up\" in ak.fields(my_array[x])]\r\n```\r\n\r\nBut I'd like to keep this Discussion open in case there's a lot of interest in the\r\n\r\n```python\r\nmy_array[[\"Muon_pt_1\", \"Muon_pt_2\", \"Electron_pt_1\", \"Electron_pt_2\"], \"Up\"]\r\n```\r\n\r\nselector.",
     "createdAt":"2020-12-22T19:28:59Z",
     "number":235312,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Having mentioned the deprecation cycle, I should point out that this would also depend on having a formal roadmap: issue #616.",
        "createdAt":"2020-12-22T19:32:30Z",
        "number":235321
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Despite all the big talk about a formal deprecation cycle, I noticed that the old behavior was never useful\u2014any application of it could be rewritten in a simpler way. So I've redefined the old behavior as a bug that #619 fixes (immediately).\r\n\r\nMore detail here: https://github.com/scikit-hep/awkward-1.0/issues/618#issuecomment-750451521.",
        "createdAt":"2020-12-23T20:02:20Z",
        "number":238365
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"maxgalli"
     },
     "body":"Thank you for the detailed answer. \r\nYes, I agree that ```my_array[[\"Muon_pt_1\", \"Muon_pt_2\", \"Electron_pt_1\", \"Electron_pt_2\"], \"Up\"]``` makes much more sense that using the ```'*'```.\r\nI will open a feature request later today and link this discussion to it.",
     "createdAt":"2020-12-23T08:33:06Z",
     "number":236402,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"For cross-linking completeness, this is issue #618.",
        "createdAt":"2020-12-23T16:06:49Z",
        "number":237647
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2020-12-22T08:05:53Z",
  "number":614,
  "title":"Selecting a name within multiple records: array[[\"pt\", \"eta\", \"phi\"], \"nominal\"]",
  "url":"https://github.com/scikit-hep/awkward/discussions/614"
 },
 {
  "author":{
   "login":"Duchstf"
  },
  "body":"so I've been trying to do this:\r\n\r\n```\r\ntruth_x_target = truth_x_target[mask][:,0]\r\n```\r\n\r\nHowever, this returns an array with the same first dimension as `mask`, whereas I want to basically \"select the first element of each event\" after the array is filtered. Is this a bug or feature of the awkward array?\r\n\r\nThank you for your help!\r\n\r\nDuc. ",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Could you give more details, like what the [type](https://awkward-array.readthedocs.io/en/latest/_auto/ak.type.html) of `truth_x_target` and `mask` are, and what you expected?\r\n\r\nWhen I tried an example, I didn't find anything unexpected:\r\n\r\n```python\r\n>>> array = ak.Array([[0.0, 1.1, 2.2], [], [3.3, 4.4], [5.5], [6.6, 7.7, 8.8, 9.9]])\r\n>>> array.type\r\n5 * var * float64\r\n>>> array.tolist()\r\n[[0.0, 1.1, 2.2], [], [3.3, 4.4], [5.5], [6.6, 7.7, 8.8, 9.9]]\r\n```\r\n\r\nFor a singly jagged array of numbers like this, there are two possible masks: flat booleans and (singly) jagged booleans. Here's an example of a flat boolean mask:\r\n\r\n```python\r\n>>> mask1 = ak.num(array) > 1\r\n>>> mask1.type\r\n5 * bool\r\n>>> mask1.tolist()\r\n[True, False, True, False, True]\r\n```\r\n\r\nand here's an example of a jagged boolean mask:\r\n\r\n```python\r\n>>> mask2 = array * 10 % 2 == 0\r\n>>> mask2.type\r\n5 * var * bool\r\n>>> mask2.tolist()\r\n[[True, False, True], [], [False, True], [False], [True, False, True, False]]\r\n```\r\n\r\nWhen you slice with a flat boolean mask, it has to have the same length as the `array` and it removes _lists_ from it:\r\n\r\n```python\r\n>>> array[mask1].type\r\n3 * var * float64\r\n>>> array[mask1].tolist()\r\n[[0.0, 1.1, 2.2], [3.3, 4.4], [6.6, 7.7, 8.8, 9.9]]\r\n```\r\n\r\nWhen you slice with a jagged boolean mask, it has to have all the same lengths for each of its nested lists, and it removes _numbers_ from those nested lists:\r\n\r\n```python\r\n>>> array[mask2].type\r\n5 * var * float64\r\n>>> array[mask2].tolist()\r\n[[0.0, 2.2], [], [4.4], [], [6.6, 8.8]]\r\n```\r\n\r\nWhat happens after that depends on the type and lengths of what the first step returned. For instance, you can have `mask1` slice the first dimension and `0` slice the second dimension in one step or in two:\r\n\r\n```python\r\n>>> array[mask1, 0]\r\n<Array [0, 3.3, 6.6] type='3 * float64'>\r\n>>> array[mask1][:, 0]\r\n<Array [0, 3.3, 6.6] type='3 * float64'>\r\n```\r\n\r\nIn my example, I can't get the first item of each list after `mask2` because it leaves some nested lists empty. So I'll start with an equivalent example.\r\n\r\n```python\r\n>>> array = ak.Array([[0.0, 1.1, 2.2], [3.3, 4.4], [5.5], [6.6, 7.7, 8.8, 9.9]])\r\n>>> mask2 = array * 10 % 2 == 1\r\n>>> array[mask2].type\r\n4 * var * float64\r\n>>> array[mask2].tolist()\r\n[[1.1], [3.3], [5.5], [7.7, 9.9]]\r\n```\r\n\r\nNow we can pick the second element, but only as a second step:\r\n\r\n```python\r\n>>> array[mask2][:, 0].type\r\n4 * float64\r\n>>> array[mask2][:, 0].tolist()\r\n[1.1, 3.3, 5.5, 7.7]\r\n```\r\n\r\nnot as a first step:\r\n\r\n```python\r\n>>> array[mask2, 0]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward/highlevel.py\", line 1005, in __getitem__\r\n    return ak._util.wrap(self._layout[where], self._behavior)\r\nValueError: in NumpyArray, too many dimensions in slice\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/1.0.2rc4/src/libawkward/array/NumpyArray.cpp#L3925)\r\n```\r\n\r\nbecause `mask1` goes one level down, letting the thing that comes after it apply to the second dimension, whereas `mask2` goes two levels down, so putting a `0` after it tries to slice the third dimension, and this `array` doesn't have a third dimension.\r\n\r\nDoes that help?",
     "createdAt":"2020-12-24T22:40:09Z",
     "number":240659,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"Duchstf"
     },
     "body":"Ah ok, I checked back my codes and I think that's not what went wrong, but it's similar\r\n\r\nSo initially I have a mask array of type:\r\n\r\n```python\r\nmask = 137178 * bool\r\n```\r\n\r\nand then I have two more arrays (`a` and `b`), both of them has the same first dimension. And I want to select the first elements in `a`, so I do this:\r\n\r\n```python\r\na = a[mask][:,0]\r\nb = b[mask]\r\n```\r\n\r\nI would expect them to have the same first dimension but `a` now has type `464 * float32` (which is what I expected). But now `b` has type `137178 * var * float32`. If I use  `b = b[mask][:]`, now it returns an array of type `464 * float32`, and this is what I want. \r\n\r\nSo I based on your response I might be experiencing a bug here? since we would expect the mask to remove lists from `b`. \r\n\r\n",
     "createdAt":"2020-12-24T23:42:59Z",
     "number":240702,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I still don't understand what the problem is: if I make `a` and `b` as having type `N * var * int64`,\r\n\r\n```python\r\n>>> a = ak.Array([[0, 1, 2], [3, 4], [5], [6, 7, 8, 9]])\r\n>>> b = ak.Array([[0, 1, 2], [3, 4], [5], [6, 7, 8, 9]])\r\n>>> mask = ak.Array([True, False, True, True])\r\n>>> a\r\n<Array [[0, 1, 2], [3, 4, ... 5], [6, 7, 8, 9]] type='4 * var * int64'>\r\n>>> b\r\n<Array [[0, 1, 2], [3, 4, ... 5], [6, 7, 8, 9]] type='4 * var * int64'>\r\n>>> mask\r\n<Array [True, False, True, True] type='4 * bool'>\r\n```\r\n\r\nthen I do `a = a[mask][:, 0]` and either `b = b[mask]` or `b = b[mask][:]`, and either way, the result is the same:\r\n\r\n```python\r\n>>> a = a[mask][:, 0]\r\n>>> b = b[mask][:]\r\n>>> a\r\n<Array [0, 5, 6] type='3 * int64'>\r\n>>> b\r\n<Array [[0, 1, 2], [5], [6, 7, 8, 9]] type='3 * var * int64'>\r\n```\r\n\r\nThat is, `a` is replaced by a non-jagged array of shorter length because (1) the `mask` drops nested lists, (2) the `[:, 0]` picks the first element from each remaining list, and (3) we only do the `mask` step to `b`. Composing with a `[:]` slice does nothing. (For Python lists, it copies, but in Awkward Array, there's no distinction between copying and viewing: it's a view in this case.)\r\n\r\nIf `b` were not jagged to start with, then `mask` would drop elements from it, making it still be non-jagged. Actually, it's always true that a boolean-array slice doesn't change the data type, other than changing length (which may be considered part of the type or not, depending on your point of view).\r\n\r\nI don't know what's happening in your case, and I only partially see what you mean by the possibility that something's wrong: it would be wrong for a jagged array to be turned into a non-jagged array by a mask.\r\n\r\n> But now `b` has type `137178 * var * float32`. If I use `b = b[mask][:]`, now it returns an array of type `464 * float32`\r\n\r\nThat one sentence sounds odd.\r\n\r\nAnyway, whatever problem you're seeing might be related to the fact that you're reusing `a` and `b` as variable names: you're replacing the original `a` and `b` with derived quantities using the same names. That sort of thing can lead to confusion if the code is run more than once. Because most operations view, rather than copy, there usually isn't much to be gained in terms of memory use by losing access to the original arrays.",
        "createdAt":"2020-12-25T03:09:23Z",
        "number":240842
       },
       {
        "author":{
         "login":"Duchstf"
        },
        "body":"> Anyway, whatever problem you're seeing might be related to the fact that you're reusing `a` and `b` as variable names: you're replacing the original `a` and `b` with derived quantities using the same names. That sort of thing can lead to confusion if the code is run more than once. Because most operations view, rather than copy, there usually isn't much to be gained in terms of memory use by losing access to the original arrays.\r\n\r\nAh that might be it!! Sorry for the confusion, thank you so much!!! ",
        "createdAt":"2020-12-25T03:16:02Z",
        "number":240848
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2020-12-24T21:32:28Z",
  "number":622,
  "title":"Array indexing after mask: bug or feature?",
  "url":"https://github.com/scikit-hep/awkward/discussions/622"
 },
 {
  "author":{
   "login":"mattbellis"
  },
  "body":"On the [tutorials site](https://awkward-array.org/)?\r\n\r\nIn the [Python docstrings](https://awkward-array.readthedocs.io/)?\r\n\r\nIn the [C++ doxygen API](https://awkward-array.readthedocs.io/en/latest/_static/index.html)?\r\n\r\nWhat, specifically, needs more explanation?\r\n\r\nI'd like to create an awkward array from a flat list of numbers and then the layout/num information. For example, can I get this\r\n\r\n```\r\n<Array [[1, 2], [3, 4, 5, 6]] type='2 * var * int64'>\r\n```\r\n\r\nfrom \r\n```\r\nvals = [1, 2, 3, 4, 5, 6]\r\nnum = [2,4]\r\n```\r\n\r\n\r\n\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Okay, this needs more explanation (as a tutorial?). Meanwhile, the place to look for your specific question is [ak.unflatten](https://awkward-array.readthedocs.io/en/latest/_auto/ak.unflatten.html).",
     "createdAt":"2020-12-28T15:50:13Z",
     "number":248341,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"mattbellis"
     },
     "body":"Ah, this is perfect! I feel like I should have been able to intuit the function name. \ud83d\ude01 Much thanks!",
     "createdAt":"2020-12-28T16:30:16Z",
     "number":248342,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"We had some discussion about the function name (@nsmith- and I) and I agree that it's not the best. It's only something that you'd think of if you had previously gone in the other direction (flatten, then unflatten).\r\n\r\nWith a long to-do list, it's been hard for me to get to writing documentation. My first goal is to get the stubs in the left-bar of [awkward-array.org](https://awkward-array.org) filled out. On the other hand, answering questions as they come up organically might actually make more difference in the long run. Although I'll make sure to include \"unflatten\" in the docs, I'll convert this request for documentation into a Q&A discussion, so that it's always prominent (not \"hidden,\" like closed issues).",
     "createdAt":"2020-12-28T17:37:13Z",
     "number":248343,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"mattbellis"
        },
        "body":"No, I think you misunderstood my sincerity! It's a good name! The opposite of flatten! I actually think I should have tried that or tried looking for that name! There was no snark intended!\r\n\r\nCommenting is hard. Sorry for the confusion of my intent.",
        "createdAt":"2020-12-28T17:44:07Z",
        "number":248351
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"(I also didn't think you were being snarky. But we did have misgivings about the name, myself included. \"unflatten\" was the best we came up with, and maybe it's better than we thought.)",
        "createdAt":"2020-12-28T18:03:32Z",
        "number":248400
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":3
  },
  "createdAt":"2020-12-28T08:11:32Z",
  "number":623,
  "title":"How to create a jagged array from a flat list and the layout/num values",
  "url":"https://github.com/scikit-hep/awkward/discussions/623"
 }
]