[
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n_(none!)_\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: remove unused keyword arg by @agoose77 in https://github.com/scikit-hep/awkward/pull/2046\r\n* fix: support `regular_to_jagged` in `Content._recursively_apply` / `ak.transform` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2048\r\n* fix: read behavior from highlevel `ak.ArrayBuilder` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2052\r\n* fix: rebuild invalid `check` pointers in `ArrayBuilder` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2055\r\n\r\n## Other\r\n\r\n* docs: correct canonical URL by @agoose77 in https://github.com/scikit-hep/awkward/pull/2040\r\n* docs: correct docstring for `ak.metadata_from_parquet` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2050\r\n* test: rename tests to use identifiers by @agoose77 in https://github.com/scikit-hep/awkward/pull/2044\r\n* chore: fix poor rename by @agoose77 in https://github.com/scikit-hep/awkward/pull/2049\r\n* chore: increase awkward-cpp version for #2055. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2056\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.4...v2.0.5\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.5'>Version 2.0.5</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-01-01T23:27:06Z",
  "number":2057,
  "title":"Version 2.0.5",
  "url":"https://github.com/scikit-hep/awkward/discussions/2057"
 },
 {
  "author":{
   "login":"marklit"
  },
  "body":"### Version of Awkward Array\r\n\r\n2.0.5\r\n\r\n### Description and code to reproduce\r\n\r\nThe following was run on Ubuntu 20 on a `e2-highcpu-32` GCP VM with 32 GB of RAM and 32 vCPUs.\r\n\r\nI downloaded the California dataset from https://github.com/microsoft/USBuildingFootprints and converted it from JSONL into Parquet with pyarrow and I attempted to do the same with fastparquet.\r\n\r\n```bash\r\n$ ogr2ogr -f GeoJSONSeq /vsistdout/ California.geojson \\\r\n    | jq -c '.properties * {geom: .geometry|tostring}' \\\r\n    > California.jsonl\r\n$ head -n1 California.jsonl | jq .\r\n```\r\n\r\n```json\r\n{\r\n  \"release\": 1,\r\n  \"capture_dates_range\": \"\",\r\n  \"geom\": \"{\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[-114.127454,34.265674],[-114.127476,34.265839],[-114.127588,34.265829],[-114.127565,34.265663],[-114.127454,34.265674]]]}\"\r\n}\r\n```\r\n\r\nAwkward is able to produce a 947 MB Parquet file in 64.60 seconds.\r\n\r\n```bash\r\n/usr/bin/time -v \\\r\n    python3 -c \"import awkward as ak; f = open('California.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); narr = arr.geom.layout.content.to_numpy(); arr2 = ak.from_json(narr.tobytes(), line_delimited=True); ak.to_parquet(arr2, 'awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\nWith ClickHouse I'm able to complete the same task in 18.26 seconds. Its resulting file size is 794 MB.\r\n\r\n```\r\n$ /usr/bin/time -v \\\r\n    clickhouse local \\\r\n          --input-format JSONEachRow \\\r\n          -q \"SELECT *\r\n              FROM table\r\n              FORMAT Parquet\" \\\r\n    < California.jsonl \\\r\n    > ch.snappy.pq\r\n```\r\n\r\nThe resulting Awkward Parquet almost matches ClickHouse in terms of row groups and using snappy compression.\r\n\r\n```\r\n<pyarrow._parquet.FileMetaData object at 0x7fb89c696d10>\r\n  created_by: parquet-cpp-arrow version 10.0.1\r\n  num_columns: 2\r\n  num_rows: 11542912\r\n  num_row_groups: 306\r\n  format_version: 2.6\r\n  serialized_size: 73744\r\n```\r\n\r\n```\r\n<pyarrow._parquet.FileMetaData object at 0x7f0926d54860>\r\n  created_by: parquet-cpp version 1.5.1-SNAPSHOT\r\n  num_columns: 3\r\n  num_rows: 11542912\r\n  num_row_groups: 306\r\n  format_version: 1.0\r\n  serialized_size: 228389\r\n```\r\n\r\nBelow is a flame graph from Awkward's execution.\r\n\r\n![parquet awkward snappy](https://user-images.githubusercontent.com/359316/211261513-06328c05-3769-4185-a1a7-9540200cfa37.svg)\r\n\r\nI ran a 10-line version of the above file through both PyArrow and ClickHouse. This is what `strace` and `perf` reported.\r\n\r\n```bash\r\n$ sudo su\r\n$ source .pq/bin/activate\r\n$ strace -wc \\\r\n    python3 -c \"import awkward as ak; f = open('cali10.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); narr = arr.geom.layout.content.to_numpy(); arr2 = ak.from_json(narr.tobytes(), line_delimited=True); ak.to_parquet(arr2, 'awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\n```\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ----------------\r\n 61.01    0.158111         261       604        50 openat\r\n 10.15    0.026304          14      1760       146 stat\r\n  6.44    0.016697          17       937           read\r\n  4.57    0.011833          11       992           fstat\r\n  3.98    0.010303          11       876         5 lseek\r\n  2.84    0.007351          13       563           close\r\n  2.61    0.006760          16       411           mmap\r\n  2.17    0.005612          12       455       438 ioctl\r\n  1.26    0.003253          27       117           munmap\r\n  1.15    0.002983          90        33           clone\r\n  0.81    0.002101          19       110           mprotect\r\n  0.80    0.002083          22        92           getdents64\r\n  0.60    0.001552          19        80           futex\r\n  0.56    0.001448          14       102           getcwd\r\n  0.35    0.000901          16        56           brk\r\n  0.26    0.000671           9        68           rt_sigaction\r\n  0.09    0.000224         224         1           execve\r\n  0.08    0.000213          11        18           pread64\r\n  0.06    0.000159          15        10           write\r\n  0.03    0.000069          13         5         2 readlink\r\n  0.03    0.000067          11         6           getpid\r\n  0.02    0.000051          12         4           getrandom\r\n  0.02    0.000044          14         3           uname\r\n  0.02    0.000042          21         2           open\r\n  0.01    0.000037          18         2           pipe2\r\n  0.01    0.000034          16         2           madvise\r\n  0.01    0.000032          10         3           sigaltstack\r\n  0.01    0.000031          10         3           rt_sigprocmask\r\n  0.01    0.000030          10         3           dup\r\n  0.01    0.000028          28         1           wait4\r\n  0.01    0.000023          11         2           sched_getaffinity\r\n  0.01    0.000022          11         2         1 arch_prctl\r\n  0.01    0.000014          14         1           sysinfo\r\n  0.01    0.000014          13         1         1 access\r\n  0.00    0.000011          11         1           fcntl\r\n  0.00    0.000011          11         1           prlimit64\r\n  0.00    0.000011          11         1           gettid\r\n  0.00    0.000009           9         1           set_tid_address\r\n  0.00    0.000009           8         1           set_robust_list\r\n------ ----------- ----------- --------- --------- ----------------\r\n100.00    0.259150                  7330       643 total\r\n```\r\n\r\n```bash\r\n$ perf stat -dd \\\r\n    ython3 -c \"import awkward as ak; f = open('cali10.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); narr = arr.geom.layout.content.to_numpy(); arr2 = ak.from_json(narr.tobytes(), line_delimited=True); ak.to_parquet(arr2, 'awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\n```\r\n  4,150.43 msec task-clock                #   11.326 CPUs utilized\r\n       105      context-switches          #   25.299 /sec\r\n         2      cpu-migrations            #    0.482 /sec\r\n    12,034      page-faults               #    2.899 K/sec                  \r\n```\r\n\r\nClickHouse's syscall counts were all much lower:\r\n\r\n```\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ----------------\r\n 29.52    0.019018        1584        12           futex\r\n 21.15    0.013625          63       214           gettid\r\n 11.19    0.007209         514        14           mprotect\r\n 11.06    0.007123         791         9         4 stat\r\n  8.72    0.005617         108        52           close\r\n  5.16    0.003327        1109         3           poll\r\n  2.19    0.001412          23        60           mmap\r\n  2.09    0.001344          39        34         1 openat\r\n  1.27    0.000816          18        44           read\r\n...\r\n  0.15    0.000098          48         2           write\r\n```\r\n\r\nAs were context switch and page fault counts.\r\n\r\n```\r\n  44      context-switches          #  372.955 /sec\r\n4997      page-faults               #   42.356 K/sec\r\n```\r\n\r\nThese are the versions of software involved:\r\n\r\n* awkward-2.0.5-py3-none-any.whl (541 kB)\r\n* awkward_cpp-6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n* ClickHouse 22.13.1.1361 (official build)",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"I only briefly looked at this, but the flamegraph (thanks for that, by the way!) suggests that ~83% of the time is spent in the `ak::ArrayBuilder` portion of our codebase, which is used to interpreting the JSON. If you were to repeat this test, but only profile the `to_parquet` portion, I'd anticipate the wall-time to be closer to ~11 seconds. I also note that the two datasets seem to have different numbers of columns, though I've not looked closely to see whether we write some additional metadata here.\r\n\r\nSo, would you be able to repeat the test and cover only the `to_parquet` call? :) If you can't easily test particular Python statements, loading from `pickle` (by pickling the `from_json` result in a different execution) should be fairly fast.",
     "createdAt":"2023-01-09T09:46:30Z",
     "number":4636660,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"marklit"
     },
     "body":"Sorry, I should have mentioned I'm interested in the end-to-end process rather than just the parquet writing on its own. Is there anything I can do to speed up the JSON reading portion of this workload if it's 83% of the work?\r\n\r\nI didn't notice it only produced two columns. If you have any tips for the JSON side of things, I can launch a new VM and see if I can figure out why there aren't three columns as well at the same time.",
     "createdAt":"2023-01-09T10:36:21Z",
     "number":4636661,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"agoose77"
     },
     "body":"> Sorry, I should have mentioned I'm interested in the end-to-end process rather than just the parquet writing on its own. \r\n\r\nOh, sure: we're interested in the end-to-end workflow too! We cater to a number of different use cases, and at some point we are more concerned with the performance of long-lived data, i.e. data that is transformed / operated upon before serialisation. @jpivarski and @ianna have a better feel for the performance implications of using `ArrayBuilder`, and where along that axis we're comfortable jumping off the optimisation train, so I've pinged them for their inputs :)",
     "createdAt":"2023-01-09T10:56:28Z",
     "number":4636662,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> If you have any tips for the JSON side of things\r\n\r\nThere is an option: [ak.from_json](https://awkward-array.org/doc/main/reference/generated/ak.from_json.html) can take a `schema` argument. With a [JSON schema](https://json-schema.org/), the function can avoid the generic [ArrayBuilder](https://awkward-array.org/doc/main/reference/generated/ak.ArrayBuilder.html), which has to remain open to the possibility that later parts of a dataset have a more general data type than earlier parts.\r\n\r\nAlthough the exact speedup will depend on the data type, our tests found that `from_json` with a schema was about four times faster than without: https://github.com/scikit-hep/awkward/pull/1165#issuecomment-978691819.\r\n\r\nAlso in that test, running RapidJSON (the C++ library that we use for JSON parsing) by itself with no output was not quite twice as fast as running RapidJSON with array output. As a pipeline, walking over the schema description and filling arrays is about as expensive as parsing the JSON itself, and therefore, there's not much further you can go. (Even with a perfectly streamlined walk over an optimized schema description, writing to contiguous memory will have _some_ cost.)\r\n\r\n------\r\n\r\nLooking at your data type, it's not very complicated, so I doubt walking through the data type is the bottleneck here. Also, it has JSON nested in JSON:\r\n\r\n```json\r\n{\r\n  \"release\": 1,\r\n  \"capture_dates_range\": \"\",\r\n  \"geom\": \"{\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[-114.127454,34.265674],[-114.127476,34.265839],[-114.127588,34.265829],[-114.127565,34.265663],[-114.127454,34.265674]]]}\"\r\n}\r\n```\r\n\r\nso your first interpretation makes a big string column for `\"geom\"` and your second interpretation interprets that string.\r\n\r\nIf you're willing to get hacky and optimize this specific case\u2014i.e. write code that won't work for other data types\u2014then I've got some suggestions.\r\n\r\nI take it from your code that you're interested in the coordinates, and I'm going to assume that the `\"type\"` field is always `\"Polygon\"` (so the `\"coordinates\"` will always be depth-3). Those coordinates always start with \"`[`\" and nothing else can start with \"`[`\" (everything that comes before it is a JSON object, bare integer, or string). Since the coordinates are all numeric\u2014no strings\u2014none of its characters are string-quoted (with a backslash).\r\n\r\nSo we can start by stripping out just the coordinates with\r\n\r\n```python\r\n>>> outer_json[outer_json.index(\"[\") : outer_json.rindex(\"]\") + 1]\r\n'[[[-114.127454,34.265674],[-114.127476,34.265839],[-114.127588,34.265829],[-114.127565,34.265663],[-114.127454,34.265674]]]'\r\n```\r\n\r\nJust to be clear, if you have any expectation that the data type can change, this is extremely brittle. But fast!\r\n\r\nIt only produces one of these outer JSON objects, right? If so, then you can immediately parse the inner JSON. If not, you'll have to concatenate many of these strings. String concatenation is probably faster in pure Python (accumulate a list and `\"\".join(...)`) than anything that Awkward can do, and UNIX command-line tools (part of your workflow, I see) are likely even faster:\r\n\r\n```bash\r\n% fgrep '[' outer_json.json | sed 's/[^[]*//' | sed 's/}\"//'\r\n[[[-114.127454,34.265674],[-114.127476,34.265839],[-114.127588,34.265829],[-114.127565,34.265663],[-114.127454,34.265674]]]\r\n```\r\n\r\nOnce you have a single string or file-like stream ([ak.from_json](https://awkward-array.org/doc/main/reference/generated/ak.from_json.html) accepts any file-like object with a `read` method), you can use `from_json` with `line_delimited=True` (doesn't actually require delimiters, just a sequence of whole JSON objects with nothing but whitespace in between) and a schema.\r\n\r\nHere's the schema for an array of lists of lists of numbers:\r\n\r\n```json\r\n{\"type\": \"array\", \"items\": {\"type\": \"array\", \"items\": {\"type\": \"array\", \"items\": {\"type\": \"number\"}}}}\r\n```\r\n\r\nSo this will read your concatenated (or only instance of) inner JSON:\r\n\r\n```python\r\n>>> ak.from_json(inner_json, line_delimited=True, schema=that_schema)\r\n<Array [[[-114, 34.3], ..., [-114, 34.3]]] type='1 * var * var * float64'>\r\n```\r\n\r\n(The distinction between concatenated/`line_delimited=True` and a single instance could result in a different number of \"`var`\" in the type: be sure you're getting the depth that you want. Slicing with `[0]` removes an unwanted, length-1 dimension and slicing with `np.newaxis` adds one.)",
     "createdAt":"2023-01-09T15:33:34Z",
     "number":4636663,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"marklit"
     },
     "body":"I copy and pasted the Python from another ticket that suggested I looked at your project. I've corrected it to produce a PQ file that matches what ClickHouse produced. In my latest test, ClickHouse produced a PQ file in 18.49 seconds and Awkward did it in 28.07s. Awkward is the fastest converter in the Python space that I've seen so far.\r\n\r\nI'll look into your schema specification suggestion but in the meantime, here are the commands and stats.\r\n\r\n```bash\r\n$ /usr/bin/time -v \\\r\n    python3 -c \"import awkward as ak; f = open('California.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); ak.to_parquet(arr, 'awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\n```\r\n<pyarrow._parquet.FileMetaData object at 0x7f1bc06793b0>\r\n  created_by: parquet-cpp-arrow version 10.0.1\r\n  num_columns: 3\r\n  num_rows: 11542912\r\n  num_row_groups: 306\r\n  format_version: 2.6\r\n  serialized_size: 213334\r\n```\r\n\r\n![parquet awkward snappy](https://user-images.githubusercontent.com/359316/211377533-94681902-33d2-4208-8894-1edeb80a6760.svg)\r\n\r\n```bash\r\n$ sudo su\r\n$ source .pq/bin/activate\r\n$ strace -wc \\\r\n    python3 -c \"import awkward as ak; f = open('cali10.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); ak.to_parquet(arr, 'cali10.awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\n```\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ----------------\r\n 23.10    0.026720          15      1760       146 stat\r\n 15.36    0.017765          18       937           read\r\n 10.70    0.012379          12       992           fstat\r\n  9.37    0.010839          17       604        50 openat\r\n  9.31    0.010770          12       877         5 lseek\r\n  6.57    0.007599          13       563           close\r\n  6.45    0.007463          16       447           mmap\r\n  5.00    0.005785          12       455       438 ioctl\r\n  3.21    0.003718          24       153           munmap\r\n  2.05    0.002369          71        33           clone\r\n  1.93    0.002235          20       110           mprotect\r\n  1.88    0.002170          23        92           getdents64\r\n  1.26    0.001463          14       102           getcwd\r\n  1.11    0.001286          18        68           futex\r\n  0.88    0.001021          18        56           brk\r\n  0.69    0.000799          11        68           rt_sigaction\r\n  0.22    0.000251         251         1           execve\r\n  0.19    0.000223          12        18           pread64\r\n  0.16    0.000189          14        13           write\r\n  0.06    0.000075          14         5         2 readlink\r\n  0.06    0.000070          11         6           getpid\r\n  0.05    0.000054          13         4           getrandom\r\n  0.04    0.000051          17         3           uname\r\n  0.04    0.000044          22         2           open\r\n  0.03    0.000038          19         2           pipe2\r\n  0.03    0.000037          12         3           sigaltstack\r\n  0.03    0.000036          11         3           dup\r\n  0.03    0.000033          16         2           madvise\r\n  0.03    0.000032          10         3           rt_sigprocmask\r\n  0.02    0.000026          12         2           sched_getaffinity\r\n  0.02    0.000026          25         1           wait4\r\n  0.02    0.000019           9         2         1 arch_prctl\r\n  0.01    0.000017          16         1           sysinfo\r\n  0.01    0.000017          16         1         1 access\r\n  0.01    0.000013          13         1           gettid\r\n  0.01    0.000012          11         1           set_tid_address\r\n  0.01    0.000011          11         1           fcntl\r\n  0.01    0.000011          11         1           prlimit64\r\n  0.01    0.000011          10         1           set_robust_list\r\n------ ----------- ----------- --------- --------- ----------------\r\n100.00    0.115675                  7394       643 total\r\n```\r\n\r\n```bash\r\n$ perf stat -dd \\\r\n    python3 -c \"import awkward as ak; f = open('cali10.jsonl', 'rb'); arr = ak.from_json(f, line_delimited=True); ak.to_parquet(arr, 'cali10.awkward.snappy.pq', compression='snappy', row_group_size=37738); f.close()\"\r\n```\r\n\r\n```\r\n  4,146.79 msec task-clock                #   11.560 CPUs utilized\r\n        97      context-switches          #   23.392 /sec\r\n         1      cpu-migrations            #    0.241 /sec\r\n    12,030      page-faults               #    2.901 K/sec\r\n```\r\n\r\nIf you have any further ideas, please share them. If not, I'm okay if you close this ticket.",
     "createdAt":"2023-01-09T18:11:07Z",
     "number":4636664,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Actually, I think it should remain as a Discussion. I don't have any further ideas, though.",
     "createdAt":"2023-01-09T18:26:47Z",
     "number":4636665,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":6
  },
  "createdAt":"2023-01-09T07:50:47Z",
  "number":2094,
  "title":"Speed up JSON reading? (Formerly: Parquet writing)",
  "url":"https://github.com/scikit-hep/awkward/discussions/2094"
 },
 {
  "author":{
   "login":"Durman"
  },
  "body":"Hello, I'm trying to adopt the library to deal with geometry data which include such types of elements as vertices. I have next shape of data which works perfectly.\r\n\r\n```py\r\nak.Array([[1],[2,3]]) + ak.Array([1])\r\n# <Array [[2], [3, 4]] type='2 * var * int64'>\r\n```\r\n\r\nBut, instead of scalar values I have vertices.\r\n\r\n```py\r\nak.Array([[[1,1,1]],[[2,2,2],[3,3,3]]]) + ak.Array([1,1,1])\r\n# Error details: cannot broadcast RegularArray of size 2 with RegularArray of size 3 in add\r\n```\r\n\r\nOk, it probably can't broadcast vertices because the array does not know that it contains vertices.\r\n\r\n<Array [[[1, 1, 1]], [[2, ...], ...]] type='2 * var * **var** * int64'>\r\n\r\nSo I've tried to build the array in more clever way.\r\n\r\n```py\r\nverts = ak.Array(ak.contents.ListOffsetArray(ak.index.Index64(np.array([0,1,3])), ak.contents.RegularArray(ak.from_iter([1,1,1,2,2,2,3,3,3], highlevel=False), 3)))\r\n# <Array [[[1, 1, 1]], [[2, 2, 2], [...]]] type='2 * var * 3 * int64'>\r\n```\r\n\r\nBut it seems does not fix anything.\r\n\r\n```py\r\nverts + ak.Array([1,1,1])\r\n# Error details: cannot broadcast RegularArray of size 2 with RegularArray of size 3 in add\r\n```\r\n\r\nThe question is how to broadcast awkward list of vertices?\r\n\r\nP.S. Also I've tried such variant:\r\n\r\n```py\r\nverts + ak.Array(ak.contents.RegularArray(ak.from_iter([1,1,1,2,2,2], highlevel=False),3))\r\n```\r\n```text\r\n    numpy.add.__call__(\r\n        <Array [[[1, 1, 1]], [[2, ...], ...]] type='2 * var * 3 * int64'>\r\n        <Array [[1, 1, 1], [2, 2, 2]] type='2 * 3 * int64'>\r\n    )\r\nError details: cannot broadcast nested list (in compiled code: https://github.com/scikit-hep/awkward-1.0/blob//src/cpu-kernels/awkward_RegularArray_broadcast_tooffsets.cpp#L18)\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @Durman,\r\n\r\nTo start with, I commend you on going the distance in trying to figure this out. We consider our `Content` classes to be advanced features that most users of the library should never need to know about. You were pretty close with your first attempt!\r\n\r\nThe first difference here is that NumPy performs _right_ broadcasting:\r\n```python\r\n>>> np.broadcast_shapes(\r\n...     (4, 3, 7,),\r\n...           (7,)\r\n... )\r\n(4, 3, 7)\r\n```\r\nwhich aligns elements \"to the right\".\r\n\r\nAwkward supports this broadcasting for entirely-regular (NumPy-like) arrays\r\n```python\r\n>>> ak.from_numpy(np.zeros((4, 3, 7))) + ak.Array([1, 2, 3, 4, 5, 6, 7])\r\n<Array [[[1, 2, 3, 4, 5, 6, 7], ..., [1, ...]], ...] type='4 * 3 * 7 * float64'>\r\n```\r\n\r\nBut for any broadcast involving a ragged array, only _left_ broadcasting is used. This would mean that, if NumPy supported this, one would see\r\n```python\r\n>>> np.broadcast_shapes(\r\n...     (4, 3, 7,),\r\n...     (4,)\r\n... )\r\n(4, 3, 7)\r\n```\r\n\r\nSo, in your case, Awkward Array is _left_ broadcasting an array of length-2 against an array of length 3. That is an invalid broadcast. You want _right_ broadcasting here, which you can perform yourself by constructing the appropriate slice to introduce regular length-1 dimensions\r\n```python\r\nx = ak.Array([[[1, 1, 1]], [[2, 2, 2], [3, 3, 3]]])\r\ny = ak.Array([1, 1, 1])\r\nz = x + y[np.newaxis, np.newaxis, :]\r\n```\r\nwhere the `:` is superfluous, but helps readability.\r\n\r\nAs an aside, you might find the [`vector` library](https://github.com/scikit-hep/vector) useful here too. It provides some Awkward [behaviour classes](https://awkward-array.org/doc/main/reference/ak.behavior.html#adding-behavior-to-arrays) that add useful methods to arrays such as vector addition, dot products, etc.",
     "createdAt":"2023-01-13T06:50:06Z",
     "number":4674967,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"Durman"
        },
        "body":"Thanks, the answer is easier than I thought. I can't say that now I clearly understand how broadcasting rules work but I hope it will be improved through practice.)\r\n\r\nThanks for pointing to the vector library I'll have a look.",
        "createdAt":"2023-01-13T07:34:12Z",
        "number":4675266
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"We have some documentation on broadcasting [here](https://awkward-array.org/doc/main/reference/generated/ak.broadcast_arrays.html), though I can summarise it.\r\n\r\nAwkward Array was originally written for Particle physicists to use in analyses. Most analyses ultimately work with data that looks like\r\n```python\r\nfor event in events:\r\n    for particle in event.particles:\r\n        do_something_with_particle()\r\n```\r\n\r\nAs an array, this would look something like\r\n```python\r\n[\r\n    [\"particle-1\", \"particle-2\", ...],                # event 1\r\n    [\"particle-1\", \"particle-2\", \"particle-3\", ...],  # event 2\r\n    ...\r\n]\r\n```\r\n\r\nIt rarely _if ever_ makes sense to do any kind of calculations that mix _different_ events, because they are unrelated. So, we always want the outermost axis `axis=0` to line up. NumPy's broadcasting rules, which align `axis=-1`, do the wrong thing as far as particle physicists are concerned. Hence, Awkward introduced \"left\" broadcasting, which always lines things up from left to right.",
        "createdAt":"2023-01-13T08:23:25Z",
        "number":4675636
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-01-13T06:08:51Z",
  "number":2118,
  "title":"Broadcasting lists with different structures",
  "url":"https://github.com/scikit-hep/awkward/discussions/2118"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: expose typetracer in public backend API by @agoose77 in https://github.com/scikit-hep/awkward/pull/2066\r\n* feat: add byteorder argument to `to_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2095\r\n* feat: add exception for missing field by @agoose77 in https://github.com/scikit-hep/awkward/pull/2120\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: support scalars in tuple (and list) arguments provided to `__array_function__` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2045\r\n* fix: support option-in-record for `fill_none` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2065\r\n* fix: support unzipping `ak.Record` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2077\r\n* fix: render keyword and varargs by @agoose77 in https://github.com/scikit-hep/awkward/pull/2074\r\n* fix: don't try to re-wrap `array_function` overload results by @agoose77 in https://github.com/scikit-hep/awkward/pull/2079\r\n* fix: support merging of `RegularArray` and `NumpyArray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2063\r\n* fix: correct NumPy zero-size broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2083\r\n* fix: implement explicit translation for NEP-18 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2089\r\n* fix: listarray - slicing expects scalars by @ianna in https://github.com/scikit-hep/awkward/pull/2069\r\n* fix: off-by-one error in `run_lengths` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2093\r\n* fix: broken links due to cpp split by @agoose77 in https://github.com/scikit-hep/awkward/pull/2087\r\n* fix: unflatten should accept non-packed `counts` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2097\r\n* fix: remove string casting from `ak.to_layout` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2098\r\n* fix: support categorical counts in `ak.unflatten` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2099\r\n* fix: use pickleable closure for `ak.mixin_class_method` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2102\r\n* fix: be more permissive with sort translation by @agoose77 in https://github.com/scikit-hep/awkward/pull/2112\r\n* fix: merging 1D `NumpyArray` with option by @agoose77 in https://github.com/scikit-hep/awkward/pull/2105\r\n* fix: support `is_indexed` types in `ak.fill_none` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2111\r\n* fix: use `object.__new__(ak.Array)` for pickling constructor by @agoose77 in https://github.com/scikit-hep/awkward/pull/2113\r\n* fix: remove Long64_t from common header-only by @ianna in https://github.com/scikit-hep/awkward/pull/2084\r\n* fix: `TypeTracerArray` binary operators, `ak.Array.__str__` with a typetracer, attempts to call `touch_data` on non-typetracers, ...? by @jpivarski in https://github.com/scikit-hep/awkward/pull/2115\r\n* fix: add `ScalarType` and treat bare strings as char arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2116\r\n* fix: ensure Exception if branch evaluates for Awkward type by @agoose77 in https://github.com/scikit-hep/awkward/pull/2019\r\n\r\n## Other\r\n\r\n* refactor: add `@final` to contents, types, and forms by @agoose77 in https://github.com/scikit-hep/awkward/pull/2033\r\n* refactor:  remove `kind` and `order` args to sorting protocols by @agoose77 in https://github.com/scikit-hep/awkward/pull/2090\r\n* docs: remove reference to sorting implementation by @agoose77 in https://github.com/scikit-hep/awkward/pull/2114\r\n* test: fix on win32 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2117\r\n* ci: remove link checker by @agoose77 in https://github.com/scikit-hep/awkward/pull/2075\r\n* chore: update pyodide-build by @agoose77 in https://github.com/scikit-hep/awkward/pull/2060\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2039\r\n* chore(deps): bump pypa/cibuildwheel from 2.11.3 to 2.11.4 by @dependabot in https://github.com/scikit-hep/awkward/pull/2038\r\n* chore(deps): bump mymindstorm/setup-emsdk from 11 to 12 by @dependabot in https://github.com/scikit-hep/awkward/pull/2119\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.5...v2.0.6\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.6'>Version 2.0.6</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-01-13T18:42:25Z",
  "number":2121,
  "title":"Version 2.0.6",
  "url":"https://github.com/scikit-hep/awkward/discussions/2121"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"This is a heads-up that NumPy 1.17.0 or later will soon be required. That's a version of NumPy that was released on July 26, 2019, so you're probably already using it. According to [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html), it's already obsolete.\r\n\r\nThis NumPy version provides some features that we have work-arounds for at the moment. We'll be able to remove those work-arounds. As a user-visible change, the equivalence of `ak.XYZ` and `np.XYZ` for functions `XYZ` that exist in both libraries is made possible by NumPy 1.17.0.\r\n\r\nThis new minimum version will go into effect in Awkward 2.1.0, which will be approximately February 1, 2022. [Here is a table of upcoming deprecations.](https://github.com/scikit-hep/awkward/wiki#api-breaking-changes-after-20) The NumPy deprecation is the only backward incompatible change in Awkward 2.1.0.\r\n\r\nSee https://github.com/scikit-hep/awkward/pull/2138#discussion_r1081204036 for how this came up.",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-01-19T22:04:18Z",
  "number":2144,
  "title":"Awkward 2.1.0 (targeting February 1, 2023) will require NumPy >= 1.17.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2144"
 },
 {
  "author":{
   "login":"Durman"
  },
  "body":"In short I'm looking for something like [serchsorted](https://numpy.org/doc/1.24/reference/generated/numpy.searchsorted.html) in numpy.\r\n\r\nThe problem.\r\nI'm trying to implement some operations with polylines. I have two lines:\r\n\r\nThey are represented similar to such array - `[[p1, p2, p3, p4], [p1, p2, p3]]`\r\n\r\nAnd have serious of numbers which represent position of some points on the lines, like this `[[1.5, 4,0],[2,0]]`.\r\n\r\n![image](https://user-images.githubusercontent.com/28003269/213742250-ad9da256-4b23-4ec9-a3c3-ae4ce4e9bd0e.png)\r\n\r\nWhat comes to my mind is using binary search with Python loops, but they might be too slow. Probably there is another solution?",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @Durman!\r\n\r\nAwkward Array does not yet have a direct function to compute positions within ragged arrays, which is what you appear to be looking for. However, we do have tools that let you build this yourself.\r\n\r\nThere are two ways of achieving this that I can think of. One is to use Numba, and the other is to flatten, search over the flattened list, and rebuild. I'll show both, but I would recommend the use of Numba for readability\r\n\r\n## 1. Numba\r\nThe simplest approach that I can think of is to use `np.searchsorted` in Numba, and then employ `ArrayBuilder` to re-build the ragged result:\r\n```python\r\nimport numba as nb\r\nimport awkward as ak\r\nimport numpy as np\r\n\r\nhaystack = ak.Array([[0.0, 1.86, 2.93, 3.62, 4.9], [0.0, 0.83, 1.52, 3.28, 4.08]])\r\nneedles = ak.Array([[1.5, 4.0], [2.0]])\r\n\r\n\r\n@nb.njit\r\ndef searchsorted_2d(builder, array, needle):\r\n    for array_i, needle_i in zip(array, needle):\r\n        result_i = np.searchsorted(np.asarray(array_i), np.asarray(needle_i))\r\n        builder.begin_list()\r\n        for x in result_i:\r\n            builder.integer(x)\r\n        builder.end_list()\r\n    return builder\r\n\r\n\r\nindex = searchsorted_2d(ak.ArrayBuilder(), haystack, needles).snapshot()\r\n```\r\n\r\nHowever, we know exactly how big our result is, so it is wasteful to use `ak.ArrayBuilder`, which is slower and uses more memory as it does not know up-front how much data (or what kinds of data) it will be working with. We can make this faster by creating a flat NumPy array to contain the result, and unflattening it after we are done:\r\n```python\r\nimport numba as nb\r\nimport awkward as ak\r\nimport numpy as np\r\n\r\nhaystack = ak.Array([[0.0, 1.86, 2.93, 3.62, 4.9], [0.0, 0.83, 1.52, 3.28, 4.08]])\r\nneedles = ak.Array([[1.5, 4.0], [2.0]])\r\n\r\n\r\n@nb.njit\r\ndef searchsorted_2d(flat_result, array, needle):\r\n    j = 0\r\n    for array_i, needle_i in zip(array, needle):\r\n        result_i = np.searchsorted(np.asarray(array_i), np.asarray(needle_i))\r\n        \r\n        k = j + len(result_i)\r\n        flat_result[j:k] = result_i\r\n\t\tj = k\r\n\r\n\r\nnum = ak.num(needles)\r\n\r\nresult_length = ak.sum(num)\r\nflat_result = np.zeros(result_length, dtype=np.int64)\r\n\r\n# Fill the result\r\nsearchsorted_2d(flat_result, haystack, needles)\r\n\r\nindex = ak.unflatten(flat_result, num)\r\n```\r\n\r\n## 2. Flattened search\r\nIn this example, I'm assuming that you have a _two_ dimensional array, and that none of the sublists are empty. If those assumptions aren't true, then we would need to update this example.\r\n\r\nThe manual way of doing this is to flatten both the \"needle\" and the \"haystack\" into one-dimensional arrays, and keep track of the \"list boundaries\" that separate elements from different sublists. We can then adjust these two arrays so that the haystack is monotonically increasing, i.e. for every input there is exactly one output (or, there are multiple outputs but they're all adjacent on the number line):\r\n```python\r\n# From\r\n[0, 1.86, 2.93, 3.62, 4.9, [boundary], 0.0, 0.83, 1.52, 3.28, 4.08]\r\n# To\r\n[0, 1.86, 2.93, 3.62, 4.9, [boundary], 4.9, 5.73, 6.42, 8.18, 8.98]\r\n```\r\n\r\nTo adjust the haystack, we can take the end values and find their cumulative sum. By assuming that each sublist in `haystack` is monotonically increasing, we can iteratively shift each sublist by the previous list's end value, e.g.\r\n```python\r\noffset = 0\r\nfor sublist in lists:\r\n    sublist += offset\r\n    offset = sublist[-1]\r\n```\r\n\r\nIn NumPy arrays, we can do this using `cumsum`:\r\n```python\r\nimport awkward as ak\r\nimport numpy as np\r\n\r\nhaystack = ak.Array([[0.0, 1.86, 2.93, 3.62, 4.9], [0.0, 0.83, 1.52, 3.28, 4.08]])\r\nneedles = ak.Array([[1.5, 4.0], [2.0]])\r\n```\r\nThis would give us the `value_starts` that we need to shift the needles and haystacks, so that we can then flatten them\r\n```python\r\n# To flatten this list so that it is monotonic increasing,\r\n# we assume each list is monotonic increasing, and cumulatively shift\r\n# each sublist by the final value\r\nvalue_starts = np.zeros(len(haystack))\r\nvalue_starts[1:] = np.cumsum(haystack[1:, -1])\r\n```\r\nWhen we've computed the result, it is going to be an array of indices into the flat search result. We'll need to adjust these indices to account for the fact that they came from smaller sublists. We can do this by building an array of the cumulative sum of sublist lengths: `[0, length_1, length_1+length_2, length_1+length_2+length_3, ...]`.\r\n```python\r\n# What are the start positions of each sublist in the flattened list?\r\nstarts = np.zeros(len(haystack), dtype=np.int64)\r\nstarts[1:] = np.cumsum(ak.num(haystack))[:-1]\r\n```\r\nNow we actually perform the search over the adjusted, flattened array\r\n```python\r\n# Compute search over flattened, adjusted array\r\nflat_index = np.searchsorted(\r\n    ak.flatten(haystack + value_starts),\r\n    ak.flatten(needles + value_starts),\r\n)\r\n```\r\nThen we unflatten this result into sublists\r\n```python\r\n# Adjust the indices back\r\nunadjusted_index = ak.unflatten(flat_index, ak.num(needles))\r\n```\r\nAnd adjust the indices\r\n```python\r\n# Adjust the indices back\r\nindex = unadjusted_index - starts\r\n```",
     "createdAt":"2023-01-20T16:28:59Z",
     "number":4739148,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"Durman"
        },
        "body":"Thanks. I also thought about the second approach but it seemed that it can be too slow if there are a lot of small polylines because in this case each value is going to be searched through all of them.\r\n\r\nI will try to implement the first suggestion. )",
        "createdAt":"2023-01-23T04:47:17Z",
        "number":4753141
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"The time complexity of the search should be `k*M*log(N)` in all solutions here; where `k` is constant differing between Numba and Python solutions, `M` is the number of \"needles\" and `N` the number of items in the \"haystack\". For the case where you have an equal number of points and sublists, I get this performance trend:\r\n![image](https://user-images.githubusercontent.com/1248413/213995564-5c8adf3e-71e9-4a7d-b038-24cf06d1245b.png)\r\n\r\nThe cause of this below-n-squared behaviour is the use of a [binary search ](https://en.wikipedia.org/wiki/Binary_search_algorithm#Derivation_of_average_case) in `np.searchsorted`. Increasing the number of items to search through (i.e. the main difference between the Numba implementations and the non-jitted version) by searching over the _entire_ haystack for each item only changes the performance by some constant shift: `log(cN) = log(c) + log(N)`.\r\n\r\nNote that I've already sorted the lists here!",
        "createdAt":"2023-01-23T08:36:32Z",
        "number":4754283
       },
       {
        "author":{
         "login":"Durman"
        },
        "body":"Interesting! I would never guess that the two solutions have the same complexity. I will start with the second one then because it seems simpler.",
        "createdAt":"2023-01-23T10:16:34Z",
        "number":4755080
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Whatever you prefer! Note that the Numba solution is still faster on the wall time: it's a constant factor faster. You could probably speed it up even further, but this might already be sufficient for your use case.",
        "createdAt":"2023-01-23T10:25:11Z",
        "number":4755144
       },
       {
        "author":{
         "login":"Durman"
        },
        "body":"I'm now on stage of proving a concept. Reaching maximum performance will be a separate step.)",
        "createdAt":"2023-01-25T05:06:46Z",
        "number":4773566
       }
      ],
      "totalCount":5
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-01-20T15:38:04Z",
  "number":2147,
  "title":"Binary search",
  "url":"https://github.com/scikit-hep/awkward/discussions/2147"
 },
 {
  "author":{
   "login":"CaueSousa"
  },
  "body":"Hello, dear community!\r\n\r\nI'm trying to solve the following issue: \r\n\r\nI have data about a particle cloud in a NumPy array with shape (1250,91,19) where the first index is related to the number of events(1250) and the other two with the rows (particles) and columns (particles features) of my data.\r\n\r\nEach event has a variable number of particles, the event with the highest number has 91 particles. Because of this zero padding was used to fill the rows up to 91.\r\n\r\nI converted this NumPy array to an awkward array and now I'm trying to get rid of the rows filled with zero.\r\n\r\nI tried to assign to each \"zero\" a None element and after this use the `a[~ak.is_none(a)]` to remove these rows:\r\n\r\n        input_events = ak.from_numpy(data_array_final)\r\n\r\n        for event in range(1250):\r\n            for row in range(91):\r\n        \r\n            #Some values of the columns can be zero in a valid row(like mass, vx, vy,vz), but\r\n            #if the second collum(collum of PDG ID) is zero, the entire row is zero:\r\n            if(input_events[event,row,1] == 0):\r\n                for collum in range(19):\r\n                    input_events[event,row,collum] = None\r\n\r\nbut this attempt would be an In-place assignment, which isn't supported as a design choice.\r\n\r\nIs there any way to remove an entire row similar to `np.delete()` from Numpy? Or to select only those rows filled with zeros and remove them from the overall array?\r\n\r\nAn example of the structure of the events can be found in the following file:\r\n[events_example.txt](https://github.com/scikit-hep/awkward/files/10492324/events_example.txt)\r\n\r\nMy apologies if this is a simple question, I've searched for some solution, but I found only the \"None element\" one.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"I have to make some assumptions here; let me know if they are wrong!\r\n\r\n- I understand that your data can contain zeros, but the second index of the inner dimension (`array[:, :, 1]`) is zero if that \"row\" (axis=1) is missing.\r\n- I assume that your intended Awkward type is `1250 * var * 19`, i.e. your final dimension is regular of length 19.\r\n\r\nWhat you probably want to use here is Awkward's ragged indexing. We'll construct an array that indexes _up to_ the second dimension, and ignore the empty rows.\r\n\r\nFirst, let's convert the array to an Awkward Array\r\n```python\r\narray = ak.from_numpy(input_events)\r\n```\r\n\r\nNow we can identify which rows are not padding, according to their second element\r\n```python\r\nrow_is_not_padding = array[:, :, 1] != 0\r\n```\r\n\r\nSubsequently, we can keep only these rows. We need to convert the index into a ragged array, so that Awkward's ragged indexing takes place. I.e., to go from\r\n```python\r\n>>> row_is_not_padding.type.show()\r\n1250 * 91 * bool\r\n```\r\nto\r\n```python\r\n>>> ak.from_regular(row_is_not_padding).type.show()\r\n1250 * var * bool\r\n```\r\n\r\nFinally, we can index into the array with this ragged index\r\n```python\r\narray_ragged = array[\r\n    ak.from_regular(row_is_not_padding)\r\n]\r\n```\r\n\r\nThe result has a ragged shape:\r\n```python\r\n>>> array_ragged.type.show()\r\n1250 * var * 19 * float64\r\n```\r\n",
     "createdAt":"2023-01-24T17:15:32Z",
     "number":4768954,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"As a question about interpreting the problem, if you have an array like this:\r\n\r\n```\r\n[\r\n    [1.1, 2.2, 3.3, 4.4, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [1.1, 2.2, 0.0, 0.0, 3.3, 4.4, 0.0, 0.0, 0.0, 0.0],\r\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1, 0.0],\r\n    [1.1, 0.0, 2.2, 3.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n]\r\n```\r\n\r\nWould you want it to be unpadded like the following (remove all zeros)?\r\n\r\n```\r\n[\r\n    [1.1, 2.2, 3.3, 4.4, 5.5],\r\n    [1.1, 2.2, 3.3, 4.4],\r\n    [1.1],\r\n    [1.1, 2.2, 3.3],\r\n]\r\n```\r\n\r\nOr would you want it to be unpadded like the following (remove all contiguous zeros, starting from the end)?\r\n\r\n```\r\n[\r\n    [1.1, 2.2, 3.3, 4.4, 5.5],\r\n    [1.1, 2.2, 0.0, 0.0, 3.3, 4.4],\r\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1],\r\n    [1.1, 0.0, 2.2, 3.3],\r\n]\r\n```\r\n\r\nIn the first case, `0.0` is never a valid value. In the second case, you can't distinguish between a valid `0.0` at the end of the valid region and where the valid region ends. Like, if a row is supposed to look like\r\n\r\n```\r\n    [1.1, 2.2, 3.3, 4.4, 5.5, 0.0],\r\n```\r\n\r\nyou wouldn't be able to tell.\r\n\r\nSince @agoose77's `row_is_not_padding` is false for any `0.0` anywhere, it implements the first case. The second case is trickier, but possible. (It would involve [ak.run_lengths](https://awkward-array.org/doc/main/reference/generated/ak.run_lengths.html).)",
        "createdAt":"2023-01-24T18:21:47Z",
        "number":4769558
       },
       {
        "author":{
         "login":"CaueSousa"
        },
        "body":"Hi, Angus!\r\n\r\nYour two assumptions are correct!\r\n\r\n- A valid row can contain zeros, but not on the second collum since this collum is the particle id according to PDG. If a row has zero on the second collum, it necessarily came from the zero padding and has to be removed!\r\n- Precisely, the number of rows (second index) should be `var` but the number of collums is fixed (third index)\r\n\r\nThank you very much! I'll read about the functions you just used since I'm starting to use Awkward. Thank you!\r\n\r\n",
        "createdAt":"2023-01-24T19:25:43Z",
        "number":4770092
       },
       {
        "author":{
         "login":"CaueSousa"
        },
        "body":"Hi, Jim!\r\n\r\nIn the example you gave, all the rows should be maintained, since none of them are completely filled with zeros. So given an array like:\r\n\r\n\r\n```\r\n[\r\n    [0, 22, 3.3, 4.4, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [1,-211, 0.0, 0.0, 3.3, 4.4, 0.0, 0.0, 0.0, 0.0],\r\n    [2,130, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1, 0.0],\r\n    [3,-11, 2.2, 3.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n]\r\n```\r\nthe idea is to keep the first 4 rows and remove the last 3 (since they only have zeros):\r\n\r\n```\r\n[\r\n    [0, 22, 3.3, 4.4, 5.5, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n    [1,-211, 0.0, 0.0, 3.3, 4.4, 0.0, 0.0, 0.0, 0.0],\r\n    [2,130, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1, 0.0],\r\n    [3,-11, 2.2, 3.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n]\r\n```\r\n\r\n\r\nThank you guys for your support! Now I can go back to my master's degree project!",
        "createdAt":"2023-01-24T19:32:59Z",
        "number":4770160
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"In that case, does `row_is_not_padding` need an `ak.all` with `axis=-1` in its definition?",
        "createdAt":"2023-01-24T19:46:36Z",
        "number":4770258
       },
       {
        "author":{
         "login":"CaueSousa"
        },
        "body":"I don't know, Jim, but I think Angus's solution is quite right.\r\n\r\nFor example, my first event had 32 valid rows and 59 filled with zeros. After applying Angus solution, this is how the first event looks like:\r\n\r\n ```\r\n [\r\n\t [0, 22, 0, -1, -1, -1, -1, 0, 0, ..., -2.8, 0.26, 0.353, 0.094, -3, 0, 0, 0, 0],\r\n\t [1, 22, 0, -1, -1, -1, -1, 0, 0, ..., 0.563, 0.259, 0.163, -2.54, 0, 0, 0, 0],\r\n\t [2, 22, 0, -1, -1, -1, -1, 0, 0, ..., 1.62, 0.477, 4.76, 2.46, 13, 0, 0, 0, 0],\r\n\t [3, 22, 0, -1, -1, -1, -1, 0, 0, ..., -2.25, -0.809, -1.01, 4.17, 0, 0, 0, 0],\r\n\t [4, 22, 0, -1, -1, -1, -1, 0, 0, ..., -2.34, -0.255, -0.263, 2.33, 0, 0, 0, 0],\r\n\t [5, 130, 0, -1, -1, -1, -1, 0, 0, ..., 0.311, 0.902, 0.29, -7.12, 0.14, 0, 0, 0],\r\n\t [6, 130, 0, -1, -1, -1, -1, 0, ..., -0.47, 0.773, -0.393, 2.09, 0.14, 0, 0, 0],\r\n\t [7, -11, 0, -1, -1, -1, -1, 0, 0, ..., 0.531, 3.44, 2.02, 9.66, 0, 0, 0, 0],\r\n\t [8, 11, 0, -1, -1, -1, -1, 0, 0, ..., -0.852, 0.343, -0.393, -4.08, 0, 0, 0, 0],\r\n\t [9, 211, 0, -1, -1, -1, -1, 0, 0, ..., -1.34, 0.09, -0.377, 3.51, 0.14, 0, 0, 0],\r\n\t [10, 211, 0, -1, -1, -1, -1, 0, ..., -2.16, -2.85, -4.27, 12.2, 0.14, 0, 0, 0],\r\n\t [11, -211, 0, -1, -1, -1, -1, 0, ..., -2.21, -3.17, -4.26, 12.1, 0.14, 0, 0, 0],\r\n\t [12, -211, 0, -1, -1, -1, -1, 0, 0, ..., 0.346, 4.35, 1.57, 10.5, 0.14, 0, 0, 0],\r\n\t [13, 211, 0, -1, -1, -1, -1, 0, ..., -2.45, -2.73, -2.27, 9.11, 0.14, 0, 0, 0],\r\n\t [14, 211, 0, -1, -1, -1, -1, 0, ..., -2.25, -1.75, -2.17, 9.33, 0.14, 0, 0, 0],\r\n\t [15, -13, 0, -1, -1, -1, -1, ..., 2.37, -0.007, 5.53, 0.106, 0, -0.018, -4.78],\r\n\t [16, -211, 0, -1, -1, -1, -1, 0, ..., 1.77, -0.449, 2.17, 15.7, 0.14, 0, 0, 0],\r\n\t [17, 211, 0, -1, -1, -1, -1, 0, 0, ..., -2.21, -1.21, -1.64, 4.3, 0.14, 0, 0, 0],\r\n\t [18, -211, 0, -1, -1, -1, -1, 0, 0, ..., -1.29, 0.55, -1.88, 19, 0.14, 0, 0, 0],\r\n\t [19, -211, 0, -1, -1, -1, -1, 0, 0, ..., 0.87, 1.16, 1.38, 6.83, 0.14, 0, 0, 0],\r\n\t [20, 211, 0, -1, -1, -1, -1, 0, ..., -2.88, -1.72, -0.471, -15.6, 0.14, 0, 0, 0],\r\n\t [21, 211, 0, -1, -1, -1, -1, 0, ..., -2.27, -1.12, -1.33, 4.19, 0.14, 0, 0, 0],\r\n\t [22, 211, 0, -1, -1, -1, -1, 0, ..., -1.76, -0.321, -1.65, 9.01, 0.14, 0, 0, 0],\r\n\t [23, 211, 0, -1, -1, -1, -1, 0, ..., -2.98, -1.42, -0.225, -7.68, 0.14, 0, 0, 0],\r\n\t [24, 211, 0, -1, -1, -1, -1, 0, ..., -1.82, -0.333, -1.32, 6.99, 0.14, 0, 0, 0],\r\n\t [25, 211, 0, -1, -1, -1, -1, 0, ..., 0.809, 0.941, 0.985, 3.07, 0.14, 0, 0, 0],\r\n\t [26, -211, 0, -1, -1, -1, -1, 0, ..., -1.35, 0.286, -1.28, -5.75, 0.14, 0, 0, 0],\r\n\t [27, -211, 0, -1, -1, -1, -1, 0, ..., -2.18, -0.763, -1.09, 4.88, 0.14, 0, 0, 0],\r\n\t [28, -211, 0, -1, -1, -1, -1, 0, ..., -2.17, -0.72, -1.06, 6.36, 0.14, 0, 0, 0],\r\n\t [29, 211, 0, -1, -1, -1, -1, 0, 0, ..., 1.23, 0.423, 1.2, 5.19, 0.14, 0, 0, 0],\r\n\t [30, -211, 0, -1, -1, -1, -1, 0, ..., -1.09, 0.578, -1.11, 8.47, 0.14, 0, 0, 0],\r\n\t [31, 211, 0, -1, -1, -1, -1, 0, 0, ..., 1.09, 0.564, 1.08, 2.77, 0.14, 0, 0, 0]\r\n ]\r\n ```\r\n\r\nonly the rows filled entirely with zeros were removed.",
        "createdAt":"2023-01-24T20:05:06Z",
        "number":4770393
       }
      ],
      "totalCount":5
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-01-24T16:58:56Z",
  "number":2156,
  "title":"Remove unwanted rows in array?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2156"
 },
 {
  "author":{
   "login":"Durman"
  },
  "body":"Hello, I'm creating something like visual programming for procedural modeling with help of the library. I've implemented several functions and faced with next problem. No matter how much data income into a function or how much data it produces the execution time is nearly the same. On the video performance of Subdivide Polyline node is always about 7 milliseconds. \r\n\r\nhttps://user-images.githubusercontent.com/28003269/214292941-dfa60612-8d90-4c32-9534-4cff91f2b0f8.mp4\r\n\r\nAt first I thought that this is a bug but after reading some answers here I came to conclusion that this is so called initial cost. So the question is there a way to reduce it? In my case it is quite significant because users can create trees with thousands of nodes and if all of them have some initial costs the tree will soon loos its ability to calculate in real time.\r\n\r\nHere is the function in case I'm doing something wrong.\r\n\r\n```py\r\nimport numpy as np\r\nimport awkward as ak\r\n\r\n\r\ndef subdivide_polyline(verts, cuts):\r\n    \"\"\"Only works with list of polylines\"\"\"\r\n    lines_mum = len(verts)\r\n    segment_num = ak.num(verts, axis=-2) - 1\r\n    segment_shape = ak.num(verts, axis=-1)[..., :-1]\r\n    _, count_per_seg = ak.broadcast_arrays(segment_shape, cuts)\r\n    new_verts_num = segment_num * cuts + ak.num(verts)\r\n    total_num = ak.sum(new_verts_num)\r\n    seg_weight0 = np.zeros(total_num - lines_mum)\r\n    seg_weight1 = ak.unflatten(seg_weight0, ak.flatten(count_per_seg)+1)\r\n    seg_weight2 = ak.unflatten(seg_weight1, segment_num)\r\n    seg_weight3 = ak.local_index(seg_weight2)\r\n    seg_weight = seg_weight3 / (count_per_seg+1)\r\n    vert1 = verts[..., :-1, :]\r\n    vert1 = vert1[..., np.newaxis, :]\r\n    vert2 = verts[..., 1:, :]\r\n    vert2 = vert2[..., np.newaxis, :]\r\n    new_verts = linear_interpolation(vert1, vert2, seg_weight)\r\n    new_verts = ak.flatten(new_verts, axis=-2)\r\n    return new_verts\r\n\r\n\r\ndef linear_interpolation(v1, v2, factor):\r\n    return v1 * (1-factor) + v2 * factor\r\n\r\n\r\nif __name__ == '__main__':\r\n    p_line = ak.Array([[[0, 0, 0], [1.5, 0, 0], [2, 0.5, 0]],\r\n                       [[0, 0, 0], [0, 1.5, 0], [0, 2, 0.5], [0, 3, 0]]])\r\n    from timeit import timeit\r\n    t = timeit('subdivide_polyline(p_line, ak.Array([1]))', 'from __main__ import ak, subdivide_polyline, p_line', number=100)\r\n    print(f\"{t*10:.1f} ms\")\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"As you observe, we anticipate a certain \"constant overhead\" that is independent of the size of the data being operated upon (and scales linearly with the number of steps that you take. Whilst there is room for some performance optimisation here, realtime performance needs (i.e. <16ms) are somewhat out of scope. You might find for your application that writing a Numba routine to perform this logic (without awkward) performs better; Numba jitted functions don't have a significant performance overhead IIRC.\r\n\r\nI will update this conversation with some pointers.",
     "createdAt":"2023-01-25T17:16:03Z",
     "number":4779870,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"agoose77"
     },
     "body":"We don't yet have a section on this in our docs, but I'll get round to that at some point!\r\n\r\nThe best solution for your needs (low overhead) is probably Numba. The trade-off of using Numba is primarily expressiveness; some things are more cumbersome or sometimes impossible to write. However, in this case, it should be fairly straightforward. Here's a function doing what I *think* you're hoping to achieve; to subdivide a set of poly-lines `N` times:\r\n\r\nThis function evaluates much, much faster than the pure Awkward variant (because the data are *so* small), which is beneficial for your use case. I get 0.02 seconds per thousand iterations, which compares with 8 seconds per thousand for the pure-awkward case. \r\n\r\nI'm assuming that you want to take a ragged array of polylines, i.e of `type`: `N * var * 3`, where `N` is the number of lines, `var` the number of vertices per line, and `3` the number of coordinates.\r\n\r\n```python\r\nimport numpy as np\r\nimport awkward as ak\r\nimport numba as nb\r\nfrom timeit import timeit\r\n\r\n\r\n@nb.njit\r\ndef subdivide_polylines(poly_lines, n_line_subdivisions):\r\n    # Pre-pass over the data to determine how large our arrays need to be\r\n    final_vertex_count = 0\r\n    for line in poly_lines:\r\n        n_segments = len(line) - 1\r\n        final_vertex_count += len(line) + n_line_subdivisions * n_segments\r\n\r\n    flat_result = np.empty((final_vertex_count, 3), dtype=np.float64)\r\n    flat_count = np.zeros(len(poly_lines), dtype=np.int64)\r\n\r\n    # New number of vertices per segment\r\n    n_final_segment_vertices = 2 + n_line_subdivisions\r\n\r\n    # Keep track of the vertex index in the flat result\r\n    l_vertex_index = 0\r\n\r\n    # For each polyline\r\n    for i_line, line in enumerate(poly_lines):\r\n        assert len(line) >= 2\r\n\r\n        # Given that stop(line i) == start(line i+1), we skip the first\r\n        # vertex of the line to avoid double counting\r\n        # Hence, let's write that here\r\n        start = np.asarray(line[0])\r\n        flat_result[l_vertex_index] = start\r\n        flat_count[i_line] += 1\r\n        l_vertex_index += 1\r\n\r\n        # For each segment (three vertices = two segments)\r\n        n_segments = len(line) - 1\r\n        for j_segment in range(n_segments):\r\n            # Get these as NumPy arrays\r\n            start = np.asarray(line[j_segment])\r\n            stop = np.asarray(line[j_segment + 1])\r\n\r\n            # For each vertex in the result, skiping the first (as explained above)\r\n            for k_segment_vertex in range(1, n_final_segment_vertices):\r\n                # Interpolate between start and stop\r\n                t = k_segment_vertex / (n_final_segment_vertices - 1)\r\n                flat_result[l_vertex_index] = start * (1 - t) + stop * t\r\n                l_vertex_index += 1\r\n        flat_count[i_line] = len(line) + n_line_subdivisions * n_segments\r\n\r\n    return flat_result, flat_count\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    p_line = ak.Array(\r\n        [\r\n            [[0, 0, 0], [1.5, 0, 0], [2, 0.5, 0]],\r\n            [[0, 0, 0], [0, 1.5, 0], [0, 2, 0.5], [0, 3, 0]],\r\n        ]\r\n    )\r\n    # Trigger the jit to compile (ensure this function is only defined once, or you'll pay the JIT cost each time)\r\n    subdivide_polylines(p_line, 1)\r\n\r\n    t = timeit(\"subdivide_polylines(p_line, 1)\", number=1000, globals=globals())\r\n    print(f\"{t:.3f} s per 1000\")\r\n\r\n    flat_result, flat_count = subdivide_polylines(p_line, 1)\r\n    result = ak.unflatten(flat_result, flat_count, axis=0)\r\n    print(result.tolist())\r\n```\r\n\r\n",
     "createdAt":"2023-01-26T13:56:35Z",
     "number":4787774,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"Durman"
        },
        "body":"Thanks for the great example! \r\nBasing on your last answers I come to a conclusion that some set of problems (like missing feature, or something does not work as somebody would expect) can be solved by switching from awkward arrays to something else (like numpy, numba or whatever). It seems like not quite valid solution because in this case the library is not used. But from another hand in this case awkward arrays acting as buffers for transferring data between more efficient or advance libraries what can be quite a way to go.\r\n\r\nI need a little clarification about using numba. Is it necessary step switching to using loops? Is it possible to gain any performance (or is it going even work) if just wrap the function with numba njit compiler without changing anything inside?",
        "createdAt":"2023-01-27T05:11:28Z",
        "number":4793726
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"In this context, I've used Awkward Arrays to represent the ragged structure of the lists. If you use NumPy to do this by itself, you would need to keep around an extra array to track the list lengths. So, awkward could be a good fit for concisely storing this metadata. Also, depending upon how much you expose to third-party scripts, it might be convenient to expose things in terms of Awkward Arrays.\r\n\r\nNumba is integrated with Awkward at the loop level, i.e. you can loop over the ragged arrays performantly, which is also the fastest way to use Numba. In short, Numba can usually get more speed out of a loop than using e.g `np.sum`.\r\n\r\nWe haven't added any support for using the `ak.xxx` operations in Numba, because they're already mostly running in C++, so there would not be much benefit. ",
        "createdAt":"2023-01-27T07:53:38Z",
        "number":4794458
       },
       {
        "author":{
         "login":"Durman"
        },
        "body":"Thanks a lot. I will try different approaches with numpy and numba to find what is better solving my problem.)",
        "createdAt":"2023-01-27T08:45:54Z",
        "number":4794770
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"> Basing on your last answers I come to a conclusion that some set of problems (like missing feature, or something does not work as somebody would expect) can be solved by switching from awkward arrays to something else (like numpy, numba or whatever). It seems like not quite valid solution because in this case the library is not used.\r\n\r\nTo clarify, yes, we don't target small arrays as a performance goal in the `ak.XXX` layer. But, Awkward Array is designed to be easy to use with Numba; you can still benefit from expressing your data in Awkward Arrays, whilst operating upon them in Numba. So, if you're not upset about including an additional dependency, I'd suggest using Awkward in this way will make your life easier.\r\n\r\nFor posterity, this is the simplest Python-only (non-Numba) Awkward solution, which runs no faster than ~5ms, but scales fairly nicely.\r\n```python\r\ndef subdivide_polylines(p_line, n_subdivisions):\r\n    p_start = p_line[:, :-1, np.newaxis]\r\n    p_stop = p_line[:, 1:, np.newaxis]\r\n    t = np.arange(n_subdivisions + 1).reshape((1, 1, -1, 1)) / (n_subdivisions + 1)\r\n\r\n    p = p_start * (1 - t) + p_stop * t\r\n    return ak.concatenate((ak.flatten(p, axis=2), p_line[:, [-1]]), axis=1)\r\n```\r\nThere's probably a nicer way of avoiding the concatenate, but I can't think of it off the top of my head.",
        "createdAt":"2023-01-27T10:03:40Z",
        "number":4795359
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Just to be clear, by \"Numba,\" we're referring to using Numba with Awkward Array, not either-or. They pair nicely: Awkward can load a large, structured dataset, and iterating over an Awkward Array in Numba is as fast as iterating over NumPy arrays in Numba, with the added advantage that the Awkward Array is structured.\r\n\r\nIn writing a function for Numba, you get the best performance by writing for loops, as though it were C code, but with Python syntax. The Numba developers have reimplemented many NumPy functions, such as `np.whatever`, so that they work-alike inside a Numba function, but creating new arrays in which to put the output and having multiple passes over an input dataset are performance bottlenecks at this scale. At the scale of compiled code, you want to avoid unnecessary allocations and loops. The Awkward Array functions, `ak.whatever`, haven't even been reimplemented for Numba, so trying to use `ak.whatever` inside of a function compiled by `@nb.njit` would raise an error.\r\n\r\nAs a dependency, Numba + llvmlite is no more than 40 MB of binary wheels (depends on platform). Depending on your requirements, it can be relatively large, but it's well packaged and installs easily on all platforms that I've tested.\r\n\r\nTo use Awkward + Numba effectively, you'd want to get all of your data into one big Awkward Array and use it repeatedly. All of this has been designed for large-scale batch processing (i.e. data analysis); we haven't thought a lot about real-time systems. Would it be possible to do that in your case? I think @agoose77 has solved the algorithm, but what about data-loading\u2014how this integrates with your larger system?",
        "createdAt":"2023-01-27T16:02:49Z",
        "number":4798481
       },
       {
        "author":{
         "login":"Durman"
        },
        "body":"@jpivarski Thanks for the clarification.\r\n\r\nUnlike data analysis in procedural modeling a lot of data can be generated. For example here is a cube which is subdivided iteratively 6 times and in the end we have thousands of points. There is even no any input data here.\r\n\r\n![image](https://user-images.githubusercontent.com/28003269/215389252-5bc2d291-e37c-4679-bb1b-d29b95390fa6.png)\r\n\r\nEach node should be able to handle one point or thousands or even millions of points. A node tree can have hundreds or even thousands of nodes. So in order it being real-time each node should be able to work pretty fast. It's not necessary to have 30 fps but the more it's close to it the more convenient work.\r\n\r\nSo since awkward arrays give performance of numpy I think I have to use numba any way to gain maximum performance. But now I'm on stage of proving concept and I'm going to use awkward first and then try what can be done with numba.",
        "createdAt":"2023-01-30T05:07:56Z",
        "number":4814697
       }
      ],
      "totalCount":6
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-01-25T05:02:05Z",
  "number":2157,
  "title":"Reduce initial costs",
  "url":"https://github.com/scikit-hep/awkward/discussions/2157"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"Whenever we perform an Awkward operation, we ultimately have to choose how parameters are merged, and where to put them. In #2179, I have made some changes to the existing rules in order to fix a bug with string merging. These changes would make `Indexed[Option]Array` nodes _more_ distinct, i.e. not merging their own parameters with their contents. \r\n\r\nThe purpose of this discussion is to formally discuss where we want our parameter system to go, serve as a reference for PRs that change these rules, and to leave room for #1391\r\n\r\nThe parameter system in Awkward is very broad, and used in a variety of ways internally. In particular, we have two kinds of `parameters`:\r\n\r\n1. User-defined Parameters\r\n\r\n    We want to be able to associate unique metadata with *every* layout node. Users can set any parameter, but we don't know how these should survive various Awkward operations, so we use `check_equal` as our metadata merging policy. This ensures that merging parameters only preserves identical key-value pairs. Unlike https://github.com/scikit-hep/awkward/issues/1391, most of this metadata is easily destroyed i.e. it's scoped to the layout node. \r\n    \r\n    Merging of layouts does not care if user-defined parameters don't match; they're just dropped at the parameter merge step.\r\n\r\n2. Awkward-defined Parameters\r\n    In addition to user-generic parameters, we have a set of reserved (special) names e.g. `__array__` and `__record__`. These parameters *are* required to match in order for layouts to be mergeable.\r\n\r\n\r\n## Array lookup problem\r\nOf particular importance is `__array__`, whose location Awkward is highly sensitive to. Unlike `__record__` , which walks through the layout tree recursively, `__array__` is taken from the first-encountered layout node. This causes the following observation\r\n```python\r\n>>> import awkward as ak\r\n>>> import numpy as np\r\n>>> type(ak.Array(ak.contents.IndexedArray(ak.index.Index64(np.arange(2)), ak.to_layout([\"Hi\", \"Bye\"]))))\r\nawkward.highlevel.Array\r\n>>> type(ak.Array(ak.to_layout([\"Hi\", \"Bye\"])))\r\nawkward.behaviors.string.StringBehavior\r\n```\r\nThe reason that the former returns `ak.highlevel.Array` in the first example is that `__array__` is resolved against the `IndexedArray` node, which has no parameters.\r\n\r\nIn many scenarios, we use parameters for user-facing operations like setting a behaviour class. It's my assertion that the user should only be required to reason about the array _type_, which does not mention the index. Therefore, I argue that the above behaviour is undesirable.\r\n    \r\nTo fix this, we have discussed introducing something like `dimension_parameter` that behaves like `purelist_parameter` within a particular dimension (i.e., stops resolution at list boundaries). A generalisation of this would be `type_parameters`, that are scoped to the dimension _and_ option type.\r\n\r\nClearly, the reserved parameters are special, and therefore we can impose our own custom lifetime rules. An alternative solution, therefore, would be to \"promote\" the `__array__` options, so that they're always set on both the indexed node and its content. I do not prefer this approach.\r\n\r\n## Array class of option?\r\nIf we treat the `type` as the mechanism for users to configure behaviours, then: \r\n- should `var * int64` have the same array class as `Option[var * int64]`? \r\n- should `var * int64` have the same array class as `var * int64?`?\r\n\r\nThe current rules are (1) no, (2) yes.\r\n\r\n## Merging arrays with & without `__array__`\r\n\r\nRight now, we treat two arrays as mergeable iff. they have the same `__array__`. I wonder whether it makes sense to loosen this; if the contents are mergeable, then we need the arrays to have _compatible_ `__array__`, i.e. not `__array__=X, __array__=Y`. If the second array does not have an `__array__` parameter, is it not mergeable?\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"@jpivarski this discussion sets the scene for a tentative PR #2179. At some point, it would be good to get your thoughts on this. Not urgent, so could do so during a 1:1.",
     "createdAt":"2023-01-31T13:21:43Z",
     "number":4829885,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I agree with your assessment: the original `parameters` mechanism is more low-level than the thing (it turns out) we actually want. The `parameters` is a function of layout/form nodes, but users see types, and count \"number of dimensions\" (through `axis`) separately from option nodes, record nodes, union nodes, etc.\r\n\r\nThe idea that dimensions/list nodes are \"more first-class\" than everything else is a point I didn't appreciate in the original design. It comes up repeatedly, for example, here: https://github.com/Cloud-Drift/ragged-array-idioms/issues/4 A naive attempt to preserve xarray dimension names as `parameters` lost the information when a node was replaced, and would not work well if that example is ever extended beyond pure lists.\r\n\r\nFor existing \"well known parameters\" like `__array__`, we already have special logic for handling them and rules for propagating them where they need to be (which apparently didn't work in #2173 and is being revised in #2179). I think that should continue because we're already pretty invested in the `__array__` and `__record__` rules, and they're publicly visible. (We are free to change them because we are fixing _bugs_; behavior like #2173 was not intended.)\r\n\r\nIn the above, it sounds like you're suggesting that we introduce a new, higher-level kind of parameter, which is attached to nested list dimensions, rather than layout nodes. That is a good idea: the need for it keeps coming up. I think that the higher-level thing can be implemented in terms of `parameters`, however\u2014I don't think we want to confuse things by having two mechanisms side by side (prompting a developer to ask, \"Which should I use?\"). It could be a naming convention: all parameters that begin with `\"dim:\"` should stick to list dimensions, perhaps?",
     "createdAt":"2023-01-31T17:24:56Z",
     "number":4832393,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":">  it sounds like you're suggesting that we introduce a new, higher-level kind of parameter\r\n\r\nAt this stage, I was even thinking of not doing this, but rather defining a mechanism to search for parameters in a type-dependent way. I.e., not just dimensional, but sensitive to options too. So, instead of special property names, this type-sensitivity becomes a property of the caller, who must use `layout.type_parameter()`. As such, we'd want our standard parameter merging logic to behave such that these type-aware queries always resolve correctly. That might not be possible, though \u2014 I have not considered all of the ways that we create new layouts.",
        "createdAt":"2023-01-31T19:12:57Z",
        "number":4833255
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Okay, it's a higher-level concept than `parameters`, but it's not baked into the parameters themselves as a naming convention; it's a matter of how they're requested. You already mentioned it, but that makes it like `purelist_parameter`, a road we've already started down.",
        "createdAt":"2023-01-31T19:41:36Z",
        "number":4833477
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Yes, that's an idea. Note, it's not the only idea. Your suggestion places the information about the parameter scope within the parameter itself, which is interesting. ",
        "createdAt":"2023-01-31T19:59:51Z",
        "number":4833597
       }
      ],
      "totalCount":3
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-01-31T13:10:20Z",
  "number":2180,
  "title":"How should parameters behave?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2180"
 },
 {
  "author":{
   "login":"fleble"
  },
  "body":"Dear experts,\r\n\r\nI am writing ROOT files using uproot. One problem I face is when a branch is empty, thus having unknown type, which cannot be written down with uproot.\r\n\r\n```bash\r\n>>> ak.__version__\r\n1.5.1\r\n>>> uproot.__version__\r\n4.3.7\r\n```\r\n\r\nThis script\r\n```python\r\nak_array = ak.Array([[], [], []])\r\nak_array = ak.values_astype(ak_array, np.float64)\r\n\r\ntree = {\"branch\": ak_array}\r\n\r\nwith uproot.recreate(\"test.root\") as file:\r\n    file[\"test\"] = tree\r\n```\r\n terminates with the following error:\r\n ```\r\n TypeError: cannot write Awkward Array type to ROOT file:\r\n\r\n    var * unknown\r\n ```\r\n\r\nAnd:\r\n ```bash\r\n>>> ak_array = ak.Array([[], [], []])\r\n>>> ak.values_astype(ak_array, np.float64)\r\n <Array [[], [], []] type='3 * var * unknown'> \r\n ```\r\n \r\n Is it possible to give a type to empty to empty awkward array?",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"fleble"
     },
     "body":"After some attempts, I found a trick by concatenating an ak array of the desired type, and filtering out the part that was concatenated.",
     "createdAt":"2023-02-01T14:14:40Z",
     "number":4841063,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Converted into an issue: https://github.com/scikit-hep/uproot5/issues/822.\r\n\r\nAnd also #2188.",
     "createdAt":"2023-02-01T14:19:32Z",
     "number":4841112,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-02-01T13:52:18Z",
  "number":2186,
  "title":"Type of empty array",
  "url":"https://github.com/scikit-hep/awkward/discussions/2186"
 },
 {
  "author":{
   "login":"radiradev"
  },
  "body":"I am looking for the most natural of creating a pytorch dataloader from awkward arrays, when the collection of those arrays does not fit into memory. The arrays I'm working with contain events with a variable-number of 4 vectors. \r\n\r\nI tried to save the files to parquet and then using the torchdata API to load them (as shown [here](https://pytorch.org/data/beta/generated/torchdata.datapipes.iter.ParquetDataFrameLoader.html#torchdata.datapipes.iter.ParquetDataFrameLoader), however I get an error:\r\n\r\n`` NotImplementedError: Unsupported Arrow type: large_list<item: float not null>\r\nThis exception is thrown by __iter__ of ParquetDFLoaderIterDataPipe(columns=None, device='', dtype=None, source_dp=FileListerIterDataPipe, use_threads=False) ``\r\n\r\nThe [nvidia-merlin](https://github.com/NVIDIA-Merlin/dataloader) library looks like it's made for this exact purpose but there isn't a lot of documentation.\r\n\r\n\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"`large_list<item: float not null>` is an Arrow data type\u2014lists built with 64-bit indexes. PyTorch's `ParquetDataFrameLoader` must be going through pyarrow (a very common thing to do, since Arrow supports all of Parquet's types).\r\n\r\nThere's also a `list<item: float not null>` type, which uses 32-bit indexes. Early in Arrow's development, this was the only list type, the argument being that if you really have 4 GB of data, it should be broken into separate partitions (row-groups in Parquet). But there are reasons why you sometimes want contiguous, large arrays, so `large_list` was later added.\r\n\r\nSince it came later, `large_list` doesn't have as wide support as `list` among software products that use Arrow, and it's not too surprising that `ParquetDataFrameLoader` raises a `NotImplementedError`. They probably intend to implement it someday.\r\n\r\nAwkward Array's lists use 64-bit signed indexes by default, but can also use 32-bit signed or unsigned. Since 64-bit is the default, many operations will end up giving you 64-bit indexes (for simplicity in implementation, actually). When converting an Awkward Array to Arrow with [ak.to_arrow](https://awkward-array.org/doc/main/reference/generated/ak.to_arrow.html) or Parquet with [ak.to_parquet](https://awkward-array.org/doc/main/reference/generated/ak.to_parquet.html), the 64-bit Awkward lists are converted into Arrow `large_list` by default, since this is zero-copy.\r\n\r\nHowever, both of these functions have a `list_to32` argument; setting `list_to32=True` would make it copy and convert the 64-bit indexes into 32-bit Arrow `list` types (similarly for Parquet), and presumably PyTorch would be able to read that.\r\n\r\n-------------\r\n\r\nIf PyTorch is not actually objecting to the `large_list` part, but the `not null` part, then that would have to be dealt with differently. The `not null` means that the Awkward type is (for example)\r\n\r\n```\r\n10000 * var * float64\r\n```\r\n\r\ninstead of\r\n\r\n```\r\n10000 * var * ?float64\r\n```\r\n\r\nwhere the `?` means that some of the values can be `None`, rather than a floating point number. In Awkward Array, the normal case is that data are \"not nullable\" (can't be missing; there must always be a number or a list there, not `None`). While Arrow supports this case, the normal (original) case is that all data at all levels are nullable. Just like SQL, it has to call out the `not null` types as unusual exceptions. Just as I'm hypothesizing that PyTorch's Parquet reader is constrained to the \"normal\" case of 32-bit indexes, maybe it's constrained to the \"normal\" case of nullable data.\r\n\r\nI don't know if we have a nice function for promoting non-nullable data into nullable data. A hacky way to do it would be to concatenate a missing value at the right depth and then slice it off, like this:\r\n\r\n```python\r\n>>> array = ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]])\r\n>>> array\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5]] type='3 * var * float64'>\r\n\r\n>>> ak.concatenate((array, [[None]]))\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5], [None]] type='4 * var * ?float64'>\r\n\r\n>>> ak.concatenate((array, [[None]]))[:-1]\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5]] type='3 * var * ?float64'>\r\n```\r\n\r\nThere would be faster-for-the-computer ways of doing this by inserting an `UnmaskedArray` node in the layout, but that's not faster-for-the-user than the above.\r\n\r\nWell, maybe this:\r\n\r\n```python\r\n>>> empty_missingness = ak.Array(ak.contents.UnmaskedArray(ak.contents.EmptyArray()))[np.newaxis][:0]\r\n>>> empty_missingness\r\n<Array [] type='0 * 0 * ?unknown'>\r\n\r\n>>> ak.concatenate((array, empty_missingness))\r\n<Array [[1.1, 2.2, 3.3], [], [4.4, 5.5]] type='3 * var * ?float64'>\r\n```\r\n\r\nThe use of `UnmaskedArray` rather than `[[None]]` minimizes the computational cost. Both of these assume that you know how many levels deep that you want it: I'm guessing that you need to put the option-type on the `float64`, rather than on the `var`. In the `empty_missingness` array, that's what the `np.newaxis` slice does. If you needed it a level deeper, like `[[[None]]]`, then you could slice with `(np.newaxis, np.newaxis)`.",
     "createdAt":"2023-02-01T17:56:00Z",
     "number":4843463,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Oh, please let us know what works, in case there are other users who need to know how to prepare the Parquet file for PyTorch.",
        "createdAt":"2023-02-01T17:57:19Z",
        "number":4843472
       },
       {
        "author":{
         "login":"radiradev"
        },
        "body":"It seemed that neither of those were what `ParquetDataFrameLoader` was looking for, I got `NotImplementedError: Unsupported Arrow type: list<item: float>` instead.",
        "createdAt":"2023-02-06T15:36:34Z",
        "number":4883821
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"radiradev"
     },
     "body":"After some time I was able to load the data in two ways using the torchdata API by creating two custom `IterDataPipe` classes. The method outlined in the documentation [by padding the arrays](https://awkward-array.org/doc/main/user-guide/how-to-restructure-pad.html) was faster.  The pytorch_geometric implementation is probably slower due to the row by row iteration within the awkward array. \r\n\r\nHere is my code for implementing the two datapipes - one for torch_geometric and one for vanilla pytorch. \r\n```\r\n@torch.utils.data.functional_datapipe('create_graph')\r\nclass AwkwardGraph(IterDataPipe):\r\n    def __init__(self, source_dp: IterDataPipe):\r\n        super().__init__()\r\n        self.source_dp = source_dp\r\n\r\n    def __iter__(self):\r\n        for path in self.source_dp:\r\n            data = ak.from_parquet(path)\r\n\r\n            for row in data:\r\n                features, pos = self._feats_and_coords(row)\r\n                yield torch_geometric.data.Data(pos=pos, x=features)\r\n    \r\n    def _feats_and_coords(self, x):\r\n        features = self._ak_to_torch(x['energy'])\r\n        coords = ['px', 'py', 'pz']\r\n        pos = torch.stack([self._ak_to_torch(x[i]) for i in coords], dim=1)\r\n        return features, pos\r\n\r\n    def _ak_to_torch(self, x):\r\n        return torch.from_numpy(x.to_numpy())\r\n\r\n@torch.utils.data.functional_datapipe('create_tensor')\r\nclass AwkwardTensor(IterDataPipe):\r\n    def __init__(self, source_dp: IterDataPipe):\r\n        super().__init__()\r\n        self.source_dp = source_dp\r\n\r\n    def __iter__(self):\r\n        for path in self.source_dp:\r\n            data = ak.from_parquet(path)\r\n            data = self._to_features(data)\r\n            for row in data:\r\n                yield row\r\n    \r\n    def _to_features(self, x):\r\n        feature_names = ['px', 'py', 'pz', 'energy']\r\n        features = torch.stack([self._pad(x[i]) for i in feature_names], dim=1)\r\n        return features\r\n\r\n    def _pad(self, x):\r\n        # pad the data to be the same size\r\n        x = ak.pad_none(x, target=100, axis=1, clip=True)\r\n        x = ak.fill_none(x, 0)\r\n        x = ak.to_numpy(x)\r\n        return torch.from_numpy(x)\r\n\r\n\r\ndef create_pipe(path, batch_size, type):\r\n    file_list = FileLister(path, '*GENIE*.parquet')\r\n    file_list = file_list.shuffle()\r\n\r\n    if type == 'graph':\r\n        dp = file_list.create_graph()\r\n        dp = dp.shuffle()\r\n        dp = dp.batch_graphs(batch_size)\r\n    \r\n    elif type == 'tensor':\r\n        dp = file_list.create_tensor()\r\n        dp = dp.shuffle()\r\n        dp = dp.batch(batch_size)\r\n    \r\n    return dp\r\n\r\ndef time_pipe(dp):\r\n    start = time()\r\n    for idx, data in enumerate(dp):\r\n        # get the current time\r\n        if idx == 0:\r\n            end = time()\r\n            first_time = end - start\r\n            start = time() # reset the start time\r\n        if idx == 100:\r\n            end = time()\r\n            avg_time = (end - start)/idx\r\n            break\r\n    \r\n    return first_time, avg_time\r\n\r\npipe_types = ['graph', 'tensor']\r\nbatch_sizes = [1, 10, 100, 1000]\r\n\r\nfor pipe_type in pipe_types:\r\n    print(pipe_type)\r\n    for batch_size in batch_sizes:\r\n        dp = create_pipe(path, batch_size, pipe_type)\r\n        first_time, avg_time = time_pipe(dp)\r\n        print(f'batch size: {batch_size}, Datapipe loading time: {first_time}, Avg batch time: {avg_time}') \r\n```\r\n\r\nAnd this is the output on my machine:\r\n```\r\ngraph\r\nBatch size: 1, Loading time: 6.00, Avg batch time: 1.008e-03\r\nBatch size: 10, Loading time: 5.31, Avg batch time: 5.993e-03\r\nBatch size: 100, Loading time: 5.41, Avg batch time: 5.678e-02\r\nBatch size: 1000, Loading time: 6.57, Avg batch time: 5.463e-01\r\ntensor\r\nBatch size: 1, Loading time: 16.40, Avg batch time: 6.821e-06\r\nBatch size: 10, Loading time: 16.64, Avg batch time: 4.721e-05\r\nBatch size: 100, Loading time: 16.39, Avg batch time: 4.353e-04\r\nBatch size: 1000, Loading time: 15.99, Avg batch time: 4.297e-03\r\n```",
     "createdAt":"2023-02-06T16:00:43Z",
     "number":4884096,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-02-01T15:08:30Z",
  "number":2189,
  "title":"What is the best way to create a pytorch dataloader from awkward arrays?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2189"
 },
 {
  "author":{
   "login":"grst"
  },
  "body":"Hi all, \r\n\r\nhere's another issue that I encountered in the context of `AwkwardArrayViews` in https://github.com/scverse/anndata/pull/647, and I'm not sure how to best solve it. I guess one option would be to wait for #1391, and implement views with that. \r\n\r\nLet's say, I want to concatenate a view with an empty array: \r\n```python\r\nclass AwkwardArrayView:\r\n    pass\r\nak.behavior[\"AwkwardArrayView\"] = AwkwardArrayView\r\n\r\nview = ak.Array([{'a': 2}, {'a': 3}])\r\nview = ak.with_parameter(view, \"__array__\", \"AwkwardArrayView\")\r\n\r\narray = ak.Array([None])\r\nres1 = ak.concatenate([view, array])\r\nres2 = ak.concatenate([array, view])\r\n```\r\n\r\nFor `res1`, I get\r\n```\r\n[{a: 2},\r\n {a: 3},\r\n None]\r\n------------------------------------------------\r\ntype: 3 * option[{\r\n    a: int64\r\n}, parameters={\"__array__\": \"AwkwardArrayView\"}]\r\n```\r\n\r\nwhich I can slice like this: \r\n\r\n```python\r\n>>> res1[:, 'a']\r\n[2,\r\n 3,\r\n None]\r\n----------------\r\ntype: 3 * ?int64\r\n```\r\n\r\nHowever, for `res2` (reversed concatenation), I get\r\n```python\r\n>>> res2\r\n[None,\r\n {a: 2},\r\n {a: 3}]\r\n----------------------------------------------------\r\ntype: 3 * union[\r\n    ?unknown,\r\n    struct[{\r\n        a: int64\r\n    }, parameters={\"__array__\": \"AwkwardArrayView\"}]\r\n]\r\n\r\n>>> res2[:, 'a']\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\nInput In [49], in <cell line: 1>()\r\n----> 1 res2[:, 'a']\r\n```\r\n\r\n<details>\r\n<summary>Stacktrace</summary>\r\n\r\n```pytb\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/highlevel.py:956, in Array.__getitem__(self, where)\r\n    527 \"\"\"\r\n    528 Args:\r\n    529     where (many types supported; see below): Index of positions to\r\n   (...)\r\n    953 have the same dimension as the array being indexed.\r\n    954 \"\"\"\r\n    955 with ak._errors.SlicingErrorContext(self, where):\r\n--> 956     out = self._layout[where]\r\n    957     if isinstance(out, ak.contents.NumpyArray):\r\n    958         array_param = out.parameter(\"__array__\")\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/content.py:509, in Content.__getitem__(self, where)\r\n    508 def __getitem__(self, where):\r\n--> 509     return self._getitem(where)\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/content.py:546, in Content._getitem(self, where)\r\n    537 nextwhere = ak._slicing.prepare_advanced_indexing(items)\r\n    539 next = ak.contents.RegularArray(\r\n    540     self,\r\n    541     self.length if self._backend.nplike.known_shape else 1,\r\n    542     1,\r\n    543     parameters=None,\r\n    544 )\r\n--> 546 out = next._getitem_next(nextwhere[0], nextwhere[1:], None)\r\n    548 if out.length == 0:\r\n    549     return out._getitem_nothing()\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/regulararray.py:416, in RegularArray._getitem_next(self, head, tail, advanced)\r\n    412 nextcontent = self._content._carry(nextcarry, True)\r\n    414 if advanced is None or advanced.length == 0:\r\n    415     return RegularArray(\r\n--> 416         nextcontent._getitem_next(nexthead, nexttail, advanced),\r\n    417         nextsize,\r\n    418         self._length,\r\n    419         parameters=self._parameters,\r\n    420     )\r\n    421 else:\r\n    422     nextadvanced = ak.index.Index64.empty(\r\n    423         self._length * nextsize, self._backend.index_nplike\r\n    424     )\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/unionarray.py:769, in UnionArray._getitem_next(self, head, tail, advanced)\r\n    761     return UnionArray.simplified(\r\n    762         self._tags,\r\n    763         outindex,\r\n    764         outcontents,\r\n    765         parameters=self._parameters,\r\n    766     )\r\n    768 elif isinstance(head, str):\r\n--> 769     return self._getitem_next_field(head, tail, advanced)\r\n    771 elif isinstance(head, list):\r\n    772     return self._getitem_next_fields(head, tail, advanced)\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/content.py:301, in Content._getitem_next_field(self, head, tail, advanced)\r\n    299 def _getitem_next_field(self, head, tail, advanced: ak.index.Index | None):\r\n    300     nexthead, nexttail = ak._slicing.headtail(tail)\r\n--> 301     return self._getitem_field(head)._getitem_next(nexthead, nexttail, advanced)\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/unionarray.py:491, in UnionArray._getitem_field(self, where, only_fields)\r\n    487 def _getitem_field(self, where, only_fields=()):\r\n    488     return UnionArray.simplified(\r\n    489         self._tags,\r\n    490         self._index,\r\n--> 491         [x._getitem_field(where, only_fields) for x in self._contents],\r\n    492         parameters=None,\r\n    493     )\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/unionarray.py:491, in <listcomp>(.0)\r\n    487 def _getitem_field(self, where, only_fields=()):\r\n    488     return UnionArray.simplified(\r\n    489         self._tags,\r\n    490         self._index,\r\n--> 491         [x._getitem_field(where, only_fields) for x in self._contents],\r\n    492         parameters=None,\r\n    493     )\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/indexedoptionarray.py:253, in IndexedOptionArray._getitem_field(self, where, only_fields)\r\n    250 def _getitem_field(self, where, only_fields=()):\r\n    251     return IndexedOptionArray.simplified(\r\n    252         self._index,\r\n--> 253         self._content._getitem_field(where, only_fields),\r\n    254         parameters=None,\r\n    255     )\r\n\r\nFile ~/anaconda3/envs/anndata_dev/lib/python3.9/site-packages/awkward/contents/emptyarray.py:107, in EmptyArray._getitem_field(self, where, only_fields)\r\n    106 def _getitem_field(self, where, only_fields=()):\r\n--> 107     raise ak._errors.index_error(self, where, \"not an array of records\")\r\n\r\nIndexError: while attempting to slice\r\n\r\n    <Array [None, {a: 2}, {a: 3}] type='3 * union[?unknown, struct[{a: int6...'>\r\n\r\nwith\r\n\r\n    (:, 'a')\r\n\r\nat inner EmptyArray of length 0, using sub-slice 'a'.\r\n\r\nError details: not an array of records.\r\n```\r\n\r\n</details>\r\n\r\nThis is somewhat related to @ivirshup's observation in https://github.com/scikit-hep/awkward/issues/2182#issuecomment-1412318839 that concatenation may result in different types depending on the order of arguments. \r\n\r\nIf I get rid of the \r\n```python\r\nview = ak.with_parameter(view, \"__array__\", \"AwkwardArrayView\")\r\n```\r\nline, the types are consistent. \r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"This is all strongly related to the bug in #2173 \u2014 `EmptyArray` is not entirely behaving like an identity in contexts that we might want it to. For context, this is what `res1.type, res2.type` prints in my branch #2179:\r\n```python\r\n>>> print(res1.type, res2.type)\r\n3 * ?{a: int64} 3 * ?{a: int64}\r\n```\r\n\r\nI am currently working on this, and will keep you updated :)",
     "createdAt":"2023-02-02T14:51:13Z",
     "number":4852466,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I was about to turn this into an issue. (I'll still do that, and you can mark it as resolved by #2179.)\r\n\r\nHere's a somewhat more minimal reproducer for the issue (both would make good test cases):\r\n\r\n```python\r\n>>> ak.concatenate((ak.with_parameter([1], \"k\", \"v\"), [None])).layout\r\n<IndexedOptionArray len='2'>\r\n    <parameter name='k'>'v'</parameter>\r\n    <index><Index dtype='int64' len='2'>[ 0 -1]</Index></index>\r\n    <content><NumpyArray dtype='int64' len='1'>[1]</NumpyArray></content>\r\n</IndexedOptionArray>\r\n```\r\n\r\nbut\r\n\r\n```python\r\n>>> ak.concatenate(([None], ak.with_parameter([1], \"k\", \"v\"))).layout\r\n<IndexedOptionArray len='2'>\r\n    <index><Index dtype='int64' len='2'>[-1  0]</Index></index>\r\n    <content><NumpyArray dtype='int64' len='1'>\r\n        <parameter name='k'>'v'</parameter>\r\n        [1]\r\n    </NumpyArray></content>\r\n</IndexedOptionArray>\r\n```\r\n\r\nThe internal merge operation (which `ak.concatenate` invokes) should have a commutative property: `x.mergemany([y, z])` should return the same _type_ for any ordering of `x`, `y`, and `z`. (Of course the values will be in a different order.) It's difficult to ensure that because `x` is given a privileged place as `self`\u2014ensuring it means comparing all of the `mergemany` implementations with each other.\r\n\r\nAs @grst demonstrated, it is definitely related to parameters:\r\n\r\n```python\r\n>>> ak.concatenate(([1], [None])).layout\r\n<IndexedOptionArray len='2'>\r\n    <index><Index dtype='int64' len='2'>[ 0 -1]</Index></index>\r\n    <content><NumpyArray dtype='int64' len='1'>[1]</NumpyArray></content>\r\n</IndexedOptionArray>\r\n```\r\n\r\nand\r\n\r\n```python\r\n>>> ak.concatenate(([None], [1])).layout\r\n<IndexedOptionArray len='2'>\r\n    <index><Index dtype='int64' len='2'>[-1  0]</Index></index>\r\n    <content><NumpyArray dtype='int64' len='1'>[1]</NumpyArray></content>\r\n</IndexedOptionArray>\r\n```\r\n\r\nIt could be in the `mergemany` implementations, which @agoose77 is working on right now, but it's also possible that it's in the `UnionArray.simplified` implementation. That constructor needs to pick one of the `contents` to be the one that gets wrapped with option-type, and that choice breaks the symmetry among `contents`. (In examples like these, the `UnionArray.simplified` constructs a non-`UnionArray`, but I'm pretty sure that the `mergemany` code uses `UnionArray.simplified` to produce its final result.)",
        "createdAt":"2023-02-02T15:00:38Z",
        "number":4852557
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-02-02T13:27:44Z",
  "number":2191,
  "title":"merging parameters during concatenation",
  "url":"https://github.com/scikit-hep/awkward/discussions/2191"
 },
 {
  "author":{
   "login":"Durman"
  },
  "body":"It seems that shape of an array forces numba to recompile. In my case it makes arrays useless to use with numba.\r\nWithout using `newaxis` it works as expected. Is it a bug or limitation?\r\n\r\n```py\r\nimport numpy as np\r\nimport awkward as ak\r\nimport numba as nb\r\nfrom timeit import timeit\r\n\r\n\r\n@nb.njit\r\ndef test(arr):\r\n    return\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    a1 = ak.Array([1, 2])\r\n    a2 = ak.Array([1, 2, 3])\r\n    a3 = ak.Array([1, 2, 3, 4])\r\n\r\n    t = timeit(\"test(a1[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n    t = timeit(\"test(a1[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n    t = timeit(\"test(a2[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n    t = timeit(\"test(a2[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n    t = timeit(\"test(a3[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n    t = timeit(\"test(a3[np.newaxis])\", number=1, globals=globals())\r\n    print(f\"{t*1000:.2f} ms\")\r\n```\r\n\r\n```text\r\n156.01 ms\r\n0.34 ms\r\n35.95 ms\r\n0.34 ms\r\n36.53 ms\r\n0.36 ms\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Regular dimensions in Awkward (if your type has `... * N * ...`, you have a regular dimension) include the shape information in their `type`. I believe that Numba does this differently for native NumPy arrays; the shape metadata is runtime-only. We have discussed this here before, and the decision at the time was \"this is a compromise\": https://github.com/scikit-hep/awkward/issues/1343\r\n\r\nIn this case, your `np.newaxis` inserts a new regular axis at `axis=0, meaning that your innermost shape changes with the list length. If you make that extra dimension ragged, e.g. with `ak.from_regular(..., axis=...)`, then you will end up with an array whose Numba type (you can see this via `array.numba_type` ) does not change with its length.\r\n\r\nIn general, this should only matter if the regular sizes of your array are changing between compiles. Usually that doesn't make sense; it's often a user error, but if it is needed in this case, then `from_regular` might be of use.",
     "createdAt":"2023-02-03T11:22:20Z",
     "number":4861203,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Different systems take different opinions on whether array lengths and shapes are compile-time or runtime data, and that determines what kinds of changes imply recompilations.\r\n\r\n  * NumPy takes all shapes, even the number of dimensions, to be runtime.\r\n  * Numba takes the number of dimensions to be compile-time, but the length of each to be runtime.\r\n  * Awkward and JAX take the lengths of regular-length dimensions to be compile-time (but Awkward also has variable-length lists, so @agoose77's suggestion of using [ak.from_regular](https://awkward-array.org/doc/main/reference/generated/ak.from_regular.html) would work).\r\n\r\nBefore getting into the below, note that @agoose77's suggestion of using [ak.from_regular](https://awkward-array.org/doc/main/reference/generated/ak.from_regular.html) is probably the solution to your problem, unless you can arrange your workflow into a smaller number of bigger runs.\r\n\r\n------\r\n\r\nFrequent recompilation is a performance hit, as you've shown, but so are runtime lengths. Knowing a loop length at compile time allows the compiler to perform more optimizations. (We can use performance as a motivation in this case because you're using Numba; of course you want it to go faster.) Which performance hit matters more depends on how many Numba runs you do and how big each array that you pass to it are, since time-to-compile scales with the number of compilations and time-to-run-one-array scales with the size of the array.\r\n\r\nI wanted to see this first-hand, so I made an example in the [Godbolt explorer](https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:'1',fontScale:14,fontUsePx:'0',j:1,lang:c%2B%2B,selection:(endColumn:2,endLineNumber:11,positionColumn:2,positionLineNumber:11,selectionStartColumn:2,selectionStartLineNumber:11,startColumn:2,startLineNumber:11),source:'void+runtime_length(int*+data,+int+num_steps)+%7B%0A++++for+(int+i+%3D+0%3B++i+%3C+num_steps%3B++i%2B%2B)+%7B%0A++++++++data%5Bi%5D%2B%2B%3B%0A++++%7D%0A%7D%0A%0Avoid+compiletime_length(int*+data)+%7B%0A++++for+(int+i+%3D+0%3B++i+%3C+1000%3B++i%2B%2B)+%7B%0A++++++++data%5Bi%5D%2B%2B%3B%0A++++%7D%0A%7D'),l:'5',n:'0',o:'C%2B%2B+source+%231',t:'0')),k:50,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:g121,deviceViewOpen:'1',filters:(b:'0',binary:'1',binaryObject:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',libraryCode:'0',trim:'1'),flagsViewOpen:'1',fontScale:14,fontUsePx:'0',j:1,lang:c%2B%2B,libs:!(),options:'-O3',selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:'5',n:'0',o:'+x86-64+gcc+12.1+(Editor+%231)',t:'0')),k:50,l:'4',n:'0',o:'',s:0,t:'0')),l:'2',n:'0',o:'',t:'0')),version:4). Here's a short function that depends on a runtime length:\r\n\r\n```c++\r\nvoid runtime_length(int* data, int num_steps) {\r\n    for (int i = 0;  i < num_steps;  i++) {\r\n        data[i]++;\r\n    }\r\n}\r\n```\r\n\r\nIt compiles to this x86 assembly:\r\n\r\n```asm\r\n        test    esi, esi\r\n        jle     .L1\r\n        lea     eax, [rsi-1]\r\n        cmp     eax, 2\r\n        jbe     .L6\r\n        mov     edx, esi\r\n        movdqa  xmm1, XMMWORD PTR .LC0[rip]\r\n        mov     rax, rdi\r\n        shr     edx, 2\r\n        sal     rdx, 4\r\n        add     rdx, rdi\r\n.L4:\r\n        movdqu  xmm0, XMMWORD PTR [rax]\r\n        add     rax, 16\r\n        paddd   xmm0, xmm1\r\n        movups  XMMWORD PTR [rax-16], xmm0\r\n        cmp     rax, rdx\r\n        jne     .L4\r\n        mov     edx, esi\r\n        and     edx, -4\r\n        test    sil, 3\r\n        je      .L9\r\n.L3:\r\n        movsx   rax, edx\r\n        lea     ecx, [rdx+1]\r\n        sal     rax, 2\r\n        add     DWORD PTR [rdi+rax], 1\r\n        cmp     esi, ecx\r\n        jle     .L1\r\n        add     edx, 2\r\n        add     DWORD PTR [rdi+4+rax], 1\r\n        cmp     esi, edx\r\n        jle     .L1\r\n        add     DWORD PTR [rdi+8+rax], 1\r\n.L1:\r\n        ret\r\n.L9:\r\n        ret\r\n.L6:\r\n        xor     edx, edx\r\n        jmp     .L3\r\n```\r\n\r\nAnd here's the same function, but with a known `num_steps`:\r\n\r\n```c++\r\nvoid compiletime_length(int* data) {\r\n    for (int i = 0;  i < 1000;  i++) {\r\n        data[i]++;\r\n    }\r\n}\r\n```\r\n\r\nIts x86 assembly is:\r\n\r\n```asm\r\n        movdqa  xmm1, XMMWORD PTR .LC0[rip]\r\n        lea     rax, [rdi+4000]\r\n.L11:\r\n        movdqu  xmm0, XMMWORD PTR [rdi]\r\n        add     rdi, 16\r\n        paddd   xmm0, xmm1\r\n        movups  XMMWORD PTR [rdi-16], xmm0\r\n        cmp     rax, rdi\r\n        jne     .L11\r\n        ret\r\n.LC0:\r\n        .long   1\r\n        .long   1\r\n        .long   1\r\n        .long   1\r\n```\r\n\r\nIt doesn't have to do nearly as much bookkeeping to know if it has reached the end of its loops. (Empirically, it runs faster in microbenchmarks, too.)\r\n\r\nSo there's an advantage to having the ability to set compile-time lengths, and Awkward's regular-list type does have the list size as part of the type description. But if it's a disadvantage in your case because you have to frequently change that size and that triggers recompilations because it's a new type, you can use [ak.from_regular](https://awkward-array.org/doc/main/reference/generated/ak.from_regular.html) to say that it's a variable-length list type.",
        "createdAt":"2023-02-03T15:43:20Z",
        "number":4863396
       },
       {
        "author":{
         "login":"Durman"
        },
        "body":"Thanks. Now it's clear. I will try `from_regular` in my case.",
        "createdAt":"2023-02-06T05:43:46Z",
        "number":4878858
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-02-03T05:51:05Z",
  "number":2197,
  "title":"Array shape effects numba compilation",
  "url":"https://github.com/scikit-hep/awkward/discussions/2197"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"* feat: add ability to forget length of typetracer created with `typetracer_from_report` by @douglasdavis in https://github.com/scikit-hep/awkward/pull/2141\r\n* feat: start hardening nplike signatures by @agoose77 in https://github.com/scikit-hep/awkward/pull/2148\r\n* feat: implement all ufuncs on TypeTracer. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2149\r\n* feat: use `None` for unknown lengths (1 of 2) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2168\r\n* feat: coerce backends to same zero-copy type (2 of 2) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2175\r\n* feat: growable buffer move_to method by @ianna in https://github.com/scikit-hep/awkward/pull/2178\r\n* feat: add `ak.merge_union_of_records` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2185\r\n* feat: add support for histogram module by @agoose77 in https://github.com/scikit-hep/awkward/pull/2190\r\n* feat: add `ak.approx_equal` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2198\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: re-order cases to handle NumPy scalar types properly by @agoose77 in https://github.com/scikit-hep/awkward/pull/2125\r\n* fix: specify `dtype` for buffers in `from_rdataframe`. by @agoose77 in https://github.com/scikit-hep/awkward/pull/2145\r\n* fix: unify typestr with `_repr` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2158\r\n* fix: update `type_to_name` for Layout builder `cxx_14` target by @ianna in https://github.com/scikit-hep/awkward/pull/2165\r\n* fix: Layout builders clean and length bug fixes by @ianna in https://github.com/scikit-hep/awkward/pull/2171\r\n* fix: support `mask_identity=True` for `axis=None` in `ptp`, `std`, etc. by @agoose77 in https://github.com/scikit-hep/awkward/pull/2172\r\n* fix: preserve dimensions for `keepdims=True`, `axis=None` reductions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2177\r\n* fix: some usages of `len(layout)` under typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2181\r\n* fix: rdataframe memory check by @ianna in https://github.com/scikit-hep/awkward/pull/2155\r\n* fix: rework parameter merging rules by @agoose77 in https://github.com/scikit-hep/awkward/pull/2179\r\n* fix: don't raise `NotImplementedError` when reading empty array from Parquet by @dsavoiu in https://github.com/scikit-hep/awkward/pull/2194\r\n* fix: ignore object arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2206\r\n* fix: ak.values_astype now turns 'unknown' type into the requested type. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2196\r\n\r\n## Other\r\n\r\n* refactor: remove `to_arraylib` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2128\r\n* refactor: move `Singleton` to its own module by @agoose77 in https://github.com/scikit-hep/awkward/pull/2131\r\n* refactor: move kernel logic to _kernels by @agoose77 in https://github.com/scikit-hep/awkward/pull/2132\r\n* refactor: use `nplike.asarray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2134\r\n* refactor: remove dead code by @agoose77 in https://github.com/scikit-hep/awkward/pull/2139\r\n* refactor: make `nplike.zeros` et al. use Array API type signatures by @agoose77 in https://github.com/scikit-hep/awkward/pull/2137\r\n* refactor: move typetracer ufunc handling to backend [1 of 2] by @agoose77 in https://github.com/scikit-hep/awkward/pull/2150\r\n* refactor: split `_nplikes.py` into `_nplikes/*.py` [2 of 2] by @agoose77 in https://github.com/scikit-hep/awkward/pull/2152\r\n* refactor: drop `UnknownScalar`, harden unknown scalar behavior by @agoose77 in https://github.com/scikit-hep/awkward/pull/2154\r\n* docs: fix bold docstring due to indent by @agoose77 in https://github.com/scikit-hep/awkward/pull/2122\r\n* docs: disable IPyParallel & load dependencies in reverse order by @agoose77 in https://github.com/scikit-hep/awkward/pull/2126\r\n* docs: improve error message by @agoose77 in https://github.com/scikit-hep/awkward/pull/2201\r\n* docs: add dsavoiu as a contributor for code by @allcontributors in https://github.com/scikit-hep/awkward/pull/2204\r\n* ci: test NumPy < 1.17 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2142\r\n* ci: run header-only tests by @agoose77 in https://github.com/scikit-hep/awkward/pull/2169\r\n* chore: apply changes from flake8 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2130\r\n* chore: isolate nox dependencies in `noxfile` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2136\r\n* chore: drop unused nplike functions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2138\r\n* chore: add helpful message if cpp install is not prepared by @agoose77 in https://github.com/scikit-hep/awkward/pull/2146\r\n* chore: move to Ruff by @henryiii in https://github.com/scikit-hep/awkward/pull/2153\r\n* chore(deps): bump pypa/cibuildwheel from 2.11.4 to 2.12.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2133\r\n* chore: update Ruff version by @henryiii in https://github.com/scikit-hep/awkward/pull/2174\r\n* chore: ruff rewrite `not in` by @henryiii in https://github.com/scikit-hep/awkward/pull/2176\r\n* chore: ruff rewrite dicts by @henryiii in https://github.com/scikit-hep/awkward/pull/2183\r\n\r\n## New Contributors\r\n\r\n* @dsavoiu made their first contribution in https://github.com/scikit-hep/awkward/pull/2194\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.6...v2.0.7\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.7'>Version 2.0.7</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-02-04T01:18:04Z",
  "number":2208,
  "title":"Version 2.0.7",
  "url":"https://github.com/scikit-hep/awkward/discussions/2208"
 },
 {
  "author":{
   "login":"kreczko"
  },
  "body":"### Version of Awkward Array\n\n2.0.7\n\n### Description and code to reproduce\n\nI am trying to use `pandas.eval` (`pandas == 1.5.3`) with awkward arrays.\r\n\r\nThe minimal example for this is\r\n```python\r\nimport awkward as ak\r\nimport pandas as pd\r\nexpression = \"a + b\"\r\na = ak.Array([[1, 2, 3], [5, 6]])\r\nb = ak.Array([[2, 3, 4], [6, 7]])\r\nresult = pd.eval(expression, engine=\"numexpr\")\r\nprint(result)\r\n```\r\nThe error I am getting is:\r\n```\r\n<snip>\r\n  File \"/software/miniconda/envs/fast-iris/lib/python3.10/site-packages/pandas/core/computation/ops.py\", line 166, in is_datetime\r\n    return issubclass(t, (datetime, np.datetime64))\r\nTypeError: issubclass() arg 1 must be a class\r\n```\r\nPatching the pandas code reveals that the value `t` in [is_datetime](https://github.com/pandas-dev/pandas/blob/main/pandas/core/computation/ops.py#L161) is\r\n```\r\n<property object at 0x7f5399ec4860>\r\n```\r\n\r\n\r\nReplacing awkward arrays with numpy arrays works (`t = <class 'numpy.int64'>`).\r\n \r\nNot sure of the exact chain of events, but before I dig deeper, I thought I post this in case someone has an \"of course, it's that thing\" moment ;).\r\nIf you need me to drill deeper, please let me know what you need.\r\n\r\n\r\nPS: Same issue with awkward 1.X, so I guess nobody tried `pandas.eval` with awkward arrays so far.\r\n\r\nNote: The reason I am trying to use pandas.eval over numexpr or awkward.<forgot>.evaluate is the ease of using custom functions (with all its downsides).",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I suppose that `pd.eval` is running [numexpr.evaluate](https://numexpr.readthedocs.io/projects/NumExpr3/en/latest/api.html), which grabs variables by name from the surrounding environment, assumes that they are NumPy arrays, and performs the calculation, returning a NumPy array.\r\n\r\nAwkward v1 had an `ak.numexpr.evaluate`, which I wasn't very happy with because it's in the `ak.*` namespace instead of `numexpr.evaluate` just knowing what to do with Awkward Arrays. So although it has been updated and is hidden in the v2 code, it hasn't been exposed publicly yet.\r\n\r\nhttps://github.com/scikit-hep/awkward/blob/6b499600342dcb6123fbbfe366e213655001989e/src/awkward/_connect/numexpr.py#L69-L71\r\n\r\nBefore just making this public, I wanted to see if there's any way to register Awkward with NumExpr (like the way that it's registered with NumPy's ufuncs or Numba's JIT). I think that was something that was going to be added to NumExpr v3, but it doesn't look like NumExpr v3 is going to happen.\r\n\r\nNumExpr expressions would be great to turn into ufuncs, and then they could be used uniformly on any array type that extends NumPy (NEP-13, `__array_ufunc__`). Let me think about that...",
     "createdAt":"2023-02-14T17:09:37Z",
     "number":4974837,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"kreczko"
     },
     "body":"Hi Jim,\r\n\r\n> suppose that pd.eval is running [numexpr.evaluate](https://numexpr.readthedocs.io/projects/NumExpr3/en/latest/api.html), > which grabs variables by name from the surrounding environment, assumes that they are NumPy arrays, and performs the calculation, returning a NumPy array.\r\n\r\nYes, I think that's what it does (with probably slight variations for different engines).\r\n\r\n> has been updated and is hidden in the v2 code\r\n\r\nNot well enough, tried this one yesterday ;).\r\n\r\nThe main issue for me are custom functions, e.g.\r\n```python\r\ndef func2(a, b):\r\n    return a + b\r\n\r\nexpression = \"a + b + func2(a, b)\"\r\n```\r\nwhich works for pandas.eval but cannot be done with ak._connect.numexpr.evaluate nor numexpr.evaluate (although in most cases things like `func2` would point to ak functions).\r\n\r\nAnyway, not part of this issue ;).\r\n\r\n> Let me think about that...\r\n\r\nOf course :). Let me know if you need a hand or two. Beats writing a custom parser for these expressions.\r\n",
     "createdAt":"2023-02-14T17:28:51Z",
     "number":4974838,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> Not well enough, tried this one yesterday\r\n\r\nNo, I mean it's still hidden; you can't use it (without going through a module name that starts with an underscore).\r\n\r\nThe one thing we can't do is make this slick, to have `ne.evaluate` or `pd.eval` just pick up the Awkward Arrays and know what to do with them.\r\n\r\nI'm also assuming that this isn't what you're looking for:\r\n\r\n```python\r\n>>> a = ak.Array([[1, 2, 3], [5, 6]])\r\n>>> b = ak.Array([[2, 3, 4], [6, 7]])\r\n>>> eval(\"a + b\")\r\n<Array [[3, 5, 7], [11, 13]] type='2 * var * int64'>\r\n```\r\n\r\nIs it about wanting to do a single pass over the data? With something like the above (execution of the string in Python), `a + b + c` would first iterate (in precompiled code) over `a` and `b`, adding each, and then iterate over the sum and `c`, adding each. The reason for using NumExpr is to avoid all of the intermediate NumPy arrays and separate passes over the data (which uses CPU caches badly).\r\n\r\nIf you're okay with an interface like this,\r\n\r\n```python\r\n>>> evaluate(\"a + b\", a=a, b=b)\r\n<Array [[3, 5, 7], [11, 13]] type='2 * var * int64'>\r\n```\r\n\r\nit can be done like this:\r\n\r\n```python\r\ndef evaluate(expression, **namespace):\r\n    arrays = {}\r\n    not_arrays = {}\r\n    for k, v in namespace.items():\r\n        if isinstance(v, (ak.Array, np.array)):  # maybe also pd.Series...\r\n            arrays[k] = v\r\n        else:\r\n            not_arrays[k] = v\r\n\r\n    def action(layouts, **ignore):\r\n        if all(x.is_numpy for x in layouts):\r\n            ns = dict(not_arrays)\r\n            for name, value in zip(arrays.keys(), layouts):\r\n                ns[name] = value.data\r\n            return ak.contents.NumpyArray(ne.evaluate(expression, ns))\r\n\r\n    return ak.transform(action, *arrays.values())\r\n```\r\n\r\nThis is, in a sense, a reimplementation of `ak.numexpr.evaluate` using [ak.transform](https://awkward-array.org/doc/main/reference/generated/ak.transform.html). It applies all of the broadcasting rules to a set of arrays (`arrays.values()`) while recursing down until you get to the level of `ak.contents.NumpyArray`, which wrap plain NumPy arrays. Then the `action` function determines what to do with those flat arrays: in this case, it fills a namespace (`ns`), calls `ne.evaluate` (can be `pd.eval`) and wraps the result as a new `ak.contents.NumpyArray` that is part of the output.\r\n\r\nIf what you really want is to get the `pd.eval` function to work, then I don't see how to do that because we can't override Pandas.",
     "createdAt":"2023-02-14T18:15:35Z",
     "number":4974839,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"If the part that you really want is to pick up the variable names from the string, that is possible if it can be parsed. `ast.parse` would do it if the language (NumExpr) is a subset of the Python language, which I think it is.\r\n\r\n```python\r\n>>> print(ast.dump(ast.parse(\"a + b\"), indent=\"    \"))\r\nModule(\r\n    body=[\r\n        Expr(\r\n            value=BinOp(\r\n                left=Name(id='a', ctx=Load()),\r\n                op=Add(),\r\n                right=Name(id='b', ctx=Load())))],\r\n    type_ignores=[])\r\n```\r\n\r\nOne could then write a `Visitor` to walk over that AST and find the `Name` objects that are not in the `function` part of a `Call` (because you want non-arrays, like `func2`, to not be interpreted as arrays).",
     "createdAt":"2023-02-14T18:18:56Z",
     "number":4974840,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"kreczko"
     },
     "body":"Thanks a lot Jim!\r\n\r\n> without going through a module name that starts with an underscore\r\n\r\nWhich is fine for single underscores:\r\n```python\r\nresult = ak._connect.numexpr.evaluate(expression)\r\n```\r\n&rarr; works (for expressions without functions)\r\n\r\n> Is it about wanting to do a single pass over the data? \r\n\r\nYes. Although I care at the moment more about completeness than efficiency.\r\n\r\nRegarding your suggestions, indeed, these are the paths I tried over the weekend - and then I remembered `pandas.eval` ;)\r\n\r\nAnyway, you are right, a custom implementation would be best as I wanted to extract a compute graph in its final form.\r\nForgot about `ast.parse` was trying out `ply` instead :D.\r\n\r\nFor `ast` it does indeed give me something very useful for `print(ast.dump(ast.parse(\"a + b + func2(a, b)\"), indent=\"  \"))`:\r\n```\r\nModule(\r\n  body=[\r\n    Expr(\r\n      value=BinOp(\r\n        left=BinOp(\r\n          left=Name(id='a', ctx=Load()),\r\n          op=Add(),\r\n          right=Name(id='b', ctx=Load())),\r\n        op=Add(),\r\n        right=Call(\r\n          func=Name(id='func2', ctx=Load()),\r\n          args=[\r\n            Name(id='a', ctx=Load()),\r\n            Name(id='b', ctx=Load())],\r\n          keywords=[])))],\r\n  type_ignores=[])\r\n```\r\nI can use this information to create a compute graph or extract & evaluate the functions to make the expression compatible with numexpr.\r\n\r\nThanks for the pointers!",
     "createdAt":"2023-02-14T19:10:14Z",
     "number":4974841,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":5
  },
  "createdAt":"2023-02-14T16:59:18Z",
  "number":2238,
  "title":"Computing expressions like `numexpr.evaluate` or `pandas.eval`",
  "url":"https://github.com/scikit-hep/awkward/discussions/2238"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: allow awkward type arrays filtering based on rdfentry by @ianna in https://github.com/scikit-hep/awkward/pull/2202\r\n* feat!: re-introduce `unknown-length` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2229\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: keep `EmptyArray` in `remove_structure` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2219\r\n* fix: add `is_c_contiguous` method to Cupy by @ianna in https://github.com/scikit-hep/awkward/pull/2221\r\n* fix: boolean indexing with non-zero starting offsets by @agoose77 in https://github.com/scikit-hep/awkward/pull/2216\r\n* fix: add license to _backends by @ianna in https://github.com/scikit-hep/awkward/pull/2224\r\n* fix: use of size in `to_RegularArray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2226\r\n* fix: indexing into `RegularArray` with typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2227\r\n* fix: support length-zero outer arrays in almost_equal by @agoose77 in https://github.com/scikit-hep/awkward/pull/2210\r\n* fix: support options in `ak.merge_union_of_records` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2236\r\n* fix: don't merge non-union parameters by @agoose77 in https://github.com/scikit-hep/awkward/pull/2241\r\n* fix: boolean slicing with non-packed arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2246\r\n\r\n## Other\r\n\r\n* refactor: add type hints for `Content._getitem_XXX` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2223\r\n* refactor: drop `NumpyLike.known_shape` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2228\r\n* refactor: change `Content._getitem_range` to use explicit indices by @agoose77 in https://github.com/scikit-hep/awkward/pull/2220\r\n* docs: fix example for `merge_union_of_records` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2213\r\n* docs: add 1.10 legacy docs to `switcher.json` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2217\r\n* docs: reintroduce Content documentation from v1 reST files. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2231\r\n* docs: add `how-to-examine-type.md` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2013\r\n* docs: improve ragged indexing docs by @agoose77 in https://github.com/scikit-hep/awkward/pull/2247\r\n* chore: include cuda kernel tests in sdist by @agoose77 in https://github.com/scikit-hep/awkward/pull/2218\r\n* chore(deps): bump amannn/action-semantic-pull-request from 5.0.2 to 5.1.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2232\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2215\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.7...v2.0.8\r\n\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.8'>Version 2.0.8</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-02-16T17:10:38Z",
  "number":2249,
  "title":"Version 2.0.8",
  "url":"https://github.com/scikit-hep/awkward/discussions/2249"
 },
 {
  "author":{
   "login":"DanRidh"
  },
  "body":"I'm currently trying to write an element-wise product (Hadamard product) function but am facing issues when the input fed is of a weird nested format. It works fine when lets say the input is;\r\n```\r\ninput_1: [1,2,3]\r\ninput_2: [4,5,6]\r\noutput: [4,10,18]\r\n```\r\n\r\nHowever, when there is nesting within a specific index i'm not sure how to get the expected output (flatenning and casting seem to be throwing errors, though this is probably due to a lack of deeper understanding on my end)\r\n\r\neg:\r\n```\r\ninput_1: [[1], [2,[3]]]\r\ninput_2: [[4], [5,[6]]]\r\nexpected_output: [[4], [10,[18]]]\r\n```\r\n\r\nAny guidance would be really helpful!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"If I multiple the arrays as you give them, the element-wise operation just works:\r\n```python\r\n>>> x = ak.Array([[1], [2,[3]]])\r\n\r\n>>> y = ak.Array( [[4], [5,[6]]])\r\n\r\n>>> x * y\r\n<Array [[4], [10, [18]]] type='2 * var * union[int64, var * int64]'>\r\n```\r\n\r\nIs this not what you observe?",
     "createdAt":"2023-03-01T16:45:49Z",
     "number":5168851,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"DanRidh"
        },
        "body":"@agoose77 thanks for such a quick response! When I try running the same as you posted it doesn't seem to create that expected output. It specifically throws an error `TypeError: concatenate() got an unexpected keyword argument 'casting'` for some reason",
        "createdAt":"2023-03-01T16:52:09Z",
        "number":5168934
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Could you clarify the version of Awkward Array that you're running?\r\n```python\r\n>>> import awkward as ak\r\n>>> ak.__version__\r\n```",
        "createdAt":"2023-03-01T16:53:11Z",
        "number":5168945
       },
       {
        "author":{
         "login":"DanRidh"
        },
        "body":"@agoose77 sure thing, I'm currently using version `2.0.8`",
        "createdAt":"2023-03-01T16:54:12Z",
        "number":5168959
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Did you copy the program directly, and run it in a new session? I can't reproduce this on my end.",
        "createdAt":"2023-03-01T16:55:37Z",
        "number":5168977
       },
       {
        "author":{
         "login":"DanRidh"
        },
        "body":"@agoose77 I just installed awkward through pip, opened a kernel on jupyter-notebook and imported awkward. Could it maybe be due to python version? I'm currently using `v3.8.12`",
        "createdAt":"2023-03-01T17:02:58Z",
        "number":5169040
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Could you share the traceback? And, perhaps also the notebook? ",
        "createdAt":"2023-03-01T17:09:57Z",
        "number":5169104
       }
      ],
      "totalCount":6
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-03-01T16:42:28Z",
  "number":2278,
  "title":"-",
  "url":"https://github.com/scikit-hep/awkward/discussions/2278"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: keep column order after filtering flag by @ianna in https://github.com/scikit-hep/awkward/pull/2234\r\n* feat: Awkward Arrays in Numba's CUDA target by @ianna in https://github.com/scikit-hep/awkward/pull/1809\r\n* feat: add 'highlevel' and 'behavior' arguments to 'ak.from_rdataframe' function by @ianna in https://github.com/scikit-hep/awkward/pull/2258\r\n* feat: add `ak.broadcast_fields` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2267\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: set dtype in `full_like` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2251\r\n* fix: use `simplified` in `ak._do.merge_as_union` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2240\r\n* fix: support unknown content length in `to_packed` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2263\r\n* fix: run-lengths with typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2259\r\n* fix: add trivial `nan_to_num` impl to typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2266\r\n* fix: keep column order in all tests by @ianna in https://github.com/scikit-hep/awkward/pull/2276\r\n\r\n## Other\r\n\r\n* test: numba cuda tests by @ianna in https://github.com/scikit-hep/awkward/pull/2264\r\n* docs: add missing entries to toctree by @agoose77 in https://github.com/scikit-hep/awkward/pull/2270\r\n* docs: fix build for latest theme by @agoose77 in https://github.com/scikit-hep/awkward/pull/2274\r\n* docs: RDataFrame add multi-threaded example by @ianna in https://github.com/scikit-hep/awkward/pull/2269\r\n* docs: add Numba CUDA guide (#2260)Co-authored-by: Angus Hollands <goosey15@gmail.com> Co-authored-by: Jim Pivarski <jpivarski@users.noreply.github.com> Co-authored-by: Jim Pivarski <jpivarski@gmail.com> by @ianna in https://github.com/scikit-hep/awkward/pull/2260\r\n* chore: use scikit-build-core 0.2's build-dir by @henryiii in https://github.com/scikit-hep/awkward/pull/2252\r\n* chore: more Ruff by @henryiii in https://github.com/scikit-hep/awkward/pull/2184\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2255\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2272\r\n* chore: Ruff updates from dev guidelines (#2268)Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com> Co-authored-by: Jim Pivarski <jpivarski@users.noreply.github.com> by @henryiii in https://github.com/scikit-hep/awkward/pull/2268\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.8...v2.0.9\r\n\r\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.9'>Version 2.0.9</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-03-03T19:03:36Z",
  "number":2281,
  "title":"Version 2.0.9",
  "url":"https://github.com/scikit-hep/awkward/discussions/2281"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: make `header-only` libraries a CMake project by @agoose77 in https://github.com/scikit-hep/awkward/pull/2280\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: apply subset of fixes for downstream dask usage by @agoose77 in https://github.com/scikit-hep/awkward/pull/2283\r\n\r\n## Other\r\n\r\n* docs: fix URI to header-only LayoutBuilder examples by @agoose77 in https://github.com/scikit-hep/awkward/pull/2279\r\n* chore: update pre-commit hooks (#2286)Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com> by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2286\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.9...v2.0.10\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.0.10'>Version 2.0.10</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-03-07T16:36:15Z",
  "number":2289,
  "title":"Version 2.0.10",
  "url":"https://github.com/scikit-hep/awkward/discussions/2289"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n_(none!)_\r\n\r\n## Bug-fixes and performance\r\n\r\n_(none!)_\r\n\r\n## Other\r\n\r\n* chore: bump NumPy version by @agoose77 in https://github.com/scikit-hep/awkward/pull/2282\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.0.10...v2.1.0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.1.0'>Version 2.1.0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-03-07T22:30:59Z",
  "number":2292,
  "title":"Version 2.1.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2292"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"This is a bug-fix release, motivated by PR #2311, which fixes a memory leak investigated in issues #1127, #1280, #2275, and #2310 (500 days from first sighting).\r\n\r\n## New features\r\n\r\n_(none!)_\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: DECREFing PyObject*s from Python C API calls in v1. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2311\r\n\r\n## Other\r\n\r\n_(none!)_\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v1.10.2...v1.10.3\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v1.10.3'>Version 1.10.3</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-03-13T21:59:53Z",
  "number":2312,
  "title":"Version 1.10.3",
  "url":"https://github.com/scikit-hep/awkward/discussions/2312"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: add support for arrays in `from_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2319\r\n* feat: validate `axis` in L1 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2285\r\n* feat: add examples to header-only module by @agoose77 in https://github.com/scikit-hep/awkward/pull/2288\r\n\r\n## Bug-fixes and performance\r\n* fix: support typetracer in `ak.unflatten` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2293\r\n* fix: view for unknown scalar by @agoose77 in https://github.com/scikit-hep/awkward/pull/2294\r\n* fix: common backend in functions accepting multiple arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2297\r\n* fix: support unknown scalars in `__getitem__` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2314\r\n* fix: fail early if index is too dimensional by @agoose77 in https://github.com/scikit-hep/awkward/pull/2304\r\n* fix: uneccessary use of `nplike_of` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2315\r\n* fix: jupyterlite dependency changes by @agoose77 in https://github.com/scikit-hep/awkward/pull/2318\r\n\r\n## Other\r\n* refactor: rename util functions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2316\r\n* docs: update version switcher (#2299)Co-authored-by: Jim Pivarski <jpivarski@users.noreply.github.com> by @agoose77 in https://github.com/scikit-hep/awkward/pull/2299\r\n* docs: add Gitter badge by @agoose77 in https://github.com/scikit-hep/awkward/pull/2298\r\n* docs: add deployment notes to contributing guide by @agoose77 in https://github.com/scikit-hep/awkward/pull/2300\r\n* chore(deps): bump aws-actions/configure-aws-credentials from 1 to 2 by @dependabot in https://github.com/scikit-hep/awkward/pull/2290\r\n* chore(deps): bump amannn/action-semantic-pull-request from 5.1.0 to 5.2.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2321\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.6.4 to 1.7.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2308\r\n* chore(deps): bump pypa/cibuildwheel from 2.12.0 to 2.12.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2309\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.7.1 to 1.8.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2322\r\n* ci: fix parsing of docs version by @agoose77 in https://github.com/scikit-hep/awkward/pull/2301\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.0...v2.1.1\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.1.1'>Version 2.1.1</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-03-18T10:12:11Z",
  "number":2323,
  "title":"Version 2.1.1",
  "url":"https://github.com/scikit-hep/awkward/discussions/2323"
 },
 {
  "author":{
   "login":"cmoore24-24"
  },
  "body":"Hello! \r\nI have created a function that uses awkward arrays to calculate an energy correlation function:\r\n```\r\ndef e23(fatjetscands, pfcands, fatjets):\r\n    jets_pt = ak.unflatten(ak.flatten(pfcands.pt[fatjetscands.pFCandsIdx]),ak.flatten(fatjets.nConstituents))\r\n    sums = ak.sum(jets_pt, axis=1)\r\n    z = (jets_pt/sums)\r\n\r\n    eta = ak.unflatten(ak.flatten(pfcands.eta[fatjetscands.pFCandsIdx]),ak.flatten(fatjets.nConstituents))\r\n\r\n    phi = ak.unflatten(ak.flatten(pfcands.phi[fatjetscands.pFCandsIdx]),ak.flatten(fatjets.nConstituents))\r\n\r\n    z_comb = ak.combinations(z, 3, axis=1)\r\n    z_ijk = z_comb['0']*z_comb['1']*z_comb['2']\r\n\r\n    eta_comb = ak.combinations(eta, 3, axis=1)\r\n    phi_comb = ak.combinations(phi, 3, axis=1)\r\n\r\n    coords = ak.zip({'phi': phi_comb, 'eta': eta_comb})\r\n\r\n    a = distance(coords, '0', '1')\r\n    b = distance(coords, '0', '2')\r\n    c = distance(coords, '1', '2')\r\n\r\n    ij_ik = a*b\r\n    ij_jk = a*c\r\n    ik_jk = b*c\r\n    \r\n    del_comb = ak.flatten(ak.zip({'ijik': ij_ik, 'ijjk': ij_jk, 'ikjk': ik_jk}))\r\n    temp_numpy = np.vstack((del_comb.ijik.to_numpy(),\r\n        del_comb.ijjk.to_numpy(), \r\n        del_comb.ikjk.to_numpy())).T\r\n    delta_r = ak.unflatten(np.amin(temp_numpy,axis=1), ak.count(z_ijk,axis=1))\r\n\r\n    e23_jetwise = ak.sum(np.multiply(z_ijk, delta_r), axis=1)\r\n    e23_eventwise = ak.unflatten(e23_jetwise, ak.count(fatjets.nConstituents, axis=1))\r\n    return e23_eventwise\r\n```\r\nbut because of the size of some of these arrays I run into memory problems pretty quickly. I assumed my only option was to rewrite in numba, but it was suggested to me that I might be able to use dask to keep my code array-oriented rather than loopy. Is there currently an easy way to incorporate dask into awkward centric code, like mine above?\r\n\r\nAny advice is greatly appreciated!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Rewriting in numba will likely give you the benefit of fewer allocations; Awkward Array natively requires a new array to be allocated for each operation (we do have non-public support for numexpr, but this can only help for ufunc operations at the moment).\n\nIf you are just worried about total memory usage, you can delete the intermediate arrays once you're finished with them. This should lead to a reduction in total usage. Note that tracking and reporting memory usage can be a bit complex, so don't be surprised if you don't necessarily see what you're expecting.\n\nDask *can* help here because it can do the lifetime tracking itself (I.e delete arrays once they're no longer needed). It also can optimise the case where you are reading more columns from your data source than are actually needed, although this can also be done by hand.\n\n",
     "createdAt":"2023-03-28T15:44:13Z",
     "number":5455876,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"cmoore24-24"
        },
        "body":"I didn't realize I could manually delete the arrays I didn't need anymore mid-calculation. I'll give that a shot, I think it'll help a lot! But it does sound like numba might still be the way to go, or at least worth checking. Thank you!",
        "createdAt":"2023-03-28T19:09:27Z",
        "number":5457804
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This is a good question. The fact that you're doing 3-way combinations of collections with \"jet\" in their name (there are often a large number of jets per event) is suggestive that this is going to use a lot of memory. \"$n$ choose 3\" can be a big number when $n$ is large.\r\n\r\n---------------------------------\r\n\r\nThe simplest thing you can do is ignore the memory use and have Dask break it into smaller chunks. That is, run `e23` more times on smaller array slices of `fatjetscands`, `pfcands`, and `fatjets`.\r\n\r\nFurther down in this response, I noticed that `pFCandsIdx` is probably a global index, and so if you slice `pfcands` into smaller arrays, the `pFCandsIdx` would have to be adjusted for the new starting index. If I'm interpreting that right, it makes this method messier: if you pass in\r\n\r\n```python\r\npfcands[start:stop]\r\n```\r\n\r\nas an argument to this function, you'd have to subtract\r\n\r\n```python\r\nfatjetscands.pFCandsIdx - start\r\n```\r\n\r\nin the slice of `pfcands.eta` and `pfcands.phi`. That's unpleasant, but it's due to the way that `pFCandsIdx` was defined (relative to the start of a _flattened_ `pfcands`, instead of indexed within each event).\r\n\r\n---------------------------------\r\n\r\nIf you want to go memory-hunting, the easiest way to find the biggest problem spot is to get `fatjetscands`, `pfcands`, and `fatjets` into an interactive environment, either Jupyter or a Python terminal prompt, do one line at a time, and watch your memory use with [htop](https://htop.dev/) in another window (or similar). [Pympler](https://pympler.readthedocs.io/en/latest/)'s SummaryTracker is also a great way to do line-by-line memory use, and it differs from the \"outside looking in\" approach of htop by giving you a table of all of the Python objects that are using memory. It's probably the case that `ak.combinations(some_big_collection, 3, axis=1)` makes one very large NumPy array.\r\n\r\n---------------------------------\r\n\r\nIt might help to know that you can run `ak.combinations` on zipped records, so\r\n\r\n```python\r\n>>> jets = ak.Array([\r\n...     [\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...     ],\r\n...     [\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...     ],\r\n...     [\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...         {\"pt\": 1, \"eta\": 2, \"phi\": 3},\r\n...     ]\r\n... ])\r\n>>> combo_jets = ak.combinations(jets, 3)\r\n>>> combo_jets.show(type=True)\r\ntype: 3 * var * (\r\n    {\r\n        pt: int64,\r\n        eta: int64,\r\n        phi: int64\r\n    },\r\n    {\r\n        pt: int64,\r\n        eta: int64,\r\n        phi: int64\r\n    },\r\n    {\r\n        pt: int64,\r\n        eta: int64,\r\n        phi: int64\r\n    }\r\n)\r\n[[({pt: 1, eta: 2, phi: 3}, {pt: 1, ...}, {...}), ..., ({...}, {...}, ...)],\r\n [],\r\n [({pt: 1, eta: 2, phi: 3}, {pt: 1, ...}, {...}), ..., ({...}, {...}, ...)]]\r\n```\r\n\r\ninstead of doing each jagged numeric field separately:\r\n\r\n```python\r\n>>> ak.combinations(jets.pt, 3).show(type=True)\r\ntype: 3 * var * (\r\n    int64,\r\n    int64,\r\n    int64\r\n)\r\n[[(1, 1, 1), (1, 1, 1), (1, 1, 1), (1, 1, 1)],\r\n [],\r\n [(1, 1, 1), (1, 1, 1), (1, 1, 1), (...), ..., (1, 1, 1), (1, 1, 1), (1, 1, 1)]]\r\n>>> ak.combinations(jets.eta, 3).show(type=True)\r\ntype: 3 * var * (\r\n    int64,\r\n    int64,\r\n    int64\r\n)\r\n[[(2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)],\r\n [],\r\n [(2, 2, 2), (2, 2, 2), (2, 2, 2), (...), ..., (2, 2, 2), (2, 2, 2), (2, 2, 2)]]\r\n>>> ak.combinations(jets.phi, 3).show(type=True)\r\ntype: 3 * var * (\r\n    int64,\r\n    int64,\r\n    int64\r\n)\r\n[[(3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)],\r\n [],\r\n [(3, 3, 3), (3, 3, 3), (3, 3, 3), (...), ..., (3, 3, 3), (3, 3, 3), (3, 3, 3)]]\r\n```\r\n\r\nMaybe you did each field separately because you thought it would use less memory. If so, it's worth knowing that the opposite is likely to be true, for two reasons: (a) all the fields in a record share the same `offsets` buffer, instead of each having their own, and (b) as an implementation detail, we don't duplicate records in `ak.combinations` the way we do numeric fields. Instead, we use an [IndexedArray](https://awkward-array.org/doc/main/reference/generated/ak.contents.IndexedArray.html) to \"lazily duplicate\" them.\r\n\r\nYou can see this implementation detail by looking at `combo_jets.layout`:\r\n\r\n```xml\r\n<ListOffsetArray len='3'>\r\n    <offsets><Index dtype='int64' len='4'>[ 0  4  4 14]</Index></offsets>\r\n    <content><RecordArray is_tuple='true' len='14'>\r\n        <content index='0'>\r\n            <IndexedArray len='14'>\r\n                <index><Index dtype='int64' len='14'>\r\n                    [0 0 0 1 5 5 5 5 5 5 6 6 6 7]\r\n                </Index></index>\r\n                <content><RecordArray is_tuple='false' len='10'>\r\n                    <content index='0' field='pt'>\r\n                        <NumpyArray dtype='int64' len='10'>[1 1 1 1 1 1 1 1 1 1]</NumpyArray>\r\n                    </content>\r\n                    <content index='1' field='eta'>\r\n                        <NumpyArray dtype='int64' len='10'>[2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n                    </content>\r\n                    <content index='2' field='phi'>\r\n                        <NumpyArray dtype='int64' len='10'>[3 3 3 3 3 3 3 3 3 3]</NumpyArray>\r\n                    </content>\r\n                </RecordArray></content>\r\n            </IndexedArray>\r\n        </content>\r\n        <content index='1'>\r\n            <IndexedArray len='14'>\r\n                <index><Index dtype='int64' len='14'>\r\n                    [1 1 2 2 6 6 6 7 7 8 7 7 8 8]\r\n                </Index></index>\r\n                <content><RecordArray is_tuple='false' len='10'>\r\n                    <content index='0' field='pt'>\r\n                        <NumpyArray dtype='int64' len='10'>[1 1 1 1 1 1 1 1 1 1]</NumpyArray>\r\n                    </content>\r\n                    <content index='1' field='eta'>\r\n                        <NumpyArray dtype='int64' len='10'>[2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n                    </content>\r\n                    <content index='2' field='phi'>\r\n                        <NumpyArray dtype='int64' len='10'>[3 3 3 3 3 3 3 3 3 3]</NumpyArray>\r\n                    </content>\r\n                </RecordArray></content>\r\n            </IndexedArray>\r\n        </content>\r\n        <content index='2'>\r\n            <IndexedArray len='14'>\r\n                <index><Index dtype='int64' len='14'>\r\n                    [2 3 3 3 7 8 9 8 9 9 8 9 9 9]\r\n                </Index></index>\r\n                <content><RecordArray is_tuple='false' len='10'>\r\n                    <content index='0' field='pt'>\r\n                        <NumpyArray dtype='int64' len='10'>[1 1 1 1 1 1 1 1 1 1]</NumpyArray>\r\n                    </content>\r\n                    <content index='1' field='eta'>\r\n                        <NumpyArray dtype='int64' len='10'>[2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n                    </content>\r\n                    <content index='2' field='phi'>\r\n                        <NumpyArray dtype='int64' len='10'>[3 3 3 3 3 3 3 3 3 3]</NumpyArray>\r\n                    </content>\r\n                </RecordArray></content>\r\n            </IndexedArray>\r\n        </content>\r\n    </RecordArray></content>\r\n</ListOffsetArray>\r\n```\r\n\r\nThe outer RecordArray is the 3-tuple of combinations fields `\"0\"`, `\"1\"`, and `\"2\"`, inside each is an IndexedArray with a different index, indicating how the same set of input records is lazily duplicated:\r\n\r\n```python\r\n>>> combo_jets.layout.content.content(\"0\").index\r\n<Index dtype='int64' len='14'>\r\n    [0 0 0 1 5 5 5 5 5 5 6 6 6 7]\r\n</Index>\r\n>>> combo_jets.layout.content.content(\"1\").index\r\n<Index dtype='int64' len='14'>\r\n    [1 1 2 2 6 6 6 7 7 8 7 7 8 8]\r\n</Index>\r\n>>> combo_jets.layout.content.content(\"2\").index\r\n<Index dtype='int64' len='14'>\r\n    [2 3 3 3 7 8 9 8 9 9 8 9 9 9]\r\n</Index>\r\n```\r\n\r\nand inside of that is the input RecordArray (not a copy).\r\n\r\n```python\r\n>>> record_in_0 = combo_jets.layout.content.content(\"0\").content\r\n>>> record_in_1 = combo_jets.layout.content.content(\"1\").content\r\n>>> record_in_2 = combo_jets.layout.content.content(\"2\").content\r\n>>> record_in_0 is record_in_1\r\nTrue\r\n>>> record_in_0 is record_in_2\r\nTrue\r\n>>> record_in_1 is record_in_2\r\nTrue\r\n```\r\n\r\nIn other words, this was all designed to minimize memory usage if you naively call `ak.combinations` on a big record without worrying about how many fields there are, and you might have made it use more memory by trying to be careful.\r\n\r\nCalling `ak.combinations` on numeric data makes copies:\r\n\r\n```python\r\n>>> combo_numeric = ak.combinations(jets.eta, 3)\r\n>>> combo_numeric.layout\r\n<ListOffsetArray len='3'>\r\n    <offsets><Index dtype='int64' len='4'>[ 0  4  4 14]</Index></offsets>\r\n    <content><RecordArray is_tuple='true' len='14'>\r\n        <content index='0'>\r\n            <NumpyArray dtype='int64' len='14'>[2 2 2 2 2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n        </content>\r\n        <content index='1'>\r\n            <NumpyArray dtype='int64' len='14'>[2 2 2 2 2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n        </content>\r\n        <content index='2'>\r\n            <NumpyArray dtype='int64' len='14'>[2 2 2 2 2 2 2 2 2 2 2 2 2 2]</NumpyArray>\r\n        </content>\r\n    </RecordArray></content>\r\n</ListOffsetArray>\r\n>>> combo_numeric.layout.content.content(\"0\").data\r\narray([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\r\n>>> nparray_in_0 = combo_numeric.layout.content.content(\"0\").data\r\n>>> nparray_in_1 = combo_numeric.layout.content.content(\"1\").data\r\n>>> nparray_in_2 = combo_numeric.layout.content.content(\"2\").data\r\n>>> np.shares_memory(nparray_in_0, nparray_in_1)\r\nFalse\r\n>>> np.shares_memory(nparray_in_0, nparray_in_2)\r\nFalse\r\n>>> np.shares_memory(nparray_in_1, nparray_in_2)\r\nFalse\r\n```\r\n\r\nIt is a trade-off: the IndexedArray saves us from rearranging/duplicating its `content` up-front, at a cost of having to do it on every access. The optimization heuristic that we use is: if it's a RecordArray, we don't know if the user is going to be interested in every field, so we introduce the IndexedArray; if it's not a RecordArray, the user can only be interested in all of its contents, so we don't introduce the IndexedArray.\r\n\r\nYou are interested in three fields, the `pt`/sum, the `eta`, and the `phi`, so you can't get away with not generating them, but if the `ak.combinations` is called on the RecordArray, at least the outer ListOffsetArray `offsets` are shared, and by generating them one at a time, maybe you can `del` the previous one before moving on to the next.\r\n\r\n---------------------------------\r\n\r\nYou do a lot of flattening and unflattening, and I don't know why. You have to flatten and unflatten if an in-between step is `np.vstack`, but you can do the same thing with [ak.concatenate](https://awkward-array.org/doc/main/reference/generated/ak.concatenate.html) (with appropriately chosen `axis`) and not have to flatten/unflatten.\r\n\r\nSince the [ListOffsetArray](https://awkward-array.org/doc/main/reference/generated/ak.contents.ListOffsetArray.html) has an `offsets` buffer, which is a cumulative sum, and [ak.unflatten](https://awkward-array.org/doc/main/reference/generated/ak.unflatten.html) takes `counts`, which is the thing that gets cumulatively summed, each round trip creates a new `offsets` when you could have continually reused the old `offsets` by not going through the round trip. (If you need to flatten and unflatten with `offsets`, rather than `counts`, you'd have to build the low-level ListOffsetArray manually.)\r\n\r\nOh, wait\u2014I think I get it\u2014the `pFCandsIdx` is a global index, so you need to flatten to get values in that index, right?\r\n\r\nIn that case, I guess you have to flatten it, but if you go a low-level route, manipulating ListOffsetArray directly instead of using the high-level `ak.unflatten` function, you'll have more opportunities to reuse `offsets`. Keep an eye out for the distinction between [ListOffsetArray](https://awkward-array.org/doc/main/reference/generated/ak.contents.ListOffsetArray.html) and [ListArray](https://awkward-array.org/doc/main/reference/generated/ak.contents.ListArray.html), which the high-level view hides.\r\n\r\n---------------------------------\r\n\r\nAnd then there's also Numba. Someone once asked me a similar question, but they were doing 5-way combinations, and the intermediate arrays with $n$ choose 5 items in each event were huge. In that case, not creating intermediate combinations-arrays was the only way to proceed. (It's a reminder that what we really want is [a language that understands combinatorics](https://indico.cern.ch/event/820598/#2-pattern-matching-for-decay-t) and can make intermediate arrays or not based on the situation.)",
     "createdAt":"2023-03-28T15:57:39Z",
     "number":5456050,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"cmoore24-24"
        },
        "body":"Thank you for your reply, Jim! \r\n\r\nYou were right on about why I did all the convoluted flattening and unflattening- Flattening Idx, and then regrouping my arrays so the elements were jets rather than events, was the best way I was able to come up with to apply pFCandsIdx to the overall candidates list (further tempered by nCandidates). It definitely seems like I can improve on this in some way, based on your comment. \r\n\r\nI'll definitely try zipping my pt, eta, and phi before calling combinations and see how that affects my memory usage. Thank you for the combo_jets example, that was very helpful!",
        "createdAt":"2023-03-28T19:09:35Z",
        "number":5457806
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-03-27T20:15:44Z",
  "number":2341,
  "title":"Is there a way to use dask to help reduce memory usage?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2341"
 },
 {
  "author":{
   "login":"matthewfeickert"
  },
  "body":"This is not a discussion about asking if Awkward has any plans to switch to using [`nanobind`][nanobind-docs] over [`pybind11`][pybind11-docs] &mdash; that's a separate discussion that I don't want to force on the team now. This is a question that is based out of my own ignorance of how things work on if the Awkward team thinks there should be any reason that [`nanobind`][nanobind-docs] couldn't support Awkward in the same way that is supports other n-dimensional arrays through the [`nanobind::ndarray` API][nanobind-ndarray-api-reference].\r\n\r\nWith the release of `nanobind` `v1.0.x`, the [\"The `nb::ndarray<..>` class\" docs][nanobind-ndarray-docs] [mention](https://github.com/wjakob/nanobind/blob/445781fc2cf2fa326cc22e8fd483e8e4a7bf6cf5/docs/ndarray.rst?plain=1#L8-L30)\r\n\r\n> nanobind can exchange n-dimensional arrays (henceforth \u201cndarrays\u201d) with popular array programming frameworks including [NumPy](https://numpy.org/), [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), and [JAX](https://jax.readthedocs.io/). It supports zero-copy exchange using two protocols:\r\n>\r\n> The classic [buffer protocol](https://docs.python.org/3/c-api/buffer.html).\r\n>\r\n> * The classic [buffer protocol](https://docs.python.org/3/c-api/buffer.html).\r\n> * [DLPack](https://github.com/dmlc/dlpack), a GPU-compatible generalization of the buffer protocol.\r\n>\r\n> To use this feature, you must add the include directive\r\n>\r\n> ```c++\r\n> #include <nanobind/ndarray.h>\r\n> ```\r\n>\r\n> to your code. Following this, you can bind functions with [nb::ndarray<...>](https://nanobind.readthedocs.io/en/latest/api_extra.html#_CPPv4IDpEN8nanobind7ndarrayE)-typed parameters and return values.\r\n\r\nwhich seems to be in contrast with the [`pybind11` docs on integration with NumPy arrays][pybind11-numpy-docs] that only discuss NumPy.\r\n\r\nWhile this is really a question that needs to be put to the `nanobind` team, does the Awkward team see any technical reason why the list of n-dimensional arrays that `nanobind` can exchange with in a zero-copy way couldn't also in the future include Awkward?\r\n\r\n\r\n[pybind11-docs]: https://pybind11.readthedocs.io/\r\n[pybind11-numpy-docs]: https://pybind11.readthedocs.io/en/stable/advanced/pycpp/numpy.html#arrays\r\n[nanobind-docs]: https://nanobind.readthedocs.io/\r\n[nanobind-ndarray-docs]: https://nanobind.readthedocs.io/en/latest/ndarray.html\r\n[nanobind-ndarray-api-reference]: https://nanobind.readthedocs.io/en/latest/api_extra.html#n-dimensional-array-type\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"@matthewfeickert would you be able to elaborate upon what you'd like to be able to do here?\r\n\r\nWith Awkward 2, nearly all of Awkward Array is implemented in Python. We have some performance logic (C++ kernels, `ArrayBuilder`, `LayoutBuilder`) written in fast compiled code, but most of what makes Awkward \"tick\" is interpreted.\r\n\r\nAs such, I'm not sure what a nanobind interface would look like, or offer to the user. For regular arrays, it would be possible to convert their layouts to e.g. `nb::ndarray`, but this would potentially fail at runtime if the layout is not regular. I don't know if that's a huge amount more convenient than either requiring a NumPy array as the argument (e.g. `my_func(ak.to_numpy(x))`) or invoking Awkward from C++ (https://nanobind.readthedocs.io/en/latest/api_core.html#python-object-api).\r\n\r\nWe could add support for DLPack (which is a todo item) that would succeed only for regular arrays. That's an agenda item that I've not spoken much to @jpivarski about yet :)",
     "createdAt":"2023-04-03T11:33:51Z",
     "number":5508897,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"matthewfeickert"
        },
        "body":"> With Awkward 2, nearly all of Awkward Array is implemented in Python. We have some performance logic (C++ kernels, `ArrayBuilder`, `LayoutBuilder`) written in fast compiled code, but most of what makes Awkward \"tick\" is interpreted.\r\n\r\nYeah, I think this is the critical point of why my original idea fundamentally doesn't make sense. That as well as @jpivarski's follow up point\r\n\r\n> I agree with @agoose77 in not seeing any benefit to having a special interface to nanobind's `nb.ndarray` class because Awkward Arrays are not \"ndarrays\". To get them in that form, one would have to call (explicitly or implicitly) `ak.to_numpy` or `ak.to_cupy`, and then nanobind already knows what to do with a NumPy or CuPy array.\r\n\r\nSo this answers the question. :+1: ",
        "createdAt":"2023-04-03T13:23:34Z",
        "number":5510048
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I've been thinking, and have mentioned a few times, that Awkward could possibly replace its pybind11 bindings with nanobind bindings, only because we don't use very much of pybind11's features and can perhaps simplify things, get smaller binaries, and maybe have faster start-up times and call overhead. A few features still use the C++ interface, such as ArrayBuilder, JSON I/O, and AwkwardForth. The kernel functions, which are a much larger fraction of Awkward's functionality, are called through ctypes, not pybind11, and it's unclear to me whether there would be an advantage to generating and compiling nanobind interfaces for all of them, too.\r\n\r\nBut that's an entirely internal change, and not high on any priority list. It wouldn't be seen from the outside.\r\n\r\nI agree with @agoose77 in not seeing any benefit to having a special interface to nanobind's `nb.ndarray` class because Awkward Arrays are not \"ndarrays\". To get them in that form, one would have to call (explicitly or implicitly) `ak.to_numpy` or `ak.to_cupy`, and then nanobind already knows what to do with a NumPy or CuPy array.\r\n\r\n(By the way, we used to use DLPack to deal with CUDA array buffers in Awkward v1\u2014as an internal implementation\u2014but we don't have to anymore because we let CuPy deal with the interface between Python and C++, in analogy with NumPy and C. Presumably, CuPy uses DLPack.)\r\n\r\nBasically, we now live one layer higher in abstraction. We don't have C or C++ interfaces, but the libraries we use do. And if you want to get nested structure/jagged arrays between languages, that's what Arrow is for, and that's why we have a lightweight `ak.to_arrow` function.",
     "createdAt":"2023-04-03T13:17:33Z",
     "number":5509989,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"matthewfeickert"
        },
        "body":"> But that's an entirely internal change, and not high on any priority list. It wouldn't be seen from the outside.\r\n\r\nYeah, agreed. That's part of what I meant by \r\n\r\n> that's a separate discussion that I don't want to force on the team now.\r\n.\r\n\r\n> (By the way, we used to use DLPack to deal with CUDA array buffers in Awkward v1\u2014as an internal implementation\u2014but we don't have to anymore because we let CuPy deal with the interface between Python and C++, in analogy with NumPy and C. Presumably, CuPy uses DLPack.)\r\n\r\n:rocket: That's slick and great. :) \r\n\r\n> Basically, we now live one layer higher in abstraction. We don't have C or C++ interfaces, but the libraries we use do. And if you want to get nested structure/jagged arrays between languages, that's what Arrow is for, and that's why we have a lightweight `ak.to_arrow` function.\r\n\r\nThis is a really nice summary in just two sentences. It along with @agoose77's point sums up what I was forgetting last night in terms of how the scope of the `awkward-cpp` kernels. :+1: ",
        "createdAt":"2023-04-03T13:29:13Z",
        "number":5510124
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-04-03T04:04:52Z",
  "number":2350,
  "title":"Possible for nanobind to support Awkward arrays?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2350"
 },
 {
  "author":{
   "login":"ianna"
  },
  "body":"![https://user-images.githubusercontent.com/1390682/230147717-453f1912-7587-4f37-a333-6f1d49cbdb76.jpeg](https://github.com/scikit-hep/awkward/files/11161042/30A48871-9569-4BD9-AD77-B1A2CF23CECA.pdf)\r\n![https://user-images.githubusercontent.com/1390682/230148000-6456a325-3a10-432a-9a12-2d8b3b40a13a.jpeg](https://github.com/scikit-hep/awkward/files/11161191/E8F925AA-0DF0-4724-8663-C0347925E8B0.pdf)\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"ianna"
     },
     "body":"@jpivarski - as discussed, here are the plots. ",
     "createdAt":"2023-04-05T16:51:01Z",
     "number":5534822,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The PDFs will be useful for talks, but for looking up this page, it will help to have large PNGs.\r\n\r\n<img src=\"https://user-images.githubusercontent.com/1852447/230164867-88a7f6c5-aa92-4293-9028-326a035d4b88.png\" width=\"100%\">\r\n\r\n<img src=\"https://user-images.githubusercontent.com/1852447/230164964-9bded2b3-7288-4a0c-a695-cc74e1637d40.png\" width=\"100%\">\r\n\r\nWords to include here so that we can find them later: GrowableBuffer panel panels std::vector like exponential memory growth versus linear speed time seconds performance allocation memcpy malloc calloc",
     "createdAt":"2023-04-05T18:03:55Z",
     "number":5535484,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-04-05T16:48:34Z",
  "number":2362,
  "title":"Growable Buffer: baseline performance tests",
  "url":"https://github.com/scikit-hep/awkward/discussions/2362"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n\r\n* feat: use cppyy for JIT by @ianna in https://github.com/scikit-hep/awkward/pull/2306\r\n* feat!: rename cpptype by @agoose77 in https://github.com/scikit-hep/awkward/pull/2331\r\n* feat: implemented GrowableBuffer in Numba as a start toward LayoutBuilder by @jpivarski in https://github.com/scikit-hep/awkward/pull/2349\r\n* feat: add `to_backend` to `ak.record.Record` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2355\r\n* feat: add type equality `is_equal_to` member by @agoose77 in https://github.com/scikit-hep/awkward/pull/2368\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: expose array interface for CUDA by @agoose77 in https://github.com/scikit-hep/awkward/pull/2327\r\n* fix: test untested path in `ak.cartesian` & broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2329\r\n* fix: `ak.cartesian` for typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2295\r\n* fix: Numba string reference count memory leak. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2332\r\n* fix: generate an array view when an Array C++ type is requested by @ianna in https://github.com/scikit-hep/awkward/pull/2335\r\n* fix: do not expose an `rdfentry_` column by @ianna in https://github.com/scikit-hep/awkward/pull/2343\r\n* fix: generate RDataSource API based on ROOT attribute by @ianna in https://github.com/scikit-hep/awkward/pull/2345\r\n* fix: simplify depth limit test to support bigger-than-depth values by @agoose77 in https://github.com/scikit-hep/awkward/pull/2347\r\n* fix: use cppyy include by @ianna in https://github.com/scikit-hep/awkward/pull/2348\r\n* fix: convert ufunc arguments to same backend by @agoose77 in https://github.com/scikit-hep/awkward/pull/2354\r\n* fix: support N-d sequences in `TypeTracer.asarray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2361\r\n* fix: make `from_iter` require iterables! by @agoose77 in https://github.com/scikit-hep/awkward/pull/2353\r\n* fix: avoid stack overflow with std::unique_ptr linked list by @ianna in https://github.com/scikit-hep/awkward/pull/2366\r\n* fix: `ak.unzip` visits all contents by @agoose77 in https://github.com/scikit-hep/awkward/pull/2373\r\n* fix: remove spurious typetracer conversion by @agoose77 in https://github.com/scikit-hep/awkward/pull/2375\r\n\r\n## Other\r\n\r\n* refactor: hide `awkward.typing` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2324\r\n* refactor: move `_parameters_XXX` functions into `_parameters` submodule by @agoose77 in https://github.com/scikit-hep/awkward/pull/2325\r\n* refactor: move `merge_as_union` to `ak_concatenate` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2351\r\n* refactor: improve broadcasting logic readability by @agoose77 in https://github.com/scikit-hep/awkward/pull/2359\r\n* refactor: wrap exceptions at catch time by @agoose77 in https://github.com/scikit-hep/awkward/pull/2370\r\n* docs: fix pyodide (again!) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2326\r\n* docs: add import statement by @raybellwaves in https://github.com/scikit-hep/awkward/pull/2358\r\n* docs: update mybinder link to example notebook by @raybellwaves in https://github.com/scikit-hep/awkward/pull/2357\r\n* docs: fix extra for pyodide by @agoose77 in https://github.com/scikit-hep/awkward/pull/2360\r\n* docs: add raybellwaves as a contributor for doc by @allcontributors in https://github.com/scikit-hep/awkward/pull/2379\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2313\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2328\r\n\r\n## New Contributors\r\n* @raybellwaves made their first contribution in https://github.com/scikit-hep/awkward/pull/2358\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.1...v2.1.2\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/'>v2.1.2</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-04-08T20:46:13Z",
  "number":2380,
  "title":"Version 2.1.2",
  "url":"https://github.com/scikit-hep/awkward/discussions/2380"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n\r\n* feat: use cppyy for JIT by @ianna in https://github.com/scikit-hep/awkward/pull/2306\r\n* feat!: rename cpptype by @agoose77 in https://github.com/scikit-hep/awkward/pull/2331\r\n* feat: implemented GrowableBuffer in Numba as a start toward LayoutBuilder by @jpivarski in https://github.com/scikit-hep/awkward/pull/2349\r\n* feat: add `to_backend` to `ak.record.Record` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2355\r\n* feat: add type equality `is_equal_to` member by @agoose77 in https://github.com/scikit-hep/awkward/pull/2368\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: expose array interface for CUDA by @agoose77 in https://github.com/scikit-hep/awkward/pull/2327\r\n* fix: test untested path in `ak.cartesian` & broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2329\r\n* fix: `ak.cartesian` for typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2295\r\n* fix: Numba string reference count memory leak. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2332\r\n* fix: generate an array view when an Array C++ type is requested by @ianna in https://github.com/scikit-hep/awkward/pull/2335\r\n* fix: do not expose an `rdfentry_` column by @ianna in https://github.com/scikit-hep/awkward/pull/2343\r\n* fix: generate RDataSource API based on ROOT attribute by @ianna in https://github.com/scikit-hep/awkward/pull/2345\r\n* fix: simplify depth limit test to support bigger-than-depth values by @agoose77 in https://github.com/scikit-hep/awkward/pull/2347\r\n* fix: use cppyy include by @ianna in https://github.com/scikit-hep/awkward/pull/2348\r\n* fix: convert ufunc arguments to same backend by @agoose77 in https://github.com/scikit-hep/awkward/pull/2354\r\n* fix: support N-d sequences in `TypeTracer.asarray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2361\r\n* fix: make `from_iter` require iterables! by @agoose77 in https://github.com/scikit-hep/awkward/pull/2353\r\n* fix: avoid stack overflow with std::unique_ptr linked list by @ianna in https://github.com/scikit-hep/awkward/pull/2366\r\n* fix: `ak.unzip` visits all contents by @agoose77 in https://github.com/scikit-hep/awkward/pull/2373\r\n* fix: remove spurious typetracer conversion by @agoose77 in https://github.com/scikit-hep/awkward/pull/2375\r\n\r\n## Other\r\n\r\n* refactor: hide `awkward.typing` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2324\r\n* refactor: move `_parameters_XXX` functions into `_parameters` submodule by @agoose77 in https://github.com/scikit-hep/awkward/pull/2325\r\n* refactor: move `merge_as_union` to `ak_concatenate` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2351\r\n* refactor: improve broadcasting logic readability by @agoose77 in https://github.com/scikit-hep/awkward/pull/2359\r\n* refactor: wrap exceptions at catch time by @agoose77 in https://github.com/scikit-hep/awkward/pull/2370\r\n* docs: fix pyodide (again!) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2326\r\n* docs: add import statement by @raybellwaves in https://github.com/scikit-hep/awkward/pull/2358\r\n* docs: update mybinder link to example notebook by @raybellwaves in https://github.com/scikit-hep/awkward/pull/2357\r\n* docs: fix extra for pyodide by @agoose77 in https://github.com/scikit-hep/awkward/pull/2360\r\n* docs: add raybellwaves as a contributor for doc by @allcontributors in https://github.com/scikit-hep/awkward/pull/2379\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2313\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2328\r\n\r\n## New Contributors\r\n* @raybellwaves made their first contribution in https://github.com/scikit-hep/awkward/pull/2358\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.1...v2.1.2\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.1.2'>v2.1.2</a>.</em>",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Hi @agoose77,\r\n\r\nTwo small corrections:\r\n\r\n  1. This release needed to be named \"Version 2.1.2\", not \"v2.1.2\" (that's the git tag name). [It did deploy successfully](https://pypi.org/project/awkward/), which I didn't think would happen, but maybe that only depends on the git tag name, not the release name. I fixed the title, both in the release and the discussion, so there's no action item.\r\n  2. It's missing `header-only.zip`. I don't know how it lost that\u2014maybe it depends on release name? I didn't fix this (I don't know how), so it should probably be done manually. Is it usually done manually? If so, it has to become automatic so that it's not forgotten...",
     "createdAt":"2023-04-12T15:42:32Z",
     "number":5594380,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Thanks! I did rename the release, I wonder what happened. I did, however, forget the headers. We need to extend our CI for this. ",
        "createdAt":"2023-04-12T16:11:50Z",
        "number":5594727
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-04-08T20:46:26Z",
  "number":2381,
  "title":"Version 2.1.2",
  "url":"https://github.com/scikit-hep/awkward/discussions/2381"
 },
 {
  "author":{
   "login":"grst"
  },
  "body":"I have an awkward array ragged lists of records like this: \r\n```python\r\narr = ak.Array([\r\n    [{\"locus\": \"TRA\", \"junction_aa\": \"CADASGT...\"}, {\"locus\": \"TRB\", \"junction_aa\": \"CTFDD...\"}],\r\n    [{\"locus\": \"IGH\", \"junction_aa\": \"CDGFFA...\"}],\r\n    [],\r\n    [{\"locus\": \"IGH\", \"junction_aa\": \"CDGFFA...\"}],\r\n    ...\r\n])\r\n```\r\n\r\nI want to apply a function to each of the Records, and I'm currently doing this naively in a double for-loop: \r\n\r\n```python\r\nfor row in arr:\r\n    for record in row: \r\n       f(record)\r\n```\r\n\r\nwhich is not exactly fast. In fact, it is even faster to do a\r\n\r\n```python\r\nfor row in ak.to_list(arr):\r\n    for record in row: \r\n       f(record)\r\n```\r\n\r\nIs there a better way of doing this?\r\n\r\n(I guess the answer is \"it depends\" and there might be specific solutions using `ak.xxx` function -- but for the sake of the question let's assume it's not covered by the builtins and needs to be a custom python function instead) \r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"You are right: imperative iteration over Awkward Arrays is considerably slower than iteration over Python builtin types, which is itself considerably slower than a vectorized computation. (\"Considerably slower\" means orders of magnitude, somewhere between 10\u00d7 and 1000\u00d7.)\r\n\r\nWe have specialized, streamlined paths for simple `ak.Array.__iter__` to make iteration as fast as possible, but it's a function-call stack several deep, terminating on `Content._getitem_at`, and that can't compete with the short path that Python builtins take to [PyIter_Next](https://docs.python.org/3/c-api/iter.html#c.PyIter_Next) and [PyList_GetItem](https://docs.python.org/3/c-api/list.html#c.PyList_GetItem).\r\n\r\n**BEGIN details:**\r\n\r\n`ak.Array.__iter__` has a specialized path for NumpyArray ([here](https://github.com/scikit-hep/awkward/blob/83df6e50563c1f2162c968117ee872510e374f6b/src/awkward/highlevel.py#L491-L502)), in the hope that `np.ndarray.__iter__` is a fast implementation, but for any non-trivial type, it goes to `Content.__iter__` ([here](https://github.com/scikit-hep/awkward/blob/83df6e50563c1f2162c968117ee872510e374f6b/src/awkward/highlevel.py#L504)). `Content.__iter__` calls `Content._getitem_at` for each integer index ([here](https://github.com/scikit-hep/awkward/blob/83df6e50563c1f2162c968117ee872510e374f6b/src/awkward/contents/content.py#L325-L326)), and thus it skips a lot of type-checking and regularization that would happen for a generic `Content.__getitem__` call, since we already know that the argument is an integer. Then each `Content` subclass has its own `_getitem_at` implementation, which generally passes down to the next level until we get to a `NumpyArray` (such as `ListOffsetArray._getitem_at`, [here](https://github.com/scikit-hep/awkward/blob/83df6e50563c1f2162c968117ee872510e374f6b/src/awkward/contents/listoffsetarray.py#L307-L308)).\r\n\r\nOne thing that you noticed, that\r\n\r\n```python\r\nfor row in ak.to_list(arr):\r\n    for record in row: \r\n       f(record)\r\n```\r\n\r\nis faster than it would be without the `ak.to_list`, is only true thanks to the fact that `ak.to_list` is not itself implemented by an iteration. Without any overriding behaviors (`Content._to_list_custom`, [here](https://github.com/scikit-hep/awkward/blob/83df6e50563c1f2162c968117ee872510e374f6b/src/awkward/contents/content.py#L1168-L1170)), `to_list` builds the lists in a semi-vectorized way. First, it descends to the `NumpyArray`, calls `np.ndarray.tolist`, then when it pops back up the recursion, it subdivides the elements of that list into new lists. It's effectively using knowledge that we want _all_ of the data to get it in a faster way than could be had by iteration.\r\n\r\n**END details.**\r\n\r\nAs for what you can do about it\u2014assuming that this process can't be addressed with an array-oriented function\u2014is to use [Numba](https://numba.pydata.org/). This comes with caveats about Numba's [supported Python features](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html) and Numba's [supported NumPy features](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html), but any Awkward Array without union-types can be iterated over in Numba-compiled functions, which run at the speed of C. (That is, considerably faster than the Python loop over builtin types.)\r\n\r\nFor example,\r\n\r\n```python\r\n>>> import awkward as ak\r\n>>> import numba as nb\r\n>>> @nb.njit\r\n... def do_something(array):\r\n...     for row in arr:\r\n...         for record in row:\r\n...             print(record[\"locus\"])\r\n... \r\n>>> arr = ak.Array([\r\n...     [{\"locus\": \"TRA\", \"junction_aa\": \"CADASGT...\"}, {\"locus\": \"TRB\", \"junction_aa\": \"CTFDD...\"}],\r\n...     [{\"locus\": \"IGH\", \"junction_aa\": \"CDGFFA...\"}],\r\n...     [],\r\n...     [{\"locus\": \"IGH\", \"junction_aa\": \"CDGFFA...\"}],\r\n... ])\r\n>>> do_something(arr)\r\nTRA\r\nTRB\r\nIGH\r\nIGH\r\n```\r\n\r\nThe iteration over Awkward Arrays is read-only, but you can construct (1) NumPy arrays for output naively, thanks to implementations in Numba itself, (2) use [ak.ArrayBuilder](https://awkward-array.org/doc/main/reference/generated/ak.ArrayBuilder.html) in Numba (see [this tutorial](https://awkward-array.org/doc/main/user-guide/how-to-create-arraybuilder.html#use-in-numba), or [this one (video)](https://youtu.be/X_BJrmofRWQ)), and (3) @ianna is working on implementing `LayoutBuilder` in Numba, which will be faster because the type is known upfront.",
     "createdAt":"2023-04-12T15:01:20Z",
     "number":5593858,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-04-12T13:40:06Z",
  "number":2392,
  "title":"iterations over awkward arrays",
  "url":"https://github.com/scikit-hep/awkward/discussions/2392"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n_(none!)_\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: support empty records in `ak.with_field` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2387\r\n* fix: only format exception for primary context by @agoose77 in https://github.com/scikit-hep/awkward/pull/2388\r\n* fix: only touch data in `nplike.asarray` if copy is required by @agoose77 in https://github.com/scikit-hep/awkward/pull/2395\r\n* fix: update `GrowableBuffer::move_to` algorithm by @ianna in https://github.com/scikit-hep/awkward/pull/2394\r\n* fix: don't touch for `ascontiguousarray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2397\r\n\r\n## Other\r\n\r\n* refactor: implement `nplike` registry (1 of 2) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2389\r\n* refactor: implement `Backend` registry (2 of 2) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2390\r\n* refactor: use existing `unset` sentinel by @agoose77 in https://github.com/scikit-hep/awkward/pull/2391\r\n* ci: add workflow to ensure C++ is released by @agoose77 in https://github.com/scikit-hep/awkward/pull/2398\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.1 to 1.8.5 by @dependabot in https://github.com/scikit-hep/awkward/pull/2356\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2342\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.2...v2.1.3\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.1.3'>Version 2.1.3</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-04-13T17:38:55Z",
  "number":2401,
  "title":"Version 2.1.3",
  "url":"https://github.com/scikit-hep/awkward/discussions/2401"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat!: raise error for out-of-bounds axis in `ak.cartesian` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2411\r\n* feat: make `ak.numba.GrowableBuffer` visible  by @ianna in https://github.com/scikit-hep/awkward/pull/2403\r\n\r\n## Bug-fixes and performance\r\n* fix: unify C++ and Python `GrowableBuffer::extend` algorithm by @ianna in https://github.com/scikit-hep/awkward/pull/2396\r\n* fix: return empty list if broadcasting no arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2407\r\n* fix: only convert NEP18 arguments to layouts if required by @agoose77 in https://github.com/scikit-hep/awkward/pull/2409\r\n* fix: partially fix string broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2410\r\n* fix: correctly convert unknown scalar from kernel to a length by @agoose77 in https://github.com/scikit-hep/awkward/pull/2417\r\n* fix: support unknown lengths when broadcasting unions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2418\r\n* fix: consistently set a `resize` default value to 8 - that is passed to GrowableBuffer by @ianna in https://github.com/scikit-hep/awkward/pull/2421\r\n* fix: `is_equal_to` bug in `UnionArray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2426\r\n* fix: handle reordered contents in `ak.almost_equal` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2424\r\n* fix: typetracer `nplike.repeat` & `ak.with_field` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2429\r\n\r\n## Other\r\n* ci: attach header-only artifact to release by @agoose77 in https://github.com/scikit-hep/awkward/pull/2406\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2423\r\n* chore(deps): bump pypa/cibuildwheel from 2.12.1 to 2.12.3 by @dependabot in https://github.com/scikit-hep/awkward/pull/2415\r\n* refactor: add custom axis error by @agoose77 in https://github.com/scikit-hep/awkward/pull/2412\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.3...v2.1.4\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.1.4'>Version 2.1.4</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-04-25T22:43:52Z",
  "number":2430,
  "title":"Version 2.1.4",
  "url":"https://github.com/scikit-hep/awkward/discussions/2430"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: canonicalise `union[?X, Y]` into `union[?X, ?Y]` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2427\r\n* feat: add `ak.forms.from_type` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2425\r\n* feat: add `ak.enforce_type` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2365\r\n* feat!: deprecate `length_zero_array` highlevel argument by @agoose77 in https://github.com/scikit-hep/awkward/pull/2437\r\n\r\n## Bug-fixes and performance\r\n* fix: avoid reference cycles with the error-handling machinery by @agoose77 in https://github.com/scikit-hep/awkward/pull/2442\r\n* fix: proper unknown size broadcasting for all-regular by @agoose77 in https://github.com/scikit-hep/awkward/pull/2444\r\n\r\n## Other\r\n* ci: publish to PyPI with OIDC by @agoose77 in https://github.com/scikit-hep/awkward/pull/2450\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.5 to 1.8.6 by @dependabot in https://github.com/scikit-hep/awkward/pull/2445\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2446\r\n* chore: prepare 2.2.0 release by @agoose77 in https://github.com/scikit-hep/awkward/pull/2451\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2443\r\n* docs: add `broadcast_fields` to toctree by @agoose77 in https://github.com/scikit-hep/awkward/pull/2436\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.1.4...v2.2.0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.2.0'>Version 2.2.0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-05-10T08:00:53Z",
  "number":2452,
  "title":"Version 2.2.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2452"
 },
 {
  "author":{
   "login":"tomeichlersmith"
  },
  "body":"Let's say I have a ragged array of strings.[^1] I want to flatten this array to numpy so I can fill a histogram of the values.[^2] The specific example is below, but the TLDR is that I get an error when attempting to convert an `ak.Array` of strings to a `np.array` of strings when awkward is trying to regularize the array. This error reads (to me) like awkward array is mistreating the strings as arrays themselves, but I cannot reproduce this error with a smaller example.\r\n\r\nThis same error occurs when trying `ak.to_regular` which I suppose makes sense since NumPy would need a regular array.\r\n\r\n**Is this a bug with awkward array? Or (more likely) is this a bug with how I'm using it?** Perhaps theres a workaround where I tell awkward what kind of type to use in the NumPy array? I couldn't find such a parameter in the docs, but I could've missed that easily.\r\n\r\n[^1]:  In my specific case, I am looking at the names of Geant4 volumes from which sim particles originated, but that is not important.\r\n\r\n[^2]: To be very specific, I first ran into this issue trying to `fill` a `Hist.hist` object with these strings.\r\n\r\nIn anycase, I have this set of strings\r\n```\r\n[['PCB_volume', 'PCB_volume', 'PCB_volume', ..., 'PCB_volume', 'PCB_volume'],\r\n ['W_front_volume_0', 'W_front_volume_0', ..., 'W_front_volume_0'],\r\n ['PCB_volume', 'PCB_volume', 'PCB_volume', ..., 'PCB_volume', 'PCB_volume'],\r\n ['W_front_volume_0', 'W_front_volume_0', ..., 'W_front_volume_0'],\r\n ['W_cooling_volume_1', 'W_cooling_volume_1', ..., 'W_cooling_volume_1'],\r\n ['W_cooling_volume_0', 'W_cooling_volume_0', ..., 'W_cooling_volume_0'],\r\n ['W_cooling_volume_0', 'W_cooling_volume_0', ..., 'W_cooling_volume_0'],\r\n ['W_cooling_volume_0', ..., 'nohole_motherboard6_assembly'],\r\n ['W_front_volume_2', 'W_front_volume_2', ..., 'W_front_volume_6'],\r\n ['PCB_volume', 'PCB_volume', ..., 'W_cooling_volume_2', 'W_cooling_volume_2'],\r\n ...,\r\n ['W_cooling_volume_0', 'W_cooling_volume_0', ..., 'W_cooling_volume_0'],\r\n ['PCB_volume', 'PCB_volume', 'PCB_volume', ..., 'PCB_volume', 'PCB_volume'],\r\n ['W_front_volume_1', 'W_front_volume_1', ..., 'W_cooling_volume_4'],\r\n ['PCB_volume', 'PCB_volume', 'PCB_volume', ..., 'PCB_volume', 'PCB_volume'],\r\n ['PCB_volume', 'PCB_volume', 'PCB_volume', ..., 'Glue_volume', 'Glue_volume'],\r\n ['W_front_volume_0', 'W_front_volume_0', ..., 'W_cooling_volume_1'],\r\n ['W_front_volume_2', 'W_front_volume_2', ..., 'W_front_volume_2'],\r\n ['W_front_volume_4', 'W_front_volume_4', ..., 'W_front_volume_4'],\r\n ['W_cooling_volume_0', 'W_cooling_volume_0', ..., 'W_cooling_volume_1']]\r\n-------------------------------------------------------------------------------\r\ntype: 15491 * var * string\r\n```\r\nAnd I can `ak.flatten` it easily\r\n```\r\n['PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n 'PCB_volume',\r\n ...,\r\n 'W_cooling_volume_0',\r\n 'W_cooling_volume_0',\r\n 'W_cooling_volume_0',\r\n 'W_cooling_volume_1',\r\n 'W_cooling_volume_1',\r\n 'W_cooling_volume_1',\r\n 'W_cooling_volume_1',\r\n 'W_cooling_volume_1',\r\n 'W_cooling_volume_1']\r\n----------------------\r\ntype: 334460 * string\r\n```\r\nBut I cannot convert `ak.to_numpy` (I get the same error using `ak.to_numpy(ak.flatten(<>))` and just `ak.to_numpy` alone).\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[115], line 1\r\n----> 1 ak.to_numpy(ak.flatten(strings))\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/operations/ak_to_numpy.py:42, in to_numpy(array, allow_missing)\r\n      8 \"\"\"\r\n      9 Args:\r\n     10     array: Array-like data (anything #ak.to_layout recognizes).\r\n   (...)\r\n     36 See also #ak.from_numpy and #ak.to_cupy.\r\n     37 \"\"\"\r\n     38 with ak._errors.OperationErrorContext(\r\n     39     \"ak.to_numpy\",\r\n     40     {\"array\": array, \"allow_missing\": allow_missing},\r\n     41 ):\r\n---> 42     return _impl(array, allow_missing)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/operations/ak_to_numpy.py:54, in _impl(array, allow_missing)\r\n     51 backend = ak._backends.NumpyBackend.instance()\r\n     52 numpy_layout = layout.to_backend(backend)\r\n---> 54 return numpy_layout.to_backend_array(allow_missing=allow_missing)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/contents/content.py:1124, in Content.to_backend_array(self, allow_missing, backend)\r\n   1122 else:\r\n   1123     backend = ak._backends.regularize_backend(backend)\r\n-> 1124 return self._to_backend_array(allow_missing, backend)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/contents/listarray.py:1451, in ListArray._to_backend_array(self, allow_missing, backend)\r\n   1450 def _to_backend_array(self, allow_missing, backend):\r\n-> 1451     return self.to_RegularArray()._to_backend_array(allow_missing, backend)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/contents/listarray.py:308, in ListArray.to_RegularArray(self)\r\n    306 def to_RegularArray(self):\r\n    307     offsets = self._compact_offsets64(True)\r\n--> 308     return self._broadcast_tooffsets64(offsets).to_RegularArray()\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/contents/listoffsetarray.py:282, in ListOffsetArray.to_RegularArray(self)\r\n    277 _size = ak.index.Index64.empty(1, self._backend.index_nplike)\r\n    278 assert (\r\n    279     _size.nplike is self._backend.index_nplike\r\n    280     and self._offsets.nplike is self._backend.index_nplike\r\n    281 )\r\n--> 282 self._handle_error(\r\n    283     self._backend[\r\n    284         \"awkward_ListOffsetArray_toRegularArray\",\r\n    285         _size.dtype.type,\r\n    286         self._offsets.dtype.type,\r\n    287     ](\r\n    288         _size.data,\r\n    289         self._offsets.data,\r\n    290         self._offsets.length,\r\n    291     )\r\n    292 )\r\n    293 size = self._backend.index_nplike.index_as_shape_item(_size[0])\r\n    294 length = self._offsets.length - 1\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/awkward/contents/content.py:281, in Content._handle_error(self, error, slicer)\r\n    278 message += filename\r\n    280 if slicer is None:\r\n--> 281     raise ak._errors.wrap_error(ValueError(message))\r\n    282 else:\r\n    283     raise ak._errors.index_error(self, slicer, message)\r\n\r\nValueError: while calling\r\n\r\n    ak.to_numpy(\r\n        array = <Array ['PCB_volume', ...] type='334460 * string'>\r\n        allow_missing = True\r\n    )\r\n\r\nError details: cannot convert to RegularArray because subarray lengths are not regular (in compiled code: https://github.com/scikit-hep/awkward/blob/awkward-cpp-12/awkward-cpp/src/cpu-kernels/awkward_ListOffsetArray_toRegularArray.cpp#L22)\r\n```\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> Is this a bug with awkward array? Or (more likely) is this a bug with how I'm using it?\r\n\r\nOn the face of it, this looks like a bug in Awkward Array. After flattening the list of strings into just strings, it should be functionally equivalent to the following.\r\n\r\nAn array of variable length strings\r\n\r\n```python\r\n>>> array = ak.Array([\"one\", \"two\", \"three\", \"four\", \"five\"])\r\n```\r\n\r\nis stored in a compact way, with all the character data contiguously, delineated by integer offsets\r\n\r\n```python\r\n>>> array.layout.content.data.tobytes()\r\nb'onetwothreefourfive'\r\n>>> array.layout.offsets.data\r\narray([ 0,  3,  6, 11, 15, 19])\r\n```\r\n\r\nwhereas a NumPy array is contiguous with fixed-sized strings (by padding all the short ones to match the length of the longest one). HOWEVER, `ak.to_numpy` knows this and pads strings to make them NumPy compatible.\r\n\r\n```python\r\n>>> ak.to_numpy(array)\r\narray(['one', 'two', 'three', 'four', 'five'], dtype='<U5')\r\n```\r\n\r\nWe can see this by looking at the NumPy array's raw bytes (every 4th byte because NumPy uses UTF-32 for general strings, whereas Awkward uses UTF-8).\r\n\r\n```python\r\n>>> ak.to_numpy(array).tobytes()[::4]\r\nb'one\\x00\\x00two\\x00\\x00threefour\\x00five\\x00'\r\n```\r\n\r\nOkay, so in my copy of Awkward (fairly recent git cloned version of `main`), `ak.to_numpy` does this properly. What could be going on in your case?\r\n\r\nI tried a jagged array of strings (array of variable-length lists of variable-length strings),\r\n\r\n```python\r\n>>> array = ak.Array([[\"one\", \"two\"], [\"three\"], [], [\"four\", \"five\"]])\r\n```\r\n\r\nPassing this directly into `ak.to_numpy` raises the error that you saw because although `ak.to_numpy` automatically pads strings (who wouldn't want that?), it does not automatically pad other (more visible) lists[^1].\r\n\r\n```python\r\n>>> ak.to_numpy(array)\r\nTraceback (most recent call last):\r\n...\r\nValueError: cannot convert to RegularArray because subarray lengths are not regular (in compiled code: https://github.com/scikit-hep/awkward/blob/awkward-cpp-15/awkward-cpp/src/cpu-kernels/awkward_ListOffsetArray_toRegularArray.cpp#L22)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/jpivarski/irishep/awkward/src/awkward/operations/ak_to_numpy.py\", line 38, in to_numpy\r\n    with ak._errors.OperationErrorContext(\r\n  File \"/Users/jpivarski/irishep/awkward/src/awkward/_errors.py\", line 56, in __exit__\r\n    self.handle_exception(exception_type, exception_value)\r\n  File \"/Users/jpivarski/irishep/awkward/src/awkward/_errors.py\", line 71, in handle_exception\r\n    raise self.decorate_exception(cls, exception)\r\nValueError: cannot convert to RegularArray because subarray lengths are not regular (in compiled code: https://github.com/scikit-hep/awkward/blob/awkward-cpp-15/awkward-cpp/src/cpu-kernels/awkward_ListOffsetArray_toRegularArray.cpp#L22)\r\n\r\nThis error occurred while calling\r\n\r\n    ak.to_numpy(\r\n        array = <Array [['one', 'two'], ..., [...]] type='4 * var * string'>\r\n        allow_missing = True\r\n```\r\n\r\nBut you said that you tried both flattening and not flattening. If you flatten the lists (to get an array of strings only), it should work.\r\n\r\n```python\r\n>>> ak.to_numpy(ak.flatten(array))\r\narray(['one', 'two', 'three', 'four', 'five'], dtype='<U5')\r\n```\r\n\r\nFor me, it does. But I also noticed that your error message is old, suggesting that you have an old version of Awkward. Might this be a bug that has been fixed?\r\n\r\n[^1]: If you want to pad variable-length lists such that they all have the same length, as a prelude to [ak.to_numpy](https://awkward-array.org/doc/main/reference/generated/ak.to_numpy.html), you can do that by [ak.pad_none](https://awkward-array.org/doc/main/reference/generated/ak.pad_none.html) (pads short lists with `None`), followed by [ak.fill_none](https://awkward-array.org/doc/main/reference/generated/ak.fill_none.html) (replaces `None` with some value of your choosing). If you have to use the version of Awkward that you're showing here, one with a bug in it, then this could be a work-around for you. It's what [ak.to_numpy](https://awkward-array.org/doc/main/reference/generated/ak.to_numpy.html) should be doing automatically for strings (the fill value is `\\x00` because most string-interpreters would interpret that as the end of a string that's shorter than its buffer).",
     "createdAt":"2023-05-21T22:19:16Z",
     "number":5961782,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"tomeichlersmith"
     },
     "body":"Thank you for the extra context @jpivarski ! I have another clue that might lead us towards a solution.\r\n\r\n_If I dump my strings to JSON and then read it back in the flattening works._\r\n\r\n```python\r\n>>> ak.to_json(strings, 'volumes.json')\r\n>>> strings = ak.from_json(pathlib.Path('volumes.json'))\r\n>>> ak.to_numpy(ak.flatten(strings))\r\narray(['PCB_volume', 'PCB_volume', 'PCB_volume', ...,\r\n       'W_cooling_volume_1', 'W_cooling_volume_1', 'W_cooling_volume_1'],\r\n      dtype='<U28')\r\n```\r\n\r\nSo I think this has to do with the memory layout because the way I am getting these strings is by making a selection of a larger awkward array. I have cooked up a smaller example to test this in a more portable way.\r\n\r\n```python\r\n>>> a = ak.Array({\r\n    'keep' : [\r\n        [True],\r\n        [False, True, True],\r\n        [],\r\n        [True, False]\r\n    ],\r\n    'mystr' : [\r\n        ['yes'],\r\n        ['foo','blabla','hellothere'],\r\n        [],\r\n        ['generalkenobi','anakin']\r\n    ]\r\n})\r\n>>> ak.to_numpy(ak.flatten(a['mystr'][a['keep']]))\r\n# produces \"cannot convert to Regular array\" error\r\n```\r\n\r\nFor context, I am using Awkward Array v2.1.1.",
     "createdAt":"2023-05-22T00:37:30Z",
     "number":5962175,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"This is good detective-work @tomeichlersmith! As @jpivarski points out, the fix came from #2449 which improved how we handle strings in this context, changing the previous naive method with a string-aware implementatino: https://github.com/scikit-hep/awkward/blob/b7971d3bff81032360e8d1f2d9e409080562ecb1/src/awkward/contents/listarray.py#L1431-L1437",
        "createdAt":"2023-05-23T12:41:27Z",
        "number":5977832
       },
       {
        "author":{
         "login":"tomeichlersmith"
        },
        "body":"Is this already incorporated into the tests? If not, I can put my simple test script into your tests.",
        "createdAt":"2023-05-23T13:40:05Z",
        "number":5978534
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"We should add a test for this, as we don't yet have one. Are you familiar with the low-level `ak.contents.Content` objects that we use to describe an array? The test would be best if it built such a `ListArray` layout: this layout is produced by your slice, and is fixed by #2449",
        "createdAt":"2023-05-23T13:54:38Z",
        "number":5978705
       },
       {
        "author":{
         "login":"tomeichlersmith"
        },
        "body":"I am not so it may be quickest if a more experienced developer wrote the test - not sure how long it will take for me to grasp the `ak.contents.Content` class.",
        "createdAt":"2023-05-23T13:57:00Z",
        "number":5978759
       }
      ],
      "totalCount":4
     }
    },
    {
     "author":{
      "login":"tomeichlersmith"
     },
     "body":"However, you are correct that this is an issue with my older version of awkward! Hooray :tada: I will upgrade.\r\n\r\n```python\r\nPython 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import awkward as ak\r\n>>> ak.__version__\r\n'2.2.1'\r\n>>> a = ak.Array({\r\n...     'keep' : [\r\n...         [True],\r\n...         [False, True, True],\r\n...         [],\r\n...         [True, False]\r\n...     ],\r\n...     'mystr' : [\r\n...         ['yes'],\r\n...         ['foo','blabla','hellothere'],\r\n...         [],\r\n...         ['generalkenobi','anakin']\r\n...     ]\r\n... })\r\n>>> ak.to_numpy(ak.flatten(a['mystr'][a['keep']]))\r\narray(['yes', 'blabla', 'hellothere', 'generalkenobi'], dtype='<U13')\r\n```",
     "createdAt":"2023-05-22T00:42:58Z",
     "number":5962197,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"tomeichlersmith"
        },
        "body":"### For any future reader\r\nI wrote a quick script to test this - right now, only the latest release _2.2.1_ passes this test script.\r\n```python3\r\nimport awkward as ak\r\nimport numpy as np\r\na = ak.Array({\r\n    'keep' : [\r\n        [True],\r\n        [False, True, True],\r\n        [],\r\n        [True, False]\r\n    ],\r\n    'mystr' : [\r\n        ['yes'],\r\n        ['foo','blabla','hellothere'],\r\n        [],\r\n        ['generalkenobi','anakin']\r\n    ]\r\n})\r\nprint(ak.__version__)\r\nassert (ak.to_numpy(ak.flatten(a['mystr'][a['keep']])) == np.array(['yes','blabla','hellothere','generalkenobi'])).all()\r\n```",
        "createdAt":"2023-05-22T13:04:11Z",
        "number":5967423
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Among the fixes in [2.2.1](https://github.com/scikit-hep/awkward/releases/tag/v2.2.1) is related to https://github.com/scikit-hep/awkward/pull/2449 (although that addressed the lack of information due to empty strings).",
        "createdAt":"2023-05-22T14:51:15Z",
        "number":5968649
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I want to keep all of the discussions open. Issues get closed when they're done, but it's valuable to keep discussions around\u2014even if they're resolved\u2014because they're useful to other people with the same questions.",
     "createdAt":"2023-12-30T15:38:59Z",
     "number":7979285,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":4
  },
  "createdAt":"2023-05-21T19:58:08Z",
  "number":2465,
  "title":"Issue Regularizing a awkward Array of Strings",
  "url":"https://github.com/scikit-hep/awkward/discussions/2465"
 },
 {
  "author":{
   "login":"dinardo"
  },
  "body":"Dear Experts,\r\nI came across this interesting paper: https://arxiv.org/pdf/2303.02205.pdf\r\nIt's not clear to me whether I can create an awkward array in C++ and \"convert it\" into a `TTree`, avoiding the annoying ROOT dictionary generation procedure.\r\n\r\nMy final goal would be to have a `TTree` branch which is a: `std::vector< std::vector<uint32_t> >`\r\n\r\nMany thanks.\r\n- Mauro.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @dinardo!\r\n\r\nAwkward Array is not intended to be used exclusively from C++. The paper that you referenced describes a mechanism for creating Awkward Arrays in C++; this header-only library is intended for use in C++ libraries that expose a Python API, but it is of course possible to write these arrays to e.g. disk, and load them in a separate process.\r\n\r\nWe implement a `to_rdataframe` API function that supports interaction with Awkward Arrays in an RDataFrame context. If your array is only singly-jagged, i.e. the array `x` shown in [this documentation](https://awkward-array.org/doc/main/reference/generated/ak.to_rdataframe.html), then you can `Snapshot` the dataframe to disk to build a TTree. However, if the type is more complex than that, this approach cannot be used.\r\n\r\nInstead, there is also `uproot`, which provides a mechanism for building new `TTree`s from many types, including Awkward Arrays. Of course, this requires that you use Python to use these libraries (though you can even do this _from_ C++, e.g. with `pybind11` for convenience).",
     "createdAt":"2023-05-24T10:26:30Z",
     "number":5987975,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"dinardo"
        },
        "body":"Many thanks @agoose77 ,\r\nit's all clear.\r\nUnfortunately, my array is not \"singly jagged\", because it's \"an array of an array\".\r\nRagards,\r\n- Mauro.\r\n",
        "createdAt":"2023-05-24T11:22:52Z",
        "number":5988473
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"If by \"array of an array,\" you mean an array of (variable-length) lists of numbers, like this\r\n\r\n```python\r\n>>> content = [0.0, 1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9]\r\n>>> lengths1 = [3, 0, 2, 1, 4]\r\n>>> ak.unflatten(content, lengths1).show()\r\n[[0, 1.1, 2.2],\r\n [],\r\n [3.3, 4.4],\r\n [5.5],\r\n [6.6, 7.7, 8.8, 9.9]]\r\n```\r\n\r\nthen that is what we mean by a singly-jagged array. But also, [ak.from_rdataframe](https://awkward-array.org/doc/main/reference/generated/ak.from_rdataframe.html) and Uproot can convert from an arbitrarily deep nesting of lists of lists of lists (i.e. doubly-jagged, triply-jagged):\r\n\r\n```python\r\n>>> lengths2 = [2, 0, 3]\r\n>>> ak.unflatten(ak.unflatten(content, lengths1), lengths2).show()\r\n[[[0, 1.1, 2.2], []],\r\n [],\r\n [[3.3, 4.4], [5.5], [6.6, 7.7, 8.8, 9.9]]]\r\n```\r\n\r\nOh! @agoose77 is right: he's saying that if you pass an Awkward Array into an RDataFrame with [ak.to_rdataframe](https://awkward-array.org/doc/main/reference/generated/ak.to_rdataframe.html), it won't be able to `Snapshot` it unless it's only one level deep (singly-jagged). [Uproot has the same limitation.](https://uproot.readthedocs.io/en/latest/basic.html#writing-ttrees-to-a-file)",
        "createdAt":"2023-05-24T16:04:40Z",
        "number":5991852
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"dinardo"
     },
     "body":"Hi @jpivarski ,\r\nwe might have a word-meaning overload :-)\r\n\r\nI need to make a `TTree` branch of: `std::vector< std::vector<uint32_t> >` in C++ (none of the two vectors has a predefined length)\r\nI'm not using `python`\r\n\r\nNormally `ROOT` requires that I make a `dictionary` which I would like to avoid.\r\nI was wondering whether I could somehow define my structure in `awkward` and convert it into a `TTree`\r\n\r\nI must say that I'm not super familiar with all these new packages, but I keep reading around about \"conversion in RDataFrame\"\r\nAs far as I understood `RDataFrame` is just an interface to a `TTree`, the underlying data structure is actually a `TTree`, in fact, I can't define `RDataFrame` \"branches\" and fill them one by one as if they were HEP events. But I might got it all wrong.\r\n\r\nMany thanks.\r\n- Mauro.",
     "createdAt":"2023-05-24T19:52:47Z",
     "number":5993945,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"NJManganelli"
     },
     "body":"Hi @dinardo,\r\n\r\nThat would be \"double-jagged\" data in this scheme, since the TTree Entry index is always treated as knowable/findable/un-fixed. So a variable number of objects per TTree Entry is single-jagged, and variable number of variable number of things is doubly-jagged.\r\n\r\nRDataFrame is, in a single blurb, a \"Declarative interface to TTree (and other) data.\" It has Snapshot functionality to write out TTrees (and through the declarative Define calls you can create new quantities, and use Filter calls to make selections on TTree entries), but it doesn't have generalized (automatic?) support for more than 1 level of jaggedness right now. That is, it works perfectly fine for CMS NanoAOD and similar ntuples.\r\n\r\nSince the interface is declarative, you don't \"manually\" fill things event-by-event, but the end result is similar (within its constraints). \r\n\r\n[https://root.cern/doc/master/classROOT_1_1RDataFrame.html](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) shows some examples.\r\n\r\nBest,\r\nNick",
     "createdAt":"2023-05-24T20:09:20Z",
     "number":5994085,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"dinardo"
        },
        "body":"Hi,\r\nok many thanks for your clarification.\r\nIt's more clear now.\r\nCheers,\r\n- Mauro.",
        "createdAt":"2023-05-25T06:00:45Z",
        "number":5997132
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":3
  },
  "createdAt":"2023-05-24T09:54:37Z",
  "number":2470,
  "title":"Awkward arrays in C++ / ROOT",
  "url":"https://github.com/scikit-hep/awkward/discussions/2470"
 },
 {
  "author":{
   "login":"alexander-held"
  },
  "body":"Following some investigations of @ekauffma into memory use, I observed that there seems to be a significant difference between using `awkward` and `numpy` for doing partial sums of higher-dimensional (large) arrays that I do not understand. I am curious if this is expected.\r\n\r\n```python\r\nimport numpy as np\r\nimport awkward as ak\r\n\r\nx = np.random.random(size=(1000, 1000, 100))\r\n\r\nak_res = ak.sum(x, axis=1)\r\nnp_res = np.sum(x, axis=1)\r\n\r\nassert np.allclose(ak_res, np_res)\r\n```\r\nI am running the script above through [`memray`](https://github.com/bloomberg/memray) via the following mini script:\r\n\r\n```bash\r\nrm -r output.bin\r\nrm -r memray-flamegraph-output.html\r\nmemray run -o output.bin test.py\r\nmemray flamegraph output.bin\r\nopen memray-flamegraph-output.html\r\n```\r\n\r\nI see a 763 MiB allocation for the array `x`, which makes sense given `float64` and 100M floats.  With `ak.sum` removed from the script, this dominates in terms of memory.\r\n\r\nSurprisingly, the addition of `ak.sum` results in an additional 2.3 GiB of allocation via various `nextcontent` / `nextparents` / `nextcarry` objects, see the screenshot below (can open in new tab to have something more readable, or reproduce with `memray`).\r\n\r\n![Screenshot 2023-05-26 at 20 48 36](https://github.com/scikit-hep/awkward/assets/45009355/e97d35d4-91cb-48ee-b4a5-7996ddb80bb9)\r\n\r\nI had naively assumed thus far that `awkward` just hands this off to `numpy` and would essentially act the same otherwise.\r\n\r\nI am using Python 3.9.16, `awkward` 2.2.1 and `numpy` 1.24.2 on macOS.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"> I had naively assumed thus far that `awkward` just hands this off to `numpy` and would essentially act the same otherwise.\r\n\r\nIt's the other way around: if `np.sum` is called on an `ak.Array`, it checks to see if `ak.Array` has a `__array_function__`, which it does, and then NumPy calls that instead of its usual `np.sum` operation.\r\n\r\nWhat you're doing here is calling `ak.sum` on a NumPy array, which converts the NumPy array into an Awkward Array (which is _not_ expensive) and then does general variable-length reduction on that Awkward Array (which is expensive). There are more intermediate arrays involved in `ak.sum`, and that will account for more memory.\r\n\r\nWe _could_ install a check in all of the NumPy functions we NEP18-overload to see if there are no Awkward Arrays in the arguments and then pass it over to the equivalent NumPy function ([here](https://github.com/scikit-hep/awkward/blob/91708e894ecb72f5c3a847da51e5b93198fe06be/src/awkward/_connect/numpy.py#L108-L138)). _But_, there's an exception to that: one of the arguments might not be an Awkward Array, but it might be an iterable that should be interpreted as an Awkward Array instead of a NumPy array (e.g. it's a list of variable-length lists), in which case you would _not_ want the NumPy version to take over. So the hardest part of this optimization would be determining if the arguments of `ak.whatever` ought to be Awkward-like. Also, `ak.sum` should return an Awkward Array, regardless of whether it is implemented by `np.sum` or not.",
     "createdAt":"2023-05-26T19:10:34Z",
     "number":6014901,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"alexander-held"
        },
        "body":"Thanks for clarifying this Jim!\r\n```python\r\nx = np.random.random(size=(1000, 1000, 100))\r\ny = ak.Array(x)\r\nnp_res = np.sum(y, axis=1)\r\n```\r\nalso reproduces the large memory requirement, so that is all consistent then.\r\n\r\nAt the risk of falling down a rabbit hole: how crucial are these intermediate arrays for performance? I imagine that there are still ways of doing this with negligible memory overhead via a jit-compiled iteration over the array? This example requires 3x additional memory compared to the array itself, are there other API calls that might require even more (and if so, could other approaches be useful there)?\r\n\r\nFurther down the rabbit hole: I assume other calculations also may use similar intermediate arrays (?) \u2014 if so, can `dask-awkward` help avoid overhead from creating the same (or similar) objects by graph optimization when users call multiple `awkward` functions on the same objects?",
        "createdAt":"2023-05-26T19:37:01Z",
        "number":6015048
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Some intermediate arrays can be avoided in the `axis=-1` case, although that would mean adding another implementation path. (`axis=-1` is the most important case, I know.) JIT-compilation is unnecessary for that: there is enough information available for everything to be precompiled.\r\n\r\ndask-awkward can't fuse Awkward operations, if that's what you're asking.",
        "createdAt":"2023-05-26T20:18:35Z",
        "number":6015467
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-05-26T18:52:05Z",
  "number":2480,
  "title":"Memory requirement of ak.sum vs np.sum",
  "url":"https://github.com/scikit-hep/awkward/discussions/2480"
 },
 {
  "author":{
   "login":"jrueb"
  },
  "body":"I think it would be very convenient if one could use awkward functions on dask_awkward arrays straight away.\r\nFor example, I think it should be very nice to be able to do\r\n```python\r\nak.unflatten(some_dask_awkward_array, num)\r\n```\r\nI would like code in general to work regardless of whether somebody decides to use dask or standard awkward (without dask).\r\nI'm saying this because this functionality is already there in case of numpy. For example I can do\r\n```python\r\nnp.reshape(some_awkward_array, newshape)\r\n```\r\nand also\r\n```python\r\nnp.reshape(some_dask_array, newshape)\r\n```\r\nOf course, reshape and unflatten just serve as examples here and this argument is meant to apply to all common functions awkward and dask_awkward have in common.\r\n\r\nIs this something that could be considered to be added?",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I think this is reasonable: to be able to use the same script on eager `ak.Array` and lazy `dak.Array` without having to change _all_ of the `ak.` to `dak.`.\r\n\r\nOne way to do it would be to check for `dak.Array` on the first line of the implementation of every function in src/awkward/operations.py. However, all of these functions already [start by going through an `OperationErrorContext`](https://github.com/scikit-hep/awkward/blob/0e08f59e488f0907bd540e4f7e1d197d2d0c0529/src/awkward/operations/ak_num.py#L72), so the check could be implemented once with minimal code duplication by adding the\r\n\r\n```python\r\nNOT_DASK = object()\r\n\r\nfor arg in arguments.values():\r\n    if type(arg).__module__.split(\".\")[0] == \"dask_awkward\":\r\n        import dask_awkward\r\n        import inspect\r\n        function_name = inspect.stack()[1].function\r\n        dask_equivalent = getattr(dask_awkward, function_name, None)\r\n        if dask_equivalent is None:\r\n            raise NotImplementedError(f\"dask-awkward function dak.{} does not exist\")\r\n        else:\r\n            return dask_equivalent(**arguments)\r\n    else:\r\n        return NOT_DASK\r\n```\r\n\r\nin the [`OperationErrorContext.__init__`](https://github.com/scikit-hep/awkward/blob/0e08f59e488f0907bd540e4f7e1d197d2d0c0529/src/awkward/_errors.py#L173).\r\n\r\nHmmm. The calling function would have to deal with continuing to normal operation on `NOT_DASK`, which means that some code would need to be added to every function in src/awkward/operations.py, after all. Also, this is abusing the notion of an \"error context\" because what we're doing here\u2014looking up an equivalent dask-awkward function for each Awkward function we're implementing\u2014has nothing to do with error messages. One thing that the `OperationErrorContext` does for us is that it puts all of the arguments into a dict, `arguments`, which we'll need to pass to `dask_equivalent`, so it's tempting to reuse the `OperationErrorContext` for that reason. Rewriting every [canonicalized list of arguments](https://github.com/scikit-hep/awkward/blob/0e08f59e488f0907bd540e4f7e1d197d2d0c0529/src/awkward/operations/ak_cartesian.py#L197-L205) would turn slightly too much boilerplate into way too much boilerplate.\r\n\r\nSo some thought is needed to do this nicely, but I agree that it should be done.",
     "createdAt":"2023-06-02T13:53:10Z",
     "number":6072288,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"@jpivarski there's also a temptation to remove the need for explicitly enumerating _those_ arguments by introducing a decorator instead. This would benefit from the same approach I think. ",
        "createdAt":"2023-06-02T16:22:38Z",
        "number":6073849
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-06-02T13:25:18Z",
  "number":2483,
  "title":"Interoperability of awkward and dask_awkward",
  "url":"https://github.com/scikit-hep/awkward/discussions/2483"
 },
 {
  "author":{
   "login":"draghuram"
  },
  "body":"\r\nPlease see the following code where I am using \"zip\" to build a record and then create combinations.\r\n\r\n```python\r\nimport awkward as ak\r\n\r\nA1 = ak.Array([\r\n        [1, 2],\r\n        [3, 4, 5],\r\n        [6]\r\n    ])\r\n\r\nA2 = ak.Array([\r\n        [11, 21],\r\n        [31, 41, 51],\r\n        [61]\r\n    ])\r\n\r\nR = ak.zip({\"a1\": A1, \"a2\": A2})\r\nprint(\"R\")\r\nR.show()\r\n\r\nC = ak.combinations(R, 2)\r\nprint(\"C\")\r\nC.show()\r\n\r\nprint(C[0][0][0])\r\n```\r\n\r\nI see the following response when I run this code:\r\n\r\n```pycon\r\n[[{a1: 1, a2: 11}, {a1: 2, a2: 21}],\r\n [{a1: 3, a2: 31}, {a1: 4, a2: 41}, {a1: 5, a2: 51}],\r\n [{a1: 6, a2: 61}]]\r\n[[({a1: 1, a2: 11}, {a1: 2, a2: 21})],\r\n [({a1: 3, a2: 31}, {a1: 4, a2: 41}), ({...}, ...), ({a1: 4, ...}, {...})],\r\n []]\r\nTraceback (most recent call last):\r\n  File \"test_ak.py\", line 23, in <module>\r\n    print(C[0][0][0])\r\n          ~~~~~~~^^^\r\n  File \".../site-packages/awkward/highlevel.py\", line 1754, in __getitem__\r\n    out = self._layout[where]\r\n          ~~~~~~~~~~~~^^^^^^^\r\n  File \".../site-packages/awkward/record.py\", line 138, in __getitem__\r\n    return self._getitem(where)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \".../site-packages/awkward/record.py\", line 142, in _getitem\r\n    raise IndexError(\"scalar Record cannot be sliced by an integer\")\r\nIndexError: scalar Record cannot be sliced by an integer\r\n\r\nThis error occurred while attempting to slice\r\n\r\n    <Record ({a1: 1, ...}, {...}) type='({a1: int64, a2: int64}, {a1: int64...'>\r\n\r\nwith\r\n\r\n    0\r\n```\r\nIt is possible that I am missing something here but I thought that \"combinations()\" should add an extra dimension to the array as it generates list of tuples. But from the error message above, it seems that a tuple of records is also treated as a record. Is that correct?\r\n\r\nI also see a \"tolist()\" method on the record and perhaps that will convert the combination tuple to a list but would it be possible to convert all record tuples to an extra dimension (axis)? I am hoping that this would allow me to create a mask such as \"> 0.5\" or something like that against entire axis. \r\n\r\nI apologize if I haven't explained the issue properly. Any help is appreciated.\r\n\r\nThanks,\r\nRaghu\r\n \r\n\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"The `Array.show()` function accepts a `type` boolean that makes it easier to see the _structure_ of the array:\r\n```python\r\n>>> C.show(type=True)\r\ntype: 3 * var * (\r\n    {\r\n        a1: int64,\r\n        a2: int64\r\n    },\r\n    {\r\n        a1: int64,\r\n        a2: int64\r\n    }\r\n)\r\n[[({a1: 1, a2: 11}, {a1: 2, a2: 21})],\r\n [({a1: 3, a2: 31}, {a1: 4, a2: 41}), ({...}, ...), ({a1: 4, ...}, {...})],\r\n []]\r\n```\r\n\r\nThe `ak.combinations` operation does not introduce new dimensions; the axis from which the combinations are taken is re-used as the result dimension (of a new length!). Note that tuples (and records) are distinct from array dimensions. So, your `C` array has the same number of dimensions as the `R` array (2).\r\n\r\nIf you want to pull out the first _slot_ of the resulting tuple, you can use a _string_ representing the index, e.g. \r\n```python\r\n>>> C[0, 0, \"0\"]\r\n{a1: 1, a2: 11}\r\n```\r\n\r\nIf you would like to name these fields, and obtain a record instead of a tuple, you can pass a `fields` argument to `ak.combinations`:\r\n```python\r\n>>> C = ak.combinations(R, 2, fields=[\"first\", \"second\"])\r\n>>> C.show(type=True)\r\ntype: 3 * var * {\r\n    first: {\r\n        a1: int64,\r\n        a2: int64\r\n    },\r\n    second: {\r\n        a1: int64,\r\n        a2: int64\r\n    }\r\n}\r\n[[{first: {a1: 1, a2: 11}, second: {a1: 2, ...}}],\r\n [{first: {a1: 3, a2: 31}, second: {a1: 4, ...}}, ..., {first: {...}, ...}],\r\n []]\r\n```",
     "createdAt":"2023-06-05T15:53:20Z",
     "number":6092102,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"draghuram"
     },
     "body":"Thanks. It is clear to me now that ``ak.combinations`` doesn't introduce new dimension. Thanks for the clarification.  Is there any way to run a filter on each of the combinations? For example, here is one combination:\r\n```\r\n({a1: 3, a2: 31}, {a1: 4, a2: 41})\r\n```\r\nIs there a way to find all combinations where at least one \"a1\" value is  > 2? I can write code that does this check for each combination but I am wondering if it is possible to do it as a vectorized operation, making it more efficient. Thanks.",
     "createdAt":"2023-06-05T17:20:57Z",
     "number":6092893,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Yes! Something like this?\r\n\r\n```python\r\nC = ak.combinations(R, 2)\r\nC_is_good = (C[\"0\", \"a1\"] > 2) | (C[\"1\", \"a1\"] > 2)\r\nC_good = C[C_is_good]\r\n```",
        "createdAt":"2023-06-05T17:45:31Z",
        "number":6093054
       },
       {
        "author":{
         "login":"draghuram"
        },
        "body":"Great, this does the trick. I am curious how ``C[\"0\", \"a1\"]`` works. It seems to directly access records in axis 1?",
        "createdAt":"2023-06-05T17:57:49Z",
        "number":6093132
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"In Awkward, field selection is orthogonal (independent of) dimension selection. You can place the field names anywhere in the slice with respect to the dimension index, as long as you don't re-order the strings. The API reference describes this [here](https://awkward-array.org/doc/main/reference/generated/ak.Array.html#projection)!\r\n\r\n```python\r\nC[\"0\", \"a1\"]\r\n```\r\nis equivalent to \r\n```python\r\nC[\"0\"][\"a1\"]\r\n```\r\nand gives you the array of \"a1\" values for the \"left\" combinations.",
        "createdAt":"2023-06-05T18:07:02Z",
        "number":6093188
       },
       {
        "author":{
         "login":"draghuram"
        },
        "body":"Got it. Thanks a lot for very quick responses. ",
        "createdAt":"2023-06-05T18:08:54Z",
        "number":6093200
       }
      ],
      "totalCount":4
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-06-05T15:13:23Z",
  "number":2491,
  "title":"A question about \"record\" combinations",
  "url":"https://github.com/scikit-hep/awkward/discussions/2491"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat!: drop string broadcasting overloading by @agoose77 in https://github.com/scikit-hep/awkward/pull/2474\r\n* feat: add `Index._touch_XXX` methods by @agoose77 in https://github.com/scikit-hep/awkward/pull/2478\r\n* feat: add `ak.typetracer.length_one_if_typetracer` by @jpivarski in https://github.com/scikit-hep/awkward/pull/2499\r\n* feat: add placeholder array by @agoose77 in https://github.com/scikit-hep/awkward/pull/2479\r\n\r\n## Bug-fixes and performance\r\n* fix!: raise error when flattening strings by @agoose77 in https://github.com/scikit-hep/awkward/pull/2471\r\n* fix: `ak.concatenate` for typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2497\r\n* fix: always touch arguments to kernels by @agoose77 in https://github.com/scikit-hep/awkward/pull/2472\r\n* fix: check `start_at_zero` in `_compact_offsets` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2477\r\n* fix: convert index to shape item by @agoose77 in https://github.com/scikit-hep/awkward/pull/2466\r\n* fix: formatting error message (missing space). by @jpivarski in https://github.com/scikit-hep/awkward/pull/2485\r\n* fix: rename tonumbatype function to conform by @ianna in https://github.com/scikit-hep/awkward/pull/2482\r\n* fix: request non-option results for overloaded positional record reducers by @agoose77 in https://github.com/scikit-hep/awkward/pull/2502\r\n* fix: starts handling in `RegularArray._reduce_next` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2492\r\n* fix: touch offsets in kernel call by @agoose77 in https://github.com/scikit-hep/awkward/pull/2469\r\n* fix: trim content when broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2489\r\n* fix: use offsets for starts to handle length-0 arrays by @agoose77 in https://github.com/scikit-hep/awkward/pull/2488\r\n* refactor: cleanup and type hints by @agoose77 in https://github.com/scikit-hep/awkward/pull/2476\r\n* refactor: improve kernel error handling logic (1 of 3) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2505\r\n* refactor: move JAX reducer dispatch to `ak._do.reduce` (2 of 3) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2506\r\n* refactor: simplify reducer boilerplate (3 of 3) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2509\r\n\r\n## Other\r\n* chore(deps): bump docker/setup-qemu-action from 2.1.0 to 2.2.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2511\r\n* chore(deps): bump pypa/cibuildwheel from 2.12.3 to 2.13.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2481\r\n* chore: add more type hints! by @agoose77 in https://github.com/scikit-hep/awkward/pull/2473\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2467\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2500\r\n* chore: upgrade CI micromamba action by @agoose77 in https://github.com/scikit-hep/awkward/pull/2494\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.2.1...v2.2.2\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.2.2'>Version 2.2.2</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-06-09T08:38:05Z",
  "number":2517,
  "title":"Version 2.2.2",
  "url":"https://github.com/scikit-hep/awkward/discussions/2517"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat!: deprecate `to_NumpyForm`'s ``dtype` argument by @agoose77 in https://github.com/scikit-hep/awkward/pull/2503\r\n* feat!: deprecate the time `__unit__` parameter by @agoose77 in https://github.com/scikit-hep/awkward/pull/2518\r\n\r\n## Bug fixes and performance\r\n* fix: don't project records during broadcasting; push index down by @agoose77 in https://github.com/scikit-hep/awkward/pull/2524\r\n* fix: protect ak.to_parquet against memory explosion when args are swapped. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2523\r\n* fix: str of `KeyError` for <3.11 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2519\r\n* fix: support `axis != -1` for record reduction by @agoose77 in https://github.com/scikit-hep/awkward/pull/2514\r\n\r\n## Other\r\n* refactor: dead c++ elimination by @agoose77 in https://github.com/scikit-hep/awkward/pull/2504\r\n* refactor: move responsibility for positional reducers to `Reducer.apply` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2507\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.2.2...v2.2.3\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.2.3'>Version 2.2.3</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-06-15T17:17:41Z",
  "number":2526,
  "title":"Version 2.2.3",
  "url":"https://github.com/scikit-hep/awkward/discussions/2526"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"One of the challenges here is the coupling between behavior classes (via `__array__` and `__record__` parameters) and array types (`__array__ = \"string\"`, ...). The intention that string classes be user-customisable _without_ requiring a significant rework of how far behaviors propagate into the codebase is one motivation, but another is generally figuring out how we _think_ about the `__array__` parameters vs other type parameters.\r\n\r\nI think it would be helpful to start with describing some use cases:\r\n\r\n1. Implementing a custom behavior for a categorical array\r\n2. Implementing a custom behavior for a string, e.g. IP address\r\n3. Implementing a custom behavior for an array with units\r\n\r\nTo compare \"types\" between two arrays, we have the following:\r\n- `NumpyArray` \u2014 do both arrays have the same primitive?\r\n- `RecordArray` \u2014 do both arrays have the same `__record__` **and** are their structures type-comparable?\r\n- `ListOffsetArray`, ..., \u2014 do both arrays have the same `__array__`, and are their contents type-comparable?\r\n\r\nIt's clear to me that `__array__` and `__record__` are quite different, beyond their association with different content classes. Unlike `__record__`, `__array__` is used to implement non-behavior customisation that precludes the use of custom behaviors. \r\n\r\nI propose we introduce a new `__kind__` parameter that can currently be one of `(\"string\", \"categorical\")`. We can introduce constraints upon which contents can be assigned with which values of `__kind__`. Introducing this parameter would allow us to separate user-provided names from built-in names, permitting custom strings and categoricals, e.g.\r\n```python\r\nmy_string = ak.contents.ListOffsetArray(\r\n    ak.index.Index64([0, 3, ..., 9]),\r\n    ak.contents.NumpyArray(\r\n        np.array(..., dtype=np.uint8)\r\n    ),\r\n    parameters={\r\n        \"__kind__\": \"string\",\r\n        \"__array__\": \"ip-address\"\r\n    }\r\n)\r\n```\r\n\r\nThe nominal type precedence is then:\r\n- `__array__`\r\n- `__kind__`\r\n\r\nand is used to resolve behaviors. Meanwhile, string-specific features check `__kind__`, or fall back upon `__array__` for legacy strings.\r\n\r\nIn this new formulation, we have the following interpretation of each parameter:\r\n- `__array__` \u2014 the nominal type of a list (OR, the kind of a \"legacy\" string or categorical)\r\n- `__record__` \u2014 the nominal type of a record\r\n- `__kind__` \u2014 the built-in nominal type of a list (e.g. `string` or `categorical`)\r\n\r\nBuilt-in types (strings, categoricals) look at `__kind__`, but high-level features like behaviors look at the resolved nominal type, i.e. via the precedence above.\r\n\r\nUnits (#2468) are a related problem; we can either implement them as a user-behavior, or as a low-level integration.\r\n\r\nIf units were implemented using behaviors, e.g. \r\n\r\n```python\r\n>>> x = ak.Array(\r\n...     [1, 2, 3, 4],\r\n...     parameters={\r\n...         \"__array__\": \"unit\",\r\n...         \"__unit__\": \"s\",\r\n...     },\r\n... )\r\n>>> y = ak.Array(\r\n...     [1000, 2000, 3000, 4000],\r\n...     parameters={\r\n...         \"__array__\": \"unit\",\r\n...         \"__unit__\": \"ms\",\r\n...     },\r\n... )\r\n>>> def add_units(left, right):\r\n...     ...\r\n>>> ak.behavior[np.add, \"unit\", \"unit\"] = add_units\r\n>>> x + y\r\nak.Array(\r\n    [2000, 4000, 6000, 8000], \r\n    parameters={\r\n        \"__array__\": \"time\",\r\n        \"__unit__\": \"ms\",\r\n    }\r\n)\r\n```\r\n\r\nthen it would not be possible to define a custom class for this array _without_ re-overloading all of the ufunc methods that implement the units system. I can't immediately see what that would be useful for, but it doesn't feel that the behavior class is strongly related to the units system. Just as in this new system, string features check `__kind__`, I think units conversion should happen in the ufunc dispatch, and look exclusively at `__unit__`, i.e.\r\n1. Do all arrays have the same nominal type (`__array__` \u2192 `__kind__`)?\r\n2. Convert all arrays to a common unit, if any arrays have a unit (or error if not possible)\r\n3. Invoke any behavior overload for the ufunc\r\n\r\nUltimately, all of this represents a different mindset; behaviours are for users, and we should only use behaviors internally iff. the new feature(s) aren't intended to compose with other features. I feel that strings are orthogonal to custom user-types, and that units are also orthogonal to custom user-types.\r\n\r\nTagging @jpivarski for visibility\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Yeah, `__array__` and `__record__` are becoming more different all the time. Most of the uses of `__array__` that we're thinking about are very special, in ways that `__record__` overloading is not.\r\n\r\nWhen we've talked about implementing `__units__`, I had been thinking of it as completely separate from `__array__` or an `__array__` replacement. It only applies to array-like things (not record-like things); in particular, `__units__` only applies to `PrimitiveType` (`NumpyArray`). I don't think it's a special kind of `__array__` overload\u2014it's _extremely_ special. (We know how to implement it for all cases: look up some info in a Pint registry and scalar-multiply.)\r\n\r\nCategorical is also its own thing, applying only to `is_indexed` node types (`IndexedArray` and `IndexedOptionArray`).\r\n\r\nThe special behavior we're pulling _out_ of generic `__array__` overloads are modifications to strings and bytestrings. That is, we're reducing the generality of `__array__` overloading to just string/bytestring-overloading. That's still very general; it's what a database would call an opaque binary blob type (overloading bytestring, specifically).\r\n\r\nI see that you're trying to pull together similar things to give them a common implementation, but\r\n\r\n  * `__array__` overloading is not an active part of the ecosystem. (I think it's _never_ been done, apart from defining strings.)\r\n  * The other cases, units and categorical, are not very much like string/bytestring overloading.\r\n  * We're somewhat constrained by backward compatibility: categorical and string/bytestring are implemented in a particular way, and I don't want to complicate things by having to support both a legacy way and a new way.\r\n\r\nWhy can't they be three special cases? They all apply to different sets of nodes:\r\n\r\n  * units: only `is_numpy`\r\n  * categorical: only `is_indexed` of anything\r\n  * strings/bytestrings: only `is_list` of `is_numpy`\r\n\r\nThey seem to be three different things to me.",
     "createdAt":"2023-06-16T22:08:54Z",
     "number":6201434,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"agoose77"
     },
     "body":"> __array__ overloading is not an active part of the ecosystem. (I think it's never been done, apart from defining strings.)\r\n\r\nI've used this (as a user), but I am in agreement that this is unlikely.\r\n\r\n> Why can't they be three special cases? They all apply to different sets of nodes:\r\n\r\nI think they mostly should be \u2014 at least, that's what I propose here. \r\n\r\n> The other cases, units and categorical, are not very much like string/bytestring overloading.\r\n\r\n`__unit__` is special (and yes, per `NumpyArray`. What unifies `categorical` and `string` is the fact that these are abstractions over existing layout nodes. That's what `__kind__` signifies \u2014 built-in abstractions over the existing layout nodes. \r\n\r\nI'd like for users to be able to add their own methods to these things via behaviors. That means either \n- moving these attributes to the layout type itself (e.g. a new initialiser argument `is_string` etc.), \n- creating a new reserved property for these abstractions(`__kind__`), or \r\n- creating a new reserved property for non-record type names (e.g. `__name__`).\r\n\r\nIn particular, I think units, strings, and categoricals have group-properties that should transcend their nominal type. That's what a custom string should have; now that strings are built in, users should have a way to add their own named strings without needing to reimplement everything.",
     "createdAt":"2023-06-17T22:01:16Z",
     "number":6206617,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Okay, I see the logic of that (`__kind__`). But would existing strings need to change? I really, really don't want to have to explain that we have new-style strings and legacy strings (and categoricals, though I think strings are a lot more likely).",
        "createdAt":"2023-06-19T01:15:10Z",
        "number":6213491
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"I am also not against making `__array__` _be_ `__kind__`, and adding a new `__name__`. In fact, that might be a better choice of names than `__kind__`. In either case, we can leave existing non-named strings as `{\"__array__\": \"string\"}` \u2014 only custom strings / categoricals would need to change. With that in mind, for symmetry it might be preferable to introduce `__name__`, rather than `__kind__`, so that custom strings look very similar to un-named strings.\r\n\r\nAdapting the statement above:\r\n\r\nIn this new formulation, we have the following interpretation & precedence of each parameter:\r\n- `__name__` \u00adthe user-provided nominal type of a list\r\n- `__array__` \u2014 the built-in semantic type of a list, e.g. `string` or `categorical`\r\n- `__record__` \u2014 the nominal type of a record\r\n\r\nThis would be an unnamed string:\r\n```python\r\nmy_string = ak.contents.ListOffsetArray(\r\n    ak.index.Index64([0, 3, ..., 9]),\r\n    ak.contents.NumpyArray(\r\n        np.array(..., dtype=np.uint8)\r\n    ),\r\n    parameters={\r\n        \"__array__\": \"string\"\r\n    }\r\n)\r\n```\r\nwhilst this one has a name:\r\n\r\n```python\r\nmy_string = ak.contents.ListOffsetArray(\r\n    ak.index.Index64([0, 3, ..., 9]),\r\n    ak.contents.NumpyArray(\r\n        np.array(..., dtype=np.uint8)\r\n    ),\r\n    parameters={\r\n        \"__array__\": \"string\",\r\n        \"__name__\": \"ip-address\"\r\n    }\r\n)\r\n```",
        "createdAt":"2023-06-19T06:44:27Z",
        "number":6215762
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"This is good because it extends from the current state. The meanings of \"name\" are perhaps too broad, maybe `__overload__`, `__override__`, or `__behavior__`? It begs the question about why `__record__` is different, since that also overloads/overrides behavior, but that is different because when you set `__record__`, it could assign an `ak.Record` subclass if the level is at a record but it could also assign an `ak.Array` subclass if it's some level above that record.",
        "createdAt":"2023-06-20T01:00:17Z",
        "number":6224664
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"`__behavior__` is perhaps too restrictive, too; it's not _just_ a key in the behavior lookup, it is also a nominal type. An intended consequence of this is that merging `string` against `ip-address` would be considered invalid. \r\n\r\nThus, I think `__record__` is justified in not having the name `__behavior__`: it affects both the choice of behavior class and the set of operations that one can perform against it (i.e., whether two record arrays can be concatenated together w/o a union is determined by whether they share the same name). I'd like the same to be true for strings and categoricals; that their name is both a nominal type, and the lookup for the behavior class. This change would mean that `__array__` becomes a more restricted parameter that is used only to tell Awkward whether a list is a string or an indexed node is a categorical.",
        "createdAt":"2023-06-20T09:44:45Z",
        "number":6228513
       }
      ],
      "totalCount":4
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-06-16T13:49:03Z",
  "number":2529,
  "title":"Separate behavior classes from types",
  "url":"https://github.com/scikit-hep/awkward/discussions/2529"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat!: canonicalise `union` of `indexed` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2527\r\n* feat: add array dispatcher (inline) by @agoose77 in https://github.com/scikit-hep/awkward/pull/2531\r\n\r\n## Bug fixes and performance\r\n* fix: patch `NDArrayOperatorsMixin` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2534\r\n* fix: improve performance of `Form.select_columns` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2536\r\n\r\n## Other\r\n* refactor: add internal `with_operation_context` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2525\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2522\r\n* chore(deps): bump pypa/cibuildwheel from 2.13.0 to 2.13.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2521\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.2.3...v2.2.4\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.2.4'>v2.2.4</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-06-22T21:14:38Z",
  "number":2539,
  "title":"Version 2.2.4",
  "url":"https://github.com/scikit-hep/awkward/discussions/2539"
 },
 {
  "author":{
   "login":"Star9daisy"
  },
  "body":"Hi, I'm just get learning how to use awkward. It confuses me that in [How to create arrays of lists](https://awkward-array.org/doc/main/user-guide/how-to-create-lists.html#from-python-lists), doc shows an awkward array as following:\r\n```\r\n[[1, 2, 3],\r\n [],\r\n [4, 5],\r\n [6],\r\n [7, 8, 9, 10]]\r\n---------------------\r\ntype: 5 * var * int64\r\n```\r\nBut in my vscode jupyter notebook or in python cli, it looks like this:\r\n```\r\n<Array [[1, 2, 3], [], [...], [6], [7, 8, 9, 10]] type='5 * var * int64'>\r\n```\r\n\r\nI install the latest 2.2.4 version via `pip`.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"This is a good spot! The reason for this is that we implement a Jupyter display formatter, which provides more detailed information (the type) in addition to the array contents. You can obtain a similar view with [`array.show(type=True)`](https://awkward-array.org/doc/main/reference/generated/ak.Array.html#ak.Array.show)",
     "createdAt":"2023-06-26T11:57:24Z",
     "number":6281450,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"Star9daisy"
        },
        "body":"I have tried it. It shows like this:\r\n```\r\ntype: 3 * {\r\n    px: float64,\r\n    py: float64,\r\n    pz: float64,\r\n    E: float64,\r\n    ex: float64\r\n}\r\n[{px: 1.2, py: 3.2, pz: 5.4, E: 2.5, ex: 0.78},\r\n {px: 32.2, py: 64.2, pz: 543, E: 24.1, ex: 0.35},\r\n {px: 32.5, py: 63.2, pz: 543, E: 24.6, ex: 0}]\r\n```\r\nIt shows more info now.  You're realy helpful!\r\n\r\nBy the way, saying your answer reminds me that I followed the same document several days before, and I got totally the same output as doc. At that time I though it was too much info printed, so I reinstalled version 1.8 to get back the one line display. I could not know what happened these days so it's impossible to reproduce this. But I guess it's alright.\r\n\r\nLove awkward! It's an amazing package! Getting more practice in array-oriented programming these days. Thanks!",
        "createdAt":"2023-06-26T12:10:45Z",
        "number":6281558
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"You will only see the detailed representation in HTML-enabled Jupyter Frontends. You can see the MIME bundle that Awkward generates with\r\n```python\r\nipython = get_ipython()\r\nipython.display_formatter.format(array)\r\n```\r\n\r\n:)",
        "createdAt":"2023-06-26T12:20:46Z",
        "number":6281645
       },
       {
        "author":{
         "login":"Star9daisy"
        },
        "body":"I just tried in jupyter lab. It did show what the doc shows! Thanks a lot!",
        "createdAt":"2023-06-26T12:25:59Z",
        "number":6281706
       }
      ],
      "totalCount":3
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I want to keep all of the discussions open. Issues get closed when they're done, but it's valuable to keep discussions around\u2014even if they're resolved\u2014because they're useful to other people with the same questions.",
     "createdAt":"2023-12-30T15:39:05Z",
     "number":7979287,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-06-26T11:53:33Z",
  "number":2542,
  "title":"An awkward array looks different from the one of online document",
  "url":"https://github.com/scikit-hep/awkward/discussions/2542"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: LayoutBuilder in Numba by @ianna in https://github.com/scikit-hep/awkward/pull/2408\r\n* feat: move string features into core by @agoose77 in https://github.com/scikit-hep/awkward/pull/2547\r\n* feat: add new `__list__` parameter for list-based array types by @agoose77 in https://github.com/scikit-hep/awkward/pull/2549\r\n* feat!: deprecate string behavior classes by @agoose77 in https://github.com/scikit-hep/awkward/pull/2528\r\n* feat!: apply retroactive deprecations by @agoose77 in https://github.com/scikit-hep/awkward/pull/2566\r\n## Bug fixes and performance\r\n* fix: support dict-likes in form.from_dict, convert fields to list by @agoose77 in https://github.com/scikit-hep/awkward/pull/2548\r\n* fix: check validity error properly by @agoose77 in https://github.com/scikit-hep/awkward/pull/2550\r\n* fix: string broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2552\r\n* fix: make C++ LayoutBuilder API consistent with the Numba's by @ianna in https://github.com/scikit-hep/awkward/pull/2553\r\n* fix: convert unknown-length to index in `ListOffsetArray.to_RegularArray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2560\r\n* fix: prefer known to unknown lengths in broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2561\r\n* fix: broadcasting of regular strings by @agoose77 in https://github.com/scikit-hep/awkward/pull/2564\r\n* fix: restore NEP-18 overloads for concatenate and where by @agoose77 in https://github.com/scikit-hep/awkward/pull/2567\r\n## Other\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2532\r\n* chore: update pyodide parts a bit by @henryiii in https://github.com/scikit-hep/awkward/pull/2538\r\n* chore: move C++ format configuration by @agoose77 in https://github.com/scikit-hep/awkward/pull/2554\r\n* chore: drop Python 3.7 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2557\r\n* chore: ruff moved to astral-sh by @henryiii in https://github.com/scikit-hep/awkward/pull/2562\r\n* chore: target-version no longer needed by Black or Ruff by @henryiii in https://github.com/scikit-hep/awkward/pull/2563\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.6 to 1.8.7 by @dependabot in https://github.com/scikit-hep/awkward/pull/2546\r\n* ci: cap `pydantic<2` to fix WASM build by @agoose77 in https://github.com/scikit-hep/awkward/pull/2558\r\n* refactor: drop unused `if` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2543\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.2.4...v2.3.0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.3.0'>Version 2.3.0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-07-04T22:53:09Z",
  "number":2568,
  "title":"Version 2.3.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2568"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n_(none!)_\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: added kernel specializations for `awkward_ListOffsetArray_reduce_local_nextparents_64` by @jpivarski in https://github.com/scikit-hep/awkward/pull/2572\r\n\r\n## Other\r\n\r\n_(none!)_\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.3.0...v2.3.1\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.3.1'>Version 2.3.1</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-07-05T21:38:10Z",
  "number":2574,
  "title":"Version 2.3.1",
  "url":"https://github.com/scikit-hep/awkward/discussions/2574"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## What's Changed\r\n* fix: backport vendored mixin from #2534 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2583\r\n* fix: (v1) merging options should produce an option by @agoose77 in https://github.com/scikit-hep/awkward/pull/2582\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v1.10.3...v1.10.4\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v1.10.4'>Version 1.10.4</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-07-19T18:37:37Z",
  "number":2589,
  "title":"Version 1.10.4",
  "url":"https://github.com/scikit-hep/awkward/discussions/2589"
 },
 {
  "author":{
   "login":"jrueb"
  },
  "body":"I often encounter the problem of wanting to evaluate a function that is numpy-compatible on awkward arrays. Let's take as an example `scipy.stats.gamma.pdf`. I can do\r\n```python\r\na = np.array([1, 2])\r\nx = a + 2\r\np = scipy.stats.gamma.pdf(x, a)\r\n```\r\nBut if `a` is an awkward array (for example `a2 = ak.Array([[[1, 2], []], [None], [[None]]])`), I have to find another way.\r\nI found this old comment about unwrapping the array manually with `array.layout.contents`: https://github.com/scikit-hep/awkward/issues/489#issuecomment-711079353\r\nHowever, this is not trivial and handling everything correctly can be error-prone if the user is not so experienced with awkward layouts.\r\nWhat I would like to have is a functionality to easily obtain the awkward array from a function like `scipy.stats.gamma.pdf`. Using above example, this functionality would easily generate an array equal to `ak.Array([[p, []], [None], [[None]]])`.\r\nMaybe one can make a function called `ak.map_content` (or something like this), that does the unwrapping. For example:\r\n```python\r\na2 = ak.Array([[[1, 2], []], [None], [[None]]])\r\np2 = ak.map_content(scipy.stats.gamma.pdf, a2 + 2, a2)\r\n```\r\nOr maybe this functionality already exists? In this case, I am happy to learn more.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @jrueb, thanks for opening this discussion!\r\n\r\nWe have a function `ak.transform` that implements a recursive layout visitor. You can use this to walk down to the final level, whereby all arrays are 1D NumPy arrays:\r\n\r\n```python\r\ndef gamma_pdf(x, *args, loc=0, scale=1):\r\n    first, *remainder = ak.broadcast_arrays(x, *args, loc, scale)\r\n\r\n    def apply(inputs, **kwargs):\r\n        if all(layout.is_numpy for layout in inputs):\r\n            arrays = [x.to_backend_array() for x in inputs]\r\n            return ak.to_layout(\r\n                scipy.stats.gamma.pdf(*arrays)\r\n            )\r\n\r\n    return ak.transform(apply, first, *remainder, return_value=\"original\")\r\n```\r\n\r\nAlthough `ak.transform` performs broadcasting, `ak.broadcast_arrays` implements an additional step that permits broadcasting scalars against arrays, so it's useful to start with an explicit broadcast.\r\n\r\nThe above implementation does not tell you if the transformer did nothing \u2014 maybe we should add that as a feature. You can quickly define an outer-scope variable to ensure this (or define a complex `if` statement to catch the exit condition):\r\n```python\r\ndef gamma_pdf(x, *args, loc=0, scale=1):\r\n    first, *remainder = ak.broadcast_arrays(x, *args, loc, scale)\r\n\r\n    transformer_did_return = False\r\n\r\n    def apply(inputs, **kwargs):\r\n        nonlocal transformer_did_return\r\n        if all(layout.is_numpy for layout in inputs):\r\n            arrays = [x.to_backend_array() for x in inputs]\r\n\r\n            transformer_did_return = True\r\n            return ak.to_layout(\r\n                scipy.stats.gamma.pdf(*arrays)\r\n            )\r\n\r\n    result = ak.transform(apply, first, *remainder, return_value=\"original\")\r\n\r\n    if not transformer_did_return:\r\n        raise TypeError\r\n\r\n    return result\r\n```\r\n\r\nHopefully this helps to answer your question?",
     "createdAt":"2023-07-27T13:38:21Z",
     "number":6565463,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jrueb"
        },
        "body":"Thanks. That does what I wanted. One could create a utility function like this\r\n```python\r\ndef map_content(func, x, *args, **kwargs):\r\n    first, *remainder = ak.broadcast_arrays(x, *args, *kwargs.values())\r\n    kwargskeys = kwargs.keys()\r\n\r\n    transformer_did_return = False\r\n\r\n    def apply(inputs, **kwargs):\r\n        nonlocal transformer_did_return\r\n        if all(layout.is_numpy for layout in inputs):\r\n            arrays = [x.to_backend_array() for x in inputs]\r\n            kwarrays = dict(zip(kwargskeys, arrays[len(args) + 1:]))\r\n            arrays = arrays[:len(args) + 1]\r\n\r\n            transformer_did_return = True\r\n            return ak.to_layout(\r\n                func(*arrays, **kwarrays)\r\n            )\r\n\r\n    result = ak.transform(apply, first, *remainder, return_value=\"original\")\r\n\r\n    if not transformer_did_return:\r\n        raise TypeError\r\n\r\n    return result\r\n```\r\nGetting the results would look like this\r\n```python\r\na2 = ak.Array([[[1, 2], []], [None], [[None]]])\r\np2 = map_content(scipy.stats.gamma.pdf, a2 + 2, a2, loc=0)\r\n```\r\nWould this be something that could go into awkward?",
        "createdAt":"2023-07-27T15:43:23Z",
        "number":6566973
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"I will ping @jpivarski for a second opinion, but I've not made up my mind on this yet.\r\n\r\nWith #2595 and another PR to remove the need for `ak.broadcast_arrays`, we'd have something like\r\n```python\r\ndef gamma_pdf(x, *args, loc=0, scale=1):\r\n    def apply(inputs, **kwargs):\r\n        if all(layout.is_numpy for layout in inputs):\r\n            arrays = [x.to_backend_array() for x in inputs]\r\n            return ak.to_layout(\r\n                scipy.stats.gamma.pdf(*arrays)\r\n            )\r\n    return ak.transform(apply, x, *args, loc, scale, return_value=\"original\")\r\n```\r\n\r\nTo me, this seems fairly concise, but I can equally see a need to keep users in our L1 \"high-level user API\" in cases where they're wanting to use these kind of functions in their analyses.\r\n\r\n",
        "createdAt":"2023-07-27T15:49:48Z",
        "number":6567038
       },
       {
        "author":{
         "login":"grst"
        },
        "body":"A L1-level `apply` function could be useful for the users of my [scverse/scirpy](https://github.com/scverse/scirpy) package, see also [this discussion](https://discourse.scverse.org/t/how-to-edit-and-filter-awkward-array-created-by-scirpy/1660). Many of the users are actually python novices who just follow a tutorial, so I wouldn't dare to suggest them writing a custom transform function. ",
        "createdAt":"2023-08-07T20:58:22Z",
        "number":6662666
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"@grst could you provide some examples of functions like this? In the case of [your linked discussion](https://discourse.scverse.org/t/how-to-edit-and-filter-awkward-array-created-by-scirpy/1660), the new `ak.str` operations submodule looks like it will be useful!\r\n\r\n```pycon\r\n>>> import awkward as ak\r\n>>> data = ak.Array(\r\n...     [\r\n...         [\"TRBC2*00\", \"TRBC2*00\"],\r\n...         [\"TRBC1*00\", \"TRAC*00\", \"TRBC1*00\"],\r\n...         [\"TRBC2*00\", \"TRBC2*00\", \"TRAC*00\"],\r\n...         [\"TRBC2*00\", \"TRAC*00\"],\r\n...         [\"TRBC2*00\", \"TRAC*00\"],\r\n...     ]\r\n... )\r\n>>> result = ak.str.split_pattern(data, \"*\")\r\n>>> no_suffix = result[..., 0]\r\n>>> no_suffix.show()\r\n[['TRBC2', 'TRBC2'],\r\n ['TRBC1', 'TRAC', 'TRBC1'],\r\n ['TRBC2', 'TRBC2', 'TRAC'],\r\n ['TRBC2', 'TRAC'],\r\n ['TRBC2', 'TRAC']]\r\n```\r\n\r\nIt sounds like we might benefit from having something like `ak.apply_at_axis` which uses `ak.transform` to operate at a given axis.",
        "createdAt":"2023-08-07T21:04:33Z",
        "number":6662709
       },
       {
        "author":{
         "login":"grst"
        },
        "body":"I'll think about it again, but a `.str` interface likely covers most (if not all) of the things I had in mind. Is this already documented somewhere? I couldn't find that in the API docs",
        "createdAt":"2023-08-07T21:08:23Z",
        "number":6662742
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"@grst my English could have been clearer there \u2014 the new `ak.str` submodule is currently under develompent in #2616",
        "createdAt":"2023-08-07T21:10:25Z",
        "number":6662757
       }
      ],
      "totalCount":6
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-07-27T11:21:25Z",
  "number":2593,
  "title":"Create awkward array of same layout from numpy-compatible function",
  "url":"https://github.com/scikit-hep/awkward/discussions/2593"
 },
 {
  "author":{
   "login":"grst"
  },
  "body":"Hi, \r\n\r\nI'm looking for a vectorized operation to check for each element of an awkward array if it contained in a list of elements, e.g.\r\n\r\n```python\r\n>>> ak_isin(\r\n        ak.Array([['a', 'b', 'c'], ['b', 'c']]), \r\n        ['b', 'x']\r\n    )\r\n\r\n[[False, True, False],\r\n [True, False]]\r\n----------------------\r\ntype: 2 * var * bool\r\n```\r\n\r\nI came up with two solutions (see below), but I was wondering if there's something builtin that I'm overlooking or any other more efficient/more elegant approach. \r\n\r\n### Solution 1: equality + reduce\r\nLikely slow when `haystack` is large \r\n```python\r\nfrom functools import reduce\r\nimport operator\r\n\r\ndef ak_isin_reduce(arr, haystack):\r\n    return reduce(operator.or_, (arr == el for el in haystack))\r\n```\r\n\r\n### Solution 2: numba\r\n```python\r\nimport numba as nb\r\nimport awkward as ak\r\n\r\n@nb.njit()\r\ndef _ak_isin_numba_inner(arr, haystack, ab):\r\n    for row in arr:\r\n        ab.begin_list()\r\n        for v in row:\r\n            ab.append(v in haystack)\r\n        ab.end_list()\r\n    return ab\r\n\r\n\r\ndef ak_isin_numba(arr, haystack):\r\n    haystack = tuple(haystack)\r\n    return _ak_isin_numba_inner(arr, haystack, ak.ArrayBuilder()).snapshot()\r\n```\r\n\r\n### Mini-benchmark\r\n```python\r\n>>> import random\r\n>>> def make_random_array(n, max_el=5):\r\n        ab = ak.ArrayBuilder()\r\n        for _ in range(n):\r\n            ab.begin_list()\r\n            for i in range(random.randint(0, max_el)):\r\n                ab.append(chr(i + 65) * 5)\r\n            ab.end_list()\r\n        return ab.snapshot()\r\n>>> arr = make_random_array(3000)\r\n[[],\r\n ['AAAAA'],\r\n ['AAAAA', 'BBBBB'],\r\n [],\r\n ...\r\n ['AAAAA', 'BBBBB', 'CCCCC', 'DDDDD']]\r\n-----------------------------------------------\r\ntype: 3000 * var * string\r\n\r\n>>> %%timeit\r\n>>> ak_isin_reduce(arr, [\"AAAAA\", \"CCCCC\", \"XXXXX\"])\r\n5.01 ms \u00b1 47.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n\r\n>>> %%timeit\r\n>>> ak_isin_numba(arr, [\"AAAAA\", \"CCCCC\", \"XXXXX\"])\r\n1.58 ms \u00b1 8.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\r\n```\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"This is now something that [`ak.str.is_in`](https://awkward-array.org/doc/main/reference/generated/ak.str.is_in.html) will provide (soon to be released)!",
     "createdAt":"2023-08-11T11:22:54Z",
     "number":6700656,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Wait\u2014although `ak.str.is_in` satisfies this particular use-case, it doesn't cover cases that a NEP-18 extension of `np.isin` would cover, and I've seen those requests come up. (For example, check to see if a `pdgId` is in a set of integers corresponding to a set of similar particles.)\r\n\r\nAlso, let's not close Discussions. This is how they're different from Issues: Issues represent work to be done and we want to close them so that we can easily see what still needs to be done. Discussions remain useful to the community after the question is answered, since someone else might have that same question. If we view this as a feature request, then it should be converted into an Issue so that it can be closed when the feature is provided. But since @grst provided nicely worked-out examples of how to implement this without a built-in function, I think those examples would be useful to other people, even if what they need is not exactly `ak.str.is_in` or `np.isin`. So I'll reopen this.",
     "createdAt":"2023-08-11T16:08:00Z",
     "number":6703348,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Oh, did it _automatically_ close because @grst selected an answer? If so, I hope I can find a way to override that. We want these Discussions to remain visible!",
        "createdAt":"2023-08-11T16:08:57Z",
        "number":6703356
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"gipert"
     },
     "body":"I was looking for `ak.isin` too today. Would be very useful to have!",
     "createdAt":"2023-10-14T16:15:12Z",
     "number":7281488,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":3
  },
  "createdAt":"2023-08-01T17:52:55Z",
  "number":2602,
  "title":"Awkward equivalent of numpy.isin",
  "url":"https://github.com/scikit-hep/awkward/discussions/2602"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: add support for expected termination of transform functions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2595\r\n* feat: export error classes by @agoose77 in https://github.com/scikit-hep/awkward/pull/2613\r\n* feat: unpickle arrays made in Awkward v1 (as v2). by @jpivarski in https://github.com/scikit-hep/awkward/pull/2604\r\n* feat: use pyarrow for string functions by @jpivarski in https://github.com/scikit-hep/awkward/pull/2616\r\n* feat: add support for dictionary encoding from Arrow by @agoose77 in https://github.com/scikit-hep/awkward/pull/2630\r\n* feat: add CPU kernel for `to_numpy` support for strings/bytestrings by @agoose77 in https://github.com/scikit-hep/awkward/pull/2631\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: don't decorate non-`Exception` subclasses by @agoose77 in https://github.com/scikit-hep/awkward/pull/2587\r\n* fix: use `to_backend_array()` instead of `asarray` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2592\r\n* fix: `artefacts` \u2192 `artifacts` in `pyproject.toml` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2612\r\n* fix: adjust for numexpr 2.8.5, which hid getContext's frame_depth argument by @jpivarski in https://github.com/scikit-hep/awkward/pull/2617\r\n* fix: add inline to prevent multiple definitions by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2606\r\n* fix: support lists of strings in `ak.zip` with `optiontype_outside_record=True` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2623\r\n* fix: support `counts=len(array)` in `ak.unflatten` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2632\r\n* fix: support non `int64` index in `ListArray`'s `pad_none` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2634\r\n* fix: `assert nextlen == 0` in reducer should also allow `unknown_length` by @jpivarski in https://github.com/scikit-hep/awkward/pull/2610\r\n\r\n## Other\r\n\r\n* refactor: add new `module` and `name` arguments to `high_level_function` decorator by @agoose77 in https://github.com/scikit-hep/awkward/pull/2620\r\n* docs: add guide on unflattening and grouping by @agoose77 in https://github.com/scikit-hep/awkward/pull/2622\r\n* docs: remove reference to old arrayclass by @agoose77 in https://github.com/scikit-hep/awkward/pull/2640\r\n* docs: initial user-guide pass for string functions by @agoose77 in https://github.com/scikit-hep/awkward/pull/2635\r\n* chore(deps): bump pypa/cibuildwheel from 2.13.1 to 2.14.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2584\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.7 to 1.8.8 by @dependabot in https://github.com/scikit-hep/awkward/pull/2580\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2565\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2585\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2619\r\n* chore: use 2x faster black mirror by @henryiii in https://github.com/scikit-hep/awkward/pull/2633\r\n* chore: drop 3.7 classifier by @agoose77 in https://github.com/scikit-hep/awkward/pull/2636\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.8 to 1.8.9 by @dependabot in https://github.com/scikit-hep/awkward/pull/2639\r\n* chore(deps): bump pypa/cibuildwheel from 2.14.1 to 2.15.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2629\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.3.1...v2.3.2\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.3.2'>Version 2.3.2</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-08-11T22:30:28Z",
  "number":2642,
  "title":"Version 2.3.2",
  "url":"https://github.com/scikit-hep/awkward/discussions/2642"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## New features\r\n\r\n* feat: add support for `__arrow_array__` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2650\r\n* feat: add `__dlpack__`, `from_dlpack` support by @agoose77 in https://github.com/scikit-hep/awkward/pull/2649\r\n\r\n## Bug-fixes and performance\r\n\r\n* fix: rename cppyy test by @ianna in https://github.com/scikit-hep/awkward/pull/2643\r\n* fix: support `highlevel=False` in all branches for `from_parquet` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2646\r\n* fix: support non-hashable values in `parameters_union` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2651\r\n* fix: remove unneeded cast by @agoose77 in https://github.com/scikit-hep/awkward/pull/2653\r\n\r\n## Other\r\n\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.9 to 1.8.10 by @dependabot in https://github.com/scikit-hep/awkward/pull/2641\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.3.2...v2.3.3\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.3.3'>Version 2.3.3</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-08-17T13:10:40Z",
  "number":2655,
  "title":"Version 2.3.3",
  "url":"https://github.com/scikit-hep/awkward/discussions/2655"
 },
 {
  "author":{
   "login":"CaueSousa"
  },
  "body":"Hello, dear community!\r\n\r\nI'm trying to figure out if is possible to do something with the help of Awkward.\r\n\r\nI have an ak array with `'21104832 * 23 * float64'` dimensions, where some lines share the same values on the first two columns:\r\n\r\n| Column 1 | Column  2| ...| Column  23|\r\n| ------------- | ------------- | ------------- | ------------- |\r\n|x1 | y1 | ...  | arbitrary|\r\n|x2 | y2 | ...  | arbitrary|\r\n|x2 | y2 | ...  | arbitrary|\r\n|x2 | y2 | ...  | arbitrary|\r\n|x3 | y3 | ...  | arbitrary|\r\n|x4 | y4 | ...  | arbitrary|\r\n|x4 | y4 | ...  | arbitrary|\r\n|x4 | y4 | ...  | arbitrary|\r\n|x4 | y4 | ...  | arbitrary|\r\n\r\n\r\nThe lines that share the same values on the first two columns are in a sequence.\r\n\r\nI would like to know if there's a way to change this ak array in order to keep these lines with same values on the first two columns separated from the other \"groups\". \r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @CaueSousa! I'm interpreting your question as:\r\n\r\nYou want to split an array of length `21104832` into sub-lists, where each sub-list contains the rows with identical leading two columns. Is this correct?\r\n\r\nOne thing that would be helpful to know; is it ever possible that the first column and second column of two rows are not both equal or non-equal? i.e., is this\r\n```\r\n10 1000 ...\r\n11 1000 ...\r\n```\r\nor this\r\n```\r\n11 1001 ...\r\n11 1000 ...\r\n```\r\npossible?\r\n\r\nAdditionally, does the order of this array matter? Can we re-order the rows, as long as the groups are preserved?",
     "createdAt":"2023-08-21T22:04:34Z",
     "number":6785674,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"We sent at the same time, and it looks like you had a different take on that this problem is.",
        "createdAt":"2023-08-21T22:07:21Z",
        "number":6785690
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"@jpivarski your answer is where my mind was going! I was unsure as to the requirement to split on both columns, but I accidentally found the solution :)\r\n\r\n@CaueSousa I wasn't initially sure how easy this would be. It turns out that there's a neat trick (or at least, I think it's a trick!) that let's do this using `run_lengths` without any complex slicing.\r\n\r\nFirst, let's define an example array\r\n```pycon\r\n>>> array = ak.Array(\r\n    [\r\n        # A\r\n        [0, 0, 1],\r\n        [0, 0, 2],\r\n        # B\r\n        [1, 1, 3],\r\n        # C\r\n        [2, 2, 4],\r\n        # D\r\n        [2, 3, 5],\r\n        [2, 3, 6],\r\n    ]\r\n)\r\n```\r\nLet's find the lengths of the \"runs\" of same-value items in the first column:\r\n```pycon\r\n>>> runs_in_col_0 = ak.run_lengths(array[:, 0])\r\n>>> runs_in_col_0\r\n[2,\r\n 1,\r\n 3]\r\n```\r\nWe can use this to introduce a new dimension that groups our rows by these runs in column 0:\r\n```pycon\r\n>>> array_by_col_0 = ak.unflatten(array, runs_in_col_0, axis=0)\r\n>>> array_by_col_0\r\n[[[0, 0, 1], [0, 0, 2]],\r\n [[1, 1, 3]],\r\n [[2, 2, 4], [2, 3, 5], [2, 3, 6]]]\r\n```\r\nThen we can compute the runs in the second column *of this unflattened array*\r\n```pycon\r\n>>> runs_in_col_1_of_grouped_by_0 = ak.run_lengths(array_by_col_0[..., 1])\r\n>>> runs_in_col_1_of_grouped_by_0\r\n[[2],\r\n [1],\r\n [1, 2]]\r\n```\r\nYou can see that this array has the same structure as our unflattened `array_by_col_0` array. This is because `run_lengths` always operates at `axis=-1`, which means that `ak.run_lengths(array_by_col_0[..., 1])` will always stop counting a run if the sublist in `array_by_col_0[..., 1]` ends. Let's remind ourselves what `array_by_col_0[..., 1]` looks like:\r\n```pycon\r\n>>> array_by_col_0[..., 1]\r\n[[0, 0],\r\n [1],\r\n [2, 3, 3]]\r\n```\r\n\r\nVisually, our runs should be `[[2], [1], [1, 2]]`, which is what we computed for `runs_in_col_1_of_grouped_by_0`.  \r\n\r\nNotice that the sums of `runs_in_col_1_of_grouped_by_0` and `runs_in_col_0` are both 6. If we flatten `runs_in_col_1_of_grouped_by_0`\r\n```python\r\n>>> runs_in_col_1_of_grouped_by_0_flat = ak.flatten(runs_in_col_1_of_grouped_by_0, axis=None)\r\n>>> runs_in_col_1_of_grouped_by_0_flat\r\n[2,\r\n 1,\r\n 1,\r\n 2]\r\n```\r\nwe can use the resulting array of counts to unflatten *the original array*:\r\n```pycon\r\n>>> ak.unflatten(array, runs_in_col_1_of_grouped_by_0_flat, axis=0)\r\n[[[0, 0, 1], [0, 0, 2]],\r\n [[1, 1, 3]],\r\n [[2, 2, 4]],\r\n [[2, 3, 5], [2, 3, 6]]]\r\n```\r\nThat's the trick \u2014 using the counts computed over the temporary `array_by_col_0` array to unflatten the _original_ array. We can do this only because the total number of rows is unchanged!\r\n\r\nThere are other ways to do this, but this approach seems the most performant to me.",
        "createdAt":"2023-08-21T22:30:44Z",
        "number":6785802
       },
       {
        "author":{
         "login":"CaueSousa"
        },
        "body":"Hi, @agoose77 \r\n\r\nYour assumptions were correct! In my context, each row carries information about an object called track(the trajectory of a charged particle) and the jet('spray' of particles) in which this track is. The first two columns are the information of the jets, and so, lines with the same values on the first two columns are inside the same jet.\r\n\r\nThis piece does the trick precisely!\r\n\r\n@agoose77 , @jpivarski you're wizards, guys. Thank you so much, seriously!",
        "createdAt":"2023-08-22T02:03:51Z",
        "number":6786823
       }
      ],
      "totalCount":3
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Oddly enough, there is a function for this. You can use [ak.run_lengths](https://awkward-array.org/doc/main/reference/generated/ak.run_lengths.html) to determine how many values are equal (contiguously), and then [ak.unflatten](https://awkward-array.org/doc/main/reference/generated/ak.unflatten.html) to make groups of those sizes. You might need to flatten and select an individual column before applying this operation, though.\r\n\r\nThe links to documentation point to similar examples.",
     "createdAt":"2023-08-21T22:06:09Z",
     "number":6785685,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-08-21T21:38:30Z",
  "number":2664,
  "title":"Changing shape based on rows with equal values",
  "url":"https://github.com/scikit-hep/awkward/discussions/2664"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: `Form.expected_from_buffers` for names/dtypes `ak.from_buffers` needs. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2660\r\n* feat: support out-of-band buffers in pickling by @agoose77 in https://github.com/scikit-hep/awkward/pull/2665\r\n* feat: add `touch_data` to `ak.typetracer` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2672\r\n* feat: add support for custom picklers by @agoose77 in https://github.com/scikit-hep/awkward/pull/2682\r\n* feat!: deprecate `forget_length`, add parameters to `typetracer_with_report` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2671\r\n* feat!: remove deprecations for 1.4.0 release by @agoose77 in https://github.com/scikit-hep/awkward/pull/2688* fix: support placeholders in shape-only routines by @agoose77 in https://github.com/scikit-hep/awkward/pull/2652\r\n\r\n## Bug-fixes and performance\r\n* fix: multiple-output ufuncs e.g. `divmod` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2654\r\n* fix: support unflattening a typetracer-backed array at `axis != 0` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2657\r\n* fix: fix IPython inspection by @agoose77 in https://github.com/scikit-hep/awkward/pull/2658\r\n* fix: using `numba.core.errors.Numba<Error>` instead of `Error` in a Numba typing context. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2659\r\n* fix: raise error for invalid object in `from_dlpack` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2662\r\n* fix: fix/harden broadcasting through tuples by @agoose77 in https://github.com/scikit-hep/awkward/pull/2663\r\n* fix: update string to search for in determing parquet column list separator by @douglasdavis in https://github.com/scikit-hep/awkward/pull/2670\r\n* fix: guard `broadcast_and_apply` from mixed backends by @agoose77 in https://github.com/scikit-hep/awkward/pull/2678\r\n* fix: support typetracer in `ak.str.` operations by @agoose77 in https://github.com/scikit-hep/awkward/pull/2679\r\n\r\n## Other\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2645\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2677\r\n* chore: bump numba and pyarrow test pins by @agoose77 in https://github.com/scikit-hep/awkward/pull/2684\r\n* chore: bump C++ standard version by @agoose77 in https://github.com/scikit-hep/awkward/pull/2685\r\n* chore(deps): bump aws-actions/configure-aws-credentials from 2 to 3 by @dependabot in https://github.com/scikit-hep/awkward/pull/2669\r\n* test: keep testing Windows 32-bit. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2681\r\n\r\n\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.3.3...v2.4.0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.0'>Version 2.4.0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-04T19:49:21Z",
  "number":2690,
  "title":"Version 2.4.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2690"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## Other\r\n- Fix docs version selector\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.0...v2.4.1\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.1'>v2.4.1</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-04T20:53:31Z",
  "number":2691,
  "title":"Version 2.4.1",
  "url":"https://github.com/scikit-hep/awkward/discussions/2691"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## Bug-fixes and performance\r\n* fix: support placeholder arrays in `ArrayModuleNumpyLike.frombuffer` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2693\r\n* fix: drop zero-cost views of `ak.Array` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2697\r\n\r\n## Other\r\n* chore(deps): bump actions/checkout from 3 to 4 by @dependabot in https://github.com/scikit-hep/awkward/pull/2689\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2692\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.1...v2.4.2\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.2'>Version 2.4.2</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-06T19:26:24Z",
  "number":2698,
  "title":"Version 2.4.2",
  "url":"https://github.com/scikit-hep/awkward/discussions/2698"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: add ak_to_feather and ak_from_feather functions by @zbilodea in https://github.com/scikit-hep/awkward/pull/2683\r\n* feat: expose simplification from `ak.from_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2713\r\n\r\n## Bug-fixes and performance\r\n* fix: unpickling of `unknown_length` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2710\r\n* fix: support placeholders in `from_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2714\r\n\r\n## Other\r\n* chore: try to reintroduce Python 3.12, now that NumPy has released a beta. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2644\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2705\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2715* chore(deps): bump aws-actions/configure-aws-credentials from 3 to 4 by @dependabot in https://github.com/scikit-hep/awkward/pull/2706\r\n* chore(deps): bump docker/setup-qemu-action from 2.2.0 to 3.0.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2707\r\n* docs: update obsolete comment in docs (relevant only in v1). by @jpivarski in https://github.com/scikit-hep/awkward/pull/2699\r\n\r\n## New Contributors\r\n* @zbilodea made their first contribution in https://github.com/scikit-hep/awkward/pull/2683\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.2...v2.4.3\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.3'>Version 2.4.3</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-19T21:29:43Z",
  "number":2717,
  "title":"Version 2.4.3",
  "url":"https://github.com/scikit-hep/awkward/discussions/2717"
 },
 {
  "author":{
   "login":"WWWonderer"
  },
  "body":"For the code below:\r\n\r\n```\r\narr = ak.Array(\r\n    [\r\n        [\r\n            [1, 2], \r\n            [1]\r\n        ],\r\n        [\r\n            [1], \r\n            [1], \r\n            [1]\r\n        ]\r\n    ]\r\n)\r\n\r\nprint(f'mean: {ak.mean(arr)}') # prints mean: 1.1666666666666667\r\nprint(f'std: {ak.std(arr)}') # error\r\n```\r\nThe mean works fine while the std gives me error with following stack trace:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/awkward/_dispatch.py](https://localhost:8080/#) in dispatch(*args, **kwargs)\r\n     59                 try:\r\n---> 60                     next(gen_or_result)\r\n     61                 except StopIteration as err:\r\n\r\n19 frames\r\nValueError: cannot broadcast nested list (in compiled code: https://github.com/scikit-hep/awkward/blob/awkward-cpp-23/awkward-cpp/src/cpu-kernels/awkward_ListArray_broadcast_tooffsets.cpp#L27)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nValueError                                Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/awkward/_errors.py](https://localhost:8080/#) in handle_exception(self, cls, exception)\r\n     80             self.decorate_exception(cls, exception)\r\n     81         else:\r\n---> 82             raise self.decorate_exception(cls, exception)\r\n     83 \r\n     84     def decorate_exception(self, cls: type[E], exception: E) -> E:\r\n\r\nValueError: cannot broadcast nested list (in compiled code: https://github.com/scikit-hep/awkward/blob/awkward-cpp-23/awkward-cpp/src/cpu-kernels/awkward_ListArray_broadcast_tooffsets.cpp#L27)\r\n\r\nThis error occurred while calling\r\n\r\n    ak.std(\r\n        <Array [[[1, 2], [1]], [[1], ...]] type='2 * var * var * int64'>\r\n    )\r\n```\r\nThis seems very counterintuitive to me as the std is nothing but some operations on mean. What can be done in mean in terms of broadcasting should also be doable in std. Is there a reason this is happening and how to solve this issue? Thanks!\r\n\r\nEdit: \r\n\r\nI went a bit deeper into the codebase and found this in variance implementation which is used by std (https://github.com/scikit-hep/awkward/blob/main/src/awkward/operations/ak_var.py):\r\n```\r\n            sumwxx = ak.operations.ak_sum._impl(\r\n                (x - xmean) ** 2, # maybe here is the broadcasting??? \r\n                axis,\r\n                keepdims=True,\r\n                mask_identity=True,\r\n                highlevel=True,\r\n                behavior=None,\r\n            )\r\n```\r\nIn the implementation of mean (https://github.com/scikit-hep/awkward/blob/main/src/awkward/operations/ak_mean.py#L156) only x is passed into ak_sum:\r\n```\r\n            sumwx = ak.operations.ak_sum._impl(\r\n                x,\r\n                axis,\r\n                keepdims=True,\r\n                mask_identity=True,\r\n                highlevel=True,\r\n                behavior=None,\r\n            )\r\n```\r\nMaybe this is the cause of the issue? But is there a way to fix it? \r\n",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-27T16:09:42Z",
  "number":2726,
  "title":"Why does ak.mean and ak.std behave differently?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2726"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New features\r\n* feat: add `buffer_key` to `typetracer_with_report` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2719\r\n\r\n## Bug-fixes and performance\r\n* fix: catch cases in which fields required by a JSON schema are not in the JSON object by @jpivarski in https://github.com/scikit-hep/awkward/pull/2712\r\n* fix: support concrete buffers in `TypeTracer.frombuffer` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2718\r\n* fix: make the examples consistent with the changes in #2553 by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2725\r\n* fix: reduction with `axis=None`, `keepdims=True` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2728\r\n\r\n## Other\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2722\r\n* chore(deps): bump pypa/cibuildwheel from 2.15.0 to 2.16.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2716\r\n* chore(deps): bump amannn/action-semantic-pull-request from 5.2.0 to 5.3.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2721\r\n* chore(deps): bump pypa/cibuildwheel from 2.16.0 to 2.16.1 by @dependabot in https://github.com/scikit-hep/awkward/pull/2723\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.3...v2.4.4\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.4'>Version 2.4.4</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-09-29T10:52:43Z",
  "number":2730,
  "title":"Version 2.4.4",
  "url":"https://github.com/scikit-hep/awkward/discussions/2730"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"## What's Changed\r\n\r\n* fix: update backport for changes in Numba, NumExpr, Arrow, and RDataFrame by @ianna and @jpivarski in https://github.com/scikit-hep/awkward/pull/2735\r\n\r\nBasically, third-party libraries have been changing. This backport brings Awkward 1.x up to speed with them.\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v1.10.4...v1.10.5\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v1.10.5'>Version 1.10.5</a>.</em>",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The [automated upload failed](https://github.com/scikit-hep/awkward/actions/runs/6411063916), but I uploaded it manually: https://pypi.org/project/awkward/1.10.5/\r\n\r\nTested pip-install:\r\n\r\n```bash\r\nmamba create -n awkward1 python=3.10 numpy packaging\r\nmamba activate awkward1\r\npip install 'awkward<2'\r\n```\r\n\r\n```\r\nCollecting awkward<2\r\n  Obtaining dependency information for awkward<2 from https://files.pythonhosted.org/packages/4d/7e/364a5a067005e5d9f67b4cc9009827d02389699ba0980e695987a521e467/awkward-1.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n  Downloading awkward-1.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\r\nRequirement already satisfied: numpy>=1.13.1 in ./mambaforge/envs/awkward1/lib/python3.10/site-packages (from awkward<2) (1.26.0)\r\nRequirement already satisfied: packaging in ./mambaforge/envs/awkward1/lib/python3.10/site-packages (from awkward<2) (23.2)\r\nDownloading awkward-1.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\r\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.2/12.2 MB 84.9 MB/s eta 0:00:00\r\nInstalling collected packages: awkward\r\nSuccessfully installed awkward-1.10.5\r\n```\r\n\r\n```python\r\n>>> import awkward as ak\r\n>>> ak.__version__\r\n'1.10.5'\r\n>>> ak.sum(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]), axis=1)\r\n<Array [6.6, 0, 9.9] type='3 * float64'>\r\n```\r\n\r\n(`ak.sum(\u00b7, axis=1)` requires access to Awkward's C++ part, so it's a good mini-test.)",
     "createdAt":"2023-10-05T00:22:20Z",
     "number":7192524,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-10-04T20:19:02Z",
  "number":2737,
  "title":"Version 1.10.5",
  "url":"https://github.com/scikit-hep/awkward/discussions/2737"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## What's Changed\r\n\r\n## New features\r\n* feat: add `recursive` argument to `expected_from_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2724\r\n* feat: infer unknown lengths from context in `from_buffers` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2732\r\n\r\n## Bug-fixes and performance\r\n* fix: don't use `np.asarray` on `Index` or `Content` objects by @agoose77 in https://github.com/scikit-hep/awkward/pull/2740\r\n* fix: swap names for `__dlpack__` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2741\r\n* fix: `__array__` accepts positional arguments by @agoose77 in https://github.com/scikit-hep/awkward/pull/2744* test: add dask-awkward to at least one of our tests. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2739\r\n\r\n## Other\r\n* chore(deps): bump pypa/cibuildwheel from 2.16.1 to 2.16.2 by @dependabot in https://github.com/scikit-hep/awkward/pull/2736\r\n* ci: improve deployment environment UX by @agoose77 in https://github.com/scikit-hep/awkward/pull/2742\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.4...v2.4.5\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.5'>Version 2.4.5</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-10-06T17:40:45Z",
  "number":2745,
  "title":"Version 2.4.5",
  "url":"https://github.com/scikit-hep/awkward/discussions/2745"
 },
 {
  "author":{
   "login":"pankajp"
  },
  "body":"I'm implementing a DAG with awkward arrays, storing operations (nodes) and data (edges) as two arrays in a numba structref based on the numba docs.\r\nI am having trouble implementing graph traversal which works in numba). I'm even ready to accept implementing it in a obhmode fallback if that's the only possible way.\r\nHere's the snippet I have till now.\r\n\r\n\r\n```python\r\nimport awkward as ak\r\nimport numba as nb\r\nimport numpy as np\r\nimport weakref\r\nfrom numba import njit\r\nfrom numba.core import types\r\nfrom numba.experimental import structref\r\nimport itertools\r\nimport collections\r\n\r\n\"\"\"Define a DAG graph of operations and data.\r\nEach operation can have 0 or more data as input and 0 or more data as output\r\nEach data can have an optional input operation (which is generating the data), and multiple operations where it is required as input\r\n\r\nChallange: Implement the Data.input() method which returns an Operation or None in numba mode, by hook or by crook (nb.objmode())\r\n\"\"\"\r\n\r\n# Define a StructRef.\r\n# `structref.register` associates the type with the default data model.\r\n# This will also install getters and setters to the fields of\r\n# the StructRef.\r\n@structref.register\r\nclass GraphType(types.StructRef):\r\n    def preprocess_fields(self, fields):\r\n        # This method is called by the type constructor for additional\r\n        # preprocessing on the fields.\r\n        # Here, we don't want the struct to take Literal types.\r\n        return tuple((name, types.unliteral(typ)) for name, typ in fields)\r\n\r\n\r\n# Define a Python type that can be use as a proxy to the StructRef\r\n# allocated inside Numba. Users can construct the StructRef via\r\n# the constructor for this type in python code and jit-code.\r\n\r\n# The weakref cache dict to get back the graph from the operations and layers\r\n# Note: Use of eval to access these to avoid pickling errors\r\n_graph_cache = weakref.WeakValueDictionary()\r\n_graph_types_cache = weakref.WeakKeyDictionary()\r\n_graph_idx_seq = itertools.count()\r\nclass Graph(structref.StructRefProxy):\r\n    def __new__(cls, ops, dat):\r\n        graph_idx = next(_graph_idx_seq)\r\n        ops = ak.Array(ops, with_name='Operation', behavior={\r\n            'Operation':Operation,\r\n            'graph': graph_idx,\r\n        })\r\n        dat = ak.Array(dat, with_name='Data', behavior={\r\n            'Data': Data,\r\n            'graph': graph_idx,\r\n            ('__numba_typer__','Data','input', ()): Data._input__numba_typer__,\r\n            ('__numba_lower__','Data','input', ()): Data._input__numba_lower__,\r\n        })\r\n        res = structref.StructRefProxy.__new__(cls, ops, dat)\r\n        res.ops = ops\r\n        res.dat = dat\r\n        eval('_graph_cache')[graph_idx] = res\r\n        eval('_graph_types_cache')[res] = nb.typeof(ops), nb.typeof(ops[0]), nb.typeof(dat), nb.typeof(dat[0])\r\n        return res\r\n\r\n\r\n# This associates the proxy with MyStructType for the given set of\r\n# fields. Notice how we are not constraining the type of each field.\r\n# Field types remain generic.\r\nstructref.define_proxy(Graph, GraphType, [\"ops\", \"dat\"])\r\n\r\n\r\nclass Operation(ak.Record):\r\n    def graph(self):\r\n        return get_graph_from_idx(self.behavior['graph'])\r\n    def inputs(self):\r\n        return [self.graph().dat[idx] for idx in self.inputs_idx]\r\n    def outputs(self):\r\n        return [self.graph().dat[idx] for idx in self.outputs_idx]\r\n\r\ndef get_graph_from_idx(idx):\r\n    return eval('_graph_cache')[idx]\r\n\r\ndef _get_types(idx):\r\n    return eval('_graph_types_cache')[eval('_graph_cache')[idx]]\r\n\r\nclass Data(ak.Record):\r\n    def graph(self):\r\n        return get_graph_from_idx(self.behavior['graph'])\r\n    def input(self):\r\n        print('input()', self)\r\n        return self.graph().ops[self.input_idx] if self.input_idx >= 0 else None\r\n    def outputs(self):\r\n        return [self.graph().ops[idx] for idx in self.outputs_idx]\r\n\r\n    def _input__numba_typer__(akt, extra=()):\r\n        return nb.types.Optional(_get_types(akt.behavior['graph'])[1])()\r\n\r\n    def _input__numba_lower__(context, builder, sig, args):\r\n        print(f'_input__numba_lower__: sig.args={[type(a) for a in sig.args]}, sig.return_type={type(sig.return_type)}, {len(args)=}')\r\n        ret_type = sig.return_type\r\n        def input_lower(dat):\r\n            # Fixme: TypingError: Failed in nopython mode pipeline\r\n            print('get_node() for:', dat.idx)\r\n            with nb.objmode(inp=ret_type):\r\n                inp = dat.input()\r\n            return inp\r\n        return context.compile_internal(builder, input_lower, sig, args)\r\n\r\noperations = ak.Array({\r\n    'idx': range(3),\r\n    'inputs_idx': [[], [0,1],[1,2]],\r\n    'outputs_idx': [[1],[2,3],[]],\r\n})\r\ndata = ak.Array({\r\n    'idx':range(4),\r\n    'input_idx': [-1, 0, 1, 1],\r\n    'input_port': [-1, 0, 0, 1],\r\n    'outputs_idx': [[1], [1,2], [2], []],\r\n})\r\nextra_op_params = {'prop1':np.sin(np.arange(3))}  # Arbitrary extra fields\r\nfor k, v in extra_op_params.items():\r\n    operations[k] = v\r\n\r\ng = Graph(operations, data)\r\n\r\n\r\n@nb.njit()\r\ndef func(l, is_compiled=False):\r\n    print('data:', l.idx, l)\r\n    with nb.objmode():\r\n        print('objmode input:', l.input())\r\n    inp = l.input()\r\n    if inp is None:\r\n        print('inp:', 'is None')\r\n    else:\r\n        print('inp:', inp)\r\n    print('Done:', is_compiled)\r\nfunc.py_func(g.dat[1])\r\nprint('----------------')\r\nfunc(g.dat[1], True)\r\n```\r\n\r\nI've run out of ideas to implement this. The error I'm getting is:\r\n```\r\ndata: 1 {idx: 1, input_idx: 0, input_port: 0, outputs_idx: [1, 2]}\r\ninput() {idx: 1, input_idx: 0, input_port: 0, outputs_idx: [1, 2]}\r\nobjmode input: {idx: 0, inputs_idx: [], outputs_idx: [1], prop1: 0}\r\ninput() {idx: 1, input_idx: 0, input_port: 0, outputs_idx: [1, 2]}\r\ninp: {idx: 0, inputs_idx: [], outputs_idx: [1], prop1: 0}\r\nDone: False\r\n----------------\r\n_input__numba_lower__: sig.args=[<class 'awkward._connect.numba.arrayview.RecordViewType'>], sig.return_type=<class 'numba.core.types.misc.Optional'>, len(args)=1\r\n---------------------------------------------------------------------------\r\nTypingError                               Traceback (most recent call last)\r\nCell In [2], line 135\r\n    133 func.py_func(g.dat[1])\r\n    134 print('----------------')\r\n--> 135 func(g.dat[1], True)\r\n\r\nFile /lan/csv/geomrd3/pankaj/proj/code/pegasus_profile/lib/python/pyenv/lib/python3.10/site-packages/numba/core/dispatcher.py:468, in _DispatcherBase._compile_for_args(self, *args, **kws)\r\n    464         msg = (f\"{str(e).rstrip()} \\n\\nThis error may have been caused \"\r\n    465                f\"by the following argument(s):\\n{args_str}\\n\")\r\n    466         e.patch_message(msg)\r\n--> 468     error_rewrite(e, 'typing')\r\n    469 except errors.UnsupportedError as e:\r\n    470     # Something unsupported is present in the user code, add help info\r\n    471     error_rewrite(e, 'unsupported_error')\r\n\r\nFile /lan/csv/geomrd3/pankaj/proj/code/pegasus_profile/lib/python/pyenv/lib/python3.10/site-packages/numba/core/dispatcher.py:409, in _DispatcherBase._compile_for_args.<locals>.error_rewrite(e, issue_type)\r\n    407     raise e\r\n    408 else:\r\n--> 409     raise e.with_traceback(None)\r\n\r\nTypingError: Failed in nopython mode pipeline (step: Handle with contexts)\r\nFailed in nopython mode pipeline (step: native lowering)\r\nFailed in nopython mode pipeline (step: Handle with contexts)\r\nFailed in nopython mode pipeline (step: nopython frontend)\r\nInternal error at <numba.core.typeinfer.CallConstraint object at 0x2abc2ec61e70>.\r\nmust be builtin_function_or_method\r\nDuring: resolving callee type: type(ObjModeLiftedWith(<function Data._input__numba_lower__.<locals>.input_lower at 0x2abc2ea9e290>))\r\nDuring: typing of call at /tmp/ipykernel_67891/2955320401.py (99)\r\n\r\nEnable logging at debug level for details.\r\n\r\nFile \"../../../../../tmp/ipykernel_67891/2955320401.py\", line 99:\r\n<source missing, REPL/exec in use?>\r\n\r\nDuring: lowering \"inp = call $72load_method.1(func=$72load_method.1, args=[], kws=(), vararg=None, varkwarg=None, target=None)\" at /tmp/ipykernel_67891/2955320401.py (127)\r\n```",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"What is `.driver()` in this context?",
     "createdAt":"2023-10-07T00:24:39Z",
     "number":7214454,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"pankajp"
        },
        "body":"That was a typo, `driver` was an earlier alias for `input`. I've updated the snippet now, but there's no change in the error.",
        "createdAt":"2023-10-07T00:59:25Z",
        "number":7214556
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"pankajp"
     },
     "body":"Changing the implementation to \r\n\r\n```python\r\n    def _input__numba_lower__(context, builder, sig, args):\r\n        print(f'_driver__numba_lower__: sig.args={[type(a) for a in sig.args]}, sig.return_type={type(sig.return_type)}, {len(args)=}')\r\n        ret_type = sig.return_type\r\n        @nb.njit(ret_type(*sig.args))\r\n        def get_data_input(dat):\r\n            with nb.objmode(inp=ret_type):\r\n                inp = dat.input()\r\n            return inp\r\n        def input_lower(dat):\r\n            # Fixme: TypingError: Failed in nopython mode pipeline\r\n            print('get_node() for:', dat.idx)\r\n            return get_data_input(dat)\r\n        return context.compile_internal(builder, input_lower, sig, args)\r\n```\r\n\r\nresults in another strange numba error:\r\n\r\n```\r\nRuntimeError: missing Environment: _ZN08NumbaEnv8__main__4Data21_input__numba_lower__12_3clocals_3e11input_lowerB3v19B42c8tJTC_2fWQI8IW1CiAAYKPM6RBFDjESZRVAJmaQIAEN2ak19RecordViewType_28ak14ArrayView_28ak23RecordArrayType_28_28ak71NumpyArrayType_28array_28int64_2c_201d_2c_20C_29_2c_20_7b_7d_29_2c_20ak71NumpyArrayType_28array_28int64_2c_201d_2c_20C_29_2c_20_7b_7d_29_2c_20ak71NumpyArrayType_28array_28int64_2c_201d_2c_20C_29_2c_20_7b_7d_29_2c_20ak55ListArrayType_28array_28int64_2c_201d_2c_20C_29_2c_20ak262NumpyArrayType_28array_28int64_2c_201d_2c_20C_29_2c_20_7b_7d_29_2c_20_7b_7d_29_29_2c_20_28_27idx_27_2c_20_27input_idx_27_2c_20_27input_port_27_2c_20_27outputs_idx_27_29_2c_20_7b_22__record___22_3a_20_22Data_22_7d_29_2c_20_7b_27Data_27_3a_20_3cclass_20_27__main__136Data_27_3e_2c_20_27graph_27_3a_200_2c_20_28_27__numba_typer___27_2c_20_27Data_27_2c_20_27input_27_2c_20_28_29_29_3a_20_3cfunction_20Data148_input__numba_typer___20at_200x2ba0b8f73490_3e_2c_20_28_27__numba_lower___27_2c_20_27Data_27_2c_20_27input_27_2c_20_28_29_29_3a_20_3cfunction_20Data67_input__numba_lower___20at_200x2ba0b8f73be0_3e_7d_2c_20_28_29_29_29E\r\n```",
     "createdAt":"2023-10-07T01:11:03Z",
     "number":7214589,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"Hi!\r\n\r\nUnfortunately, I can't tell, by reading the code, whether it's supposed to work or not. Even if it were my own code, I would break it down into smaller pieces and get each piece working before attempting these large code blocks that mix many (probably incompatible) concepts. If one piece doesn't work that seems like it ought to, that would be a bug report.\r\n\r\nAwkward Arrays are intended to be used as arguments and return values of functions decorated as `@nb.njit` and its equivalents. These are the high-level, user-facing parts of Numba, as opposed to its mechanism for making extensions. (Awkward is itself a Numba extension.)\r\n\r\nBeyond that, if you want to add methods to `ak.Records` nested within the array, you can use the [behavior](https://awkward-array.org/doc/main/reference/ak.behavior.html) argument, but that's an advanced use for making fancy APIs. Before adding functionality as methods, can you compute it as Numba-compiled functions that you just pass the arrays into manually? (Also, it would be best to not put `'Data'` and `'graph'` in the `behavior` dict. That dict is not generic metadata\u2014it's used by Awkward Array for functionality.)\r\n\r\n`numba.experimental.structref` defines a record-like structure as a Numba extension. In a sense, `StructRef` is an alternative to Awkward Array, though they differ because Awkward Array stores columnar data and `StructRef` makes conventional \"structs.\" `StructRef` is itself an alternative to `jitclass`, another experimental way to make record-like Numba extensions.\r\n\r\n`context.compile_internal` is something you wouldn't ever use unless you're making a Numba extension. It's [not even documented](https://numba.readthedocs.io/en/stable/search.html?q=compile_internal&check_keywords=yes&area=default) in the [Extending Numba documentation](https://numba.readthedocs.io/en/stable/extending/index.html). At this level, you wouldn't be using Awkward Arrays but their lowered equivalents, which aren't documented because they're private implementation details. (We might change them without warning.)\r\n\r\nI can't tell what the weakrefs are for, but I doubt they play well with Numba. You probably can't pass them as arguments to a compiled function or as parts of a `StructRef`. Weak references are not listed in [Numba's supported Python features](https://numba.readthedocs.io/en/stable/reference/pysupported.html), and only language features and libraries on that page can be used in a compiled context.\r\n\r\nWhy `eval('_graph_cache')[idx]`? Why not `_graph_cache[idx]`?\r\n\r\nThe\r\n\r\n```\r\nRuntimeError: missing Environment: _ZN08NumbaEnv8__main__4Data21...\r\n```\r\n\r\nlooked to me like a mangled C++ name, but I ran it through `c++filt` and it's not a C++ name. It's something that Numba made, and very likely an internal detail.",
     "createdAt":"2023-10-10T00:41:16Z",
     "number":7235373,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"pankajp"
        },
        "body":"Hi @jpivarski . Thanks a lot for taking the time to read my post and the elaborate response.\r\nI realize that the code is longer than it should, accumulating cruft over multiple attempts to get it working.\r\n\r\n> Beyond that, if you want to add methods to ak.Records nested within the array, you can use the [behavior](https://awkward-array.org/doc/main/reference/ak.behavior.html) argument, but that's an advanced use for making fancy APIs. Before adding functionality as methods, can you compute it as Numba-compiled functions that you just pass the arrays into manually? (Also, it would be best to not put 'Data' and 'graph' in the behavior dict. That dict is not generic metadata\u2014it's used by Awkward Array for functionality.)\r\n\r\nI realize `graph` doesn't conform to what awkward array expects and I put it there because I couldn't find any other way to stick in metadata to an awkward array. However, `Data` is exactly intended for the purpose of using a record subclass to add methods to the record (`input()` method here for example). \r\n\r\n> `numba.experimental.structref` defines a record-like structure as a Numba extension. In a sense, StructRef is an alternative to Awkward Array, though they differ because Awkward Array stores columnar data and StructRef makes conventional \"structs.\" StructRef is itself an alternative to jitclass, another experimental way to make record-like Numba extensions.\r\n\r\nYes, an earlier approach used jitclass, but it had more overhead and couldn't cache the compilation. The structref here is intended to store the two awkward arrays.\r\n\r\n>`context.compile_internal` is something you wouldn't ever use unless you're making a Numba extension. It's [not even documented](https://numba.readthedocs.io/en/stable/search.html?q=compile_internal&check_keywords=yes&area=default) in the [Extending Numba documentation](https://numba.readthedocs.io/en/stable/extending/index.html). At this level, you wouldn't be using Awkward Arrays but their lowered equivalents, which aren't documented because they're private implementation details. (We might change them without warning.)\r\n\r\nIronically I found `context.compile_internal` in awkward docs ( https://awkward-array.org/doc/main/reference/ak.behavior.html?highlight=compile_internal#overriding-behavior-in-numba ) for the purpose I am using it :)\r\n\r\n> I can't tell what the weakrefs are for, but I doubt they play well with Numba. You probably can't pass them as arguments to a compiled function or as parts of a StructRef. Weak references are not listed in [Numba's supported Python features](https://numba.readthedocs.io/en/stable/reference/pysupported.html), and only language features and libraries on that page can be used in a compiled context.\r\n\r\nWeakrefs aren't intended to be interfaced with numba or awkward code, but you are right they are extraneous code which isn't necessary here.\r\n\r\n`Why eval('_graph_cache')[idx]? Why not _graph_cache[idx]?`\r\n\r\n`eval` because otherwise numba wants to pickle and cache the global references as constants and I don't want to pickle and create copies of the full graph and its two awkward arrays.\r\n\r\nThanks again for your inputs, I'll try to simplify the code and make reproduce the problem with less complexity.\r\n\r\n",
        "createdAt":"2023-10-10T22:38:40Z",
        "number":7246583
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"pankajp"
     },
     "body":"I finally got it working.\r\n- The `RuntimeError: missing Environment` got fixed by removing the print() call within the lower() function.\r\n- That resulted in a segfault, which I fixed by adding an access to `.numba_type` so that the numba view is created for the record\r\n  This segfault is what I haven been trying to fix for a long while and which led me to the complex code I shared, changing the graph implementation between a namedtuple, a jitclass, a structmodel and a structref.\r\n\r\n```python\r\n    def _input__numba_lower__(context, builder, sig, args):\r\n        print(f'_driver__numba_lower__: sig.args={[type(a) for a in sig.args]}, sig.return_type={type(sig.return_type)}, {len(args)=}')\r\n        ret_type = sig.return_type\r\n        @nb.njit(ret_type(*sig.args))\r\n        def get_data_input(dat):\r\n            with nb.objmode(inp=ret_type):\r\n                inp = dat.input()\r\n                inp.numba_type  # >>> Removing this line causes segfault\r\n            return inp\r\n        def input_lower(dat):\r\n            # Fixme: TypingError: Failed in nopython mode pipeline\r\n            # print('get_node() for:', dat.idx) # >>> having print here causes numba \"RuntimeError: missing Environment\"\r\n            return get_data_input(dat)\r\n        return context.compile_internal(builder, input_lower, sig, args)\r\n```\r\n",
     "createdAt":"2023-10-11T17:11:01Z",
     "number":7255237,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I'm glad this is working!",
        "createdAt":"2023-10-11T18:30:44Z",
        "number":7255818
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I want to keep all of the discussions open. Issues get closed when they're done, but it's valuable to keep discussions around\u2014even if they're resolved\u2014because they're useful to other people with the same questions.",
     "createdAt":"2023-12-30T15:39:13Z",
     "number":7979289,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":5
  },
  "createdAt":"2023-10-06T23:49:56Z",
  "number":2746,
  "title":"Implementing a DAG graph with ak Arrays",
  "url":"https://github.com/scikit-hep/awkward/discussions/2746"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New Features\r\n* feat!: revert breaking component of `asarray` PR by @agoose77 in https://github.com/scikit-hep/awkward/pull/2752* fix: update cppyy module by @ianna in https://github.com/scikit-hep/awkward/pull/2747\r\n\r\n## Bug-fixes and performance\r\n* fix: update cppyy version by @ianna in https://github.com/scikit-hep/awkward/pull/2748\r\n* fix: don't call asarray on `Index` objects internally by @agoose77 in https://github.com/scikit-hep/awkward/pull/2749\r\n\r\n## Other\r\n* chore: update CITATION.cff by @agoose77 in https://github.com/scikit-hep/awkward/pull/2750\r\n\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.5...v2.4.6\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.6'>Version 2.4.6</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-10-12T17:45:32Z",
  "number":2753,
  "title":"Version 2.4.6",
  "url":"https://github.com/scikit-hep/awkward/discussions/2753"
 },
 {
  "author":{
   "login":"gipert"
  },
  "body":"Assume that a filter operation is performed on a column after a `pandas.DataFrame.groupby()` call, and this results in a variable number of elements (of that column) in each obtained group. Would it be possible to interpret such a Series as an Awkward array?\r\n\r\nHere's for example a dataframe that contains variably sized groups, after grouping on `event`:\r\n\r\n```pycon\r\n>>> import pandas as pd\r\n>>> df = pd.DataFrame({\r\n>>>   \"event\": [0, 0, 1, 2, 2, 2],\r\n>>>   \"ch_energy\": [0.1, 0.2, 0.5, 0.8, 1.2, 4.2\r\n>>> })\r\n>>> df.groupby(\"event\").ch_energy.size()\r\nevent\r\n1    2\r\n2    1\r\n3    3\r\n```\r\n\r\nI would be interested into extracting an awkward array that looks like this:\r\n```text\r\n[[0.1, 0.2],\r\n [0.5],\r\n [0.8, 1.2, 4.2]\r\n]\r\n```\r\n\r\nThanks for helping!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"I can certainly weigh in here, but a MWE would be useful to frame our discussion!\r\n",
     "createdAt":"2023-10-12T21:17:51Z",
     "number":7267783,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"gipert"
        },
        "body":"Hi @agoose77, I have edited the original post!",
        "createdAt":"2023-10-13T08:49:23Z",
        "number":7271718
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"@douglasdavis I anticipated that there might be a straightforward function in `awkward-pandas` to leverage the result of a `groupby`. Is that not the case?",
        "createdAt":"2023-10-13T09:18:28Z",
        "number":7271985
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-10-12T20:53:23Z",
  "number":2755,
  "title":"Pandas group-by filter outputs to Awkward",
  "url":"https://github.com/scikit-hep/awkward/discussions/2755"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## Bug Fixes and Performance\r\n* fix: drop lengths recursively by @agoose77 in https://github.com/scikit-hep/awkward/pull/2775\r\n\r\n\r\n## Other\r\n* chore: remove `ak.to_categorical` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2779\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.7...v2.5.0rc0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.5.0rc0'>Version 2.5.0rc0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-10-27T10:08:41Z",
  "number":2780,
  "title":"Version 2.5.0rc0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2780"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New Features\r\n* feat: add `to_buffer` and helper methods in layout builder by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2766\r\n* feat: add helper methods to `utils.h` by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2771\r\n* feat!: rework ufunc type promotion handling by @agoose77 in https://github.com/scikit-hep/awkward/pull/2767\r\n* feat: extend `to_layout` options by @agoose77 in https://github.com/scikit-hep/awkward/pull/2763\r\n\r\n## Bug Fixes and Performance\r\n* fix: add `highlevel`, `behavior` arguments to composite reducers by @agoose77 in https://github.com/scikit-hep/awkward/pull/2754\r\n* fix: export `nan` variants by @agoose77 in https://github.com/scikit-hep/awkward/pull/2758\r\n* fix: update `__class__` for both `layout` and `behavior` consistently by @agoose77 in https://github.com/scikit-hep/awkward/pull/2759\r\n* fix: support all-`None` index in `awkward_Index_nones_as_index.cpp` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2769\r\n* fix: handle unhashable behaviour type by @ianna in https://github.com/scikit-hep/awkward/pull/2770\r\n* fix: protect RecordForm against len(fields) != len(contents) by @jpivarski in https://github.com/scikit-hep/awkward/pull/2776\r\n* fix: drop lengths recursively by @agoose77 in https://github.com/scikit-hep/awkward/pull/2775\r\n* fix: `ak.num` should always return a useful (non-unknown length) type by @agoose77 in https://github.com/scikit-hep/awkward/pull/2785\r\n* fix: remove old argument from `broadcast_and_apply` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2790\r\n* fix: don't preserve unexpected option for is_in by @agoose77 in https://github.com/scikit-hep/awkward/pull/2792\r\n* fix: support scalar strings in `fill_none` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2793\r\n* fix: support arbitrary ufuncs with respect to NEP-50 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2799\r\n\r\n## Other\r\n* chore: add trove classifier to awkward-cpp by @agoose77 in https://github.com/scikit-hep/awkward/pull/2729\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2733\r\n* chore: set `pyupgrade` version by @agoose77 in https://github.com/scikit-hep/awkward/pull/2756\r\n* chore: prepare for ruff-format by @henryiii in https://github.com/scikit-hep/awkward/pull/2773\r\n* chore: move to Ruff-format by @henryiii in https://github.com/scikit-hep/awkward/pull/2777\r\n* chore: run mypy in CI by @agoose77 in https://github.com/scikit-hep/awkward/pull/2789\r\n* chore: run mypy on `ak.types` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2791\r\n* ci: fix oldest-supported-dependencies test workflow by @agoose77 in https://github.com/scikit-hep/awkward/pull/2783\r\n* refactor: drop `behavior` broadcasting by @agoose77 in https://github.com/scikit-hep/awkward/pull/2761\r\n* refactor: introduce parametrised nplike types by @agoose77 in https://github.com/scikit-hep/awkward/pull/2795\r\n* chore(deps): bump amannn/action-semantic-pull-request from 5.3.0 to 5.4.0 by @dependabot in https://github.com/scikit-hep/awkward/pull/2796\r\n\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.6...v2.4.8\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.9'>Version 2.4.9</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-11-06T16:34:36Z",
  "number":2800,
  "title":"Version 2.4.9",
  "url":"https://github.com/scikit-hep/awkward/discussions/2800"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## What's Changed\r\n* fix: backport #2809 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2810\r\n\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.9...v2.4.10\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.4.10'>Version 2.4.10</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-11-09T11:59:27Z",
  "number":2811,
  "title":"Version 2.4.10",
  "url":"https://github.com/scikit-hep/awkward/discussions/2811"
 },
 {
  "author":{
   "login":"jpivarski"
  },
  "body":"I'm moving a question from https://github.com/pydata/xarray/discussions/7988#discussioncomment-7505474 into this forum because that thread is about ragged xarrays.\r\n\r\nHere's the comment from @swamidass:\r\n\r\n> @jpivarski Im happy to explain more the graph use case and why ak package doesn't work so well. Basically there are two key needs:\r\n> \r\n> 1. A good data loading and management library that:\r\n> \r\n>  - is numpy restricted. other small dependencies are fine, but nothing large or with portability issues, or interferes with major tensor libraries (onnx, torch, Jax, tf).\r\n> \r\n> - keeps all the meta data together in a clean way.\r\n> \r\n> - supports lazy loading of files.\r\n> \r\n> As you can see, Xarray fits the bill here quite nicely, even including dask as a way to parallelize. It is missing ragged integration (Datatree does not work), but that's workable with composite tensors (I'll add explain in another response).\r\n> \r\n> \r\n> 2. A backend agnostic library for native ragged array calculations (the key two basic ops are segment reduce and broadcast, from which most everything can be constructed). Key backends to include are tensorflow, numpy (strict!), Jax and torch. This library would need to provide a consistent set of ops with identical API for all four backends, and ideally also a context manager for switching between backends in different parts of the code (usually between numpy and one of tensorback ends).\r\n> \r\n> Right now this library just doesn't exist. Leaving aside  ragged arrays, this doesn't exist for even just normal array ops. \r\n> \r\n> If it did exist, though, and ak built itself around such a library, it might be perfect for us.\r\n> \r\n> This would enable us to write complicated functions, as complex as the leading graph neural networks in one function. One function, based on context, could work natively with any one of the tensor packages, and also operate in the non-GPU preprocessing and deployment contexts (which are a many!).\r\n> \r\n> If Ak allowed us to do that, we switch over to it tomorrow. Is that something you'd be interested in?\r\n> \r\n> If so, I do think I recently found a surprising way to accomplish the main blocker: building that backend  agnostic tensor library. If that worked, I'd be curious if ak could produce low dependency (and perhaps reduced feature) API that restricts itself to this set of ops. \r\n> \r\n> If you did that would be a compelling reason to move over. Though some attention would have to be put into ensuring some key details that are critical for interoperating with tensor libraries and our graph use case.\r\n\r\nI'll start with a response because I think Awkward Array already covers this\u2014you can tell me if I'm still missing something.\r\n\r\n> numpy restricted. other small dependencies are fine, but nothing large or with portability issues\r\n\r\nThe strict (can't be installed without) dependencies for Awkward Array are `numpy`, `packaging`, and `importlib_metadata`, `typing_extensions` if the Python version is not the latest. It's deliberately a small list. The flip-side of that is that if you use even basic functionality like writing to Parquet, Awkward will complain that `pyarrow` isn't installed, so the workflow of trying something, finding out that you need to install something else, then trying it again may be annoying, but the alternative would be to make Awkward difficult to install for some users, and we chose the conservative approach.\r\n\r\n> keeps all the meta data together in a clean way\r\n\r\nDepending on what you mean by metadata, that may be a new feature: #2757 (in `main`) added a top-level `attrs` dict (that gets propagated through all operations) and #2794 (still-open PR) adds per-field attributes. This was inspired by an issue that compared Awkward with xarray (#1391). I said there that we're not attempting to displace xarray (or any array library for _rectilinear_ data), but sometimes you'll get data from a metadata-rich source and at least want to preserve that metadata through pre-processing to the next step, which could be xarray.\r\n\r\n> supports lazy loading of files\r\n\r\n[dask-awkward](https://github.com/dask-contrib/dask-awkward) is a Dask container type, like `dask.array` and `dask.bag`, but for Awkward Arrays. Everything is lazy up to the `compute()` call.\r\n\r\n> backend agnostic library for native ragged array calculations\r\n\r\n:heavy_check_mark:\r\n\r\n> segment reduce and broadcast\r\n\r\n```python\r\n>>> array = ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]])\r\n\r\n>>> ak.sum(array, axis=1)\r\n<Array [6.6, 0, 9.9] type='3 * float64'>\r\n\r\n>>> array + ak.Array([10, 20, 30])\r\n<Array [[11.1, 12.2, 13.3], [], [34.4, 35.5]] type='3 * var * float64'>\r\n```\r\n\r\n> Key backends to include are tensorflow ... torch\r\n\r\n#1466 is for the set of functions that convert between Awkward and TensorFlow RaggedTensor and Torch NestedTensor. If it would be helpful to add that, we can get back to it. I think I saw that TensorFlow exposes the offsets and content views, so it can be an easy _O(1)_ function in both directions.\r\n\r\n> numpy\r\n\r\nThat's default.\r\n\r\n> Jax\r\n\r\nAwkward has a backend for JAX, specifically for the purpose of [supporting autodiff](https://awkward-array.org/doc/main/user-guide/how-to-specialize-differentiate-jax.html). It is experimental\u2014requested for autodiff in particle physics (https://github.com/gradhep), but not widely used yet.\r\n\r\nFor JAX's JIT-compilation, there doesn't seem to be a way to support it. Even with PyTrees, we run into issues in which we need to create arrays whose shapes are determined by values in other arrays, and that's forbidden in the XLA model. We have [Numba](https://awkward-array.org/doc/main/user-guide/how-to-use-in-numba-cuda.html) and [cppyy](https://cppyy.readthedocs.io/en/latest/) (and soon [Julia](https://github.com/jpivarski/AwkwardArray.jl)) for compiled backends, but not JAX.\r\n\r\n> This library would need to provide a consistent set of ops with identical API for all four backends\r\n\r\nAh, I just realized that you meant for the buffers in an Awkward Array to be _backed_ by TensorFlow or Torch, which is not what #1466 will do\u2014it's for conversions. For backing arrays (see [ak.to_backend](https://awkward-array.org/doc/main/reference/generated/ak.to_backend.html)), we only have NumPy for main memory and CuPy for GPUs because once that choice is made, any Python library can view the data without copying.\r\n\r\nWe don't advertise the CuPy backend yet because we have not yet implemented the full API on GPUs yet. Awkward Arrays in `@numba.cuda.jit`-compiled functions is complete (and was [presented in a tutorial](https://github.com/jpivarski-talks/2023-11-02-atlas-gpu-python-tutorial)), but not the `ak.*` functions, and we need those to consider Awkward Arrays to be feature-complete on GPUs. This project should be finished next summer. (There's a fixed set of [cpu-kernels](https://github.com/scikit-hep/awkward/tree/main/awkward-cpp/src/cpu-kernels) to rewrite as [cuda-kernels](https://github.com/scikit-hep/awkward/tree/main/src/awkward/_connect/cuda/cuda_kernels).)[^1]\r\n\r\n> ideally also a context manager for switching between backends in different parts of the code\r\n\r\nEach `ak.Array` has its own backend, so it wouldn't be a global context switch. CPU calculations on NumPy-backed Awkward Arrays can be happening at the same time as CUDA calculations on CuPy-backed Awkward Arrays.\r\n\r\nA lot of the discussion about ragged arrays and xarray has focused on keeping the xarray interface, which I'm in favor of\u2014xarray users should have a familiar interface, even if that means restricting to only ragged arrays, not the full typesystem. But it sounds like your needs are different, and I don't know of any blockers to using Awkward Array for your task.\r\n\r\n[^1]: I'm being cagey about the distinction between GPUs and CUDA because we pass this handling, down to the compilation itself, onto CuPy. I don't know if CuPy has or will have the capability to cross-compile to ROCm, etc. We're writing very generic CUDA in the hope that auto-translation will become possible.",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"swamidass"
     },
     "body":"Thanks for the note. The issue is still being able to write graph kernels in a single library that can work with any backend. Right now it doesn't seem Awk can do that. Am I missing something?",
     "createdAt":"2023-11-13T16:59:51Z",
     "number":7556471,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"What do you mean by \"graph kernels\"? Do you mean user-defined functions with specific kinds of input or output types?\r\n\r\nIf that function is expressed by combining ak.* functions, then only the CPU backend is currently supported; the GPU backend will be done by mid-summer next year.\r\n\r\nIf the function is expressed in [Numba](https://numba.pydata.org/), then both CPU and GPU backends are currently supported.\r\n\r\nThe disconnect between you and me is likely in what you mean by a kernel\u2014I'm assuming that you'd just write functions, but maybe there's a specific form that it has to take, that it has to be a subclass of something in Torch or TensforFlow? Because on the point of writing high-performance functions, that's what Awkward Array has been about since the beginning.\r\n\r\n------------\r\n\r\nI'll write up an example, which might clarify what I mean. Suppose you have a ragged array, which I'll construct from NumPy.\r\n\r\n```python\r\n>>> import numpy as np\r\n>>> import awkward as ak\r\n>>> counts = np.random.poisson(5, 1000000)\r\n>>> values = np.random.normal(0, 1, counts.sum())\r\n>>> array = ak.unflatten(values, counts)\r\n\r\n>>> array.type.show()\r\n1000000 * var * float64\r\n\r\n>>> array.show()\r\n[[-0.0131, -0.0111, -0.296, 1.13, -1.4],\r\n [-1.28, 0.976, -0.72],\r\n [-0.0116, 2.77, -0.445, -0.623, -1.34, ..., 0.512, -0.686, 2.42, 1.76, -0.232],\r\n [-0.318, -0.345, -1, -0.959, -1.12],\r\n [-1.25, 0.19],\r\n [0.205, 0.0524, 0.318, 1.52],\r\n [0.534, -0.461, 1.31, 0.603, -0.223, -1.3, -0.554],\r\n [0.133],\r\n [-1.49, -0.779, 1.2],\r\n [0.679, 0.101, 1.9, -0.671, -0.43, 1.32, -1.57, 0.38, 0.307],\r\n ...,\r\n [-0.0507, 1.06, -0.2, -1.35, 0.134, -0.591, 0.515, -0.389],\r\n [-1.16, -1.14, 0.144],\r\n [1.06, 1.28, 0.8, -0.284, -0.0306, 1.5, 0.131, -0.621],\r\n [0.54, -1.06, -0.0903, -0.215, -0.0229, 0.518, -0.556],\r\n [-1.87, 0.344, 0.653, 2.59, -0.372],\r\n [-0.0513, 0.988, -0.0958, 0.436, -0.524, -0.446, 0.588],\r\n [0.848, -0.467, 0.122],\r\n [0.224, 0.783, 1.06, 0.826, -0.828, -0.908],\r\n [-0.00619, 0.0185, 1.05, -0.221]]\r\n```\r\n\r\nAnd suppose that the operation you want is \"standard deviation of each segment.\" There's a function for this,\r\n\r\n```python\r\n>>> ak.std(array, axis=1)\r\n<Array [0.807, 0.958, 1.25, ..., 0.538, 0.791, 0.493] type='1000000 * float64'>\r\n```\r\n\r\nbut I could have constructed it by combining ak.* functions.\r\n\r\n```python\r\n>>> cnt = ak.count(array, axis=1)\r\n>>> np.sqrt(ak.sum(array**2, axis=1)/cnt - (ak.sum(array, axis=1)/cnt)**2)\r\n<Array [0.807, 0.958, 1.25, ..., 0.538, 0.791, 0.493] type='1000000 * float64'>\r\n```\r\n\r\nThere's a [large suite of such functions](https://awkward-array.org/doc/main/reference/index.html) that perform the computation on the CPU using arrays in main memory. You can move the function to a GPU (whichever one is in the current stream selected by CuPy):\r\n\r\n```python\r\n>>> array_gpu = ak.to_backend(array, \"cuda\")\r\n```\r\n\r\nbut currently, not all of the ak.* functions can be performed on that GPU-bound array.\r\n\r\nNumba provides an alternative way to write functions, using `for` loops, but JIT-compiled and fast:\r\n\r\n```python\r\n>>> @nb.njit\r\n... def calculate_standard_deviation(array):\r\n...     output = np.empty(len(array), dtype=np.float64)\r\n...     for i, segment in enumerate(array):\r\n...         sum_x = 0.0\r\n...         sum_xx = 0.0\r\n...         for x in segment:\r\n...             sum_x += x\r\n...             sum_xx += x**2\r\n...         if len(segment) == 0:\r\n...             output[i] = 0\r\n...         else:\r\n...             output[i] = np.sqrt(sum_xx/len(segment) - (sum_x/len(segment))**2)\r\n...     return output\r\n... \r\n>>> calculate_standard_deviation(array)\r\narray([0.8070488 , 0.958046  , 1.25189563, ..., 0.53779815, 0.79106332,\r\n       0.4933499 ])\r\n```\r\n\r\n[which already works for GPUs](https://awkward-array.org/doc/main/user-guide/how-to-use-in-numba-cuda.html). (The following is untested because I'm on a computer without an NVIDIA GPU right now.)\r\n\r\n```python\r\nimport math\r\n\r\n@nb.cuda.jit\r\ndef calculate_standard_deviation(array, output):\r\n    i = nb.cuda.grid(1)   # equivalent of CUDA's threadIdx\r\n    if i < len(array):\r\n        sum_x = 0.0\r\n        sum_xx = 0.0\r\n        for x in array[i]:\r\n            sum_x += x\r\n            sum_xx += x**2\r\n        if len(segment) == 0:\r\n            output[i] = 0\r\n        else:\r\n            output[i] = math.sqrt(sum_xx/len(segment) - (sum_x/len(segment))**2)\r\n\r\noutput = np.empty(len(array), dtype=np.float64)\r\nnum_threads = 1024\r\nnum_blocks = int(math.ceil(len(output) / num_threads))\r\ncalculate_standard_deviation[num_blocks, num_threads](array, output)\r\n```\r\n\r\nWhatever the inputs and outputs need to be, it should be possible to calculate it either in an array-oriented way or in an imperative way with Numba. If the array object needs automated conversion to and from RaggedTensor or NestedTensor, then that's a matter of just finishing #1466 and we can re-prioritize that.",
        "createdAt":"2023-11-13T20:31:39Z",
        "number":7558345
       },
       {
        "author":{
         "login":"swamidass"
        },
        "body":"Perhaps this will make some sense of it. See this Jax library:\n\nhttps://github.com/google-deepmind/jraph/blob/master/jraph/_src/models.py\n\nThat's the sort of computations I'd want to be able to write one time and have work across multiple different tensor libraries, without converting to numpy arrays unless I want to.\n\nAnd using Numba isn't helpful because that isn't automatically differentiated. \n\nIt would be better if awk could use different tensor frameworks as the backend, with clearer separation between the algorithms/computations/data models and the backend ops, so the same code can be run on any one of many possible backends.",
        "createdAt":"2023-11-18T00:52:47Z",
        "number":7604230
       },
       {
        "author":{
         "login":"swamidass"
        },
        "body":"There are two libraries that achieve this aim that would be worth looking at.\n\nThe first is keras_core, which can work on Jax, numpy/jax, tensorflow or torch. https://keras.io/keras_core/\n\nThe second is dgl, which can run on both tensorflow and PyTorch. https://www.dgl.ai/\n\nBoth are architected in a similar way too.",
        "createdAt":"2023-11-18T00:59:32Z",
        "number":7604254
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"I think the key point must be the automatic differentiation.\r\n\r\nWhen I talk about \"conversions,\" I mean zero-copy views: to take the bytes in RAM or GPU global memory that a Torch tensor `PyObject` is pointing to and make a NumPy or CuPy `PyObject` point to the same bytes in memory. If we implement the same conversions to and from TensorFlow and JAX, then a function on those NumPy or CuPy arrays _does_ work across those three tensor libraries.\r\n\r\nWe do have a clear separation between data backends and algorithms/computations: none of the Awkward Array operations (`ak.*` functions, slices, ufuncs, etc.) explicitly refer to NumPy. They all go through a class called `NumpyLike` which homogenizes the interfaces to the backends. Those backends are NumPy, CuPy, and JAX, because any array/tensor in RAM from any library can be zero-copied to and from NumPy and any array/tensor in GPU global memory from any library can be zero-copied to and from CuPy. (JAX is there for automatic differentiation.) We could do exactly what you're asking by adding shims between Torch's and TensorFlow's APIs (which are not very NumPy-like, so it would be a lot of work) but it wouldn't increase our ability to do computations on tensors from these libraries. What matters is the values in the array and their interpretation, not the type of the `PyObject` that points to them.\r\n\r\nAutomatic differentiation is different because it's no longer just one array to carry around, but its derivative as well, and the operations would need to know how to compute derivatives. But that's why we have a third backend, JAX. A similar argument could be made for anything auxiliary, such as metadata or units, but we can pass metadata through a calculation by putting it in an `ak.Array`'s `attrs`.\r\n\r\nWe can finish work on #1466 to perform these zero-copy views, and that would make it easier to cast between the tensor libraries and Awkward Array, because it would hide the steps involved in checking which device the tensor is on, choosing NumPy or CuPy, and calling the appropriate `asarray`/`frombuffer` equivalent. But actually matching all of Torch/TensorFlow's API calls to equivalents in `NumpyLike` wouldn't add capabilities that zero-copy viewing them doesn't already provide.",
        "createdAt":"2023-11-18T02:02:56Z",
        "number":7604433
       }
      ],
      "totalCount":4
     }
    },
    {
     "author":{
      "login":"ConstantinVasilev"
     },
     "body":"Hi @swamidass could you please give simple example of such function that performs graph calculation using ragged tensors? Does it rely on representing the graphs as ragged tensors?\r\n\r\n> This would enable us to write complicated functions, as complex as the leading graph neural networks in one function.",
     "createdAt":"2024-01-03T06:46:16Z",
     "number":7999892,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"swamidass"
        },
        "body":"\r\nSee the GraphNetwork function in jraph (https://github.com/google-deepmind/jraph/blob/master/jraph/_src/models.py) for a code for the key graph-network operation. The rest of the file shows how that function can be used to create most well known graph network architectures.\r\n\r\nOf note, that function uses \"segment\" functions extensively (e.g. segment_sum, segment_max, segment_sort, etc). Segment tensors are, essentially, ragged tensors with one None axis.\r\n\r\nThere are other ways of doing this, but they usually have big downsides compared to using segment/ragged tensors.",
        "createdAt":"2024-01-03T08:33:17Z",
        "number":8000465
       },
       {
        "author":{
         "login":"ConstantinVasilev"
        },
        "body":"Thanks, but isnt this what libraries like tf with their ragged tensors do, why do you need this in xr or ak?\r\n\r\nOne more Q, you mentioned that xr Datatree doesnt work as ragged integration why is that?",
        "createdAt":"2024-01-04T08:13:32Z",
        "number":8010185
       },
       {
        "author":{
         "login":"swamidass"
        },
        "body":"The issue is that:\r\n\r\n1. these libraries are all different, wiht different APIs and different support, and a compatibility layer in something like awk would be valuable. For example, the functions I showed there are all in Jax, which doesn't work with torch, etc. \r\n\r\n2. they are focused on autodifferentiation, not the sort of things that xarray are good at it. Ideally a library could use any of the tensor libraries as backend arrays, while providing a common api for all of them.\r\n\r\nFor your last question, I think I explained it before. But perhaps you could could show me how you'd use datatree to represent, say, 1,000 molecule graphs (atoms are nodes, bonds are graphs). \r\n\r\n\r\n",
        "createdAt":"2024-01-08T00:26:56Z",
        "number":8042611
       }
      ],
      "totalCount":3
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-11-10T19:49:50Z",
  "number":2814,
  "title":"Awkward Array for ML on graphs?",
  "url":"https://github.com/scikit-hep/awkward/discussions/2814"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New Features\r\n* feat: add `.attrs` to highlevel objects by @agoose77 in https://github.com/scikit-hep/awkward/pull/2757\r\n* feat: add string formatter to `ak.Array.show` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2803\r\n* feat: expose attrs in typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2806\r\n* feat: export more of typetracer by @agoose77 in https://github.com/scikit-hep/awkward/pull/2816\r\n* feat!: prepare for 2.5.0 by @agoose77 in https://github.com/scikit-hep/awkward/pull/2798\r\n* feat!: drop `forget_length` in `typetracer_with_report` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2807\r\n\r\n## Bug Fixes and Performance\r\n* fix: support bool types in `resolve_dtypes` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2809\r\n* fix: support scalar returns from `firsts` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2815\r\n* fix: include `_kernel_signatures.py` in package by @agoose77 in https://github.com/scikit-hep/awkward/pull/2819* refactor: more type hints by @agoose77 in https://github.com/scikit-hep/awkward/pull/2804\r\n\r\n## Other\r\n* chore: drop `isort` config, require annotation imports by @agoose77 in https://github.com/scikit-hep/awkward/pull/2801\r\n* chore: only build _ext and kernels by @agoose77 in https://github.com/scikit-hep/awkward/pull/2813\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2817\r\n* docs: how to accelerate awkward arrays with cppyy by @ianna in https://github.com/scikit-hep/awkward/pull/2334\r\n* refactor: drop use of `behavior` in `recursively_apply` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2805\r\n* test: Make cuda tests pass by @kkothari2001 in https://github.com/scikit-hep/awkward/pull/2570\r\n\r\n\r\n## New Contributors\r\n* @kkothari2001 made their first contribution in https://github.com/scikit-hep/awkward/pull/2570\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.4.9...v2.5.0\n\n<hr /><em>This discussion was created from the release <a href='https://github.com/scikit-hep/awkward/releases/tag/v2.5.0'>Version 2.5.0</a>.</em>",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-11-16T18:11:19Z",
  "number":2836,
  "title":"Version 2.5.0",
  "url":"https://github.com/scikit-hep/awkward/discussions/2836"
 },
 {
  "author":{
   "login":"tomeichlersmith"
  },
  "body":"Howdy everyone! :cowboy_hat_face: I have greatly appreciated using `awkward` in my HEP research since it so neatly follows the structure of our data. I am now working on a project to try to load data stored in [LCIO](https://github.com/iLCSoft/LCIO) into `ak.Array` in-memory using the header-only version of awkward to access the LCIO C++ API and construct the array.\r\n\r\nThe basic demo for using awkward with pybind11 has been very helpful and I have gotten pretty far, but now I am stuck at (what I believe to be) the largest hurdle: representing \"references\" in the data (what LCIO calls \"relations\"). In general, these \"references\" come in two types:\r\n\r\n1. An object has a reference to one (or more) objects that are \"parts\" of it (e.g. the `EVENT::Track` object contains references to the `EVENT::TrackerHit`s which make up the track).\r\n2. An stand-alone collection which maps objects from one collection to another collection (collections of `EVENT::LCRelation`). These are often helpful for associating extra information that is not always necessary (e.g. data about the kinks in any constructed tracks can be related to the tracks via this object).\r\n\r\nI'm curious if awkward experts have a good idea on how to design this reference behavior. I know I'll need to implement some awkward behavior so that \"de-referencing\" can happen in an automatic way ([coffea already has \"de-referencing\" for the PhysLite schema](https://github.com/CoffeaTeam/coffea/blob/master/src/coffea/nanoevents/methods/physlite.py) so I'm not too worried about writing that side of things), but what about the actual data construction side? Should I just have a \"reference\" be a `Numpy` array of `int`s that I can apply as indices? Is `IndexOptionArray` what I'm looking for?\r\n\r\nAs a side note, it appears to me that the LCIO file format (well, technically the `slcio` file format since its LCIO written with SIO - confusing I know) is _completely_ row-wise - i.e. there is no chunking of columns near to each other in the file (like how ROOT does with TBasket), so I _will_ need to construct the array one event at a time. This _will_ be relatively slow but I think I'll implement some caching-to-parquet protocol if it is really painful. In addition, this means I am focusing on doing a single-pass reading all requested data into memory (a.k.a. I'm not going to attempt to do lazy-loading at this time).\r\n\r\nHopefully this project will be promoted to a \"Show and Tell\" project in a few weeks :wink: but we will see if I am able to get it into a good enough form to display.\r\n\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"In the array structure itself, a `NumpyArray` of integers is the best you can do. An Awkward Array is a tree structure, not a general graph[^1], so any links that would make it not a tree have to at least be of a different kind, like weak references or symlinks. A `NumpyArray` of integers is like weak references because the existence of the reference doesn't guarantee the existence of the referent; it's a lookup address that you can follow and hope to find the referent.\r\n\r\nThe lookup function (and action to be taken if the referent is not there) can be encapsulated in a behavior, as it is for Coffea.\r\n\r\nDoing a row-wise read in C++ is not as bad as doing it in Python. At least there's that.  `:)`\r\n\r\nI was going to say that I was surprised that something as new as the ILC would be based on a custom row-wise format, but I see that the paper goes back to 2003. That's a long development time. Will the same technology be used when the ILC is actually built? CMS switched frameworks twice in its early development. (From something before my time, to ORCA, which I saw the very end of, to CMSSW.)\r\n\r\n[^1]: Historically, we went back and forth on that one, and there are Awkward v0 demonstrations of how you can make a graph, both with cycles (a node's child can be its ancestor) and as a DAG (a node's child can be its cousin). When this is possible, all recursive functions need to keep track of what nodes they've seen to avoid recursing in an infinite loop. Also, even when they're possible, these structures are hard to set up, and can't be done without modifying pre-built structures (Python doesn't have [lazy val](https://stackoverflow.com/a/7486796/1623645)), so the original structure needed a placeholder that was later thrown away. These complications, on top of the fact that demonstrations of non-tree Awkward Arrays were ignored, led to them eventually being dropped.",
     "createdAt":"2023-11-16T23:03:27Z",
     "number":7593335,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"To add to @jpivarski's reply, we just added support for stashing metadata in `ak.Array.attrs`. Coffea doesn't yet use this, as it's such a new addition, so instead stores references in `ak.Array.behavior`.\r\n\r\nThe node for re-indexing another node is `ak.contents.IndexedArray` (which is identical to `ak.contents.IndexedOptionArray` but without the option-type).\r\n\r\nA note on references (without thinking too much about your data structures): it's worth also thinking about whether the constraints that lead to the need for references disappear when working with Awkward Arrays.",
        "createdAt":"2023-11-16T23:35:53Z",
        "number":7593478
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"The indexed node types can't break the tree structure, which is what I think @tomeichlersmith needs, at least for part 2. Perhaps you're right that an `IndexedArray` could be used in part 1, in which a set of tracks reference each others' hits.\r\n\r\n* list of events\r\n  * list of tracks\r\n    * list of\r\n      * `IndexedArray`\r\n        * hits\r\n\r\nMultiple tracks would be able to point to the same hits, and some hits might not be pointed to by any tracks. As long as the hits node is exclusively under the tracks node, this is fine. But if tracks and hits were both directly under events:\r\n\r\n* list of events\r\n  * list of tracks\r\n  * list of hits\r\n\r\nthen the tracks couldn't point into the hits, because the hits would then be both a sibling and a child\u2014the graph would become a DAG, rather than a tree.\r\n\r\n----------------\r\n\r\nThis is a fundamental issue\u2014Awkward Array types are strictly tree-like. (The values can be DAGs, as illustrated in my first example with two tracks including the same hit through an `IndexedArray`. From a user perspective, though, the distinction between the multiple views and a copy is hidden\u2014as far as users are aware, the hit might be copied in both tracks.) The strict tree of types also means that a value can't be arbitrarily deep: we can make Awkward Arrays whose values are depth $n$ trees by nesting $n$ type nodes.\r\n\r\nEven though I say that this is a fundamental limitation, one _could_ go behind the public interface and try to force it:\r\n\r\n```python\r\ninfinite_depth = ak.Array([None, 1, 2, 3, 4, 5, 6, 7, 8, 9])\r\ninfinite_depth.layout._content = infinite_depth.layout\r\ninfinite_depth.layout.index.data[:] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\r\n```\r\n\r\nmakes an `IndexedOptionArray` that has itself as its child, such that index `0` is index `1` is index `2` is ... is index `9` is index `0`...\r\n\r\n```python\r\ninfinite_depth[0]\r\n```\r\n\r\nraises a RecursionError. Okay, that's an infinite depth value, but what about using a recursive type to make a finite but arbitrary depth tree value?\r\n\r\n```python\r\narbitrary_depth = ak.Array([[1], [2, 3], [4, 5], [6, 7], [], [], [], []])\r\narbitrary_depth.layout._content = ak.contents.IndexedArray(\r\n    ak.index.Index(arbitrary_depth.layout.content.data),\r\n    arbitrary_depth.layout\r\n)\r\narbitrary_depth.layout.offsets._data = np.array([0, 1])\r\n```\r\n\r\n_should_ make a structure like this\r\n\r\n```python\r\n[[[[]], [[]]], [[[]], [[]]]]\r\n```\r\n\r\nbut still, trying to look at it causes a RecursionError because somewhere in the pretty-printer, we try to make a Form, which recurses infinitely. If we instead use `ak.to_list`, we get a different RecursionError because `ak.to_list` calls `ak.to_packed`.\r\n\r\nSo in some cases, self-reference should be broken, in other cases, it's accidentally broken by the fact that we do recursion on Types and Forms, and in all cases, one has to break the public interface to even attempt it.\r\n\r\nWe're firmly in the camp of tree-like data only. But that only means that if we want to express something that's _like_ a non-tree, we have to introduce a distinction between strong references and weak references, or hard links and symbolic links in a filesystem. The weak/symbolic links are virtual, but a behavior can execute the code that would make them active.\r\n\r\n-----------------\r\n\r\nOh, I've only been showing pathologies in graphs with cycles. You'd still have to break the public interface, but you could make DAGs.\r\n\r\n```python\r\nevents = ak.Array([\r\n    {\"tracks\": [[0, 1], [1], [1, 1, 1]], \"hits\": [1.1, 2.2]}, \r\n    {\"tracks\": [[2, 2, 3, 3], [3]], \"hits\": [3.3, 4.4, 5.5]}.\r\n])\r\nevents.layout.content(0).content._content = ak.contents.IndexedArray(\r\n    ak.index.Index(events.layout.content(0).content.content.data),\r\n    events.layout.content(1).content\r\n)\r\n```\r\n\r\nNow the `hits` is a sibling to `tracks` and it _looks_ like another copy of it is nested within `tracks`:\r\n\r\n```python\r\n>>> events.type.show()\r\n2 * {\r\n    tracks: var * var * float64,\r\n    hits: var * float64\r\n}\r\n>>> events.tolist()\r\n[\r\n    {'tracks': [[1.1, 2.2], [2.2], [2.2, 2.2, 2.2]], 'hits': [1.1, 2.2]},\r\n    {'tracks': [[3.3, 3.3, 4.4, 4.4], [4.4]], 'hits': [3.3, 4.4, 5.5]},\r\n]\r\n```\r\n\r\nand even\r\n\r\n```python\r\n>>> events.layout\r\n<RecordArray is_tuple='false' len='2'>\r\n    <content index='0' field='tracks'>\r\n        <ListOffsetArray len='2'>\r\n            <offsets><Index dtype='int64' len='3'>\r\n                [0 3 5]\r\n            </Index></offsets>\r\n            <content><ListOffsetArray len='5'>\r\n                <offsets><Index dtype='int64' len='6'>\r\n                    [ 0  2  3  6 10 11]\r\n                </Index></offsets>\r\n                <content><IndexedArray len='11'>\r\n                    <index><Index dtype='int64' len='11'>\r\n                        [0 1 1 1 1 1 2 2 3 3 3]\r\n                    </Index></index>\r\n                    <content><NumpyArray dtype='float64' len='5'>[1.1 2.2 3.3 4.4 5.5]</NumpyArray></content>\r\n                </IndexedArray></content>\r\n            </ListOffsetArray></content>\r\n        </ListOffsetArray>\r\n    </content>\r\n    <content index='1' field='hits'>\r\n        <ListOffsetArray len='2'>\r\n            <offsets><Index dtype='int64' len='3'>\r\n                [0 2 5]\r\n            </Index></offsets>\r\n            <content><NumpyArray dtype='float64' len='5'>[1.1 2.2 3.3 4.4 5.5]</NumpyArray></content>\r\n        </ListOffsetArray>\r\n    </content>\r\n</RecordArray>\r\n```\r\n\r\nbut there's only one copy of the hits in memory. That situation might not last if some `ak.*` operation needs to make a copy of the `tracks`'s nested contents, but deep copies are avoided whenever possible.",
        "createdAt":"2023-11-17T00:38:30Z",
        "number":7593805
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Yes, this last example is what I'm pointing to -- as long as you aren't trying to make cycles, we can share layouts at different depths within our layout system!",
        "createdAt":"2023-11-17T00:59:33Z",
        "number":7593917
       },
       {
        "author":{
         "login":"tomeichlersmith"
        },
        "body":"Thank you for this long and detailed discussion @jpivarski and @agoose77 - I've learned some more and I got some ideas to try in my loading framework.\r\n\r\n>  break the public interface\r\n\r\nHow bad would it be if I did this? Would that just mean my package would be more \"delicate\" to future developments of awkward?\r\n\r\n> Will the same technology be used when the ILC is actually built?\r\n\r\nI am actually not involved with the ILC at all, so I unfortunately cannot answer this question. I'm working with [an experiment at SLAC](https://confluence.slac.stanford.edu/display/hpsg/Heavy+Photon+Search+Experiment) which chose LCIO as the data format for their reconstruction software (written in java) and I am interested in getting the data files into `awkward` in an easier/faster way than my current solution (which is just to copy the data into a ROOT file and then use uproot). ",
        "createdAt":"2023-11-17T14:55:18Z",
        "number":7600281
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"The internals (anything starting with an underscore) can in principle be changed at any time, and we wouldn't know who is using it to contact everybody before making a change. So it would be a risk that you'd be taking on, a risk that some new version of Awkward Array could break your code without any warning (which we post as deprecation warnings when changing the public interface).\r\n\r\nThe breakage might be unlikely...\r\n\r\n> I am actually not involved with the ILC at all, so I unfortunately cannot answer this question. I'm working with [an experiment at SLAC](https://confluence.slac.stanford.edu/display/hpsg/Heavy+Photon+Search+Experiment) which chose LCIO as the data format for their reconstruction software (written in java) and I am interested in getting the data files into `awkward` in an easier/faster way than my current solution (which is just to copy the data into a ROOT file and then use uproot).\r\n\r\nIt sounds like a good project!",
        "createdAt":"2023-11-17T20:23:57Z",
        "number":7602965
       }
      ],
      "totalCount":5
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-11-16T22:11:04Z",
  "number":2838,
  "title":"Preparing for reference behavior while using header-only awkward",
  "url":"https://github.com/scikit-hep/awkward/discussions/2838"
 },
 {
  "author":{
   "login":"amoschoomy"
  },
  "body":"Hello, I need help to compare two awkward arrays for equality, \r\n\r\n```\r\n>       assert anndata.obsm[\"airr\"] == anndata.obsm['airr']\r\n\r\ntests\\test_io.py:313: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\nenv\\Lib\\site-packages\\awkward\\_operators.py:50: in func\r\n    return ufunc(self, other)\r\nenv\\Lib\\site-packages\\awkward\\highlevel.py:1423: in __array_ufunc__\r\n    return ak._connect.numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\nenv\\Lib\\site-packages\\awkward\\_connect\\numpy.py:425: in array_ufunc\r\n    out = ak._broadcasting.broadcast_and_apply(\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:1037: in broadcast_and_apply\r\n    out = apply_step(\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:1016: in apply_step\r\n    return continuation()\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:984: in continuation\r\n    return broadcast_any_list()\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:632: in broadcast_any_list\r\n    outcontent = apply_step(\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:1016: in apply_step\r\n    return continuation()\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:984: in continuation\r\n    return broadcast_any_list()\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:697: in broadcast_any_list\r\n    outcontent = apply_step(\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:1016: in apply_step\r\n    return continuation()\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:988: in continuation\r\n    return broadcast_any_record()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n    def broadcast_any_record():\r\n        if not options[\"allow_records\"]:\r\n>           raise ValueError(f\"cannot broadcast records{in_function(options)}\")\r\nE           ValueError: cannot broadcast records in equal\r\nE           \r\nE           This error occurred while calling\r\nE           \r\nE               numpy.equal.__call__(\r\nE                   <Array [[{c_call: 'IGHM', ...}, ...], ...] type='10 * var * {c_call...'>\r\nE                   <Array [[{c_call: 'IGHM', ...}, ...], ...] type='10 * var * {c_call...'>\r\nE               )\r\n\r\nenv\\Lib\\site-packages\\awkward\\_broadcasting.py:474: ValueError\r\n\r\n```\r\n\r\nThis is the error that I get even when I try to perform equality comparison on the same object",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"The reason you get an error message is because binary operators such as `+` and `==` are not allowed on record types. The motivation was so that wrong interpretations wouldn't happen by accident. Specifically, people had 3D vectors represented by records, sometimes with fields `x`, `y`, `z` and sometimes with field `rho`, `phi`, `theta`. The naive `+` operation makes a lot of sense on `x`, `y`, `z`, but not on `rho`, `phi`, `theta`. By preventing `+` (etc.) on generic records, [behavioral overloads](https://awkward-array.org/doc/main/reference/ak.behavior.html), such as the ones in the [Vector package](https://github.com/scikit-hep/vector#awkward-arrays-of-vectors), could be overlaid to convert these vectors correctly, and the error message was an indication that the overload was forgotten or didn't get applied correctly.\r\n\r\nBut `==` and `!=` are special binary operators. Perhaps they should be allowed? Even if so, you might be surprised by the output:\r\n\r\n```python\r\nak.Array([{\"x\": 1, \"y\": 2}, {\"x\": 3, \"y\": 4}]) == ak.Array([{\"x\": 1, \"y\": 2}, {\"x\": 3, \"y\": 4444}])\r\n```\r\n\r\nwould result in\r\n\r\n```python\r\nak.Array([{\"x\": True, \"y\": True}, {\"x\": True, \"y\": False}])\r\n```\r\n\r\nrather than\r\n\r\n```python\r\nak.Array([True, False])\r\n```\r\n\r\nas you might be expecting. Is that the case\u2014are you expecting `==` on records to replace the whole record with a boolean true or false?\r\n\r\n--------------------\r\n\r\n@agoose77, this could be implemented as a default behavior for records, for `==` and `!=` only. It would just need to check the equality of all of its fields, applying `ak.all` to any nested lists until they're flat at the level of the record.\r\n\r\nIf the two sides of `==` have a different set of fields, either an error or false would be the appropriate result. Error is safer, but false would always work in unions.\r\n\r\nI think it could be implemented in such a way that nested records would perform this operation recursively, so that the boolean result would always come in at the top-most record.\r\n\r\nI could take a look at implementing that, but first, what do you think? Do you think this sounds reasonable? Since we'd be replacing an error condition with a meaningful result, we could do it without a deprecation cycle.",
     "createdAt":"2023-11-21T03:34:18Z",
     "number":7625858,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"This indeed is something we should be able to do (c.f. https://github.com/scikit-hep/awkward/issues/2367). I'm in favour of implementing this.\r\n",
        "createdAt":"2023-11-21T07:48:19Z",
        "number":7627220
       },
       {
        "author":{
         "login":"amoschoomy"
        },
        "body":"I think the latter makes much more sense to me but thanks anyway for the reply and glad to see updates to this being considered",
        "createdAt":"2023-11-22T00:44:21Z",
        "number":7636692
       }
      ],
      "totalCount":2
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-11-21T02:56:44Z",
  "number":2843,
  "title":"How to compare awkward arrays for equality",
  "url":"https://github.com/scikit-hep/awkward/discussions/2843"
 },
 {
  "author":{
   "login":"gipert"
  },
  "body":"I'm trying to write a robust and zero-copy de-serializer of 2D jagged numerical vectors, written to disk according to [this specification](https://legend-exp.github.io/legend-data-format-specs/dev/hdf5/#Vector-of-vectors), into Awkward 2.x arrays. This is what I have written so far:\r\n```python\r\ndef _ak_from_buffers(flattened_data: NDArray, cumulative_length: NDArray):\r\n    # should also run ak.is_valid() before returning?\r\n    return ak.from_buffers(\r\n        {\r\n            \"class\": \"ListOffsetArray\",\r\n            \"offsets\": \"i64\",  # how to get this from cumulative_length.dtype?\r\n            \"content\": {\r\n                \"class\": \"NumpyArray\",\r\n                \"primitive\": ak.types.numpytype.dtype_to_primitive(flattened_data.dtype),\r\n                \"form_key\": \"node1\",\r\n            },\r\n            \"form_key\": \"node0\",\r\n        },\r\n        len(cumulative_length) - 1,\r\n        {\r\n            \"node0-offsets\": cumulative_length,  # how to prepend the zero but avoid copy?\r\n            \"node1-data\": flattened_data,\r\n        },\r\n    )\r\n```\r\nand I have a couple of questions (also inlined in the code):\r\n1. The value of `\"offsets\"` in the Form is hardcoded, is there a way to get it from `cumulative_length.dtype`?\r\n2. The offsets in the container should start from zero, but the input `cumulative_length` does not. Is there a way to fix this without making a copy?\r\n3. Is there anything else that can be improved?",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"Hi @gipert, interesting discussion!\r\n\r\n1. We don't publicly expose a direct mapping from dtype to offsets. I'd suggest just writing a mapping yourself (it won't be very big). Also, see (3). Note that our kernels only support a small set of dtypes, so anything that's not `int64` will often be copied once the array is manipulated.\r\n2. We don't provide any layout types with an implicit zero start index. I think you're going to have to copy here, unfortunately.\r\n3. You don't _need_ to use `ak.from_buffers` here. You can also directly construct the layout nodes using our layout system. This would mean that you didn't need to figure out the index-type associated with a dtype.\r\ne.g.\r\n```python\r\noffsets = np.empty(len(cumulative_length) + 1, dtype=cumulative_length.dtype)\r\noffsets[1:] = cumulative_length\r\noffsets[0] = 0\r\n\r\nlayout = ak.contents.ListOffsetArray(\r\n    offsets=ak.index.Index(offsets),\r\n    content=ak.contents.NumpyArray(flattened_data)\r\n)\r\n```",
     "createdAt":"2023-11-22T18:03:22Z",
     "number":7645164,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"gipert"
        },
        "body":"Thanks a lot! I guess I just initialize the array as `ak.Array(layout)` then?",
        "createdAt":"2023-11-23T15:20:45Z",
        "number":7652979
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-11-22T17:33:01Z",
  "number":2848,
  "title":"Zero-copy view of offsets and flattened data Numpy arrays as 2D Awkward arrays",
  "url":"https://github.com/scikit-hep/awkward/discussions/2848"
 },
 {
  "author":{
   "login":"vischia"
  },
  "body":"Hi,\r\n\r\nI need to read a tree with 39 columns with a mix of int, bool, float, and lists of ints and floats, and then I need to pad everything to the maximum length of any of the dimensions. Finally, I have to write that in to an HDF5 file.\r\n\r\nAfter a lot of struggling (it seems it is not trivial to mix data types like this), I arrived to a solution.\r\n\r\nNow I would like to extract three columns from my padded array, and change their names. Before I was forced to use awkward arrays instead of pandas dataframes by the procedure above, I was doing\r\n\r\n```\r\nmy_columns = branches[['name1', 'name2', 'name3']].copy()\r\nmy_columns.columns = ['newname1', 'newname2', 'newname3']\r\n```\r\n\r\nHowever, now that `branches` is an awkward array the above code doesn't work anymore (no member `copy`).\r\nI tried variations of:\r\n\r\n```\r\nmy_columns = copy.deepcopy(branches[['name1', 'name2', 'name3']])\r\nmy_columns.columns = ['newname1', 'newname2', 'newname3']\r\n```\r\nbut I keep getting complaints that named arrays are unmodifiable, so I cannot change column names.\r\n\r\nHow can I change column names?\r\n\r\nThank you very much in advance!\r\n\r\nCheers,\r\nPietro",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"vischia"
     },
     "body":"P.S. afaik the relative documentation is [here](https://awkward-array.org/doc/main/user-guide/how-to-restructure-rename-records.html), where it says the content does not exist yet.",
     "createdAt":"2023-12-04T16:15:13Z",
     "number":7754970,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"vischia"
     },
     "body":" Sorry for the spam.\r\n\r\nI solved by creating a new thing\r\n\r\n```\r\nmy_columns = {'newname1': branches['name1'], 'newname2': branches['name2'], 'newname3': branches['name3']}\r\n```\r\n\r\nIt is somehow inconvenient though, it would be great if down the line there were dedicated functions that trivially do this.",
     "createdAt":"2023-12-04T16:22:19Z",
     "number":7755076,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"You've created a Python dict of arrays; if you wanted them to be columns of a new Awkward Array, you would use [ak.zip](https://awkward-array.org/doc/main/reference/generated/ak.zip.html).\r\n\r\n```python\r\n>>> array = ak.Array([{\"x\": 1, \"y\": 2, \"z\": 3}, {\"x\": 1.1, \"y\": 2.2, \"z\": 3.3}])\r\n>>> array.show(type=True)\r\ntype: 2 * {\r\n    x: float64,\r\n    y: float64,\r\n    z: float64\r\n}\r\n[{x: 1, y: 2, z: 3},\r\n {x: 1.1, y: 2.2, z: 3.3}]\r\n>>> array2 = ak.zip({\"a\": array[\"x\"], \"b\": array[\"y\"], \"c\": array[\"z\"]})\r\n>>> array2.show(type=True)\r\ntype: 2 * {\r\n    a: float64,\r\n    b: float64,\r\n    c: float64\r\n}\r\n[{a: 1, b: 2, c: 3},\r\n {a: 1.1, b: 2.2, c: 3.3}]\r\n```\r\n\r\nI hear what you're saying about the inconvenience of listing each of the columns individually. Since the above can be done manually, it can also be automated, for instance by using Python [dict comprehensions](https://peps.python.org/pep-0274/). There isn't a standard function for that (and can't be) because it would depend on how you're getting your columns. The specific transformation you want to do is different from the transformation someone else wants to do. We're relying on you to use Python tools like dict comprehensions, for loops, and such to generalize any metadata management, such as changing column names. (That's why all of the examples show how to do this manually.)",
        "createdAt":"2023-12-04T16:33:35Z",
        "number":7755221
       },
       {
        "author":{
         "login":"vischia"
        },
        "body":"Thank you very much, creating a new awkward array seems indeed the way to go. However,  if I use `ak.zip` then another package complains that it cannot actually recognize the new names of the columns, whereas it does not complain if I pass the dict of arrays, so I think that for my use case I can just live with the dict of arrays.",
        "createdAt":"2023-12-04T16:40:09Z",
        "number":7755319
       },
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"If another library needs a dict, then make a dict and not `ak.zip`. (See how we can't provide a canned function? `:)`)",
        "createdAt":"2023-12-04T16:43:35Z",
        "number":7755360
       }
      ],
      "totalCount":3
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"I moved this to the Awkward Array repo, since this question is about manipulating arrays, not getting data from Uproot.\r\n\r\nYou mention padding arrays. You have a solution, but in case it's useful, the usual way is through [ak.pad_none](https://awkward-array.org/doc/main/reference/generated/ak.pad_none.html) and [ak.fill_none](https://awkward-array.org/doc/main/reference/generated/ak.fill_none.html).\r\n\r\nLet's leave these Discussions open, too, so that they'll be helpful to more people in the future.",
     "createdAt":"2023-12-04T16:35:52Z",
     "number":7755256,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"vischia"
        },
        "body":"Ultimately I used `padded_branches=ak.to_dataframe(branches)`, which seems to do it automatically.\r\nI had tried through [ak.pad_none](https://awkward-array.org/doc/main/reference/generated/ak.pad_none.html) and [ak.fill_none](https://awkward-array.org/doc/main/reference/generated/ak.fill_none.html), but I got in trouble when defining the maximum length (code complaining that `num()` was acting on an axis of unsuitable length, or complaining that `.count` does not exist, at various stages of desperation).",
        "createdAt":"2023-12-04T16:42:07Z",
        "number":7755338
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":3
  },
  "createdAt":"2023-12-04T16:08:13Z",
  "number":2868,
  "title":"Pad awkward array with nested lists, and changing column names",
  "url":"https://github.com/scikit-hep/awkward/discussions/2868"
 },
 {
  "author":{
   "login":"alig146"
  },
  "body":"Hi,\r\n\r\nI\u2019m trying to convert RDataFrame to awkward array and i seem to get a error with ak.from_rdataframe. Basically i have ROOT and Awkward downloaded via conda and when i run the following:\r\n\r\n\r\n```\r\ndf3 = ROOT.RDataFrame(\"CollectionTree\", \"/global/u2/a/agarabag/pscratch/ditdau_samples/graviton.root\")\r\nnpy3 = ak.from_rdataframe(df3, columns=(\"DiTauJetsAuxDyn.ditau_pt\", \"EventInfoAuxDyn.mcEventWeights\"), keep_order=True)\r\n```\r\n\r\ni get the below error:\r\n\r\n>  File \"/global/u2/a/agarabag/plotter_v5.py\", line 534, in plot_branches\r\n>     npy3 = ak.from_rdataframe(df3, columns=(\"DiTauJetsAuxDyn.ditau_pt\", \"EventInfoAuxDyn.mcEventWeights\"), keep_order=True)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_dispatch.py\", line 39, in dispatch\r\n>     gen_or_result = func(*args, **kwargs)\r\n>                     ^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/operations/ak_from_rdataframe.py\", line 56, in from_rdataframe\r\n>     return _impl(rdf, columns, highlevel, behavior, with_name, offsets_type, keep_order)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/operations/ak_from_rdataframe.py\", line 62, in _impl\r\n>     import awkward._connect.rdataframe.from_rdataframe  # noqa: F401\r\n>     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/ROOT/_facade.py\", line 154, in _importhook\r\n>     return _orig_ihook(name, *args, **kwds)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_connect/rdataframe/from_rdataframe.py\", line 51, in <module>\r\n>     cppyy.add_include_path(\r\n>   File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy/__init__.py\", line 221, in add_include_path\r\n>     raise OSError(\"no such directory: %s\" % path)\r\n> OSError: no such directory: /global/u2/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_connect/header-only\r\n> \r\n> This error occurred while calling\r\n\r\n> ak.from_rdataframe(\r\n>         RDataFrame-instance\r\n>         columns = ('DiTauJetsAuxDyn.ditau_pt', 'EventInfoAuxDyn.mcEventWeights')\r\n>         keep_order = True\r\n>     )\r\n\r\nI wanted to know if anyone knows what could be causing this error? i have tried removing and re downloading awkward but that hasn\u2019t helped. The \u201cheader-only\u201d dir indeed does not exist but I\u2019m not sure why. also awkward functions normally its only when calling ak.from_rdataframe that i get this error.\r\n\r\nROOT Version: 6.28.4\r\nawkward version: 2.5.0",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"ianna"
     },
     "body":"Hi Ali,The header-only is a part of awkward-cpp. Please check if it is installed. Thanks, Yana.\r\nSent from my iPhone\r\n",
     "createdAt":"2023-12-12T06:48:56Z",
     "number":7827288,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"alig146"
        },
        "body":"Hi Yana,\r\n\r\nyes, awkward-cpp is installed (version 26). also i tried to downgrade to 2.4 and got the same error and i also jumped to version 2.1.1 and the code is running now. ",
        "createdAt":"2023-12-12T12:58:45Z",
        "number":7830652
       },
       {
        "author":{
         "login":"alig146"
        },
        "body":"also I wanted to ask a bit unrelated questions. the code works with version 2.1.1 on rather small root files. when i try to run on root files > 1 GB i get \"Segmentation fault\". i assume this is a memory issue. does this mean my machine does not have enough memory or something more complicated? and also wanted to check that is this a known limit, that is with above some threshold ak.from_rdataframe doesn't work? ",
        "createdAt":"2023-12-12T15:18:07Z",
        "number":7832074
       }
      ],
      "totalCount":2
     }
    },
    {
     "author":{
      "login":"ianna"
     },
     "body":"> Hi Yana,\r\n> \r\n> yes, awkward-cpp is installed (version 26). also i tried to downgrade to 2.4 and got the same error and i also jumped to version 2.1.1 and the code is running now.\r\n\r\nOh, it looks like a bug. Thanks for reporting it!\r\n\r\nI am constructing a path to the `header-only` directory, but it looks like it is valid only in a developers installation:\r\n\r\nhttps://github.com/scikit-hep/awkward/blob/ae5923e957406f1c0af3728abafde9dd9cde9097/src/awkward/_connect/rdataframe/from_rdataframe.py#L51-L59\r\n",
     "createdAt":"2023-12-12T16:51:54Z",
     "number":7833095,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"agoose77"
        },
        "body":"This *should* work in production, even though it won't work with zipfile modules. Perhaps @alig146 could report what the following script yields?\r\n```python\r\n#!/usr/bin/env python3\r\nimport awkward._connect.rdataframe.from_rdataframe\r\nimport os.path\r\n\r\nsearch_path = os.path.abspath( \r\n   os.path.join( \r\n       os.path.dirname(os.path.realpath(awkward._connect.rdataframe.from_rdataframe.__file__)), \r\n       os.path.pardir, \r\n       \"header-only\", \r\n   ) \r\n) \r\nprint(search_path)\r\nprint(os.listdir(search_path))\r\n\r\n```",
        "createdAt":"2023-12-12T17:04:54Z",
        "number":7833219
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Then, which parts of the path that is reported actually exist on your file system?",
        "createdAt":"2023-12-12T17:06:23Z",
        "number":7833239
       },
       {
        "author":{
         "login":"alig146"
        },
        "body":"Hi I ran the script. and here are the print results\r\n\r\nfor awkward version 2.1.1:\r\n**first print:** \r\n/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy_backend/loader.py:90: UserWarning: No precompiled header available (/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy_backend/etc not writable); this may impact performance.\r\n  warnings.warn('No precompiled header available (%s); this may impact performance.' % msg)\r\n/global/u2/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_connect/header-only\r\n\r\n**second print:**\r\n ['awkward']\r\n\r\nfor awkward version 2.5.0:\r\n**first print:** \r\n /global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy_backend/loader.py:90: UserWarning: No precompiled header available (/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy_backend/etc not writable); this may impact performance.\r\n  warnings.warn('No precompiled header available (%s); this may impact performance.' % msg)\r\nTraceback (most recent call last):\r\n  File \"/global/u2/a/agarabag/test.py\", line 2, in <module>\r\n    import awkward._connect.rdataframe.from_rdataframe\r\n  File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_connect/rdataframe/from_rdataframe.py\", line 51, in <module>\r\n    cppyy.add_include_path(\r\n  File \"/global/homes/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/cppyy/__init__.py\", line 221, in add_include_path\r\n    raise OSError(\"no such directory: %s\" % path)\r\nOSError: no such directory: /global/u2/a/agarabag/.conda/envs/ditau/lib/python3.11/site-packages/awkward/_connect/header-only\r\n\r\n\r\n\r\nIn version 2.1.1 header-only directory exists while in 2.5.0 it does not. \r\n",
        "createdAt":"2023-12-13T02:47:26Z",
        "number":7837336
       },
       {
        "author":{
         "login":"agoose77"
        },
        "body":"Ah @alig146 I *think* I'm figuring out what's happened here. Thanks!",
        "createdAt":"2023-12-13T13:44:44Z",
        "number":7842596
       }
      ],
      "totalCount":4
     }
    },
    {
     "author":{
      "login":"ianna"
     },
     "body":"> also I wanted to ask a bit unrelated questions. the code works with version 2.1.1 on rather small root files. when i try to run on root files > 1 GB i get \"Segmentation fault\". i assume this is a memory issue. does this mean my machine does not have enough memory or something more complicated? and also wanted to check that is this a known limit, that is with above some threshold ak.from_rdataframe doesn't work?\r\n\r\nI think, an insufficient memory is a valid guess. You can try to monitor it to check it's limit on a file size for your computer. It may depend on what else you are running. The stack trace could provide more detailed information about it.",
     "createdAt":"2023-12-12T16:58:12Z",
     "number":7833148,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"alig146"
        },
        "body":"when i run over > 1GB file which I think is actually not that large, i just get the Segmentation fault message and the script is terminated there is no other print (i assume this is what you meant by stack trace). also i'm running on perlmutter cluster now so i think the computing resources are fine. if you like to reproduce this i have put the root files, conda env, and script here:  https://cernbox.cern.ch/s/BYiAkT0HMXxBCHI",
        "createdAt":"2023-12-13T14:15:18Z",
        "number":7842955
       }
      ],
      "totalCount":1
     }
    },
    {
     "author":{
      "login":"ianna"
     },
     "body":"> when i run over > 1GB file which I think is actually not that large, i just get the Segmentation fault message and the script is terminated there is no other print (i assume this is what you meant by stack trace). also i'm running on perlmutter cluster now so i think the computing resources are fine. if you like to reproduce this i have put the root files, conda env, and script here: https://cernbox.cern.ch/s/BYiAkT0HMXxBCHI\r\n\r\nIndeed, I've tried to run it on a local copy of your file - it doesn't take long at all - it's not that large:\r\n```python\r\nIn [1]: import ROOT\r\n\r\nIn [2]: import awkward as ak\r\n\r\nIn [3]: ROOT.ROOT.EnableImplicitMT(16)\r\nInstalled ROOT event loop hook.\r\n\r\nIn [4]: %%timeit\r\n   ...: df3 = ROOT.RDataFrame(\"CollectionTree\", \"/Users/yana/Downloads/user.agarabag.34455039._000004.output.root\")\r\n   ...: \r\n   ...: \r\nThe slowest run took 8.06 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n830 \u00b5s \u00b1 1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n\r\n```\r\n\r\nretrieving the columns takes a bit longer (the data is copied):\r\n```python\r\nIn [7]: %%timeit\r\n   ...: npy3 = ak.from_rdataframe(df3, columns=(\"DiTauJetsAuxDyn.ditau_pt\", \"EventInfoAuxDyn.mcEventWeights\"), keep_order=True)\r\n   ...: \r\n   ...: \r\nWarning in <TClass::Init>: no dictionary for class xAOD::EventFormat_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLinkBase is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TruthParticle_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::EventInfo_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TrackParticle_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::EventInfo_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class SG::AuxElement is available\r\nWarning in <TClass::Init>: no dictionary for class SG::IAuxElement is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::EventAuxInfo_v2 is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::AuxInfoBase is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::AuxContainerBase is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TruthVertex_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::TruthParticleAuxContainer_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::TruthParticle_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::TauJet_v3 is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::Jet_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::Vertex_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::DiTauJetAuxContainer_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::DiTauJet_v1 is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::ShallowAuxContainer is available\r\nWarning in <TClass::Init>: no dictionary for class DataLink<SG::IConstAuxStore> is available\r\nWarning in <TClass::Init>: no dictionary for class ElementLink<DataVector<xAOD::TruthEventBase_v1> > is available\r\nWarning in <TClass::Init>: no dictionary for class SG::IAuxStore is available\r\nWarning in <TClass::Init>: no dictionary for class SG::IConstAuxStore is available\r\nWarning in <TClass::Init>: no dictionary for class SG::IAuxStoreIO is available\r\nWarning in <TClass::Init>: no dictionary for class SG::IAuxStoreHolder is available\r\nWarning in <TClass::Init>: no dictionary for class xAOD::IParticle is available\r\nWarning in <TClass::Init>: no dictionary for class DataLinkBase is available\r\n5.21 s \u00b1 90.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n```\r\nand it produces some result:\r\n```python\r\nIn [10]: print(ak.flatten(npy3[\"DiTauJetsAuxDyn.ditau_pt\"]))\r\n[0, 2.83e+04, 2.17e+04, 4.03e+04, 0, ..., 0, 2.29e+04, 5.45e+04, 2.6e+05]\r\n```\r\n\r\nI'm using different versions though:\r\n```python\r\n>>> ROOT.__version__\r\n'6.28/04'\r\n>>> ak.__version__\r\n'2.4.5'\r\n>>> \r\n```\r\n<strike>I'll try to do</strike> the same with `awkward 2.5.1`.",
     "createdAt":"2023-12-13T14:44:47Z",
     "number":7843304,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"ianna"
        },
        "body":"@alig146 - it is possible that the failing jobs produce a log file somewhere on the cluster. Please, check with your devops. Alternatively, I could suggest to: please, try run it in single thread, run the script with just opening the file, try extracting one column, try to apply a filter before extracting the columns. ",
        "createdAt":"2023-12-13T15:01:22Z",
        "number":7843504
       },
       {
        "author":{
         "login":"alig146"
        },
        "body":"hi, thank you for testing the script and the suggestions, i will also try to reach out to the devops. regarding your suggestions i tried your suggestions and i only got it to work when extracting just one column as shown below:\r\n`npy3 = ak.from_rdataframe(df3, columns=(\"DiTauJetsAuxDyn.ditau_pt\", ), keep_order=True)\r\n`\r\nthen i tried other variables and they also worked (with single column), i also tried multiple columns of other variables and it worked except when i included \"EventInfoAuxDyn.mcEventWeights\" (even with single column) so i guess it doesn't like this variable for some reason. but its strange that it worked for you. unfortunately i can't try version 2.4.5 because of the header-only error. ",
        "createdAt":"2023-12-14T00:53:28Z",
        "number":7848495
       },
       {
        "author":{
         "login":"alig146"
        },
        "body":"i also got it to work with newer version. however, when i started running over all my root files i again ran into the Segfault with files > 4 GB. I have put one of these files in Cernbox (user.agarabag.34455039._000003.output.root). If you have time could you please see if you can run this one as well (i have also tried running with 2.5.1). ",
        "createdAt":"2023-12-19T03:25:16Z",
        "number":7893113
       }
      ],
      "totalCount":3
     }
    }
   ],
   "totalCount":4
  },
  "createdAt":"2023-12-12T03:33:49Z",
  "number":2892,
  "title":"Converting RDataFrames to awkward array",
  "url":"https://github.com/scikit-hep/awkward/discussions/2892"
 },
 {
  "author":{
   "login":"agoose77"
  },
  "body":"## New Features\r\n\r\n* feat: add `enforce_concatenated_form` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2860\r\n* feat: add `Form.is_equal_to` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2862\r\n* feat: Implement Indexed builder by @zonca in https://github.com/scikit-hep/awkward/pull/2883\r\n\r\n## Bug Fixes and Performance\r\n\r\n* fix: ufunc handling of attrs by @agoose77 in https://github.com/scikit-hep/awkward/pull/2837\r\n* fix: only compare scalars in full_like by @agoose77 in https://github.com/scikit-hep/awkward/pull/2857\r\n* fix: `Array.__getitem__` should set `attrs` on result by @agoose77 in https://github.com/scikit-hep/awkward/pull/2866\r\n* fix: errors in existing `cuda_kernels` by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2877\r\n* fix: register Numba in test by @agoose77 in https://github.com/scikit-hep/awkward/pull/2879\r\n* fix: failing tests after #2877 by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2886\r\n* fix: support revertable for concatenate in pyarrow logic by @agoose77 in https://github.com/scikit-hep/awkward/pull/2889\r\n\r\n\r\n## Other\r\n\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2842\r\n* chore: make the CUDA test configuration more resilient at startup by @agoose77 in https://github.com/scikit-hep/awkward/pull/2846\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2850\r\n* chore: formatted kernel-test-data.json for better searching and editing in git. by @jpivarski in https://github.com/scikit-hep/awkward/pull/2874\r\n* chore: use tomli by @henryiii in https://github.com/scikit-hep/awkward/pull/2882\r\n* chore: appease pylint by @agoose77 in https://github.com/scikit-hep/awkward/pull/2890\r\n* chore: update pre-commit hooks by @pre-commit-ci in https://github.com/scikit-hep/awkward/pull/2891* chore: only copy non-test headers by @agoose77 in https://github.com/scikit-hep/awkward/pull/2893\r\n* chore(deps): bump mymindstorm/setup-emsdk from 12 to 13 by @dependabot in https://github.com/scikit-hep/awkward/pull/2847\r\n* chore(deps): bump pypa/gh-action-pypi-publish from 1.8.10 to 1.8.11 by @dependabot in https://github.com/scikit-hep/awkward/pull/2855\r\n* chore(deps): bump actions/setup-python from 4 to 5 by @dependabot in https://github.com/scikit-hep/awkward/pull/2873\r\n* ci: fix path to header only tests by @zonca in https://github.com/scikit-hep/awkward/pull/2851\r\n* ci: compile header only tests in Debug mode by @zonca in https://github.com/scikit-hep/awkward/pull/2870\r\n* docs: link to execute JupyterLite full screen by @zonca in https://github.com/scikit-hep/awkward/pull/2854\r\n* refactor: split \"meta\" into `Meta` by @agoose77 in https://github.com/scikit-hep/awkward/pull/2841\r\n* refactor: remove dead code in generate-tests.py by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2875\r\n* refactor: remove obsolete cuda_kernels by @ManasviGoyal in https://github.com/scikit-hep/awkward/pull/2876\r\n\r\n\r\n## New Contributors\r\n* @zonca made their first contribution in https://github.com/scikit-hep/awkward/pull/2851\r\n\r\n**Full Changelog**: https://github.com/scikit-hep/awkward/compare/v2.5.0...v2.5.1",
  "comments":{
   "nodes":[],
   "totalCount":0
  },
  "createdAt":"2023-12-12T21:36:16Z",
  "number":2895,
  "title":"Version 2.5.1",
  "url":"https://github.com/scikit-hep/awkward/discussions/2895"
 },
 {
  "author":{
   "login":"lobis"
  },
  "body":"I'm using ArrayBuilder on some C++ code to build awkward arrays.\r\n\r\nI'm struggling to go back on an append / begin_list call. From some offline conversation with @jpivarski I thought it should be possible to \"move the pointer / index\" back and keep building (without any overhead, because you are not really deleting anything) but I'm not finding how to do this.\r\n\r\n```cpp\r\ntemplate<class PRIMITIVE>\r\nusing NumpyBuilder = awkward::LayoutBuilder::Numpy<PRIMITIVE>;\r\n\r\ntemplate<class PRIMITIVE, class BUILDER>\r\nusing ListOffsetBuilder = awkward::LayoutBuilder::ListOffset<PRIMITIVE, BUILDER>;\r\n\r\nListOffsetBuilder<int, NumpyBuilder<int>> builder;\r\n\r\nbuilder.begin_list();\r\nbuilder.append(1);\r\nbuilder.append(2);\r\nbuilder.being_list();\r\n\r\n// I no longer want this list and wish to keep on building\r\n```\r\n\r\nThanks!\r\n",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"@lobis I never spent a huge amount of time thinking about `LayoutBuilder`, but AFAICR we don't implement an \"undo\". It wouldn't be *that* hard to do (I don't _think_). Is there a reason you can't avoid the list altogether?",
     "createdAt":"2023-12-14T18:47:34Z",
     "number":7856820,
     "replies":{
      "nodes":[
       {
        "author":{
         "login":"jpivarski"
        },
        "body":"Oh, yeah\u2014this came out of a conversation that @lobis and I had a few days ago. LayoutBuilders don't have an undo, but easily could. (Same for ArrayBuilder, but this is for a LayoutBuilder application that wants to produce arrays without large entries, without knowing ahead of time whether the next entry will be large.)",
        "createdAt":"2023-12-14T19:10:44Z",
        "number":7857006
       }
      ],
      "totalCount":1
     }
    }
   ],
   "totalCount":1
  },
  "createdAt":"2023-12-14T18:26:14Z",
  "number":2903,
  "title":"ArrayBuilder (C++) - How to go back / move the index",
  "url":"https://github.com/scikit-hep/awkward/discussions/2903"
 },
 {
  "author":{
   "login":"srivarra"
  },
  "body":"### Description of new feature\r\n\r\nHello, thanks for making `awkward`! I'd love a way to save an `awkward` Array to the [`Zarr`](https://zarr.readthedocs.io/en/stable/index.html) format if possible! I've checked the links and searched for `Zarr` and found a discussion [post](https://github.com/scikit-hep/awkward/discussions/29)\r\n\r\nThis would be specifically beneficial for Image Mass Spectrometry, where we may have tens of thousands to hundreds of thousands of pixels, each having variable length masses and intensities (this is where `awkward` has been helping me). \r\n\r\nIf this is a feature worth considering / in the scope of `awkward`, I'd also love to help with a contribution or two!",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"A single (non-rectangular) Awkward Array could be encoded in Zarr by breaking it down into buffers, saving those as one-dimensional arrays in Zarr, and then reconstituting it from Zarr. Earlier discussions with the Zarr team were about defining a _standard_ way to do that, so that the Zarr object would declare itself to be an Awkward Array, because the intermediate buffers are not meaningful by themselves.\r\n\r\n[This documentation](https://awkward-array.org/doc/main/user-guide/how-to-convert-buffers.html) describes the process of breaking an Awkward Array into buffers and reconstituting it, with an example of saving it to HDF5. HDF5 has the same problem\u2014if someone opens the HDF5 file of raw buffers without knowing that it's supposed to be interpreted as an Awkward Array, they wouldn't necessarily be able to make sense of its contents. (That's why we don't have a _standard_ way to save to HDF5.)\r\n\r\nI haven't been following Zarr developments recently. Is it looking like a version 3 extension could mark a collection of differently sized, differently partitioned buffers as a higher-level object that should be interpreted by the Awkward library?\r\n\r\nAlternatively, do you need this for your own purposes, such that the encoding does not need to be standardized? (That could be done by just following the above-linked documentation, replacing Zarr for HDF5, and wouldn't need anything to be contributed centrally.)",
     "createdAt":"2023-10-27T19:06:10Z",
     "number":8158018,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"srivarra"
     },
     "body":"Yeah I just needed this for my own purposes, so it didn't need to be standardized. I'll go ahead give your suggestion a shot, thank you!",
     "createdAt":"2023-10-30T17:01:36Z",
     "number":8158019,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":2
  },
  "createdAt":"2023-10-27T17:51:42Z",
  "number":2955,
  "title":"Write to `Zarr`",
  "url":"https://github.com/scikit-hep/awkward/discussions/2955"
 },
 {
  "author":{
   "login":"kevinxu-git"
  },
  "body":"### Version of Awkward Array\r\n\r\n2.5.0\r\n\r\n### Description and code to reproduce\r\n\r\n## Context\r\nIn order to pass a ragged array in a class wrapped using `@jitclass` of `numba`. I want to use `ak.Array` to store some information that will be used inside a method of the class. \r\n\r\n## Example of usage\r\n```python\r\nimport awkward as ak\r\nimport numpy as np\r\nfrom numba.experimental.jitclass import jitclass\r\nfrom unittest import TestCase, main\r\n\r\n@jitclass([(\"arr\", ak.Array([[[0]]]).numba_type)])\r\nclass A:\r\n    def __init__(self, arr):\r\n        self.arr = arr\r\n\r\n    def do_smth(self):\r\n        # some access to information stored in self.arr\r\n        self.arr[0][0]\r\n        print(len(self.arr))\r\n\r\ndef create_a():\r\n    arr = ak.Array([\r\n         [[0]], \r\n         [[0]],\r\n         [[0]]\r\n    ])\r\n    return A(arr=arr)\r\n\r\nclass TestA(TestCase):\r\n    def test_a(self):\r\n        a = create_a()\r\n        \r\n        a.do_smth()\r\n        x = np.zeros(4)\r\n        a.do_smth()\r\n\r\nmain(argv=[''], verbosity=2, exit=False)\r\n```\r\n\r\n## Issue\r\nThis code raises : \r\n`ValueError: slice index out of bounds`\r\n![Capture d\u2019e\u0301cran 2023-12-01 a\u0300 16 25 11](https://github.com/scikit-hep/awkward/assets/33251676/658f79a7-bafd-4753-8097-996b0b994ab2)\r\n\r\nIt seems like only the first call to `do_smth` can access to `self.arr`, but the second call can't find anymore the values in `self.arr`\r\n\r\n**What's more surprising** is that \r\n- When I init `arr` with more or less elements, it works ... It's only when there are exactly 3 elements that breaks\r\n- If I remove `x = np.zeros(4)`, it works as well\r\n- If I use `x = np.zeros(3)`, it works as well ...\r\n\r\n\r\nSo, if anymore could help me to explain this bug and how to solve it \ud83e\udd72",
  "comments":{
   "nodes":[
    {
     "author":{
      "login":"agoose77"
     },
     "body":"@ianna is this something that you'd be the person to ping for? :)",
     "createdAt":"2023-12-01T15:28:48Z",
     "number":8186944,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"This is the sort of thing that @ianna can look into, but we haven't thought about what would happen if someone tries to use Awkward Arrays in `jitclass`; we should probably figure out if they can be expected to work and confirm that they're supported or else declare them unsupported, preferably with an error message.\r\n\r\nThe symptoms sound a lot like looking at uninitialized memory\u2014to have something work with anything but 3 elements suspiciously sounds like the \"working\" cases are just lucky that nothing has overwritten that memory. If so, it's very unlikely that the \"working\" cases will continue to work on another computer or another operating system.\r\n\r\nAwkward Arrays in Numba are borrowed references\u2014the `Lookup` object on the Python side holds a reference to keep the array in memory while the Numba-compiled function runs. If it goes out of scope on the Python side and gets deleted by the Python garbage collector (or just when the reference count goes to zero), then the Numba-compiled function will be looking at memory that has been released, which _might or might not_ still have the array's data in it.\r\n\r\nUnderstanding what's happening here would involve understanding how Numba's `jitclass` holds things in memory. (Also, we should verify with the Numba team whether `jitclass` is an interface that will continue to be supported. There's another way to make class-like objects that seems more robust and I'm wondering if it's intended as a replacement. I can't remember its name and I can't find it right now. I think it started with \"Struct...\".)",
     "createdAt":"2023-12-01T17:50:20Z",
     "number":8186945,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"kevinxu-git"
     },
     "body":"> The symptoms sound a lot like looking at uninitialized memory\u2014to have something work with anything but 3 elements suspiciously sounds like the \"working\" cases are just lucky that nothing has overwritten that memory. If so, it's very unlikely that the \"working\" cases will continue to work on another computer or another operating system.\r\n> \r\n> Awkward Arrays in Numba are borrowed references\u2014the `Lookup` object on the Python side holds a reference to keep the array in memory while the Numba-compiled function runs. If it goes out of scope on the Python side and gets deleted by the Python garbage collector (or just when the reference count goes to zero), then the Numba-compiled function will be looking at memory that has been released, which _might or might not_ still have the array's data in it.\r\n\r\nI see, it would explain it !\r\n\r\n> Understanding what's happening here would involve understanding how Numba's `jitclass` holds things in memory. (Also, we should verify with the Numba team whether `jitclass` is an interface that will continue to be supported. There's another way to make class-like objects that seems more robust and I'm wondering if it's intended as a replacement. I can't remember its name and I can't find it right now. I think it started with \"Struct...\".)\r\n\r\nIn the current version of the awkward library, it's not supposed to be used with `jitclass` then \ud83d\ude05 ",
     "createdAt":"2023-12-04T14:37:25Z",
     "number":8186946,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    },
    {
     "author":{
      "login":"jpivarski"
     },
     "body":"We need to have more comprehensive documentation on using Awkward Array in Numba, and that documentation would specify which Numba features are applicable and which are not. For now, though, I'll make this a Discussion, since it can act as a public service announcement to not use Awkward Arrays in `nb.jitclass`.",
     "createdAt":"2024-01-20T00:00:05Z",
     "number":8186947,
     "replies":{
      "nodes":[],
      "totalCount":0
     }
    }
   ],
   "totalCount":4
  },
  "createdAt":"2023-12-01T15:25:43Z",
  "number":2972,
  "title":"Using Awkward Arrays in Numba's `jitclass`",
  "url":"https://github.com/scikit-hep/awkward/discussions/2972"
 }
]