[
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-04T19:54:06Z",
  "comments":0,
  "created_at":"2020-01-04T01:51:58Z",
  "draft":false,
  "id":545226936,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzU5MTcyNTIw",
  "number":40,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-04T19:54:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Rename Identity/id -> Identities/identities and location -> identity.",
  "updated_at":"2020-01-04T19:54:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I found that I may need this in my explorations.",
  "closed_at":"2020-01-04T19:34:05Z",
  "comments":2,
  "created_at":"2020-01-04T19:09:56Z",
  "draft":false,
  "id":545320963,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzU5MjM5MDMy",
  "number":41,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-04T19:34:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bring FillableArray::index to regular python interface",
  "updated_at":"2020-01-04T19:34:58Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-06T14:34:36Z",
  "comments":5,
  "created_at":"2020-01-04T20:14:52Z",
  "draft":false,
  "id":545327313,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzU5MjQzNjk4",
  "number":42,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-06T14:34:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Create stubs for the `flatten` operation.",
  "updated_at":"2020-01-06T14:34:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"```python\r\ncheck = ak.Array([{\"x\": \"b\"}, {\"x\": \"b\"}, {\"x\": \"a\"}, {\"x\": \"b\"}])\r\nprint(check.layout)\r\n\r\nprint(ak.tolist(check))\r\nprint(ak.tolist(check.layout))\r\n```\r\n\r\nresults in:\r\n```\r\n<RecordArray>\r\n    <type>{\"x\": string}</type>\r\n    <field index=\"0\" key=\"x\">\r\n        <ListOffsetArray64>\r\n            <type>string</type>\r\n            <offsets><Index64 i=\"[0 1 2 3 4]\" offset=\"0\" at=\"0x7fb342145600\"/></offsets>\r\n            <content><NumpyArray format=\"B\" shape=\"4\" data=\"0x 62626162\" at=\"0x7fb342034800\">\r\n                <type>utf8</type>\r\n            </NumpyArray></content>\r\n        </ListOffsetArray64>\r\n    </field>\r\n</RecordArray>\r\n[{'x': [98]}, {'x': [98]}, {'x': [97]}, {'x': [98]}]\r\n[{'x': [98]}, {'x': [98]}, {'x': [97]}, {'x': [98]}]\r\n```\r\n\r\n```python\r\ncheck = ak.Array([{\"x\": b\"b\"}, {\"x\": b\"b\"}, {\"x\": b\"a\"}, {\"x\": b\"b\"}])\r\nprint(check.layout)\r\n\r\nprint(ak.tolist(check))\r\nprint(ak.tolist(check.layout))\r\n```\r\n\r\nresults in:\r\n```\r\n<RecordArray>\r\n    <type>{\"x\": bytes}</type>\r\n    <field index=\"0\" key=\"x\">\r\n        <ListOffsetArray64>\r\n            <type>bytes</type>\r\n            <offsets><Index64 i=\"[0 1 2 3 4]\" offset=\"0\" at=\"0x7fb3431d6e00\"/></offsets>\r\n            <content><NumpyArray format=\"B\" shape=\"4\" data=\"0x 62626162\" at=\"0x7fb34314e200\">\r\n                <type>byte</type>\r\n            </NumpyArray></content>\r\n        </ListOffsetArray64>\r\n    </field>\r\n</RecordArray>\r\n[{'x': [98]}, {'x': [98]}, {'x': [97]}, {'x': [98]}]\r\n[{'x': [98]}, {'x': [98]}, {'x': [97]}, {'x': [98]}]\r\n```\r\n\r\nHowever:\r\n```python\r\nfor out in check:\r\n    print(out[\"x\"])\r\n```\r\n\r\nresults in (similar for strings):\r\n```\r\nb'b'\r\nb'b'\r\nb'a'\r\nb'b'\r\n```\r\n\r\nbut:\r\n```python\r\nfor out in check.layout:\r\n    print(out[\"x\"])\r\n```\r\n\r\nresults in\r\n```\r\n<NumpyArray format=\"B\" shape=\"1\" data=\"0x 62\" at=\"0x7fb3439c8200\">\r\n    <type>byte</type>\r\n</NumpyArray>\r\n<NumpyArray format=\"B\" shape=\"1\" data=\"0x 62\" at=\"0x7fb3439c8200\">\r\n    <type>byte</type>\r\n</NumpyArray>\r\n<NumpyArray format=\"B\" shape=\"1\" data=\"0x 61\" at=\"0x7fb3439c8200\">\r\n    <type>byte</type>\r\n</NumpyArray>\r\n<NumpyArray format=\"B\" shape=\"1\" data=\"0x 62\" at=\"0x7fb3439c8200\">\r\n    <type>byte</type>\r\n</NumpyArray>\r\n```\r\n\r\nIt looks like the underlying behavior is correct but the handling is inconsistent?",
  "closed_at":"2020-01-06T15:31:58Z",
  "comments":1,
  "created_at":"2020-01-05T15:46:16Z",
  "id":545433569,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NDU0MzM1Njk=",
  "number":43,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Type of strings and bytes inconsistent iterating manually or in .tolist()",
  "updated_at":"2020-02-03T23:21:30Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-06T15:31:57Z",
  "comments":0,
  "created_at":"2020-01-06T14:37:08Z",
  "draft":false,
  "id":545759122,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzU5NTY5MzU2",
  "number":44,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-06T15:31:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Reproduce and fix issue #43.",
  "updated_at":"2020-01-06T15:32:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"TODO:\r\n  * implement checks for an argument **axis**: if less or equal **-1** or greater then **dimension** trigger a wrong user input by throwing **std::invalid_argument**\r\n  * add tests for the above\r\n  *<strike> add a C++ test for a **RawArrayOf**</strike>\r\n  * finish **flatten** implementations\r\n\r\n@jpivarski - please, comment\r\n\r\n\r\n",
  "closed_at":"2020-01-13T23:03:09Z",
  "comments":14,
  "created_at":"2020-01-07T10:59:02Z",
  "draft":false,
  "id":546219111,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzU5OTM3MDQ4",
  "number":45,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-13T23:03:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Start flatten implementation and add tests",
  "updated_at":"2020-01-13T23:03:13Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-08T20:58:44Z",
  "comments":0,
  "created_at":"2020-01-07T18:54:55Z",
  "draft":false,
  "id":546449754,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYwMTI0ODkz",
  "number":46,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-08T20:58:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Start IndexedArray (with and without OptionType).",
  "updated_at":"2020-01-08T20:58:48Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"```python\r\nout = ak.FillableArray()\r\n\r\nout.beginrecord()\r\nout.field(\"x\")\r\nout.integer(3)\r\n\r\nout.field(\"extreme\")\r\nout.beginrecord()\r\nout.field(\"pt\")\r\nout.real(3.3)\r\nout.field(\"charge\")\r\nout.integer(-1)\r\nout.field(\"iso\")\r\nout.integer(100)\r\nout.endrecord()\r\nout.endrecord()\r\n\r\nout.beginrecord()\r\nout.field(\"x\")\r\nout.integer(3)\r\nout.endrecord()\r\n\r\nss = out.snapshot()\r\n\r\nprint(ak.tolist(ss))\r\n```\r\n\r\nShould result in:\r\n```python\r\n[{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}, {'x': 3, 'extreme': None}]\r\n```\r\nbut instead results in:\r\n```python\r\n[{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}]\r\n```\r\n\r\nSimilarly:\r\n```python\r\nak.tolist(ak.Array([{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}, {'x': 3}]))\r\n```\r\nincorrectly yields:\r\n```python\r\n[{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}]\r\n```\r\n\r\nMinimal reproducer:\r\n```python\r\nassert ak.tolist(ak.Array([{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}, {'x': 3}])) == [{'x': 3, 'extreme': {'pt': 3.3, 'charge': -1, 'iso': 100}}, {'x': 3, 'extreme': None}]\r\n```",
  "closed_at":"2020-01-09T15:39:27Z",
  "comments":2,
  "created_at":"2020-01-08T22:29:17Z",
  "id":547140266,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NDcxNDAyNjY=",
  "number":47,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Incorrrect behavior in FillableArray + Option / ak.Array python constructor",
  "updated_at":"2020-02-03T23:21:39Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-09T15:38:46Z",
  "comments":0,
  "created_at":"2020-01-09T15:28:53Z",
  "draft":false,
  "id":547549395,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYxMDE3MzA1",
  "number":48,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-09T15:38:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Reproduce and fix issue #47.",
  "updated_at":"2020-01-09T15:38:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-10T13:53:11Z",
  "comments":1,
  "created_at":"2020-01-10T13:39:22Z",
  "draft":false,
  "id":548084992,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYxNDU0NzY5",
  "number":49,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-10T13:53:11Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Use ak.Array vs ak.Record to distinguish RecordArray from Record.",
  "updated_at":"2020-01-10T13:53:29Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-15T01:50:23Z",
  "comments":1,
  "created_at":"2020-01-14T14:47:22Z",
  "id":549615301,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NDk2MTUzMDE=",
  "number":50,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"IndexedArray::flatten for axis=0",
  "updated_at":"2020-01-15T01:50:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"All array types, including `IndexedArray` (and `UnionArray`, if it exists when you're ready for it).\r\n\r\nDiscussion of how to interpret negative `axis` [here](https://github.com/scikit-hep/awkward-1.0/pull/45#issuecomment-573783659).",
  "closed_at":"2020-03-10T05:03:59Z",
  "comments":6,
  "created_at":"2020-01-14T14:49:29Z",
  "id":549616639,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MTY2Mzk=",
  "number":51,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"*::flatten and *::count for axis != 0",
  "updated_at":"2020-03-10T05:03:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-15T21:26:21Z",
  "comments":2,
  "created_at":"2020-01-14T14:50:24Z",
  "id":549617260,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NDk2MTcyNjA=",
  "number":52,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"IndexedArray::setidentities",
  "updated_at":"2020-01-15T22:22:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-16T02:07:07Z",
  "comments":1,
  "created_at":"2020-01-14T14:50:52Z",
  "id":549617543,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":"2020-01-21T05:18:35Z",
   "closed_issues":3,
   "created_at":"2020-01-14T15:09:48Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Want to turn any JSON into Awkward Arrays and iterate over them in Numba.",
   "due_on":"2020-01-20T08:00:00Z",
   "id":5003818,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgxOA==",
   "number":2,
   "open_issues":0,
   "state":"closed",
   "title":"For Numba demo",
   "updated_at":"2020-01-21T05:18:35Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MTc1NDM=",
  "number":53,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"IndexedArray Numba lowering",
  "updated_at":"2020-01-16T02:07:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Not the SparseUnionArray; leave that for later.\r\n\r\nIncludes `setidentities` and Numba lowering.",
  "closed_at":"2020-01-16T23:45:41Z",
  "comments":3,
  "created_at":"2020-01-14T14:51:35Z",
  "id":549617986,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":"2020-01-21T05:18:35Z",
   "closed_issues":3,
   "created_at":"2020-01-14T15:09:48Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Want to turn any JSON into Awkward Arrays and iterate over them in Numba.",
   "due_on":"2020-01-20T08:00:00Z",
   "id":5003818,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgxOA==",
   "number":2,
   "open_issues":0,
   "state":"closed",
   "title":"For Numba demo",
   "updated_at":"2020-01-21T05:18:35Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MTc5ODY=",
  "number":54,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"UnionArray",
  "updated_at":"2020-01-16T23:45:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"To protect VirtualArrays from accidentally being read when viewed from above.\r\n\r\nQuantified by `start`, `stride`, `length` (because that's more easily composable). Defers to `IndexedArray` when sliced by an array.\r\n\r\nProbably need to update [SlicedArray wiki page](https://github.com/scikit-hep/awkward-1.0/wiki/SlicedArray.md).",
  "closed_at":"2020-02-21T21:45:29Z",
  "comments":1,
  "created_at":"2020-01-14T14:59:37Z",
  "id":549623014,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":4,
   "created_at":"2020-01-14T15:05:26Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Just getting arrays (including lazy arrays) out of uproot requires all of these types.\r\n\r\nSome users use the uproot lazy arrays; dropping that in uproot 4.0 is not an option. (Even temporarily?)",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003808,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgwOA==",
   "number":1,
   "open_issues":0,
   "state":"open",
   "title":"Needed for uproot",
   "updated_at":"2020-04-29T02:31:24Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MjMwMTQ=",
  "number":55,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"SlicedArray",
  "updated_at":"2020-02-21T21:45:29Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fully functional in C++. This is not the `RegularChunkedArray`.\r\n\r\nMight need to update the [ChunkedArray wiki page](https://github.com/scikit-hep/awkward-1.0/wiki/ChunkedArray.md).",
  "closed_at":"2020-04-19T15:29:39Z",
  "comments":2,
  "created_at":"2020-01-14T15:01:41Z",
  "id":549624263,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":4,
   "created_at":"2020-01-14T15:05:26Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Just getting arrays (including lazy arrays) out of uproot requires all of these types.\r\n\r\nSome users use the uproot lazy arrays; dropping that in uproot 4.0 is not an option. (Even temporarily?)",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003808,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgwOA==",
   "number":1,
   "open_issues":0,
   "state":"open",
   "title":"Needed for uproot",
   "updated_at":"2020-04-29T02:31:24Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MjQyNjM=",
  "number":56,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"PartitionedArray",
  "updated_at":"2020-04-19T15:29:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Can be passed through C++, but it's only functional in Python.\r\n\r\nHave to think hard about how to do this in Numba. Materialize on entry or pass around `PyObject` pointer?\r\n\r\nMight have to change (and rename) [VirtualArray wiki page](https://github.com/scikit-hep/awkward-1.0/wiki/VirtualArray.md).",
  "closed_at":"2020-04-29T02:31:23Z",
  "comments":1,
  "created_at":"2020-01-14T15:03:05Z",
  "id":549625157,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":4,
   "created_at":"2020-01-14T15:05:26Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Just getting arrays (including lazy arrays) out of uproot requires all of these types.\r\n\r\nSome users use the uproot lazy arrays; dropping that in uproot 4.0 is not an option. (Even temporarily?)",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003808,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgwOA==",
   "number":1,
   "open_issues":0,
   "state":"open",
   "title":"Needed for uproot",
   "updated_at":"2020-04-29T02:31:24Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MjUxNTc=",
  "number":57,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"VirtualArray",
  "updated_at":"2020-04-29T02:31:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Ironically, `IndexedMaskedArray` (from `FillableArray`) and `BitMaskedArray` (from Arrow/Parquet) are more important than `ByteMaskedArray`. The `ByteMaskedArray` might actually lag behind and not get implemented for a while.\r\n\r\nMight need to change the [BitMaskedArray wiki page](https://github.com/scikit-hep/awkward-1.0/wiki/BitMaskedArray.md).",
  "closed_at":"2020-03-16T18:04:44Z",
  "comments":2,
  "created_at":"2020-01-14T15:15:03Z",
  "id":549632735,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":3,
   "created_at":"2020-01-14T15:12:55Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Which is relevant for ServiceX.",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003826,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgyNg==",
   "number":3,
   "open_issues":0,
   "state":"open",
   "title":"Needed for Arrow/Parquet",
   "updated_at":"2020-05-14T02:53:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MzI3MzU=",
  "number":58,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"BitMaskedArray",
  "updated_at":"2020-03-16T18:04:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Any Arrow/Parquet data that doesn't have an explicit mask should be an `UnmaskedArray`, so that the data types are uniform.\r\n\r\nMight need to change the [UnmaskedArray wiki page](https://github.com/scikit-hep/awkward-1.0/wiki/UnmaskedArray.md).",
  "closed_at":"2020-03-16T18:04:44Z",
  "comments":0,
  "created_at":"2020-01-14T15:16:35Z",
  "id":549633713,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":3,
   "created_at":"2020-01-14T15:12:55Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Which is relevant for ServiceX.",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003826,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgyNg==",
   "number":3,
   "open_issues":0,
   "state":"open",
   "title":"Needed for Arrow/Parquet",
   "updated_at":"2020-05-14T02:53:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MzM3MTM=",
  "number":59,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"UnmaskedArray",
  "updated_at":"2020-03-16T18:04:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Also known as [NEP 13](https://www.numpy.org/neps/nep-0013-ufunc-overrides.html).",
  "closed_at":"2020-01-21T05:18:16Z",
  "comments":1,
  "created_at":"2020-01-14T15:20:27Z",
  "id":549636272,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":"2020-01-21T05:18:35Z",
   "closed_issues":3,
   "created_at":"2020-01-14T15:09:48Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Want to turn any JSON into Awkward Arrays and iterate over them in Numba.",
   "due_on":"2020-01-20T08:00:00Z",
   "id":5003818,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgxOA==",
   "number":2,
   "open_issues":0,
   "state":"closed",
   "title":"For Numba demo",
   "updated_at":"2020-01-21T05:18:35Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MzYyNzI=",
  "number":60,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"NumPy ufuncs",
  "updated_at":"2020-01-21T05:18:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Also known as [NEP 18](https://www.numpy.org/neps/nep-0018-array-function-protocol.html).",
  "closed_at":"2020-01-24T23:29:49Z",
  "comments":1,
  "created_at":"2020-01-14T15:21:13Z",
  "id":549636761,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2MzY3NjE=",
  "number":61,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"NumPy functions",
  "updated_at":"2020-01-24T23:29:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-28T23:00:57Z",
  "comments":1,
  "created_at":"2020-01-14T15:22:21Z",
  "id":549637482,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2Mzc0ODI=",
  "number":62,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.Array.__getattr__ should pass through Record fields",
  "updated_at":"2020-01-28T23:00:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-28T21:51:19Z",
  "comments":2,
  "created_at":"2020-01-14T15:23:04Z",
  "id":549637942,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2Mzc5NDI=",
  "number":63,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.Array should be a Pandas column type",
  "updated_at":"2020-01-28T21:51:19Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-16T05:32:48Z",
  "comments":2,
  "created_at":"2020-01-14T15:23:53Z",
  "id":549638463,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2Mzg0NjM=",
  "number":64,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.Array and ak.Record in Numba",
  "updated_at":"2020-02-16T05:32:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This function exists for all types, but raises an error if it cannot immediately be converted to a regular NumPy array (including, possibly, [structured arrays](https://docs.scipy.org/doc/numpy/user/basics.rec.html) and [masked arrays](https://docs.scipy.org/doc/numpy/reference/maskedarray.html)).\r\n\r\nA `ListType` that happens to be regular just gets converted without error.\r\n\r\nIf it's clear how to get a regular array, but in a way that does not preserve information (e.g. flattening), include that hint in the error message. Users attempting to histogram a jagged array is a very common issue.",
  "closed_at":"2020-01-28T21:50:55Z",
  "comments":1,
  "created_at":"2020-01-14T15:28:53Z",
  "id":549641865,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NDE4NjU=",
  "number":65,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.tonumpy and ak.Array.__array__",
  "updated_at":"2020-01-28T21:50:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Similar to\r\n\r\n   * [numpy.broadcast](https://docs.scipy.org/doc/numpy/reference/generated/numpy.broadcast.html)\r\n   * [numpy.broadcast_arrays](https://docs.scipy.org/doc/numpy/reference/generated/numpy.broadcast_arrays.html)\r\n   * [numpy.broadcast_to](https://docs.scipy.org/doc/numpy/reference/generated/numpy.broadcast_to.html)\r\n\r\n(or maybe just one or two of them). It should return the same results for regular arrays, but extend naturally to jagged arrays and masked arrays.\r\n\r\nFollow `pyarrow.Array`'s behavior for slicing with masked arrays (`IndexedOptionArray`, `BitMaskedArray`, and eventually `ByteMaskedArray`).",
  "closed_at":"2020-01-21T05:30:34Z",
  "comments":0,
  "created_at":"2020-01-14T15:33:38Z",
  "id":549645173,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NDUxNzM=",
  "number":66,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Explicit broadcasting functions for jagged and non-jagged arrays and scalars.",
  "updated_at":"2020-01-21T05:30:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"~~Relies upon #66.~~\r\n\r\nFollow `pyarrow.Array`'s behavior for slicing with masked arrays (`IndexedOptionArray`, `BitMaskedArray`, and eventually `ByteMaskedArray`).\r\n\r\nWill need to extend `Slice` hierarchy and add jagged and masked cases to `Content::getitem_*`.",
  "closed_at":"2020-02-09T10:46:43Z",
  "comments":8,
  "created_at":"2020-01-14T15:35:45Z",
  "id":549646666,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NDY2NjY=",
  "number":67,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Extend `__getitem__` to include jagged and masked arrays in slices.",
  "updated_at":"2020-02-09T10:46:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjM5ODc4Njc1",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Similar to the [Awkward \u2194 Arrow conversions in Awkward0](https://github.com/scikit-hep/awkward-array/blob/master/awkward/arrow.py), except in C++, rather than Python.\r\n\r\nIt's a recursive if-elseif-elseif-...-else chain down the list of array node types, replacing each from one library with its equivalent in the other. Conversions from Arrow \u2192 Awkward can be zero-copy, now that BitMaskedArray exists, and conversions from Awkward \u2192 Arrow would involve one copy (to move the disparate buffers into Arrow's single buffer format).",
  "closed_at":"2020-05-14T02:53:21Z",
  "comments":5,
  "created_at":"2020-01-14T15:37:10Z",
  "id":549647583,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":3,
   "created_at":"2020-01-14T15:12:55Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Which is relevant for ServiceX.",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003826,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgyNg==",
   "number":3,
   "open_issues":0,
   "state":"open",
   "title":"Needed for Arrow/Parquet",
   "updated_at":"2020-05-14T02:53:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NDc1ODM=",
  "number":68,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"toarrow and fromarrow",
  "updated_at":"2020-05-14T02:53:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is an operation, so it is similar in scope to `Content::flatten`. (Time management: it's one of the hardest; maybe you don't want to _start_ with this.)\r\n\r\nThe generic reducer operation reduces list depth by 1, much like the `Content::flatten` operation. It takes an array at some depth (`axis` parameter, just like `flatten`), a function of two arguments (maybe templated by array type?), and an identity (of that same type).\r\n\r\nOnce the generic reducer is in place, all concrete reducers can be implemented. They are:\r\n\r\n| reducer | type | binary function | identity |\r\n|:--:|:--:|:--:|:--:|\r\n| **any** | boolean | logical or | `false` |\r\n| **all** | boolean | logical and | `true` |\r\n| **count** | any | `+1` for each argument | `0` |\r\n| **count_nonzero** | numerical | `+1` for each non-zero argument | `0` |\r\n| **sum** | numerical | `+` | `0` |\r\n| **prod** | numerical | `*` | `1` |\r\n| **min** | numerical | `x < y ? x : y` | `inf` |\r\n| **max** | numerical | `x > y ? x : y` | `-inf` |\r\n\r\nFor integer types, **min** and **max** should use the integer type's maximum and minimum value as an identity.\r\n\r\nAs a later enhancement, there should also be a way to skip `None` in arrays of OptionType.",
  "closed_at":"2020-02-16T05:08:23Z",
  "comments":2,
  "created_at":"2020-01-14T15:51:06Z",
  "id":549656559,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NTY1NTk=",
  "number":69,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Generic reducer operation",
  "updated_at":"2020-02-16T05:08:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Like the [NumPy functions of the same name](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html), these operations return an integer array of the _positions_ of the minimum and maximum values per subarray. (By the way, this is technically not a reducer in the sense of issue #69 and it would have an independent implementation.)\r\n\r\n```python\r\n>>> import numpy\r\n>>> nparray = numpy.array([[1.1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]])\r\n>>> nparray.argmin(axis=0).tolist()\r\n[0, 0, 0]\r\n>>> nparray.argmax(axis=0).tolist()\r\n[2, 2, 2]\r\n```\r\n\r\nThe old Awkward Array had a different return type for this function:\r\n\r\n```python\r\n>>> import awkward\r\n>>> akarray = awkward.fromiter([[1.1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]])\r\n>>> akarray.argmin().tolist()\r\n[[0], [0], [0]]\r\n>>> akarray.argmax().tolist()\r\n[[2], [2], [2]]\r\n```\r\n\r\nin order to handle cases without a minimum or maximum, which are possible because of the existence of jagged arrays.\r\n\r\n```python\r\n>>> akarray = awkward.fromiter([[1.1, 2.2, 3.3], [], [4.4, 5.5]])\r\n>>> akarray.argmin().tolist()\r\n[[0], [], [0]]\r\n>>> akarray.argmax().tolist()\r\n[[2], [], [1]]\r\n```\r\n\r\nThese jagged integer arrays could then be used as slices, so it was a _useful_ deviation from NumPy.\r\n\r\nHowever, deviating at all from NumPy is bad, especially if the function has the same name and mostly the same meaning. Instead of what was done in the old Awkward, the above should return\r\n\r\n```python\r\n>>> ak.tolist(ak.argmin(akarray))\r\n[0, None, 0]\r\n>>> ak.tolist(ak.argmax(akarray))\r\n[2, None, 1]\r\n```\r\n\r\nFor regular arrays, this behavior would be identical to NumPy's; for irregular ones, users are introduced to OptionType arrays (most likely [IndexedOptionArray](https://github.com/scikit-hep/awkward-1.0/wiki/IndexedOptionArray.md), which has already been implemented, but possibly [ByteMaskedArray](https://github.com/scikit-hep/awkward-1.0/wiki/ByteMaskedArray.md) or [BitMaskedArray](https://github.com/scikit-hep/awkward-1.0/wiki/BitMaskedArray.md)).\r\n\r\nI'll be allowing these arrays as slices in #67 (following the behavior established by `pyarrow`), so they'll also be useful.\r\n\r\n@nsmith- might want to comment on this change in behavior.",
  "closed_at":"2020-03-17T01:07:06Z",
  "comments":2,
  "created_at":"2020-01-14T16:26:07Z",
  "id":549678116,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2NzgxMTY=",
  "number":70,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"argmin and argmax",
  "updated_at":"2020-04-06T20:56:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"**Edit:** instead of providing the `dropna` operation in C++, it would be sufficient to provide an `isna` (which takes an `axis` and returns boolean at the level of the `axis` as to whether an element is `None` or not). This would be easier to implement and we can do `dropna` as a combination of `isna` and slicing (at the Python level if a convenience function is needed, if at all).\r\n\r\n------------------\r\n\r\nNamed after the [Pandas function of the same name](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), this removes `None` values from an array with OptionType.\r\n\r\nNote that it can turn `RegularArrays` into `ListOffsetArrays`, but preserves the level of nesting. It takes an `axis` parameter, and that `axis` has to correspond with an OptionType array or it does nothing.\r\n\r\nThis operation makes the new return behavior of `argmin`/`argmax` more useful because now that users have to deal with a lot of `None` values; maybe they just want to get rid of them. @nsmith- may want to comment on this as well.\r\n\r\nThe existence of `dropna` could make it unnecessary for reducers to explicitly deal with missing values, which is a nice simplification (to issue #69). Users could call `dropna` before calling the reducer if they don't want to count/sum/whatever the missing values.\r\n\r\nThis and other \"*na\" functions should take a `nan_is_na=True` parameter to control whether floating-point `NaN` counts as a missing value to drop. The primary missing value is `None`, which is only possible for arrays with OptionType. `NaN` is a weird exception for agreement with Pandas, which ought to be optional. @nsmith- may have opinions about this, too.",
  "closed_at":"2020-01-28T21:59:30Z",
  "comments":4,
  "created_at":"2020-01-14T16:36:18Z",
  "id":549684312,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2ODQzMTI=",
  "number":71,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"isna (formerly: dropna)",
  "updated_at":"2020-01-31T18:52:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Similar to #71, except that it replaces the values of `None` elements, rather than dropping them. (Therefore, list lengths don't change, `RegularArrays` can't change into `ListOffsetArrays`, etc. This is easier than #71.) It's also inspired by a [Pandas function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) and should have the `nan_is_na` option.\r\n\r\nOld Awkward had this as well, and it has proven its usefulness.",
  "closed_at":"2020-03-17T21:21:10Z",
  "comments":1,
  "created_at":"2020-01-14T16:39:16Z",
  "id":549686096,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2ODYwOTY=",
  "number":72,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"fillna",
  "updated_at":"2020-03-17T21:21:11Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is an operation that turns an array at some level (i.e. has an `axis` parameter) into an OptionType by putting extra `None` elements in until it reaches a given length.\r\n\r\nOld Awkward [had an implementation of this](https://github.com/scikit-hep/awkward-array/blob/3442c51ed5dafb7d94f828c6cdc07659f9c03244/awkward/array/jagged.py#L1839-L1888), though it will probably be simpler now. Also, ignore the old `clip` parameter: that's easy enough to do with a slice after the fact. This was another proven-to-be useful operation.\r\n\r\nDon't double-up OptionTypes: if something is already an OptionType, extend it.\r\n\r\nThe implementation might be identical for all non-OptionTypes (those are exceptional because you have to explicitly avoid doubling-up the OptionType): you just put the existing array in an `IndexedOptionArray` that points to the original array with gaps left for the new `None` values.",
  "closed_at":"2020-03-09T14:06:20Z",
  "comments":2,
  "created_at":"2020-01-14T16:45:02Z",
  "id":549689392,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2ODkzOTI=",
  "number":73,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"pad",
  "updated_at":"2020-03-09T14:06:20Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"At some level (i.e. this has an `axis` parameter), sort the array. Define the `argsort` version in C++ and we can do the `sort` with an array-slice on the Python side.\r\n\r\nSort orders for numbers in NumpyArray are easy to define, but something will have to be done to sort arrays and records as well. Python has an ordering defined on lists:\r\n\r\n```python\r\n>>> [1, 2, 3] < [1, 2]\r\nFalse\r\n>>> [1, 2, 3] > [1, 2]\r\nTrue\r\n```\r\n\r\nbut not records (dicts):\r\n\r\n```python\r\n>>> {\"one\": 1, \"two\": 2, \"three\": 3} < {\"one\": 1, \"two\": 2}\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: '<' not supported between instances of 'dict' and 'dict'\r\n```\r\n\r\nHowever, our `Record` types are actually tuples\u2014there's a defined field order (unlike Python dicts), so we should be able to inherit a definition from Python tuples:\r\n\r\n```python\r\n>>> (1, \"a\", None) < (1, \"a\")\r\nFalse\r\n>>> (1, \"a\", None) > (1, \"a\")\r\nTrue\r\n```",
  "closed_at":"2020-06-15T18:37:21Z",
  "comments":3,
  "created_at":"2020-01-14T16:50:06Z",
  "id":549692230,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2OTIyMzA=",
  "number":74,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"argsort and sort",
  "updated_at":"2020-06-15T18:37:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"[numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html) takes three arguments (ignore the single-argument version: it's equivalent to `nonzero` and we can do that other ways):\r\n\r\n   * `condition`, a boolean array\r\n   * `x`, any array\r\n   * `y`, any array\r\n\r\nand returns a single array with `x` values if `condition` is `true` and `y` values if `condition` is false.\r\n\r\nWe can do this in Awkward even if `x` and `y` are not the same type; `ak.where` would return a [UnionArray](https://github.com/scikit-hep/awkward-1.0/wiki/UnionArray.md) (my issue #54).\r\n\r\nIf `x` and `y` do have the same type, we can return something simpler. Actually, we can do well by implementing the general case with `UnionArray` first, then add special cases like \"both are `NumpyArrays` of the same `format`\" or \"both have ListType with compatible `content`,\" one by one as needed.",
  "closed_at":"2020-01-24T23:28:45Z",
  "comments":2,
  "created_at":"2020-01-14T16:55:26Z",
  "id":549695327,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2OTUzMjc=",
  "number":75,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"where",
  "updated_at":"2020-01-24T23:28:45Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Another basic operation, again following [NumPy's naming convention](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html).\r\n\r\nThere was an [implementation of this in old Awkward](https://github.com/scikit-hep/awkward-array/blob/3442c51ed5dafb7d94f828c6cdc07659f9c03244/awkward/array/jagged.py#L1621-L1722), but only for `axis=0` and `axis=1` because all other cases were too hard. It has been used as a motivating case for writing Awkward 1.0 because these should be easier now.\r\n\r\nLike `where` (issue #75), `concatenate` can start by always returning a `UnionArray`, because that will always work. Then, maybe, special cases can be added.",
  "closed_at":"2020-01-25T23:32:13Z",
  "comments":1,
  "created_at":"2020-01-14T17:00:36Z",
  "id":549698331,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk2OTgzMzE=",
  "number":76,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"concatenate",
  "updated_at":"2020-01-25T23:32:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is an operation that combines a list (`std::vector`) of arrays (`std::shared_ptr<Content>`) into a `RecordArray` if any member of that list is one-dimensional, and a `ListArray` or `RegularArray` of `RecordArray` for each dimension that all arrays share.\r\n\r\nIt [existed in old Awkward](https://github.com/scikit-hep/awkward-array/blob/3442c51ed5dafb7d94f828c6cdc07659f9c03244/awkward/array/jagged.py#L1724-L1837), though the implementation will be easier now. Here's what that looked like:\r\n\r\n```python\r\n>>> import awkward\r\n>>> first = awkward.fromiter([[1, 2, 3], [], [4, 5]])\r\n>>> second = awkward.fromiter([[1.1, 2.2, 3.3], [], [4.4, 5.5]])\r\n>>> awkward.JaggedArray.zip(first, second)\r\n<JaggedArray [[(1, 1.1) (2, 2.2) (3, 3.3)] [] [(4, 4.4) (5, 5.5)]] at 0x7fb20a91c590>\r\n```\r\n\r\nThose 2-tuples are a `RecordArray` in which the first field is from `first` and the second field is from `second`. Since `first` and `second` are both ListType _with the same subarray lists for each element_, the output is a ListType of RecordType (e.g. `ListOffsetArray` of `RecordArray`), in which the shared `offsets` are used in the single `ListOffsetArray` that wraps the `RecordArray`.\r\n\r\nPerhaps this was too implicit in the past\u2014perhaps there should be a `zipdepth` parameter that explicitly controls how many levels of list nesting to _expect_ to be identical for all arguments (throwing an error if they're not).\r\n\r\n`zip` is the way to make particle records from CMS NanoAOD, for instance. (It's useful.)",
  "closed_at":"2020-03-11T15:35:55Z",
  "comments":4,
  "created_at":"2020-01-14T17:12:10Z",
  "id":549704512,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk3MDQ1MTI=",
  "number":77,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"zip",
  "updated_at":"2020-03-11T15:35:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Implementing `argcross` in C++ is sufficient; we can do `cross` in Python.\r\n\r\nThis computes a Cartesian product per element. Given a list (`std::vector`) of arrays (`std::shared_ptr<Content>`), it makes a `ListOffsetArray` of `RecordArray` of combinations. For example,\r\n\r\n```python\r\n>>> import awkward\r\n>>> first = awkward.fromiter([[1, 2, 3], [], [4, 5]])\r\n>>> second = awkward.fromiter([[\"a\", \"b\"], [\"c\"], [\"d\", \"e\", \"f\"]])\r\n>>> first.cross(second)\r\n<JaggedArray [[(1, a) (1, b) (2, a) (2, b) (3, a) (3, b)]\r\n              []\r\n              [(4, d) (4, e) (4, f) (5, d) (5, e) (5, f)]]>\r\n```\r\n\r\nThis and `choose` (issue #79) are the two basic generators of particle combinatorics in HEP analyses.",
  "closed_at":"2020-03-11T22:58:27Z",
  "comments":5,
  "created_at":"2020-01-14T17:17:46Z",
  "id":549707470,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk3MDc0NzA=",
  "number":78,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"argcross and cross",
  "updated_at":"2020-03-12T01:36:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Like #78, it is sufficient to define only `argchoose` in C++; we can add `chose` in Python.\r\n\r\nThis takes only one array and computes the per-element upper triangle of combinations of that array with itself. It is \"choosing without replacement.\" For example,\r\n\r\n```python\r\n>>> import awkward\r\n>>> first = awkward.fromiter([[1, 2, 3], [], [4, 5]])\r\n>>> second = awkward.fromiter([[\"a\", \"b\"], [\"c\"], [\"d\", \"e\", \"f\"]])\r\n>>> first.choose(2)\r\n<JaggedArray [[(1, 2) (1, 3) (2, 3)] [] [(4, 5)]] at 0x7fc91ccce850>\r\n>>> second.choose(2)\r\n<JaggedArray [[(a, b)] [] [(d, e) (d, f) (e, f)]] at 0x7fc91d58b110>\r\n```\r\n\r\nThe parameter, `n >= 2`, is the number of fields the output tuples should have. Choosing with `n=3` is different from choosing with `n=2` and then `cross` on the output: `choose` selects the upper diagonal in an `n`-dimensional matrix of possibilities. For example,\r\n\r\n```python\r\n>>> second.choose(3)\r\n<JaggedArray [[] [] [(d, e, f)]] at 0x7fc91ccce590>\r\n```\r\n\r\nis not the same as\r\n\r\n```python\r\n>>> second.choose(2).cross(second)\r\n<JaggedArray [[(a, b, a) (a, b, b)] [] [(d, e, d) (d, e, e) (d, e, f) ... (e, f, d) (e, f, e) (e, f, f)]] at 0x7fc91cc6add0>\r\n```\r\n\r\nbecause the latter doesn't eliminate duplicates like `(a, b, a)`. The only way to pick three letters without duplicates is if the original array had three elements, like `[\"d\", \"e\", \"f\"]` in `second[2]` (which is why it's the only non-empty result of `second.choose(3)`.\r\n\r\nThis and `cross` (issue #78) are the two basic generators of particle combinatorics in HEP analyses.",
  "closed_at":"2020-03-13T02:24:17Z",
  "comments":3,
  "created_at":"2020-01-14T17:28:27Z",
  "id":549712945,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NDk3MTI5NDU=",
  "number":79,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"argchoose and choose",
  "updated_at":"2020-03-13T02:24:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Like the old `topandas(flatten=True)`.",
  "closed_at":"2020-03-10T23:07:49Z",
  "comments":1,
  "created_at":"2020-01-14T17:35:56Z",
  "id":549716558,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":4,
   "created_at":"2020-01-14T15:05:26Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"Just getting arrays (including lazy arrays) out of uproot requires all of these types.\r\n\r\nSome users use the uproot lazy arrays; dropping that in uproot 4.0 is not an option. (Even temporarily?)",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003808,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzgwOA==",
   "number":1,
   "open_issues":0,
   "state":"open",
   "title":"Needed for uproot",
   "updated_at":"2020-04-29T02:31:24Z"
  },
  "node_id":"MDU6SXNzdWU1NDk3MTY1NTg=",
  "number":80,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"flatpandas: flatten jaggedness and records into MultiIndex rows and columns",
  "updated_at":"2020-03-10T23:07:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-15T01:13:10Z",
  "comments":0,
  "created_at":"2020-01-14T17:54:45Z",
  "draft":false,
  "id":549725593,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYyNzY0MTkx",
  "number":81,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-15T01:13:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Issue #50: IndexedArray::flatten for axis=0",
  "updated_at":"2020-01-15T01:13:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Issue #52 and maybe also #53.",
  "closed_at":"2020-01-16T02:16:34Z",
  "comments":0,
  "created_at":"2020-01-15T19:37:48Z",
  "draft":false,
  "id":550388151,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYzMzAzMjIz",
  "number":82,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-16T02:16:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Finish up IndexedArray.",
  "updated_at":"2020-01-16T02:16:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Start work on issue #51\r\n",
  "closed_at":"2020-01-29T16:32:13Z",
  "comments":9,
  "created_at":"2020-01-16T10:23:02Z",
  "draft":false,
  "id":550711380,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYzNTY2OTg5",
  "number":83,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-29T16:32:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"*::flatten for axis != 0",
  "updated_at":"2020-01-31T08:45:47Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This will address #54. Another issue should be made to make `UnionArray` complete, as this PR won't include such things as ~`Identities` and~ the Numba implementation.",
  "closed_at":"2020-01-17T00:23:27Z",
  "comments":2,
  "created_at":"2020-01-16T15:40:11Z",
  "draft":false,
  "id":550888268,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzYzNzEwNzIx",
  "number":84,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-17T00:23:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"UnionArray: only the basics so that any JSON can be ingested.",
  "updated_at":"2020-01-17T14:49:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"PR #84 implements `UnionArray` with `Identities`, but not with a Numba.\r\n\r\nHow _would_ Numba handle variant data?",
  "closed_at":"2020-02-16T05:32:07Z",
  "comments":1,
  "created_at":"2020-01-16T23:47:11Z",
  "id":551119544,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTExMTk1NDQ=",
  "number":85,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"UnionArray in Numba",
  "updated_at":"2020-02-16T05:32:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-21T05:30:33Z",
  "comments":0,
  "created_at":"2020-01-18T01:48:21Z",
  "draft":false,
  "id":551704433,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY0Mzc4OTA4",
  "number":86,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-21T05:30:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"For issue #60, NEP 13: allow NumPy ufuncs to be called on ak.Array",
  "updated_at":"2020-01-21T05:30:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-01-22T04:16:51Z",
  "comments":0,
  "created_at":"2020-01-21T13:40:31Z",
  "draft":false,
  "id":552883649,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY1MzEwNjAz",
  "number":87,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-22T04:16:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Start working on a demo for Numba.",
  "updated_at":"2020-01-22T04:16:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"```python\r\nimport awkward1 as ak\r\na = ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5], [6.6, 7.7, 8.8, 9.9]])\r\nb = ak.Array([[100, 200, 300], [],       None, [600, 700, 800, 900]])\r\nak.tolist(a + b)\r\n```",
  "closed_at":"2020-01-23T16:15:43Z",
  "comments":4,
  "created_at":"2020-01-21T21:59:00Z",
  "id":553160073,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTMxNjAwNzM=",
  "number":88,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Maybe need to handle OptionTypes before ListTypes in ufuncs",
  "updated_at":"2020-01-23T16:53:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Also, think hard about this problem of left-broadcasting versus right-broadcasting and whether ambiguity in list-vs-mask or ambiguous list depth makes `np.newaxis` _necessary_ for broadcasting.\r\n\r\nI might need to modify `minmax_depth` and/or add similar functions to C++.",
  "closed_at":"2020-01-24T23:43:26Z",
  "comments":0,
  "created_at":"2020-01-23T15:40:04Z",
  "draft":false,
  "id":554236882,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY2NDI3NjM4",
  "number":89,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-24T23:43:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Address issues #88 and #61 with more complete tests.",
  "updated_at":"2020-01-24T23:43:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-03T21:47:40Z",
  "comments":2,
  "created_at":"2020-01-24T22:21:13Z",
  "id":554982392,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTQ5ODIzOTI=",
  "number":90,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"UnionArray.simplify method, which functions like ak.where can use to output non-unions if possible",
  "updated_at":"2020-02-03T21:47:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It should become a real implemention (not just working but also satisfying the \"no Python loops\" rule).",
  "closed_at":"2020-02-06T00:13:02Z",
  "comments":1,
  "created_at":"2020-01-24T23:37:13Z",
  "id":555003867,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTUwMDM4Njc=",
  "number":91,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"numpy.equal(string, string) is a (working) dummy implementation",
  "updated_at":"2020-02-06T00:13:02Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I.e. implement issue #63.",
  "closed_at":"2020-01-28T21:49:18Z",
  "comments":6,
  "created_at":"2020-01-25T20:43:05Z",
  "draft":false,
  "id":555135909,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY3MTUzMjQ0",
  "number":92,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-28T21:49:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Make ak.Array a Pandas DType extension.",
  "updated_at":"2020-01-29T15:00:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #90.",
  "closed_at":"2020-02-03T22:15:34Z",
  "comments":0,
  "created_at":"2020-01-28T22:05:50Z",
  "draft":false,
  "id":556500077,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY4MjU1OTE2",
  "number":93,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-03T22:15:34Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"UnionArray::simplify and IndexedOptionArray::simplify, to be used by functions that would naively return uniontypes and optiontypes.",
  "updated_at":"2020-02-03T22:15:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #62.",
  "closed_at":"2020-01-28T23:00:56Z",
  "comments":0,
  "created_at":"2020-01-28T22:11:29Z",
  "draft":false,
  "id":556503559,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY4MjU4OTI3",
  "number":94,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-28T23:00:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ak.Array.__getattr__ for record fields",
  "updated_at":"2020-01-28T23:00:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The StructModels that we're using now are all pass-by-value. Since all of the reference counts need to be debugged anyway, let's do that after converting all the field references to pointers.\r\n\r\nWe've already seen linear scaling with the number of fields in records\u2014unused record fields ight to have no impact on performance.\r\n\r\nThe conversion can be done on mass by replacing the chutils `proxy_helper` with my own, to do the deferencing and reference counting automatically.",
  "closed_at":"2020-02-25T21:26:34Z",
  "comments":0,
  "created_at":"2020-01-29T12:13:08Z",
  "id":556823000,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTY4MjMwMDA=",
  "number":95,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Migrate Numba models to have CPointers to fields",
  "updated_at":"2020-02-25T21:26:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Second part of the issue #51\r\n\r\nImplement *::count for axis !=0 where the following error is thrown:\r\n```RuntimeError: FIXME: ListOffsetArray::count(axis != 0)```\r\n```RuntimeError: FIXME: NumpyArray::count(axis != 0)```\r\n```RuntimeError: FIXME: RegularArray::count(axis != 0)```\r\n",
  "closed_at":"2020-02-04T17:04:03Z",
  "comments":3,
  "created_at":"2020-01-29T14:35:56Z",
  "draft":false,
  "id":556903138,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY4NTkwOTYy",
  "number":96,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-04T17:04:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implemented *::count for axis != 0",
  "updated_at":"2020-02-04T22:21:59Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"If in an interactive terminal, the `name` attribute of the top frame module is None, so guard against it.\r\n\r\nIncidentally, `awkward1/signatures/Identities_8cpp.xml` was modified.  It appears machine-generated, is it something that should be in version control? Should I add it?",
  "closed_at":"2020-01-29T17:18:03Z",
  "comments":1,
  "created_at":"2020-01-29T17:12:17Z",
  "draft":false,
  "id":557000789,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY4NjcxODgz",
  "number":97,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-29T17:18:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Guard against inspecting __main__ module",
  "updated_at":"2020-01-29T17:25:30Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"* fix NumpyArray 32-bit vs 64-bit errors\r\n",
  "closed_at":"2020-01-30T18:32:53Z",
  "comments":7,
  "created_at":"2020-01-30T11:32:57Z",
  "draft":false,
  "id":557434521,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY5MDI0MjI1",
  "number":98,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-01-30T18:32:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bugfix for NumpyArray 32-bit vs 64-bit errors",
  "updated_at":"2020-01-30T18:32:56Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I'm building up the example classes for such a study in `studies/flatten.py`. It's a good idea to make sure the logic is fully understood first.",
  "closed_at":"2020-03-05T20:10:20Z",
  "comments":13,
  "created_at":"2020-01-30T22:49:51Z",
  "draft":false,
  "id":557804023,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY5MzI3Nzg2",
  "number":99,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[WIP] Study flatten logic in a simplified environment before writing the real thing.",
  "updated_at":"2020-03-10T06:17:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Some records have lots of fields, and the specialization has been more trouble than it's worth.",
  "closed_at":"2020-02-03T23:20:20Z",
  "comments":1,
  "created_at":"2020-01-31T00:33:30Z",
  "id":557840521,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTc4NDA1MjE=",
  "number":100,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Record should maintain a std::shared_ptr to the RecordArray, not an instance",
  "updated_at":"2020-02-03T23:20:20Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-06T00:11:27Z",
  "comments":2,
  "created_at":"2020-01-31T01:14:24Z",
  "id":557852846,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTc4NTI4NDY=",
  "number":101,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Need to distinguish between `ak.classes` for arrays and for records",
  "updated_at":"2020-02-06T00:11:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Flatten RecordArray and UnionArray only if the ```axis``` doesn't flatten the structure immediately within the *Arrays. \r\n\r\nThe PR addresses comments https://github.com/scikit-hep/awkward-1.0/pull/83#discussion_r372439470 and https://github.com/scikit-hep/awkward-1.0/pull/83#discussion_r372440992",
  "closed_at":"2020-03-05T20:09:05Z",
  "comments":2,
  "created_at":"2020-01-31T08:17:08Z",
  "draft":false,
  "id":557981075,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY5NDYzMzQy",
  "number":102,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[WIP] flatten RecordArray and UnionArray",
  "updated_at":"2020-03-05T20:22:28Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-04T21:22:28Z",
  "comments":1,
  "created_at":"2020-01-31T19:56:53Z",
  "id":558341254,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTgzNDEyNTQ=",
  "number":103,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Assign fields to records (`__setitem__`), which passes through all other types (including IndexedArray)",
  "updated_at":"2020-02-04T21:22:28Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-02T02:18:27Z",
  "comments":0,
  "created_at":"2020-02-01T23:07:02Z",
  "draft":false,
  "id":558612476,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzY5OTUwNjA2",
  "number":105,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-02T02:18:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Turn study/flatten.py into array documentation.",
  "updated_at":"2020-02-02T02:18:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #100.",
  "closed_at":"2020-02-03T23:30:22Z",
  "comments":0,
  "created_at":"2020-02-03T22:43:56Z",
  "draft":false,
  "id":559379623,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzcwNTU5NjA0",
  "number":106,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-03T23:30:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Record should hold a pointer to RecordArray, not an instance.",
  "updated_at":"2020-02-03T23:30:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #103. We'll need an `inverse` function on `IndexedArrays` and `UnionArrays`.",
  "closed_at":"2020-02-04T21:21:07Z",
  "comments":0,
  "created_at":"2020-02-03T23:25:54Z",
  "draft":false,
  "id":559395800,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzcwNTcyOTM3",
  "number":107,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-04T21:21:07Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Assign fields to records (deeply, through all structure).",
  "updated_at":"2020-02-04T21:21:11Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Here:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/b644322308f76ad37d7dc2a2bf7ad1af1b1fb608/awkward1/operations/structure.py#L27-L33",
  "closed_at":"2020-02-04T22:40:44Z",
  "comments":1,
  "created_at":"2020-02-04T14:40:35Z",
  "id":559763688,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTk3NjM2ODg=",
  "number":108,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.isna needs to `simplify` its UnionArray output",
  "updated_at":"2020-02-04T22:40:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Something like this:\r\n\r\n```c++\r\nreinterpret_cast<double*>(output.ptr())[0]\r\n```\r\n\r\n@lukasheinrich ",
  "closed_at":"2020-02-04T21:49:53Z",
  "comments":2,
  "created_at":"2020-02-04T21:03:36Z",
  "id":559977427,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NTk5Nzc0Mjc=",
  "number":109,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Numpy::asscalar<T>",
  "updated_at":"2020-02-04T22:06:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Likely includes\r\n\r\n   * [x] #91\r\n   * [x] #101\r\n   * [x] #108\r\n   * [x] #109.",
  "closed_at":"2020-02-06T00:32:08Z",
  "comments":0,
  "created_at":"2020-02-04T21:31:43Z",
  "draft":false,
  "id":559990924,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzcxMDYwNzE2",
  "number":110,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-06T00:32:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix several issues and anything that looks in need of cleanup.",
  "updated_at":"2020-02-06T00:32:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #67.",
  "closed_at":"2020-02-09T16:15:26Z",
  "comments":6,
  "created_at":"2020-02-06T00:34:33Z",
  "draft":false,
  "id":560710271,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzcxNjUzMjE2",
  "number":111,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-09T16:15:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Allow Awkward Arrays to be used as slices, including list-type and option-type.",
  "updated_at":"2020-02-09T16:15:29Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This needs to become a bunch of small files, in part to reduce compilation times.\r\n\r\nBut also, it should become a bunch of Python submodules, and I should verify that new Python modules can dynamically link to it and use the same types in C++.\r\n\r\nThis is relevant for @glass-ships's project.",
  "closed_at":"2020-02-11T04:36:57Z",
  "comments":0,
  "created_at":"2020-02-06T19:57:24Z",
  "id":561235902,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NjEyMzU5MDI=",
  "number":112,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Refactor pyawkward.cpp",
  "updated_at":"2020-02-11T04:36:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It should be easy now that `_util.broadcast_and_apply` exists. I should do it sometime when I only have a laptop, because it doesn't involve any compilation, just Python.",
  "closed_at":"2020-02-18T14:02:07Z",
  "comments":0,
  "created_at":"2020-02-07T14:16:09Z",
  "id":561662812,
  "labels":null,
  "locked":false,
  "milestone":{
   "closed_at":null,
   "closed_issues":31,
   "created_at":"2020-01-14T15:19:49Z",
   "creator":{
    "gravatar_id":"",
    "id":1852447,
    "login":"jpivarski",
    "node_id":"MDQ6VXNlcjE4NTI0NDc=",
    "site_admin":false,
    "type":"User"
   },
   "description":"A set of features that should be available on Day 1, also necessary for proper testing of the new `vector` library (upgrade of `hepvector` and `uproot-methods`'s `TLorentzVector`).",
   "due_on":"2020-02-28T08:00:00Z",
   "id":5003865,
   "node_id":"MDk6TWlsZXN0b25lNTAwMzg2NQ==",
   "number":4,
   "open_issues":0,
   "state":"open",
   "title":"Minimum viable product for analysis",
   "updated_at":"2020-06-15T18:37:21Z"
  },
  "node_id":"MDU6SXNzdWU1NjE2NjI4MTI=",
  "number":113,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"NumExpr support",
  "updated_at":"2020-02-18T14:02:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"addressing issue #73 \r\n",
  "closed_at":"2020-03-05T17:42:58Z",
  "comments":6,
  "created_at":"2020-02-10T10:55:36Z",
  "draft":false,
  "id":562481571,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzczMDY4MzU4",
  "number":114,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[WIP] rpad operation to length in axis",
  "updated_at":"2020-03-12T18:29:11Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #69.",
  "closed_at":"2020-02-16T05:08:23Z",
  "comments":3,
  "created_at":"2020-02-10T12:14:47Z",
  "draft":false,
  "id":562522094,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzczMTAxODk4",
  "number":115,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-16T05:08:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add reducer operations (with an 'axis' parameter).",
  "updated_at":"2020-02-16T05:08:28Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-11T04:36:58Z",
  "comments":4,
  "created_at":"2020-02-10T13:38:18Z",
  "draft":false,
  "id":562566541,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzczMTM5MTUy",
  "number":116,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-11T04:36:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Refactor pyawkward.cpp both for compilation speed and so that arrays can be dynamically loaded by dependent Python modules.",
  "updated_at":"2020-02-11T16:41:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"(It's important that it's plural: `sizes`!)\r\n\r\nThis is a follow-on from https://github.com/scikit-hep/awkward-1.0/pull/115#issuecomment-586623849.\r\n\r\nGiven an array like\r\n\r\n```python\r\n[[[  2,   3,   5,   7,  11],\r\n  [ 13,  17,  19,  23,  29],\r\n  [ 31,  37,  41,  43,  47]],\r\n [[ 53,  59,  61,  67,  71],\r\n  [ 73,  79,  83,  89,  97],\r\n  [101, 103, 107, 109, 113]]]\r\n```\r\n\r\n   * `array.sizes(axis=0)` should return `[3, 3]` (as a NumpyArray)\r\n   * `array.sizes(axis=1)` should return `[[5, 5, 5], [5, 5, 5]]` (as a RegularArray/ListArray/ListOffsetArray of NumpyArray)\r\n   * `array.sizes(axis=2)` should be illegal.\r\n\r\nI guess negative `axis` should count from the deepest possible, so `axis=-1` \u2192 `axis=1` and `axis=-2` \u2192 `axis=0`. Whatever this does, `flatten` should do the same, so this issue might supersede #51.\r\n\r\nLet's consider some examples with branching, to figure out what they should do. An array like\r\n\r\n```python\r\n[[{\"x\": [], \"y\": [[]]},\r\n  {\"x\": [1], \"y\": [[], [1]]},\r\n  {\"x\": [2, 2], \"y\": [[], [1], [2, 2]]}],\r\n [],\r\n [{\"x\": [3, 3, 3], \"y\": [[], [1], [2, 2], [3, 3, 3]]},\r\n  {\"x\": [4, 4, 4, 4], \"y\": [[], [1], [2, 2], [3, 3, 3], [4, 4, 4, 4]]}]]\r\n```\r\n\r\nhas depth 3 along `\"x\"` and depth 4 along `\"y\"`.\r\n\r\n   * `array.sizes(axis=0)` should return `[3, 0, 2]`.\r\n   * `array.sizes(axis=1)` should return `[[{\"x\": 0, \"y\": 1}, {\"x\": 1, \"y\": 2}, {\"x\": 2, \"y\": 3}], [], [{\"x\": 3, \"y\": 4}, {\"x\": 4, \"y\": 5}]]`\r\n   * `array.sizes(axis=2)` should be illegal because it fails for `\"x\"`. An exception occurs during the recursive descent; we don't have to check for it before descending.\r\n\r\nNow for the negative `axis` values:\r\n\r\n   * `array.sizes(axis=-1)` should return `[[{\"x\": 0, \"y\": [0]}, {\"x\": 1, \"y\": [0, 1]}, {\"x\": 2, \"y\": [0, 1, 2]}], [], [{\"x\": 3, \"y\": [0, 1, 2, 3]}, {\"x\": 4, \"y\": [0, 1, 2, 3, 4]}]]` because it represents the deepest `axis` along each branch.\r\n   * `array.sizes(axis=-2)` should be illegal because it wants to be a non-record along `\"x\"` and a record along `\"y\"`.\r\n\r\nSo, negative `axis` values aren't just synonyms for non-negative `axis` values, as they are for rectilinear data. The reducer operations (PR #115) have a similar meaning, though reducers can be applied one level deeper than `sizes` and `flatten` can, so it's a little different.\r\n\r\nI'm not sure whether @ianna or I will do this. We might need to figure it out together.\r\n\r\n@nsmith-: you might have opinions about the usefulness of negative `axis` having a different meaning than positive `axis` minus depth.",
  "closed_at":"2020-03-10T05:03:59Z",
  "comments":5,
  "created_at":"2020-02-15T18:57:07Z",
  "id":565793788,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NjU3OTM3ODg=",
  "number":117,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Rename counts (and counts64) to \"sizes\" and get the axis right",
  "updated_at":"2020-03-10T05:03:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-25T21:50:12Z",
  "comments":4,
  "created_at":"2020-02-16T05:14:24Z",
  "draft":false,
  "id":565853338,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzc1Nzg4NTgy",
  "number":118,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-25T21:50:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Replace Numba StructModels with CPointers and check all reference counts.",
  "updated_at":"2020-02-25T21:50:15Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses #113 and #66.",
  "closed_at":"2020-02-18T14:02:07Z",
  "comments":0,
  "created_at":"2020-02-18T12:13:57Z",
  "draft":false,
  "id":566852435,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzc2NTgzNzcz",
  "number":119,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-18T14:02:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Support NumExpr and add a 'broadcast_arrays' function.",
  "updated_at":"2020-02-18T14:02:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"pyhf has been asking for this (or something like it).",
  "closed_at":"2020-02-18T23:15:23Z",
  "comments":0,
  "created_at":"2020-02-18T21:44:10Z",
  "draft":false,
  "id":567176966,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzc2ODUxMTM5",
  "number":120,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-18T23:15:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Support the Autograd library in much the same way as NumExpr.",
  "updated_at":"2020-02-18T23:15:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-19T02:38:38Z",
  "comments":0,
  "created_at":"2020-02-19T02:02:21Z",
  "draft":false,
  "id":567267494,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzc2OTI1MTY5",
  "number":121,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-19T02:38:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Better distribution: drop case-sensitive name and ensure that RapidJSON is in the source distribution.",
  "updated_at":"2020-02-19T02:38:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It would perform all the tests described in [layouts.ipynb](https://github.com/scikit-hep/awkward-1.0/blob/master/docs/layouts.ipynb); for debugging.\r\n\r\nWhen something goes wrong on a user's system, we can ask, \"What happens if you call `isvalid` first?\"",
  "closed_at":"2020-03-06T20:07:26Z",
  "comments":0,
  "created_at":"2020-02-21T22:55:34Z",
  "id":569225279,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NjkyMjUyNzk=",
  "number":122,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"isvalid as an operation",
  "updated_at":"2020-03-06T20:07:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"We don't want `length()` queries to scale with `contents_.size()`.\r\n\r\nAlso, it's simpler: in many cases, an `if-else` branch for picking a constructor can be reduced to just one constructor call.\r\n\r\nThe reason it was introduced was because in Awkward0, `__setitem__` changed a `Table` in place, so we had to keep checking to find the new length because it could have changed. Now `ak.Array.__setitem__` replaces its `_layout` with `RecordArray.withfield` and so the `RecordArray` itself is immutable. Hence, hard-coding a `length_` in its constructor is fine.",
  "closed_at":"2020-03-06T15:19:57Z",
  "comments":0,
  "created_at":"2020-02-25T15:10:50Z",
  "id":570638890,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzA2Mzg4OTA=",
  "number":123,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"RecordArray should use `length_` as its length regardless of its `contents_`.",
  "updated_at":"2020-03-06T15:19:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I want to finish and uncomment this test:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/6c70299f12afc17c8d183c799343a571fb62d917/tests/test_0118-numba-cpointers.py#L894-L910",
  "closed_at":"2020-03-05T01:23:48Z",
  "comments":0,
  "created_at":"2020-02-25T21:58:16Z",
  "id":570861668,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzA4NjE2Njg=",
  "number":124,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Arrays marked as `\"string\"` should materialize as strings in Numba",
  "updated_at":"2020-03-05T01:23:48Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Because you really don't want that to be burned into a huge dataset.\r\n",
  "closed_at":"2020-03-06T02:53:10Z",
  "comments":0,
  "created_at":"2020-02-25T23:10:13Z",
  "id":570905183,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzA5MDUxODM=",
  "number":125,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"The \"__typestr__\" must not be a data property; it must be a behavior",
  "updated_at":"2020-03-06T02:53:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Maybe as one of the \"convert\" operations.",
  "closed_at":"2020-03-04T16:58:03Z",
  "comments":0,
  "created_at":"2020-02-25T23:14:05Z",
  "id":570907732,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzA5MDc3MzI=",
  "number":126,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Awkward0 \u2194 Awkward1 translator",
  "updated_at":"2020-03-04T16:58:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It has the advantage that it doesn't change the length of the array, maintaining broadcastability of datasets.",
  "closed_at":"2020-03-16T18:04:44Z",
  "comments":0,
  "created_at":"2020-02-25T23:21:34Z",
  "id":570912869,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzA5MTI4Njk=",
  "number":127,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"tomask: an operation that creates an OptionType instead of applying a cut",
  "updated_at":"2020-03-16T18:04:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-02-29T15:19:44Z",
  "comments":0,
  "created_at":"2020-02-26T17:10:30Z",
  "draft":false,
  "id":571533382,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgwNDAzNDE0",
  "number":128,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-02-29T15:19:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Any tweaks that are necessary for Henry's demo.",
  "updated_at":"2020-02-29T15:19:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Still to do:\r\n- [x] Fix install location of python & so files (currently in .env base dir!)\r\n- [x] Restore non-Scikit-build build (since Scikit Build 0.11 has not been released yet, and 0.10 does not support Python 0.10, see https://github.com/scikit-build/scikit-build/issues/362)\r\n",
  "closed_at":"2020-03-02T04:44:10Z",
  "comments":6,
  "created_at":"2020-02-29T15:31:14Z",
  "draft":false,
  "id":573315999,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgxODY3NTA1",
  "number":129,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-02T04:44:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Improve build procedure building from setup.py.",
  "updated_at":"2020-03-04T09:10:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-01T00:04:40Z",
  "comments":0,
  "created_at":"2020-02-29T21:40:07Z",
  "draft":false,
  "id":573416145,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgxOTQ3ODQx",
  "number":130,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-01T00:04:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Rename 'FillableArray' to 'ArrayBuilder' and all 'fillable' to 'builder'.",
  "updated_at":"2020-03-01T00:04:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@henryiii The \"fallback\" mechanism you implemented last night was not actually tested because I disabled the one test that would use it. Since it ought to work, I'm reinstating it.\r\n\r\nI've also changed the logic to always go for the copy of the library that's embedded in the versioned Python directory, rather than the one that's visible system-wide. The system-wide one is there for dependent projects, and is not installed on Windows (since we don't really know how that works and I've never gotten the `dependent_project` to work on Windows anyway).",
  "closed_at":"2020-03-02T20:53:50Z",
  "comments":0,
  "created_at":"2020-03-02T12:43:43Z",
  "draft":false,
  "id":573949274,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgyMzYzMjA5",
  "number":131,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-02T20:53:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Reintroduce Numba \"cpointers\" test.",
  "updated_at":"2020-03-02T20:53:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@ianna I think it will be easier to merge all of your work in with side-by-side PRs. We can use Atom Teletype to collaborate on the sources in your directory, so that they get committed with your name. See you tomorrow!",
  "closed_at":"2020-03-09T14:06:20Z",
  "comments":9,
  "created_at":"2020-03-02T21:00:46Z",
  "draft":false,
  "id":574245061,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgyNjA1Mzkz",
  "number":132,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-09T14:06:20Z"
  },
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Merge all the rpad work (#114) into new environment.",
  "updated_at":"2020-03-09T14:06:33Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Maybe the easiest way to fix them is to make them immutable.\r\n\r\nAfter that, `parameters` will be the only non-immutable part of an array, so that would go next to make them purely immutable.",
  "closed_at":"2020-03-03T20:15:52Z",
  "comments":3,
  "created_at":"2020-03-02T21:14:19Z",
  "draft":false,
  "id":574251981,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgyNjExMjIy",
  "number":133,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-03T20:15:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix the tests that are currently skipped due to setidentity segfaults.",
  "updated_at":"2020-03-03T20:15:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Motivated by scikit-hep/awkward-array#235.",
  "closed_at":"2020-03-03T18:41:06Z",
  "comments":1,
  "created_at":"2020-03-03T18:26:18Z",
  "id":574856664,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzQ4NTY2NjQ=",
  "number":134,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.isin (wrapped as __contains__), or at least a way to check for None",
  "updated_at":"2020-03-03T18:41:06Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-04T16:58:04Z",
  "comments":0,
  "created_at":"2020-03-03T20:39:43Z",
  "draft":false,
  "id":574927715,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzMTYzNTM1",
  "number":135,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-04T16:58:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Convert between Awkward0 and Awkward1.",
  "updated_at":"2020-03-04T16:58:08Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Since #68 is being scaled back to a Python function, C++ will need _some_ serialization layer. `awkward0.persist` should be ported to C++.\r\n\r\nAgain, this is not for performance, but for accessibility.",
  "closed_at":"2020-07-27T23:42:35Z",
  "comments":2,
  "created_at":"2020-03-04T12:49:16Z",
  "id":575374752,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzUzNzQ3NTI=",
  "number":136,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Serialization protocol in C++",
  "updated_at":"2020-07-27T23:42:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The branch name really should have been `bug/PR137-fix-deployment`. Oops.\r\n\r\nFrom @henryiii:\r\n\r\n   * [x] Add `cp wheel/awkward1* dist/` to ~setup.py~ Azure.\r\n   * [x] Add `ARCHIVE DESTINATION` to CMakeLists.txt.\r\n\r\nFrom @jpivarski:\r\n\r\n   * [x] Stop the static/shared libraries from being added to `lib/pythonX.Y/site-packages/lib`, but keep putting them in `lib`. It's probably the first `install` in CMakeLists.txt that's doing it, but we must make sure that it doesn't break the `data_files` directive that later moves them to `lib`.\r\n   * [x] Follow through and test, which might involve iterations on master to work out any remaining bugs in the deployment pipeline.",
  "closed_at":"2020-03-04T19:41:03Z",
  "comments":0,
  "created_at":"2020-03-04T15:29:07Z",
  "draft":false,
  "id":575502626,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzNjQxMDI4",
  "number":137,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-04T19:41:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix deployment.",
  "updated_at":"2020-03-04T19:41:15Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Example: scikit-hep/awkward-array#236, although I'm pretty sure it's happened more than once.",
  "closed_at":"2020-03-04T17:58:52Z",
  "comments":0,
  "created_at":"2020-03-04T16:51:35Z",
  "id":575570395,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzU1NzAzOTU=",
  "number":138,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"EmptyArray should have type \"int64\" so that jagged integer indexing doesn't fail unexpectedly",
  "updated_at":"2020-03-04T17:58:52Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes #138, and does one better: the type of an EmptyArray depends on how it's used.",
  "closed_at":"2020-03-04T17:58:52Z",
  "comments":0,
  "created_at":"2020-03-04T17:42:31Z",
  "draft":false,
  "id":575613076,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzNzM2MDA4",
  "number":139,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-04T17:58:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"EmptyArrays have float64 type (like NumPy), but are integer arrays when used as a slice (fixing scikit-hep/awkward-array#236).",
  "updated_at":"2020-03-04T17:58:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"To do:\r\n\r\n   * [x] If there's any `astype` method, get rid of it. It doesn't mean what it used to. (We might do an `leavesastype` or something someday.)\r\n   * [x] The `type` C++ methods need to take an argument, and it needs to be a layout method, not a property, in Python. This argument is the mapping from record/array names to `__typestr__`.\r\n   * [x] Populate this argument from Python (search for `typestrs`).\r\n   * [x] The Type `tostring` methods should also take this argument and use it to replace their own type strings with whatever the behavior prescribes.\r\n   * [x] Go through the tests, removing references to `\"__typestr__\"` and adding typestrings via behavior.\r\n   * [x] Remove all references to hard-coded `\"__typestr__\"` in the codebase.\r\n   * [x] Fix the VERSION_INFO because this number has been taken by a deployment re-try.\r\n",
  "closed_at":"2020-03-06T02:53:10Z",
  "comments":0,
  "created_at":"2020-03-04T20:15:11Z",
  "draft":false,
  "id":575737634,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzODQ2NjU3",
  "number":140,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-06T02:53:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Make __typestr__ a behavior, not a data property.",
  "updated_at":"2020-03-06T02:53:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This structure is wrong:\r\n\r\n```\r\n.\r\n\u251c\u2500\u2500 awkward1\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _autograd.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward-cpu-kernels.dll\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward-cpu-kernels.exp\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward-cpu-kernels.lib\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward-cpu-kernels-static.lib\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward.dll\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward.exp\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward.lib\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 awkward-static.lib\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 behaviors\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 string.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _cpu_kernels.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 highlevel.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _io.cp37-win32.pyd\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 layout.cp37-win32.pyd\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _libawkward.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _numba\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 arrayview.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 builder.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 layout.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 numba.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _numexpr.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _numpy.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 operations\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 convert.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 describe.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 reducers.py\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 structure.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _pandas.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 types.cp37-win32.pyd\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 _util.py\r\n\u251c\u2500\u2500 awkward1-0.1.138.data\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 data\r\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 include\r\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 awkward\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 array\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 EmptyArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 IndexedArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ListArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ListOffsetArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 None.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 NumpyArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RawArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RecordArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 Record.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RegularArray.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 UnionArray.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 builder\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ArrayBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ArrayBuilderOptions.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 BoolBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 Builder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 Float64Builder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 GrowableBuffer.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 IndexedBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 Int64Builder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ListBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 OptionBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RecordBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 StringBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 TupleBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 UnionBuilder.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 UnknownBuilder.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Content.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 cpu-kernels\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 getitem.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 identities.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 operations.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 reducers.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 util.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Identities.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Index.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 io\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 json.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 root.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Iterator.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 python\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 content.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 identities.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 index.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 util.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Reducer.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 Slice.h\r\n\u2502\u00a0\u00a0             \u251c\u2500\u2500 type\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ArrayType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 ListType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 OptionType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 PrimitiveType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RecordType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 RegularType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 Type.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u251c\u2500\u2500 UnionType.h\r\n\u2502\u00a0\u00a0             \u2502\u00a0\u00a0 \u2514\u2500\u2500 UnknownType.h\r\n\u2502\u00a0\u00a0             \u2514\u2500\u2500 util.h\r\n\u251c\u2500\u2500 awkward1-0.1.138.dist-info\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 entry_points.txt\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 LICENSE\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 METADATA\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 RECORD\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 top_level.txt\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 WHEEL\r\n\u251c\u2500\u2500 _io.cp37-win32.pyd\r\n\u251c\u2500\u2500 layout.cp37-win32.pyd\r\n\u2514\u2500\u2500 types.cp37-win32.pyd\r\n```\r\n\r\nbecause the three extension modules are both in the Python package _and_ at site-packages root. This would allow `import layout` in addition to `import awkward1.layout`. Worse yet, `import types` might shadow the standard library module!\r\n\r\nThis needs to be fixed before we get any Windows users.",
  "closed_at":"2020-03-05T17:59:21Z",
  "comments":0,
  "created_at":"2020-03-04T21:11:04Z",
  "id":575776554,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzU3NzY1NTQ=",
  "number":141,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Windows wheel puts _io*.pyd, layout*.pyd, and types*.pyd at root level.",
  "updated_at":"2020-03-05T17:59:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-05T17:59:21Z",
  "comments":6,
  "created_at":"2020-03-04T21:19:44Z",
  "draft":false,
  "id":575783355,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzODg3MDkw",
  "number":142,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-05T17:59:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix Windows wheel and add auditwheel.",
  "updated_at":"2020-03-05T17:59:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"To do:\r\n\r\n   * [x] Create a ByteMaskedArray.\r\n     * [x] setidentities\r\n     * [x] deep_copy\r\n     * [x] getitem_nothing\r\n     * [x] validityerror\r\n     * [x] num\r\n     * [x] offsets_and_flattened\r\n     * [x] mergeable\r\n     * [x] reverse_merge\r\n     * [x] merge\r\n     * [x] rpad\r\n     * [x] rpad_and_clip\r\n     * [x] reduce_next\r\n     * [x] localindex\r\n     * [x] choose\r\n     * [ ] ~~getitem_next(at)~~\r\n     * [ ] ~~getitem_next(range)~~\r\n     * [ ] ~~getitem_next(array)~~\r\n     * [ ] ~~getitem_next(jagged)~~\r\n   * [x] Create a BitMaskedArray that defers to `toByteMaskedArray` for almost everything\r\n     * [x] `toByteMaskedArray`\r\n     * [x] everything else\r\n   * [x] Create an UnmaskedArray.\r\n   * [x] Extend IndexedOptionArray's `simplify` to merge the other masked array types.\r\n   * [x] Add a `simplify` to the three masked arrays.\r\n     * [x] ByteMaskedArray\r\n     * [x] BitMaskedArray\r\n     * [x] UnmaskedArray\r\n   * [x] Rename `UnionArray::simplify` and `*Option/MaskedArray::simplify` and add a generic `simplify` across all types.\r\n   * [x] Integrate ByteMaskedArray, BitMaskedArray, and UnmaskedArray into Numba.\r\n   * [x] Find all the places where IndexedOptionArray is used that would be better served by ByteMaskedArray and replace it.\r\n   * [x] Add the `tomask` operation, which can be pure Python without an `axis` parameter.\r\n   * [x] Give layout reducers a `semigroup` parameter to mask out identities; this is on by default for `min` and `max`, off by default for the others.\r\n   * [ ] ~~Add a `leafnones` operation to push `None` values to the lowest level (just above the leaves), and use this as a preprocessing step in reducers.~~\r\n   * [x] Fix VERSION_INFO, close, and deploy!\r\n",
  "closed_at":"2020-03-16T18:04:44Z",
  "comments":1,
  "created_at":"2020-03-04T21:22:53Z",
  "draft":false,
  "id":575785882,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzODg5Mjg3",
  "number":143,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-16T18:04:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ByteMaskedArray, BitMaskedArray, and tomask operation",
  "updated_at":"2020-03-16T18:04:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-05T01:23:48Z",
  "comments":0,
  "created_at":"2020-03-04T22:27:29Z",
  "draft":false,
  "id":575835095,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzgzOTMzMzEx",
  "number":144,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-05T01:23:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Strings in Numba",
  "updated_at":"2020-03-05T01:23:52Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"It looks like the `fillable` directory is no more, which means import statements for `FillableArray` et alia must be adjusted.\r\n\r\nWhat is the appropriate import given these changes?",
  "closed_at":"2020-03-04T22:55:24Z",
  "comments":2,
  "created_at":"2020-03-04T22:37:22Z",
  "id":575842021,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzU4NDIwMjE=",
  "number":145,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"new FillableArray option?",
  "updated_at":"2020-03-04T22:55:40Z",
  "user":"MDQ6VXNlcjI2OTc1NTMw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Maybe it's too early for such bug reports and I am also not using the latest `master` but `0.1.137` from PyPI but I started migrating and discovered that nested Numpy arrays are causing issues, as seen here:\r\n\r\n```python\r\nIn [30]: ak.Array([[1,2,3], [4,5,6]])\r\nOut[30]: <Array [[1, 2, 3], [4, 5, 6]] type='2 * var * int64'>\r\n\r\nIn [31]: ak.Array([np.array([1,2,3]), np.array([4,5,6])])\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-31-27b5fb98a962> in <module>\r\n----> 1 ak.Array([np.array([1,2,3]), np.array([4,5,6])])\r\n\r\n~/Dev/km3io/venv/lib/python3.7/site-packages/awkward1/highlevel.py in __init__(self, data, behavior)\r\n     30             layout = awkward1.operations.convert.fromjson(data).layout\r\n     31         else:\r\n---> 32             layout = awkward1.operations.convert.fromiter(data).layout\r\n     33         if not isinstance(layout, awkward1.layout.Content):\r\n     34             raise TypeError(\"could not convert data into an awkward1.Array\")\r\n\r\n~/Dev/km3io/venv/lib/python3.7/site-packages/awkward1/operations/convert.py in fromiter(iterable, highlevel, behavior, initial, resize)\r\n     53     out = awkward1.layout.ArrayBuilder(initial=initial, resize=resize)\r\n     54     for x in iterable:\r\n---> 55         out.fromiter(x)\r\n     56     layout = out.snapshot()\r\n     57     if highlevel:\r\n\r\nValueError: cannot convert 1 to an array element\r\n\r\nIn [32]: ak.Array([np.array([1,2,3]), np.array([4,5,6])][0])\r\nOut[32]: <Array [1, 2, 3] type='3 * int64'>\r\n\r\nIn [33]: ak.Array([np.array([1,2,3]), np.array([4,5,6])][1])\r\nOut[33]: <Array [4, 5, 6] type='3 * int64'>\r\n\r\nIn [34]: ak.__version__\r\nOut[34]: '0.1.137'\r\n```",
  "closed_at":"2020-03-11T23:40:56Z",
  "comments":10,
  "created_at":"2020-03-05T07:52:14Z",
  "id":576058211,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzYwNTgyMTE=",
  "number":146,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Which ak.Array constructor signatures should be allowed? e.g. [np.array([1, 2, 3]), np.array([4, 5, 6, 7])]",
  "updated_at":"2020-03-12T06:46:47Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] Remove unnecessary constructors.\r\n   * [x] Simplify `RecordArray::length()` to just return `length_`.\r\n   * [x] Ensure that this `length_` is always set properly.\r\n   * [x] Including Numba.\r\n   * [x] Update VERSION_INFO.",
  "closed_at":"2020-03-06T15:19:57Z",
  "comments":0,
  "created_at":"2020-03-06T14:00:14Z",
  "draft":false,
  "id":576950387,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg0ODM2MDQ4",
  "number":147,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-06T15:19:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"RecordArray should use its length_ parameter, regardless of contents_.size()",
  "updated_at":"2020-03-06T15:20:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] `Content::validity` that takes breadcrumbs (`path`) string and returns an error string.\r\n   * [x] `ak.isvalid(message=False, exception=False)` always returns `True` if no errors; other cases depend on arguments.\r\n   * [x] VERSION_INFO",
  "closed_at":"2020-03-06T20:07:26Z",
  "comments":0,
  "created_at":"2020-03-06T15:52:37Z",
  "draft":false,
  "id":577018468,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg0ODkyNzMx",
  "number":148,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-06T20:07:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"isvalid as an operation",
  "updated_at":"2020-03-06T20:07:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"In this sense:\r\n\r\n```python\r\nbehavior = dict(ak.behavior)\r\nbehavior.update(user_supplied)\r\n```\r\n\r\nAlthough that might be a lot of dict-copying every time an `ak.Array` gets constructed...",
  "closed_at":"2020-03-06T21:43:12Z",
  "comments":2,
  "created_at":"2020-03-06T16:01:47Z",
  "id":577024700,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzcwMjQ3MDA=",
  "number":149,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"User-supplied behaviors shouldn't replace ak.behavior; they should be merged with it.",
  "updated_at":"2020-03-06T21:43:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"https://github.com/scikit-hep/awkward-1.0/blob/c953d877a0b46c7faa25cfedf8c41fca4e78b343/src/awkward1/highlevel.py#L85-L98\r\n\r\nMissing attributes (e.g. methods) of mix-in classes aren't caught by the `where in dir(super(Array, self))` (because they're superclasses of this array but not superclasses of `Array`).\r\n\r\nMaybe `where in dir(type(self))`?",
  "closed_at":"2020-03-06T21:43:13Z",
  "comments":9,
  "created_at":"2020-03-06T16:46:31Z",
  "id":577050653,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzcwNTA2NTM=",
  "number":150,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"High-level Arrays and Records attribute-handling is still swallowing unrelated AttributeErrors",
  "updated_at":"2020-03-06T21:43:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-06T21:43:13Z",
  "comments":0,
  "created_at":"2020-03-06T20:45:43Z",
  "draft":false,
  "id":577166724,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg1MDEzOTAw",
  "number":151,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-06T21:43:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Issues #149 and #150: AttributeErrors and merging ak.behavior",
  "updated_at":"2020-03-06T21:43:16Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-10T05:03:59Z",
  "comments":3,
  "created_at":"2020-03-06T22:05:05Z",
  "draft":false,
  "id":577200592,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg1MDQyMTYw",
  "number":152,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-10T05:03:59Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Finish the count/sizes/num operation and the flatten operation",
  "updated_at":"2020-03-10T08:48:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-10T23:07:49Z",
  "comments":0,
  "created_at":"2020-03-10T05:17:00Z",
  "draft":false,
  "id":578343364,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg1OTQyMzky",
  "number":154,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-10T23:07:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add the ak.pandas.multiindex(array) function.",
  "updated_at":"2020-03-10T23:07:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"issue https://github.com/scikit-hep/awkward-1.0/issues/72",
  "closed_at":"2020-03-17T18:53:53Z",
  "comments":1,
  "created_at":"2020-03-10T11:24:25Z",
  "draft":false,
  "id":578511071,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg2MDc3MjQw",
  "number":155,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-17T18:53:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fillna operation",
  "updated_at":"2020-03-17T18:54:04Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"In one of my analysis frameworks I introduced a `Table` class, which is a thin wrapper to  `numpy.recarray` and has also a constructor which takes a dictionary as input. It became quite popular among our users due to the ability to quickly create type-safe 2D recarrays. Here is an example\r\n\r\n```python\r\nIn [1]: import km3pipe as kp\r\n\r\nIn [2]: t = kp.Table({'a': [1,2,3], 'b': [4.5, 6.7, 8.9], 'c': False})\r\n\r\nIn [3]: t\r\nOut[3]: Generic Table <class 'km3pipe.dataclasses.Table'> (rows: 3)\r\n\r\nIn [4]: print(t)\r\nGeneric Table <class 'km3pipe.dataclasses.Table'>\r\nHDF5 location: /misc (no split)\r\n<i8 (dtype: a) = [1 2 3]\r\n<f8 (dtype: b) = [4.5 6.7 8.9]\r\n|b1 (dtype: c) = [False False False]\r\n\r\nIn [5]: t.dtype\r\nOut[5]: dtype((numpy.record, [('a', '<i8'), ('b', '<f8'), ('c', '?')]))\r\n\r\nIn [6]: t[0]\r\nOut[6]: (1, 4.5, False)\r\n\r\nIn [7]: type(t[0])\r\nOut[7]: numpy.record\r\n\r\nIn [8]: t[0].b\r\nOut[8]: 4.5\r\n\r\nIn [9]: t[1:3]\r\nOut[9]: Generic Table <class 'km3pipe.dataclasses.Table'> (rows: 2)\r\n```\r\n\r\nThe inspiration came from Pandas which offers a similar constructor:\r\n\r\n```python\r\nIn [5]: import pandas as pd\r\n\r\nIn [6]: df = pd.DataFrame({'a': [1,2,3], 'b': [4,5,6], 'c': True})\r\n\r\nIn [7]: df\r\nOut[7]:\r\n   a  b     c\r\n0  1  4  True\r\n1  2  5  True\r\n2  3  6  True\r\n```\r\n\r\nWith awkward array, the corresponding constructor only does a \"`for element in dict`\"-like iteration, which in Python boils down to an iteration over the dictionary `.keys()`. This might confuse people who already worked with pandas.DataFrames or similar classes. For the sake of completeness, here is what we get when passing a dictionary (no surprise for us but I post it here in for future reference):\r\n\r\n```python\r\nIn [1]: import awkward1 as ak\r\n\r\nIn [2]: arr = ak.Array({'a': [1,2,3], 'b': [4,5,6,7,8]})\r\n\r\nIn [3]: arr\r\nOut[3]: <Array ['a', 'b'] type='2 * string'>\r\n\r\nIn [4]: arr.a\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-7be3c5184803> in <module>\r\n----> 1 arr.a\r\n\r\n~/Dev/awkward-1.0/awkward1/highlevel.py in __getattr__(self, where)\r\n     95                     raise AttributeError(\"while trying to get field {0}, an exception occurred:\\n{1}: {2}\".format(repr(where), type(err), str(err)))\r\n     96             else:\r\n---> 97                 raise AttributeError(\"no field named {0}\".format(repr(where)))\r\n     98\r\n     99     def __dir__(self):\r\n\r\nAttributeError: no field named 'a'\r\n```\r\n\r\nWith pandas it'\r\n\r\nOf course the `DataFrame` or `Table` classes are mostly simple 2D table with the requirement of equal lengths for each field (that's why it e.g. auto-repeat-expands single value attributes) but I think this constructor would be a handy addition to `akward.Arrays`, especially since it accepts awkward data shapes and layouts \ud83d\ude09 \r\n\r\nWhat do you think? I am not sure if I find time to come up with a solid PR until 1.0.",
  "closed_at":"2020-03-11T23:50:35Z",
  "comments":5,
  "created_at":"2020-03-10T21:46:47Z",
  "id":578880221,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1Nzg4ODAyMjE=",
  "number":156,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.Array constructor from {\"key\": whole_array}",
  "updated_at":"2020-03-11T23:50:36Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Copied from https://github.com/scikit-hep/awkward-1.0/issues/156#issuecomment-597366071\r\n\r\n   * [X] The `ak.Array` and `ak.Record` constructor bugs (iterating over the dict keys and implementing that FIXME)\r\n   * [x] Make `fromiter` iterate over `py::array` (mentioned in #146)\r\n   * [ ] ~~Possibly, but not necessarily, `ak.zip` (described in #77).~~\r\n\r\nI'm going to do `ak.zip` in a separate PR because this one has some bug-fixes.",
  "closed_at":"2020-03-11T13:21:03Z",
  "comments":5,
  "created_at":"2020-03-10T23:37:20Z",
  "draft":false,
  "id":578921391,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg2NDEzODk1",
  "number":157,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-11T13:21:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ak.Array and ak.Record constructors. Maybe the `ak.zip` function.",
  "updated_at":"2020-03-11T13:21:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"High-quality documentation is a serious need. Uproot has [one big page of tutorial](https://github.com/scikit-hep/uproot#readme) (which doubles as a [Binder-based interactive notebook](https://mybinder.org/v2/gh/scikit-hep/uproot/master?urlpath=lab/tree/binder%2Ftutorial.ipynb)), [readthedocs for references](https://uproot.readthedocs.io/), and [StackOverflow for example-driven questions](https://stackoverflow.com/questions/tagged/uproot). Awkward 0 only has a [big page tutorial](https://github.com/scikit-hep/awkward-array#readme).\r\n\r\n### Some observations:\r\n\r\n   * The big-page tutorial was motivated by early observations that users seemed to know what was on the GitHub front page but not what was in readthedocs. \"Search in page\" seems to be much more common than clicking through to find things. Therefore, I moved all the introductory/tutorial-like text out of readthedocs and into the GitHub front page.\r\n   * However, this does not scale. It's hard to add new content to this monolith because it breaks the flow of text. When I have serious changes to make (e.g. Uproot 2 \u2192 3), I take a few days and rewrite the whole thing.\r\n   * But it's wrong to assume that anybody reads this from top to bottom\u2014surely, they're searching for examples, and it must be broken up to fit that pattern.\r\n   * Almost nobody uses the interactive tutorial. It was broken for months (the notebook JSON was badly formatted\u2014it couldn't even be loaded as a notebook) before somebody complained. Creating interactive tutorials is not time well spent. Removing this requirement also relaxes the one-big-page problem, because the big page was designed to be the same as the notebook.\r\n   * Although I like to write about concepts and the big-picture vision of columnar analysis, there's more of a demand for \"how do I...?\" documentation that focuses on specific problems. I can't know all of these problems in advance, so the set of little \"how do I...?\" pages has to be an easily expandable set.\r\n   * I had hoped that StackOverflow would provide the \"how do I...?\" examples, but so far, there has been considerable confusion about what is a usage question (for StackOverflow) and what is a bug report (for GitHub Issues). I'd like to have community help in filling out usage examples, but a pattern needs to be established first to give a sense of what kinds of things should have recipes and what kinds of things are just broken and need to be fixed.\r\n   * One thought I had was to write the how-to documentation on StackOverflow by phrasing each task as a question and answering my own questions. (A bit like _Jeopardy_.) I found [StackOverflow Documentation](https://stackoverflow.blog/2016/07/21/introducing-stack-overflow-documentation-beta/), which sounded promising, until I found out that it was [cancelled one year later](https://meta.stackoverflow.com/q/354217/1623645). Yikes! I'm glad I didn't try that.\r\n   * Another promising option is to write a [Wikibook](https://en.wikibooks.org/). This would satisfy the constraints of being mostly single author (me) while still being open to community contributions (same openness as Wikipedia\u2014no user accounts required!), it is easily editable (though a different syntax than markdown), and it isn't going anywhere. Wikibooks is an old project (started 2003), with [peak interest around 2008](https://trends.google.com/trends/explore?date=all&q=%2Fm%2F01wlhc), which makes it old and boring, and that's great for long-term support. Having settled into its stride, it seems to be mostly used for manuals, particularly LaTeX, C/C++, and radiation oncology (see previous link: related searches). The [Haskell Wikibook](https://en.wikibooks.org/wiki/Haskell) is an example of what a finished book can look like, with searching capabilities, PDF/e-book versions, beginner's track/advanced track, and good syntax coloring. **I'm strongly considering Wikibooks.**\r\n   * [GitBooks](https://www.gitbook.com/) also have the PDF/e-book features, the focus on writing software manuals, but it adds the possibility of interactivity. Also, it's [young and hip](https://trends.google.com/trends/explore?date=all&q=Wikibook,GitBook), but still it's been widely popular since 2016 and has reached about the same level (in Google searches) as Wikibooks. Whereas Wikibooks has edit links on every page, inviting minimum-barrier contributions, GitBook is git-backed and has a pull-request process. (Or, it would be because I'd link GitBook to GitHub and edit it there.) This puts two things in GitBook's favor: (1) editing doesn't have to be online and (2) we can easily backup all the content with `git clone`. I'd prefer not putting too many barriers in the way of users wanting to contribute, and if I didn't know better, I'd think the \"get GitHub account, submit pull request\" would be a lot more prohibitive than \"click on the 'edit' link.\" However, we have plenty of experience with Twiki to know that our community doesn't like to edit \"somebody else's\" wiki and is surprisingly more willing to go through the pull request process. (And just about everybody in our field has a GitHub account.) Maybe people feel better about _suggesting_ an edit than _making_ an edit because they're humble enough to want review. Anyway, **I'm even more strongly considering GitBooks.**\r\n   * I think the GitHub front-pages for Awkward 1.0 and Uproot 4.0 should be kept clean, with minimal content except links to the documentation. Awkward should probably get three big buttons: \"Documentation for data analysts,\" \"Documentation for framework developers,\" and \"Documentation for Awkward developers.\" The first covers `ak.Array` and its operations; the middle covers layouts and writing software that depends on Awkward; the last covers the project as a whole, including \"how to contribute.\"\r\n   * The C++ should all get Doxygenized, the Python should all get Sphinxized, and if it's possible to put both of these on readthedocs, that's what I'll do. Or maybe I should try to centralize things using something like [Doxybook2](https://github.com/matusnovak/doxybook2#readme) to turn Doxygen XML into GitBook pages (that can then be integrated with the main GitBook documentation). For Python, perhaps [doxypypy](https://github.com/Feneric/doxypypy#readme) can be used to turn Python docstrings into Doxygen, which then goes to GitBook. This project seems to have plateaued, but why shouldn't it? It just has to turn human-readable docstrings into the appropriate Doxygen tags. **I'm strongly considering a doxypypy \u2192 Doxygen \u2192 GitBook workflow for Python, and Doxygen \u2192 GitBook for C++.**\r\n   * I don't want to deal with Sphinx. Writing reST is no fun and even with autodoc, you have to remember to add reST to invoke the autodoc. The \"Documentation for data analysts\" (and possibly \"Documentation for framework developers\") should have hand-picked links to useful functions, but the \"Documentation for Awkward developers\" should always include all classes, functions, etc.\r\n\r\n### Thoughts? Suggestions?\r\n\r\nLet me know below. With documentation, it's hard to back up and use something different once some serious writing has begun because every toolchain has consequences on how the text is formatted. I want to get this right the first time.",
  "closed_at":"2020-04-02T02:01:50Z",
  "comments":14,
  "created_at":"2020-03-11T14:52:49Z",
  "id":579323485,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1NzkzMjM0ODU=",
  "number":158,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Strategy for documentation",
  "updated_at":"2020-04-02T02:01:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"After some consideration, I'm going to use @nsmith-'s nifty trick: https://github.com/scikit-hep/awkward-1.0/issues/78#issuecomment-579577077\r\n\r\nThe reason against it was that although it uses broadcasting on the axis we want to cross, it might accidentally use broadcasting on some other axes as well. On the other hand, a pattern is emerging in which we're applying broadcasting to all functions of more than one array, so maybe that's a feature, not an antifeature.\r\n\r\nAlso, defining functions of more than one array in C++ is hard because the arrays might consist of different node types; checking all the possibilities is not scalable. There are a few such functions, such as `Content::merge`, but for these, we \"bite the bullet\" and do all the cases because it's a utility function used to simplify other functions (all that nasty complexity is concentrated in one place).\r\n\r\nOne difference, though: I'm not going to use empty slices (i.e. `:`) and `np.newaxis` (i.e. `None`) to create the RegularArrays; I'm going to put them in with `awkward1._util.recursively_apply`. This avoids the array-scaling overhead of tuple-slicing. If all the elements of the tuple-slice are `:` and `np.newaxis`, then no arrays need to be touched. Perhaps someday, `Content::getitem` will have enough optimizations that this would be the case, but as of right now, `awkward1._util.recursively_apply` is the only way to do it in _O(1)_ time.\r\n\r\nThe `cross` function will not depend on `argcross`. In fact, `argcross` will have to be a little more expensive, as it needs to replace the data with integer arrays before crossing. Maybe that (equivalent to Awkward0's `localindex`) should be in C++.",
  "closed_at":"2020-03-11T22:58:27Z",
  "comments":1,
  "created_at":"2020-03-11T16:11:23Z",
  "draft":false,
  "id":579380821,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg2Nzg0OTkx",
  "number":159,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-11T22:58:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement 'argcross' and 'cross'.",
  "updated_at":"2020-03-19T20:28:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [X] stubs\r\n   * [x] test file\r\n   * [x] high-level interface (without `nested` to flatten)\r\n   * [x] ListOffsetArray for `axis == depth + 1`\r\n   * [x] ListArray\r\n   * [x] RegularArray\r\n   * [x] convenience function for the `axis == depth` case\r\n   * [x] implement all other types (`axis == depth` and `axis > depth + 1` cases)\r\n   * [ ] ~~add `nested` to flatten~~\r\n   * [x] add `argchoose`\r\n   * [x] switch `localindex` over to using `localindex_axis0` in the `axis == depth` case",
  "closed_at":"2020-03-13T02:24:18Z",
  "comments":0,
  "created_at":"2020-03-12T01:25:31Z",
  "draft":false,
  "id":579634919,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg2OTkzNjc4",
  "number":160,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-13T02:24:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"argchoose and choose.",
  "updated_at":"2020-03-13T02:24:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"When `True`, identity values are covered up by `None`. This is on by default for `min` and `max` (though it can be turned on or off for any reducer).\r\n\r\nThis feature is mentioned in #58, but ByteMaskedArray (the subject of that issue) is a _prerequisite_ for this parameter. It's much easier to cover up values with `None` when you have a ByteMaskedArray than with an IndexedOptionArray.\r\n\r\nPR #143 will be providing ByteMaskedArray, so that's a _prerequisite_ for this issue. This issue might even be added as a checkbox for that PR. (Oh, it already is.)",
  "closed_at":"2020-03-16T18:04:44Z",
  "comments":1,
  "created_at":"2020-03-13T02:35:21Z",
  "id":580332154,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODAzMzIxNTQ=",
  "number":161,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add a 'semigroup' parameter to reducers",
  "updated_at":"2020-03-16T18:04:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Right now, there seem to be no exceptions to the rule that layer 3 (i.e. libawkward.so, as opposed to libawkward-cpu-kernels.so) code never _iterates_ over the raw buffers, but there are a few isolated cases where it accesses the first or last element. These have to be turned into kernels (albeit trivial ones) because when the buffers are hosted on a GPU, any direct access would cause a segmentation fault.\r\n\r\nThis can be done in a visual inspection sweep over the code\u2014it wouldn't take longer than an afternoon. Suspicious cases look like\r\n\r\n```c++\r\noffsets_.get().ptr()[0]      // (first)\r\n```\r\n\r\nor\r\n\r\n```c++\r\noffsets_.get().ptr()[offsets_.length() - 1]      // (last)\r\n```\r\n\r\nSome are assignments:\r\n\r\n```c++\r\noffsets_.get().ptr()[0] = 0;\r\n```\r\n\r\nThey should all be centralized in `Index` methods, like `Index::getitem_at_nowrap` and those methods should call the kernels.",
  "closed_at":"2020-03-17T15:59:05Z",
  "comments":1,
  "created_at":"2020-03-14T15:03:13Z",
  "id":581243803,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODEyNDM4MDM=",
  "number":162,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Layer 3 C++ code must never directly access Index.ptr, NumpyArray.ptr, or RawArray.ptr contents",
  "updated_at":"2020-03-17T15:59:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"A lot of operations are using it, but right now it raises a \"not implemented\" runtime error if the `axis` really is negative. Fixing this would solve it for all of the operations.",
  "closed_at":"2020-07-20T17:56:44Z",
  "comments":1,
  "created_at":"2020-03-14T15:10:52Z",
  "id":581246679,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODEyNDY2Nzk=",
  "number":163,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Remember to 'implement axis_wrap_if_negative'",
  "updated_at":"2020-07-20T17:56:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"For now, the raw ptr access is replaced by their respective methods. Although, in `RawArray.h` there's a method `merge` which attempts to make a temporary `RawArray` named `raw_other` and memcpy into `ptr`, the problem is when replacing the raw_ptr access with `IndexOf<T>::getitem_at_nowrap`, the compiler does give out a `-fpermissive` warning which is due to the access of temporary memory. I'll keep looking for a better fix for this.",
  "closed_at":"2020-03-17T15:59:04Z",
  "comments":7,
  "created_at":"2020-03-16T09:33:52Z",
  "draft":false,
  "id":582139218,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg5MTAyNjEz",
  "number":164,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-17T15:59:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #162. Replaces all Raw Pointer Access with wrappers.",
  "updated_at":"2020-03-21T04:55:53Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Despite what I said in #70, maybe this is a reducer (now that it's not producing empty and singleton lists to deal with the fact that some arrays are empty).",
  "closed_at":"2020-03-17T01:07:06Z",
  "comments":0,
  "created_at":"2020-03-16T18:51:05Z",
  "draft":false,
  "id":582529335,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg5NDM2MjQw",
  "number":165,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-17T01:07:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement argmin and argmax.",
  "updated_at":"2020-03-17T01:07:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"So that if a user calls `tomask` instead of applying a cut, the reduced version would be equivalent to event-level variables with the same mask.\r\n\r\nNote: it's only a bug if that's not what currently happens. This is just something to check.",
  "closed_at":"2020-03-18T04:46:14Z",
  "comments":0,
  "created_at":"2020-03-17T04:15:26Z",
  "id":582742904,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODI3NDI5MDQ=",
  "number":166,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"A reducer applied to an axis with None values should preserve the Nones",
  "updated_at":"2020-03-18T04:46:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It seems I ought to be able to do that, and I distinctly remember writing a test for it.\r\n\r\nIf the problem is that my new examples are jagged, then that's definitely a problem to fix.",
  "closed_at":"2020-03-18T04:46:14Z",
  "comments":0,
  "created_at":"2020-03-17T14:27:07Z",
  "id":583053027,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODMwNTMwMjc=",
  "number":167,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Why can't I do `array_of_strings == string`?",
  "updated_at":"2020-03-18T04:46:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Addressing issue #74 \r\nOperations `argsort` and `sort` are applied in `axis` and also takes the following parameters:\r\n```c++\r\nbool ascending\r\n```\r\nIf `true`, the values will be sorted in an ascending order.\r\n```c++\r\nbool stable\r\n```\r\nIf `true`, the values will be sorted by a stable sort algorithm to maintain the relative order of records with equal keys (i.e. values).\r\n```c++\r\nargsort(int64_t axis, bool ascending, bool stable)\r\nsort(int64_t axis, bool ascending, bool stable)\r\n```",
  "closed_at":"2020-06-15T18:37:21Z",
  "comments":20,
  "created_at":"2020-03-17T14:52:59Z",
  "draft":false,
  "id":583071454,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg5ODg1NDI0",
  "number":168,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-15T18:37:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"sort and argsort operations applied in axis",
  "updated_at":"2020-06-15T18:37:28Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I'm adopting PR #164 into a new PR to make it possible to run Azure CI on it.",
  "closed_at":"2020-03-17T15:08:35Z",
  "comments":4,
  "created_at":"2020-03-17T15:02:58Z",
  "draft":false,
  "id":583078651,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzg5ODkxNTMy",
  "number":169,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #162. Replaces all Raw Pointer Access with wrappers.",
  "updated_at":"2020-03-19T20:30:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"So that scripts based on Uproot 3 with this stepping-stone don't break when Uproot 4 comes along.",
  "closed_at":"2020-03-18T04:46:14Z",
  "comments":0,
  "created_at":"2020-03-17T21:00:15Z",
  "id":583295775,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODMyOTU3NzU=",
  "number":170,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.fromawkward0 should not complain if given an Awkward1 array",
  "updated_at":"2020-03-18T04:46:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"They're small enough that they don't need the formality of individually waiting for tests to finish.\r\n\r\n   * [x] 166: reducers with `axis=-1` shouldn't drop `None` values from a masked dataset.\r\n      * [x] IndexedOptionArray\r\n      * [x] ByteMaskedArray and BitMaskedArray (the latter is trivial)\r\n   * [x] 167: investigate `numpy.equal` in which one side is a string (or bytestring)\r\n      * [x] Is it broken?\r\n      * [x] Did you fix it?\r\n   * [x] 170: put in a quick check for Awkward1 arrays passed to `ak.fromawkward0`. It should be a pass-through.",
  "closed_at":"2020-03-18T04:46:14Z",
  "comments":0,
  "created_at":"2020-03-17T21:50:13Z",
  "draft":false,
  "id":583319978,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzkwMDk1NTQ2",
  "number":171,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-18T04:46:14Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Issues #166, #167, #170 in one PR.",
  "updated_at":"2020-03-18T04:46:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"There's no `astype`, and a general one might want to change such things as non-optiontype arrays into UnmaskedArrays or filter/rearrange the order of record fields. Before we need something like that, though, it would be useful to simply change the leaf types (like what NumPy's `astype` does). Should it be named `ak.withleaftype(array, np.int32)`?",
  "closed_at":"2020-08-06T17:09:55Z",
  "comments":3,
  "created_at":"2020-03-18T05:14:18Z",
  "id":583471892,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzE4OTI=",
  "number":173,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"An operation to change the number type",
  "updated_at":"2020-08-06T17:09:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Currently, union-type data can pass through Numba, but it can't be operated on (`__getitem__`). This is a particularly hard problem because Numba has no dynamic types (unlike C++, which at least has runtime polymorphism/virtual methods). It could be represented by a new `ArrayView` that holds multiple possibilities, some `MultiArrayView`, and it can raise exceptions at runtime if the tag is inappropriate for any one of those views. However, the view that does not raise an exception, which ultimately resolves to a number, has `MultiArrayView` type in Numba but must satisfy all the operations of a number. \"All the operations of a number\" is an extremely wide-open set\u2014this is the hard part, figuring out how to make a new type that satisfies everything a number satisfies.\r\n\r\nWe might need help from Numba experts on this one.",
  "closed_at":"2022-04-15T19:53:34Z",
  "comments":2,
  "created_at":"2020-03-18T05:18:33Z",
  "id":583473209,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzMyMDk=",
  "number":174,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Union-type data in Numba",
  "updated_at":"2022-04-15T19:53:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Encoded strings materialize as a \"unicode\" type in Numba, but bytestrings are uninterpreted. This is an oversight: bytestrings should get the same kind of treatment as encoded strings.",
  "closed_at":"2020-08-18T23:11:04Z",
  "comments":0,
  "created_at":"2020-03-18T05:19:50Z",
  "id":583473619,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzM2MTk=",
  "number":175,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Bytestrings in Numba",
  "updated_at":"2020-08-18T23:11:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Instead of `setidentities`, the function should be `withidentities` and it should return a new array object.\r\n\r\nAlso, there's no high-level interface to identities and minimal testing. But identities are just a little more than a stub right now: they will be needed, will need to be enhanced when needed, and doing that will be much, much easier because they've been included all along and we won't be trying to fit them in after the fact.",
  "closed_at":"2022-04-15T19:53:12Z",
  "comments":1,
  "created_at":"2020-03-18T05:24:00Z",
  "id":583475156,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzUxNTY=",
  "number":176,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Identities should not be assigned in place",
  "updated_at":"2022-04-15T19:53:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Array nodes should become fully immutable. Removing the `setidentities` and assigning them only in the constructor would involve fixing a few tests.\r\n\r\nAlso, there's no high-level interface to setting parameters: it's all done through a back door (`.layout`) right now. Parameters are more for framework developers than data analysts, though, so maybe that's appropriate.",
  "closed_at":"2022-04-15T19:52:57Z",
  "comments":1,
  "created_at":"2020-03-18T05:26:47Z",
  "id":583476139,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzYxMzk=",
  "number":177,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Parameters should not be assigned in place",
  "updated_at":"2022-04-15T19:52:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"An array type containing a `std::weak_ptr` to another node. This is the only way to make circular references (a data structure that is more general than a DAG).\r\n\r\nThe value of this `std::weak_ptr` should be the only array node object that is mutable by design. Since Python/C++ has no lazy semantics (like Scala), you have to build the tree without interconnections before attaching the interconnections.",
  "closed_at":"2022-04-15T19:52:26Z",
  "comments":4,
  "created_at":"2020-03-18T05:29:12Z",
  "id":583476974,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0NzY5NzQ=",
  "number":178,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"RedirectArray",
  "updated_at":"2022-04-15T19:52:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"There would be many opportunities for optimization here: a `filter` used by itself should generate a mask and apply it to the array; if it's used in a chain it should be called as a step in that chain (fusing). Some methods might use ArrabyBuilders in some contexts and masks/indexes in others.\r\n\r\nMaybe the interface should follow RDataFrame for user-familiarity. (The code in each block would be Numbafied Python, rather than C++, though.)",
  "closed_at":"2024-01-19T22:41:19Z",
  "comments":1,
  "created_at":"2020-03-18T05:45:52Z",
  "id":583482696,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODM0ODI2OTY=",
  "number":179,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"A suite of functional methods that compile through Numba",
  "updated_at":"2024-01-19T22:41:20Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-19T16:15:55Z",
  "comments":2,
  "created_at":"2020-03-18T19:36:17Z",
  "draft":false,
  "id":583957931,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzkwNjI2NzI2",
  "number":180,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-19T16:15:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Configure documentation (not content, just how the workflow will work).",
  "updated_at":"2020-03-19T16:16:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"If it doesn't behave the same as a mask-slice in this regard, it's a bug.\r\n\r\nThe `broadcast_and_apply` function can probably be used here, with new `implicitleft` and `implicitright` flags set to a non-default `False` to prevent implicit broadcasting.",
  "closed_at":"2020-04-08T12:44:27Z",
  "comments":1,
  "created_at":"2020-03-19T13:14:16Z",
  "id":584402989,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODQ0MDI5ODk=",
  "number":181,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.tomask should accept jagged masks, if it doesn't already",
  "updated_at":"2020-04-08T12:44:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I am failing to install from source. The build succeeds, but the resultant file is apparently not found. This may be a .so/.dynlib kind of thing. Logs below.\r\n```\r\n> pip install -e .\r\nObtaining file:///Users/mdurant/code/awkward-1.0\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n    Preparing wheel metadata ... done\r\nRequirement already satisfied: numpy>=1.13.1 in /Users/mdurant/anaconda/envs/py3/lib/python3.7/site-packages (from awkward1==0.2.7) (1.16.4)\r\nInstalling collected packages: awkward1\r\n  Running setup.py develop for awkward1\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Users/mdurant/anaconda/envs/py3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/Users/mdurant/code/awkward-1.0/setup.py'\"'\"'; __file__='\"'\"'/Users/mdurant/code/awkward-1.0/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\r\n         cwd: /Users/mdurant/code/awkward-1.0/\r\n    Complete output (131 lines):\r\n    running develop\r\n    running egg_info\r\n    writing src/awkward1.egg-info/PKG-INFO\r\n    writing dependency_links to src/awkward1.egg-info/dependency_links.txt\r\n    writing entry points to src/awkward1.egg-info/entry_points.txt\r\n    writing requirements to src/awkward1.egg-info/requires.txt\r\n    writing top-level names to src/awkward1.egg-info/top_level.txt\r\n    reading manifest file 'src/awkward1.egg-info/SOURCES.txt'\r\n    reading manifest template 'MANIFEST.in'\r\n    warning: no files found matching '*.dll'\r\n    writing manifest file 'src/awkward1.egg-info/SOURCES.txt'\r\n    running build_ext\r\n    -- The CXX compiler identification is AppleClang 10.0.0.10001145\r\n    -- Check for working CXX compiler: /usr/bin/g++\r\n    -- Check for working CXX compiler: /usr/bin/g++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Detecting CXX compile features\r\n    -- Detecting CXX compile features - done\r\n    -- CMake version 3.16.3\r\n    -- Release\r\n    -- Found PythonInterp: /Users/mdurant/anaconda/envs/py3/bin/python (found version \"3.7.3\")\r\n    -- Found PythonLibs: /Users/mdurant/anaconda/envs/py3/lib/libpython3.7m.dylib\r\n    -- pybind11 v2.4.3\r\n    -- Performing Test HAS_FLTO\r\n    -- Performing Test HAS_FLTO - Success\r\n    -- LTO enabled\r\n    -- Configuring done\r\n    -- Generating done\r\n    -- Build files have been written to: /Users/mdurant/code/awkward-1.0/build/temp.macosx-10.9-x86_64-3.7\r\n    Scanning dependencies of target awkward-objects\r\n    [  4%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Content.cpp.o\r\n    [  4%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Identities.cpp.o\r\n    [  4%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Index.cpp.o\r\n    [  6%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Iterator.cpp.o\r\n    [  9%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Slice.cpp.o\r\n    [  9%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/Reducer.cpp.o\r\n    [ 10%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/BitMaskedArray.cpp.o\r\n    Scanning dependencies of target awkward-cpu-kernels-objects\r\n    [ 12%] Building CXX object CMakeFiles/awkward-cpu-kernels-objects.dir/src/cpu-kernels/getitem.cpp.o\r\n    [ 14%] Building CXX object CMakeFiles/awkward-cpu-kernels-objects.dir/src/cpu-kernels/identities.cpp.o\r\n    [ 15%] Building CXX object CMakeFiles/awkward-cpu-kernels-objects.dir/src/cpu-kernels/operations.cpp.o\r\n    [ 17%] Building CXX object CMakeFiles/awkward-cpu-kernels-objects.dir/src/cpu-kernels/reducers.cpp.o\r\n    [ 18%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/ByteMaskedArray.cpp.o\r\n    [ 20%] Building CXX object CMakeFiles/awkward-cpu-kernels-objects.dir/src/cpu-kernels/util.cpp.o\r\n    [ 21%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/EmptyArray.cpp.o\r\n    [ 23%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/IndexedArray.cpp.o\r\n    [ 25%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/ListArray.cpp.o\r\n    [ 26%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/ListOffsetArray.cpp.o\r\n    [ 28%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/None.cpp.o\r\n    [ 29%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/NumpyArray.cpp.o\r\n    [ 29%] Built target awkward-cpu-kernels-objects\r\n    [ 31%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/Record.cpp.o\r\n    Scanning dependencies of target awkward-cpu-kernels-static\r\n    [ 32%] Linking CXX static library libawkward-cpu-kernels-static.a\r\n    [ 32%] Built target awkward-cpu-kernels-static\r\n    [ 34%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/RecordArray.cpp.o\r\n    Scanning dependencies of target awkward-cpu-kernels\r\n    [ 35%] Linking CXX shared library libawkward-cpu-kernels.dylib\r\n    [ 35%] Built target awkward-cpu-kernels\r\n    [ 37%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/RegularArray.cpp.o\r\n    [ 39%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/UnionArray.cpp.o\r\n    [ 40%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/array/UnmaskedArray.cpp.o\r\n    [ 42%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/ArrayBuilder.cpp.o\r\n    [ 43%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/ArrayBuilderOptions.cpp.o\r\n    [ 45%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/BoolBuilder.cpp.o\r\n    [ 46%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/Builder.cpp.o\r\n    [ 48%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/Float64Builder.cpp.o\r\n    [ 50%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/GrowableBuffer.cpp.o\r\n    [ 51%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/IndexedBuilder.cpp.o\r\n    [ 53%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/Int64Builder.cpp.o\r\n    [ 54%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/ListBuilder.cpp.o\r\n    [ 56%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/OptionBuilder.cpp.o\r\n    [ 57%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/RecordBuilder.cpp.o\r\n    [ 59%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/StringBuilder.cpp.o\r\n    [ 60%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/TupleBuilder.cpp.o\r\n    [ 62%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/UnionBuilder.cpp.o\r\n    [ 64%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/builder/UnknownBuilder.cpp.o\r\n    [ 65%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/io/json.cpp.o\r\n    [ 67%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/io/root.cpp.o\r\n    [ 68%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/ArrayType.cpp.o\r\n    [ 70%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/ListType.cpp.o\r\n    [ 73%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/OptionType.cpp.o\r\n    [ 73%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/PrimitiveType.cpp.o\r\n    [ 75%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/RecordType.cpp.o\r\n    [ 76%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/RegularType.cpp.o\r\n    [ 78%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/Type.cpp.o\r\n    [ 79%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/UnionType.cpp.o\r\n    [ 81%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/type/UnknownType.cpp.o\r\n    [ 82%] Building CXX object CMakeFiles/awkward-objects.dir/src/libawkward/util.cpp.o\r\n    [ 82%] Built target awkward-objects\r\n    Scanning dependencies of target awkward-static\r\n    Scanning dependencies of target awkward\r\n    [ 85%] Linking CXX shared library libawkward.dylib\r\n    [ 85%] Linking CXX static library libawkward-static.a\r\n    [ 85%] Built target awkward-static\r\n    [ 85%] Built target awkward\r\n    Scanning dependencies of target _io\r\n    Scanning dependencies of target types\r\n    Scanning dependencies of target layout\r\n    [ 87%] Building CXX object CMakeFiles/_io.dir/src/python/_io.cpp.o\r\n    [ 89%] Building CXX object CMakeFiles/types.dir/src/python/types.cpp.o\r\n    [ 90%] Building CXX object CMakeFiles/layout.dir/src/python/layout.cpp.o\r\n    [ 92%] Building CXX object CMakeFiles/layout.dir/src/python/layout/content.cpp.o\r\n    [ 93%] Building CXX object CMakeFiles/layout.dir/src/python/layout/identities.cpp.o\r\n    [ 95%] Building CXX object CMakeFiles/layout.dir/src/python/layout/index.cpp.o\r\n    [ 96%] Linking CXX shared module _io.cpython-37m-darwin.so\r\n    [ 96%] Built target _io\r\n    [ 98%] Linking CXX shared module types.cpython-37m-darwin.so\r\n    [ 98%] Built target types\r\n    [100%] Linking CXX shared module layout.cpython-37m-darwin.so\r\n    [100%] Built target layout\r\n    [  7%] Built target awkward-cpu-kernels-objects\r\n    [  9%] Built target awkward-cpu-kernels-static\r\n    [ 81%] Built target awkward-objects\r\n    [ 82%] Built target awkward\r\n    [ 84%] Built target awkward-static\r\n    [ 92%] Built target layout\r\n    [ 95%] Built target _io\r\n    [ 96%] Built target awkward-cpu-kernels\r\n    [100%] Built target types\r\n    Install the project...\r\n    -- Install configuration: \"Release\"\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/libawkward-static.a\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/libawkward.dylib\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/libawkward-cpu-kernels.dylib\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/libawkward-cpu-kernels-static.a\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/layout.cpython-37m-darwin.so\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/types.cpython-37m-darwin.so\r\n    -- Installing: /Users/mdurant/code/awkward-1.0/build/lib.macosx-10.9-x86_64-3.7/awkward1/_io.cpython-37m-darwin.so\r\n    error: can't copy 'build/lib.macosx-10.9-x86_64-3.7/awkward.cpython-37m-darwin.so': doesn't exist or not a regular file\r\n```",
  "closed_at":"2020-03-20T21:29:05Z",
  "comments":5,
  "created_at":"2020-03-19T15:27:47Z",
  "id":584494764,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODQ0OTQ3NjQ=",
  "number":182,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"build on mac",
  "updated_at":"2020-03-20T21:29:05Z",
  "user":"MDQ6VXNlcjYwNDIyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"For the Python code, this is one item in the [PEP 8 style](https://www.python.org/dev/peps/pep-0008/#maximum-line-length). But I'm going to do the same thing for C++.\r\n\r\nIt seems that most of the Python world agrees with this: [80 is a drop-off point in the distribution](https://jakevdp.github.io/blog/2017/11/09/exploring-line-lengths-in-python-packages/).\r\n\r\n![image](https://user-images.githubusercontent.com/1852447/77114809-2d8acb80-69fb-11ea-83d6-5b36cf2bc9ce.png)\r\n\r\n```\r\nI don't find the arguments for this compelling; of course I know that we want t\\\r\no put code side-by-side on our wide screens. Our text editors simply shouldn't \\\r\nbe set up for horizontal scrolling: it should reflow with the window width. How\\\r\never, I don't mean that awful reflow that Atom does (and I can't seem to turn i\\\r\nt off), in which it breaks at word boundaries and tries to indent the remainder\\\r\n---that makes it even more unreadable. I mean it should reflow the way Emacs do\\\r\nes: the last character that fits in the window should turn into a \"\\\" and the r\\\r\nest goes on the next line. Sure words will be broken, but we've all learned to \\\r\nread that from using terminals all these years, right? When lines are hard-wrap\\\r\nped at some number of characters, they can't make full use of wider windows and\\\r\n become completely unusable when the window is less than the fixed number of ch\\\r\naracters, because soft reflow doesn't mix well with hard line breaks. But that'\\\r\ns why I checked the histogram above: if everyone _agrees_ with the same choice,\\\r\n then it's not quite as terrible.\r\n```",
  "closed_at":"2020-03-21T00:46:04Z",
  "comments":3,
  "created_at":"2020-03-19T21:15:45Z",
  "draft":false,
  "id":584704428,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzkxMjQxMjE5",
  "number":183,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-21T00:46:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Enforce a 79 character maximum on all lines, 72 on docstrings/comments.",
  "updated_at":"2020-03-21T00:47:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This was an oversight: it's really needed but I closed the \"concatenate\" issue (#76) once the function existed, though there's a NotImplementedError in it:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/afaa40f3993819d7beac903f701a4a1fb7f69897/src/awkward1/operations/structure.py#L151-L154\r\n\r\nThis operation is known to be useful from Awkward0; it was even an external contribution (https://github.com/scikit-hep/awkward-array/pull/80).\r\n\r\nIn Awkward1, it can probably be implemented as a broadcast in Python + specialized C++ method on ListArray, ListOffsetArray, and RegularArray (nothing else). That would allow all possible `axis` values.",
  "closed_at":"2020-11-17T14:02:21Z",
  "comments":7,
  "created_at":"2020-03-20T21:26:28Z",
  "id":585335965,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODUzMzU5NjU=",
  "number":184,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Concatenate for axis != 0",
  "updated_at":"2020-11-17T14:02:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] include/awkward/array/NumpyArray.h\r\n   * [x] include/awkward/array/RawArray.h\r\n   * [x] include/awkward/array/ListOffsetArray.h\r\n   * [x] include/awkward/array/ListArray.h\r\n   * [x] include/awkward/array/RegularArray.h\r\n   * [x] include/awkward/array/IndexedArray.h\r\n   * [x] include/awkward/array/ByteMaskedArray.h\r\n   * [x] include/awkward/array/BitMaskedArray.h\r\n   * [x] include/awkward/array/UnmaskedArray.h\r\n   * [x] include/awkward/array/EmptyArray.h\r\n   * [x] include/awkward/array/None.h\r\n   * [x] include/awkward/array/RecordArray.h\r\n   * [x] include/awkward/array/Record.h\r\n   * [x] include/awkward/array/UnionArray.h\r\n   * [x] include/awkward/Content.h\r\n   * [x] include/awkward/Index.h\r\n   * [x] include/awkward/Iterator.h\r\n   * [x] include/awkward/Identities.h\r\n   * [x] include/awkward/Reducer.h\r\n   * [x] include/awkward/Slice.h\r\n   * [x] include/awkward/util.h\r\n   * [x] include/awkward/type/PrimitiveType.h\r\n   * [x] include/awkward/type/ListType.h\r\n   * [x] include/awkward/type/RegularType.h\r\n   * [x] include/awkward/type/OptionType.h\r\n   * [x] include/awkward/type/RecordType.h\r\n   * [x] include/awkward/type/UnionType.h\r\n   * [x] include/awkward/type/UnknownType.h\r\n   * [x] include/awkward/type/ArrayType.h\r\n   * [x] include/awkward/type/Type.h\r\n   * [x] include/awkward/builder/Builder.h\r\n   * [x] include/awkward/builder/ArrayBuilder.h\r\n   * [x] include/awkward/builder/Int64Builder.h\r\n   * [x] include/awkward/builder/Float64Builder.h\r\n   * [x] include/awkward/builder/BoolBuilder.h\r\n   * [x] include/awkward/builder/ListBuilder.h\r\n   * [x] include/awkward/builder/StringBuilder.h\r\n   * [x] include/awkward/builder/OptionBuilder.h\r\n   * [x] include/awkward/builder/UnknownBuilder.h\r\n   * [x] include/awkward/builder/RecordBuilder.h\r\n   * [x] include/awkward/builder/TupleBuilder.h\r\n   * [x] include/awkward/builder/UnionBuilder.h\r\n   * [x] include/awkward/builder/IndexedBuilder.h\r\n   * [x] include/awkward/builder/GrowableBuffer.h\r\n   * [x] include/awkward/builder/ArrayBuilderOptions.h\r\n   * [x] include/awkward/io/root.h\r\n   * [x] include/awkward/io/json.h\r\n   * [x] include/awkward/python/util.h\r\n   * [x] include/awkward/python/content.h\r\n   * [x] include/awkward/python/identities.h\r\n   * [x] include/awkward/python/index.h\r\n   * [ ] ~~include/awkward/cpu-kernels/getitem.h~~\r\n   * [ ] ~~include/awkward/cpu-kernels/identities.h~~\r\n   * [ ] ~~include/awkward/cpu-kernels/operations.h~~\r\n   * [ ] ~~include/awkward/cpu-kernels/reducers.h~~\r\n   * [ ] ~~include/awkward/cpu-kernels/util.h~~\r\n",
  "closed_at":"2020-03-25T12:48:51Z",
  "comments":0,
  "created_at":"2020-03-21T15:31:38Z",
  "draft":false,
  "id":585521509,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzkxODczMzQz",
  "number":185,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-25T12:48:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Start writing doxygen comments in C++.",
  "updated_at":"2020-03-25T12:48:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The [util::quote](https://github.com/scikit-hep/awkward-1.0/blob/a4dad4996c03162db1d83f17c1c2d4adb59a1941/src/libawkward/util.cpp#L65-L74) function is supposed to use RapidJSON to add escape sequences to the strings that it quotes. Currently, it just puts quotation marks around the string without inspecting it.\r\n\r\nDon't forget this to-do item!",
  "closed_at":"2020-08-31T15:51:18Z",
  "comments":0,
  "created_at":"2020-03-24T16:00:39Z",
  "id":587073375,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODcwNzMzNzU=",
  "number":186,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Remember to introduce proper string-escape sequences in util::quote.",
  "updated_at":"2020-08-31T15:51:18Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-26T18:22:59Z",
  "comments":2,
  "created_at":"2020-03-25T14:43:38Z",
  "draft":false,
  "id":587748495,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0MzkzNjI5ODUy",
  "number":187,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-26T18:22:59Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Set up for Python documentation (including front page)",
  "updated_at":"2020-03-26T18:23:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-28T12:06:42Z",
  "comments":1,
  "created_at":"2020-03-26T18:37:34Z",
  "draft":false,
  "id":588640157,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk0MzQ5MTA0",
  "number":188,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-28T12:06:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Really write those Python docstrings this time.",
  "updated_at":"2020-03-28T12:06:46Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-04-17T18:26:44Z",
  "comments":4,
  "created_at":"2020-03-26T19:21:28Z",
  "draft":false,
  "id":588667264,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk0MzcxMDg5",
  "number":189,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-17T18:26:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update to Numba 0.49 and make that the minimal version",
  "updated_at":"2020-04-17T18:26:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] awkward1/highlevel.py\r\n   * [x] awkward1/operations/convert.py\r\n   * [x] awkward1/operations/describe.py\r\n   * [x] awkward1/operations/reducers.py\r\n   * [x] awkward1/operations/structure.py\r\n",
  "closed_at":"2020-03-30T01:56:35Z",
  "comments":1,
  "created_at":"2020-03-28T12:13:15Z",
  "draft":false,
  "id":589565820,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk1MDg3ODI1",
  "number":190,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-30T01:56:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those Python docs.",
  "updated_at":"2020-03-30T01:56:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"@jpivarski \r\n\r\nUse: `g++ -c -fPIC arrow_c_interface.cpp -o foo.o`\r\n`g++ -shared -Wl,-soname,libfoo.so -o libfoo.so  foo.o`\r\nto build the c++ library. use_array is the python file. So far I can get the bytes from the C struct but not from the Arrow Array, it doesn't consider `pyarrow.Array` as a byte object.",
  "closed_at":"2020-03-28T16:56:15Z",
  "comments":0,
  "created_at":"2020-03-28T16:54:13Z",
  "draft":false,
  "id":589615213,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk1MTIyNDkz",
  "number":191,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Studying Arrow Convertions",
  "updated_at":"2020-03-28T16:56:15Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"How can we get the C `FILE` object from a Python file?\r\n\r\nThis will also require a new function in the `_io` module.",
  "closed_at":"2022-08-23T03:41:26Z",
  "comments":8,
  "created_at":"2020-03-28T21:34:31Z",
  "id":589664147,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODk2NjQxNDc=",
  "number":192,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.to_json/ak.from_json should be revamped/organized for v2",
  "updated_at":"2022-08-23T03:41:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"And it should probably become a C++ method. It was only implemented in Python because we needed it right away to support Pandas. (That's also why it doesn't have an `axis` parameter\u2014it's a bare minimum.)\r\n\r\nAlso, none of the \"na\" functions recognize floating-point `nan` as the same thing as `None`. Pandas seems to be trying to get away from that misidentification, but maybe there are specialized needs for it\u2014in that case, there should be a function that turns floating-point `nan` into None. (There's already one for the other direction: `ak.fillna` can be used to turn None into any value, such as `nan`.)",
  "closed_at":"2020-12-09T22:41:50Z",
  "comments":5,
  "created_at":"2020-03-29T17:37:20Z",
  "id":589843240,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1ODk4NDMyNDA=",
  "number":193,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.is_none should have an axis parameter",
  "updated_at":"2020-12-09T22:41:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-03-30T13:56:46Z",
  "comments":1,
  "created_at":"2020-03-30T01:57:38Z",
  "draft":false,
  "id":589941273,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk1MzYzNTI5",
  "number":194,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-03-30T13:56:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those Python docs.",
  "updated_at":"2020-03-30T13:56:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] Handmade `ak.layout.Content` subclasses.\r\n   * [x] Handmade `ak.layout.Record`.\r\n",
  "closed_at":"2020-04-01T00:46:29Z",
  "comments":5,
  "created_at":"2020-03-30T13:57:55Z",
  "draft":false,
  "id":590313649,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk1NjY5OTAz",
  "number":195,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-01T00:46:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those Python docs.",
  "updated_at":"2020-04-01T00:46:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] Handmade `ak.behavior` with all the recognized rules.\r\n",
  "closed_at":"2020-04-01T21:43:40Z",
  "comments":0,
  "created_at":"2020-04-01T00:47:36Z",
  "draft":false,
  "id":591538217,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk2Njk3NTE3",
  "number":196,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-01T21:43:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those Python docs.",
  "updated_at":"2020-04-01T21:43:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   * [x] Handmade `ak.layout.Iterator`.\r\n   * [x] Handmade `ak.layout.Index`.\r\n   * [x] Handmade `ak.layout.Identities`.\r\n   * [x] Handmade `ak.layout.ArrayBuilder`.\r\n   * [x] Handmade `ak.types.Type` subclasses.\r\n",
  "closed_at":"2020-04-02T01:47:55Z",
  "comments":2,
  "created_at":"2020-04-01T21:44:45Z",
  "draft":false,
  "id":592222480,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk3MjQ3NzMy",
  "number":197,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-02T01:47:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those Python docs.",
  "updated_at":"2020-04-02T01:47:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-04-07T06:38:00Z",
  "comments":0,
  "created_at":"2020-04-02T01:49:15Z",
  "draft":false,
  "id":592302902,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk3MzEzMTMw",
  "number":198,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-07T06:38:00Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Start tutorial documentation.",
  "updated_at":"2020-04-07T06:38:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"NumPy has an [np.choose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.choose.html) function and it's something that could conceivably be NEP18-overloaded someday. Awkward can't have an [ak.choose](https://awkward-array.readthedocs.io/en/latest/_auto/ak.choose.html) function that does something different, or we'd never be able to overload NumPy's (and it would be confusing to users, anyway).\r\n\r\nPerhaps the right name is \"combinations\", since [itertools.combinations](https://docs.python.org/2/library/itertools.html#itertools.combinations) is exactly what our function does. Moreover, the `diagonal=True` option should probably be \"replacement\" because [itertools.combinations_with_replacement](https://docs.python.org/2/library/itertools.html#itertools.combinations_with_replacement) (too long of a name, in my opinion) is exactly what that option does.\r\n\r\nOn a similar note, perhaps [ak.cross](https://awkward-array.readthedocs.io/en/latest/_auto/ak.cross.html) should become \"product\" because then we'd be consistently getting our names from itertools: [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product). I'm a little afraid that \"product\" would be confused with multiplication\u2014in particular, ak.prod (so named because of [np.prod](https://docs.scipy.org/doc/numpy/reference/generated/numpy.prod.html)).\r\n\r\nThoughts? I'm asking everyone who's had opinions on Awkward naming before: @HDembinski, @henryiii, @nsmith-, @masonproffitt, @eduardo-rodrigues, @chrisburr, @lgray, @ianna, @lukasheinrich...\r\n\r\nI need to pick a final name before I do a tutorial on April 8, which will definitely include combinatorics. At that point, the names would be \"out in the wild\" and much harder to change again.",
  "closed_at":"2020-04-03T17:29:54Z",
  "comments":14,
  "created_at":"2020-04-02T18:17:25Z",
  "id":592833516,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTI4MzM1MTY=",
  "number":199,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.choose MUST be renamed, maybe ak.cross, too",
  "updated_at":"2020-04-03T17:29:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Proposing a new structure operation akin to pandas' [stack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html) and [unstack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html) which pivots a record structure to a jagged array and vice versa. The main difference is that we do not have a non-trivial row index, so the `ak.unstack` operation would create tuple RecordArray rather than labeled columns, as is done for structure operations like `ak.cross`.  Similarly, it might make sense to impose that `ak.unstack` will only operate on a tuple RecordArray. As in pandas, the default axis (level) should probably be -1 for this operation.\r\n\r\nExamples:\r\n```python\r\na = ak.Array([[(1, 2), (1, 3), (2, 3)], [], [(4, 5), (6, 7, 8)]])\r\nassert ak.tolist(a.stack()) == [[[1, 2], [1, 3], [2, 3]], [], [[4, 5], [6, 7, 8]]]\r\nassert ak.tolist(a.stack(dropna=False)) == [[[1, 2, None], [1, 3, None], [2, 3, None]], [], [[4, 5, None], [6, 7, 8]]]\r\n\r\na = ak.Array([[[1, 2], [1, 3], [2, 3]], [], [[4, 5], [6]]])\r\nassert ak.tolist(a.unstack()) == [[(1, 2), (1, 3), (2, 3)], [], [(4, 5), (6, None)]]\r\n\r\na = ak.Array([{'x': (2, 3), 'y': 1}, {'x': (4, 5), 'y': 0}])\r\nassert ak.tolist(a.stack()) == [{'x': [2, 3], 'y': [[0, 1], [2, 3]]}, {'x': [4, 5], 'y': [[0, 1], [2, 3]]}]\r\n\r\n# for\r\na = ak.zip({'x': [[1, 2, 3], [4, 5, 6, 7]], 'y': [[1, 2, 3], [4, 5, 6, 7]]})\r\n# the following\r\nb = ak.choose(a, 3).i0 + ak.choose(a, 3).i1 + ak.choose(a, 3).i2\r\n# could be written\r\nb = ak.sum(ak.stack(ak.choose(a, 3)), -1)\r\n```\r\n\r\n",
  "closed_at":null,
  "comments":2,
  "created_at":"2020-04-02T19:38:59Z",
  "id":592879384,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTI4NzkzODQ=",
  "number":200,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"open",
  "state_reason":null,
  "title":"ak.stack, ak.unstack",
  "updated_at":"2023-07-02T18:03:42Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is for #199, and I think I'm going to go with\r\n\r\n   * `choose` \u2192 `combinations`\r\n   * `diagonal` \u2192 `replacement`\r\n   * `cross` \u2192 `product`\r\n\r\nfor the sake of following itertools as much as possible. `cartesian` is also a good word for the last one, but I think if we're going to follow itertools for one, we should follow it for both. (These two functions are related; rules for one should apply to the other.) Besides, someone might not know who Descartes is.",
  "closed_at":"2020-04-03T17:49:01Z",
  "comments":6,
  "created_at":"2020-04-02T21:27:58Z",
  "draft":false,
  "id":592927570,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0Mzk3ODE2NTky",
  "number":201,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-03T17:49:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Rename ak.choose and ak.cross.",
  "updated_at":"2020-04-03T17:49:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"These are often useful in NumPy, and Awkward arrays need more general broadcasting.",
  "closed_at":"2020-04-08T12:42:35Z",
  "comments":1,
  "created_at":"2020-04-02T23:06:51Z",
  "id":592970500,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTI5NzA1MDA=",
  "number":202,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.minimum, ak.maximum to override np.minimum, np.maximum",
  "updated_at":"2020-04-08T12:42:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"[The technique described here](https://nbviewer.jupyter.org/github/jpivarski/2020-04-08-eic-jlab/blob/master/2020-04-08-eic-jlab-EVALUATED.ipynb#Reducing-from-combinations) works and is fully general, but confusing and more intricate than a data analyst should have to deal with when they just want to min/maximize by some parameter.\r\n\r\nPerhaps there should be a `ak.minby` and `ak.maxby` pair to do all the steps, though this means that an index derived from one collection can't be used multiple times. Maybe `ak.pick`, which takes output from `ak.argmin`/`ak.argmax`. Maybe it should have a similar status to `ak.mask` in having a method as well:\r\n\r\n```python\r\narray.pick[ak.argmax(array.pt)]\r\n```\r\n\r\nlike\r\n\r\n```python\r\narray.mask[array.pt > 5]\r\n```",
  "closed_at":"2022-04-07T15:52:39Z",
  "comments":6,
  "created_at":"2020-04-08T12:55:48Z",
  "id":596556573,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTY1NTY1NzM=",
  "number":203,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Simplify min/max by another quantity through wrapper functions",
  "updated_at":"2022-04-07T15:52:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The `axis=0` case already does this (because arrays are long), but the other cases probably should, too, since combinatorics in the wild ends up duplicating many record fields when only a couple are desired.\r\n\r\nIn `ak.combinations`, the fix goes [right here](https://github.com/scikit-hep/awkward-1.0/blob/8215351f09de3773b14318815538ec0faaeb6235/src/libawkward/array/ListOffsetArray.cpp#L1514).\r\n\r\nIn `ak.cartesian`, it's actually in broadcasting, [right here](https://github.com/scikit-hep/awkward-1.0/blob/8215351f09de3773b14318815538ec0faaeb6235/src/awkward1/_util.py#L589-L597), and maybe `broadcast_tooffsets64` should take an option to make an IndexedArray instead of carrying ([here](https://github.com/scikit-hep/awkward-1.0/blob/8215351f09de3773b14318815538ec0faaeb6235/src/libawkward/array/ListOffsetArray.cpp#L132)) for specially chosen cases like `ak.cartesian`.",
  "closed_at":"2020-07-20T17:55:09Z",
  "comments":2,
  "created_at":"2020-04-08T13:08:47Z",
  "id":596564741,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTY1NjQ3NDE=",
  "number":204,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.cartesian and ak.combinations should make an IndexedArray for axis > 0 as well",
  "updated_at":"2020-07-20T17:55:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I see the following TypeError when calling `dir()`  on instances of `ak.highlevel.Record`:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-9-fb278c25e68f> in <module>\r\n----> 1 dir(rec)\r\n\r\n~/miniconda3/envs/awkward/lib/python3.8/site-packages/awkward1/highlevel.py in __dir__(self)\r\n   1620         that can be accessed as attributes.\r\n   1621         \"\"\"\r\n-> 1622         return sorted(set(dir(super(Array, self))\r\n   1623                           + [x for x in self._layout.keys()\r\n   1624                                if _dir_pattern.match(x) and\r\n\r\nTypeError: super(type, obj): obj must be an instance or subtype of type\r\n```\r\n\r\nI can reproduce the exception by running the following snippet on:\r\n* macOS 10.15.4, Python 3.8.2, awkward1==0.2.10\r\n* Ubuntu 18.04, Python 3.7.4, awkward1==0.2.10\r\n\r\n```python\r\nimport awkward1 as ak\r\n\r\n# Introspecting the class is fine\r\ndir(ak.highlevel.Record)\r\n\r\nrec = ak.from_iter({\r\n    'numbers': [1, 2, 3],\r\n    'letters': ['a', 'b', 'c'],\r\n})\r\n\r\n# Introspecting an instance raises TypeError\r\ndir(rec)\r\n```\r\n\r\nThe traceback leads me to the implementation of `Record.__dir__`:\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/8215351f09de3773b14318815538ec0faaeb6235/src/awkward1/highlevel.py#L1617-L1625\r\n\r\nI think the issue can be fixed by changing the first argument in the call to `super()` from Array to Record, but in case I'm not seeing something I defer to the authors on what the passed type should be.",
  "closed_at":"2020-04-10T19:43:53Z",
  "comments":2,
  "created_at":"2020-04-10T18:42:48Z",
  "id":598034352,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTgwMzQzNTI=",
  "number":205,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"TypeError when introspecting ak.highlevel.Record",
  "updated_at":"2020-04-10T19:45:19Z",
  "user":"MDQ6VXNlcjc2NDkxMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-04-10T19:43:52Z",
  "comments":0,
  "created_at":"2020-04-10T18:50:41Z",
  "draft":false,
  "id":598038277,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDAyMDI0NjM0",
  "number":206,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-10T19:43:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"This should fix #205.",
  "updated_at":"2020-04-10T19:43:56Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"The current release tarball\r\nhttps://files.pythonhosted.org/packages/24/81/9798b934e4c9313abb5d4ffe8af86f7a5cf87eb873de463b294813518eea/awkward1-0.2.11.tar.gz\r\nis missing requirements-docs.txt and requirements-dev.txt, which are still required by setup.py",
  "closed_at":"2020-04-11T13:26:48Z",
  "comments":10,
  "created_at":"2020-04-11T03:26:44Z",
  "id":598179730,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTgxNzk3MzA=",
  "number":207,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"release tarball is missing files",
  "updated_at":"2020-04-11T17:30:25Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This should include all the files it needs to fix #207.\r\n\r\nI'm also _attempting_ to fix the visibility warnings when compiling on MacOS. It shouldn't be complaining about \"different symbol visibility\" because CMake explicitly says `PROPERTIES CXX_VISIBILITY_PRESET hidden` on every project. But just in case, I'm also adding `-fvisibility=hidden -fvisibility-inlines-hidden`.\r\n\r\nAt least this shouldn't break the build. (Check!)",
  "closed_at":"2020-04-11T13:26:48Z",
  "comments":1,
  "created_at":"2020-04-11T12:41:08Z",
  "draft":false,
  "id":598258285,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDAyMTg0OTI2",
  "number":208,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-11T13:26:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #207 (missing files in tarball)",
  "updated_at":"2020-04-11T13:26:52Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-04-13T17:37:33Z",
  "comments":31,
  "created_at":"2020-04-11T17:49:45Z",
  "draft":false,
  "id":598317376,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDAyMjI0Mjgz",
  "number":209,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-13T17:37:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Try again on visibility and also ensure -frtti",
  "updated_at":"2020-04-13T17:37:46Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"An alternative approach to close #209. This doesn't work yet. Just wanted to see if this passes CI.\r\n\r\nIf there is some mismatch between typeinfo symbols due to copies that\r\nmay appear due to static linking, this might fix it. Interestingly,\r\nthis instead turns 13 test failures into 171 test failures of the same\r\nkind:\r\n\r\nRuntimeError: missing boxer for Content subtype\r\n\r\nThis also removes \"CXX_VISIBILITY_PRESET hidden\" from libawkard\r\ninterface as it currently hides typeinfo symbols.",
  "closed_at":"2020-04-13T06:12:12Z",
  "comments":7,
  "created_at":"2020-04-12T16:34:44Z",
  "draft":false,
  "id":598522726,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDAyMzY0ODQ2",
  "number":210,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[WIP] [don't merge] Link python extensions against shared libawkward",
  "updated_at":"2020-04-18T18:29:52Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This issue is to document test failure reported in https://github.com/scikit-hep/awkward-1.0/issues/207#issuecomment-612451163 . From the looks of it, this is an instance of https://github.com/pybind/pybind11/issues/912.\r\n\r\n### Context\r\nEverything presented here is done with MacOS 10.14 + nixpkgs (5c72e8416984879bd7bd884a392b7c915c28171a).\r\n```\r\n# clang -v\r\nclang version 7.1.0 (tags/RELEASE_710/final)\r\nTarget: x86_64-apple-darwin18.7.0\r\nThread model: posix\r\nInstalledDir: /nix/store/xbd074qa4p62sjbcmkvbzrb1d4zcj79n-clang-7.1.0/bin\r\n# ld -v\r\n@(#)PROGRAM:ld  PROJECT:ld64-450.3\r\nBUILD 08:28:49 Apr  2 2020\r\n```\r\n\r\nThe following options are unset, which, I guess, is the default.\r\n```\r\n_LIBCXX_DYNAMIC_FALLBACK\r\n_LIBCPP_HAS_NONUNIQUE_TYPEINFO\r\n_LIBCPP_NONUNIQUE_RTTI_BIT\r\n```\r\n\r\ndlopen flags:\r\n```\r\n>>> import sys; sys.getdlopenflags() == os.RTLD_NOW\r\nTrue\r\n```\r\n\r\n### Steps to reproduce\r\n```\r\n>>> import awkward1; awkward1.from_json(\"[1,2,3]\", highlevel=False)[0]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nRuntimeError: missing boxer for Content subtype\r\n```\r\n\r\n### Analysis\r\nWhat happens under the hood is `awkward1.from_json` is calling into `awkward1._io.fromjson`\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/awkward1/operations/convert.py#L418\r\nwhich allocates an instance of ak::NumpyArray:\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/libawkward/builder/Int64Builder.cpp#L61-L68\r\none part I don't understand is how it is able to return ak::Content:\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/python/_io.cpp#L20-L25\r\nBecause pybind should not know about `ak::Content` as a python class without \"awkward1.layout\" which defines it in\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/python/layout/content.cpp#L807-L810\r\nWhen we call into `__getitem__` we definitely get into awkward1.layout\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/python/layout/content.cpp#L570-L572\r\nand that somehow is dispatched to `NumpyArray::getitem_at_nowrap` in the \"awkward1._io\" library. There it allocates another NumpyArray:\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/libawkward/array/NumpyArray.cpp#L776-L783\r\nThat we then attempt to box (why do even need the box, didn't we just successfully return `ak::Content` from the `awkward1._io.fromjson`? what happens with the ownership of `content`?)\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/python/layout/content.cpp#L12-L25\r\nbut \"awkward1.layout\" fails to recognise an instance of `NumpyArray` and finally fails:\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/77c3e7ff7304734f7e917c9223adf473eace521b/src/python/layout/content.cpp#L121-L124\r\n\r\nInspecting typeinfo for the classes I found that:\r\n1. Both `typeid(*content.get()).name()` and `typeid(ak::NumpyArray).name()` have the same mangled typeinfo name \"N7awkward10NumpyArrayE\"\r\n2. `typeid(*content.get()).hash_code()` differs from `typeid(ak::NumpyArray).hash_code()`\r\n3. `typeid(*content.get()) != typeid(ak::NumpyArray)`\r\n\r\nNow, in principle, some implementations may choose to compare type_info instances by comparing their names only. [1][2] I've tried enabling that, it has some interesting behaviour depending on the value of _LIBCPP_NONUNIQUE_RTTI_BIT. For small values (like 0xF) there is no apparent difference, for very large values it crashes in the dynamic loader, for an intermediate value I get an error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"lib/python3.7/site-packages/awkward1/__init__.py\", line 16, in <module>\r\n    import awkward1.layout\r\nImportError: generic_type: type \"IndexU8\" is already registered!\r\n```\r\n\r\nThere is also _LIBCXX_DYNAMIC_FALLBACK [3].\r\n\r\n### Inspecting the symbols\r\n\r\nThe next logical step was to look for a duplicate symbol for the typeinfo for akward::NumpyArray. We first examine the object files to see if different typeinfo's are present in different translation units.\r\n\r\nUsing nm:\r\n```\r\n# find . -name \"*.o\" | xargs nm -o | grep N7awkward10NumpyArrayE | c++filt -_ | grep \"typeinfo for aw\"     \r\n./_io.dir/src/python/_io.cpp.o:                  U typeinfo for awkward::NumpyArray\r\n./layout.dir/src/python/layout/content.cpp.o:                  U typeinfo for awkward::NumpyArray\r\n./awkward-objects.dir/src/libawkward/array/NumpyArray.cpp.o: 000000000002ce90 S typeinfo for awkward::NumpyArray\r\n```\r\n\r\nOr objdump:\r\n```\r\n# find . -name \"*.o\" | xargs objdump -tC | grep 'typeinfo for awkward::NumpyArray' \r\n0000000000000000 g       01 UND    00 0000 typeinfo for awkward::NumpyArray\r\n0000000000000000 g       01 UND    00 0000 typeinfo for awkward::NumpyArray\r\n000000000002ce90 g       0f SECT   08 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n```\r\n\r\nThis looks very reasonable - only one translation unit has an instance of the typeinfo. The undefined symbol in ./_io.dir/src/python/_io.cpp.o can be easily removed by dropping `make_fromroot_nestedvector`, but that doesn't help the problem.\r\n\r\nNow we take a look at the final python libraries:\r\n\r\n```\r\n# find result/ -name \"*.so\" | xargs nm -o | grep N7awkward10NumpyArrayE | c++filt -_ | grep \"typeinfo for aw\"\r\nresult/lib/python3.7/site-packages/awkward1/layout.cpython-37m-darwin.so: 00000000004acf60 S typeinfo for awkward::NumpyArray\r\nresult/lib/python3.7/site-packages/awkward1/_io.cpython-37m-darwin.so: 0000000000205440 S typeinfo for awkward::NumpyArray\r\nresult/lib/python3.7/site-packages/awkward1/types.cpython-37m-darwin.so: 00000000002499e0 S typeinfo for awkward::NumpyArray\r\n# find result/ -name \"*.so\" | xargs objdump -tC | grep 'typeinfo for awkward::NumpyArray' \r\n0000000000000000      d  20 GSYM   00 0000 typeinfo for awkward::NumpyArray\r\n00000000004acf60 g       0f SECT   0d 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n0000000000000000      d  20 GSYM   00 0000 typeinfo for awkward::NumpyArray\r\n0000000000205440 g       0f SECT   0d 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n0000000000000000      d  20 GSYM   00 0000 typeinfo for awkward::NumpyArray\r\n00000000002499e0 g       0f SECT   0d 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n```\r\n\r\nI assume, \"GSYM\" supposed to denote a global symbol, not sure how loader deals with the three available pieces.\r\n\r\nThis is how symbol tables look for the *.so files in the awkward1-0.2.12-cp37-cp37m-macosx_10_9_x86_64.whl:\r\n\r\n```\r\n# find . -name \"*.so\" | xargs nm -o | grep N7awkward10NumpyArrayE | c++filt -_ | grep \"typeinfo for aw\"      \r\n./layout.cpython-37m-darwin.so: 0000000000443738 S typeinfo for awkward::NumpyArray\r\n./_io.cpython-37m-darwin.so: 000000000020ee60 S typeinfo for awkward::NumpyArray\r\n./types.cpython-37m-darwin.so: 0000000000245f80 S typeinfo for awkward::NumpyArray\r\n# find . -name \"*.so\" | xargs objdump -tC | grep 'typeinfo for awkward::NumpyArray'                             \r\n0000000000443738 g       0f SECT   0c 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n000000000020ee60 g       0f SECT   0c 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n0000000000245f80 g       0f SECT   0c 0000 [.const_data] typeinfo for awkward::NumpyArray\r\n```\r\n\r\nThe problem is not seen with `python3` and `python3Packages.numpy` from nixpkgs and awkward from the wheel:\r\n```\r\n>>> import awkward1; awkward1.from_json(\"[1,2,3]\", highlevel=False)[0]\r\n1\r\n```\r\n\r\n### Summary\r\n\r\nThe problem itself seems to stem from having objects passed across multiple python libraries. Perhaps, it is triggered by some specific toolchain or libc++ version?\r\n\r\n[1] https://reviews.llvm.org/D38599?id=118502\r\n[2] https://dholmes215.github.io/c++/2017/06/30/fun-with-typeid.html\r\n[3] https://github.com/llvm-mirror/libcxxabi/blob/master/src/private_typeinfo.cpp",
  "closed_at":"2020-10-30T22:05:49Z",
  "comments":4,
  "created_at":"2020-04-13T06:11:41Z",
  "id":598697502,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU1OTg2OTc1MDI=",
  "number":211,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"typeinfo mismatch in separate Python extension modules that both produce Awkward Arrays",
  "updated_at":"2020-10-30T22:05:49Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Addresses issue #56, which is part of what's needed for virtual arrays in uproot.\r\n\r\n   * [x] In a new `partitioned/` directory, create an abstract base class and IrregularlyPartitionedArray, RegularlyPartitionedArray pair.\r\n   * [x] Give it the `getitem_*` methods that do not take a general `Slice`.\r\n   * [x] Give it a `repartition` method that divides it up differently (one for regular, one for irregular).\r\n   * [x] Turning a partitioned array into a `Slice` concatenates it.\r\n   * [x] Generic `__getitem__` by repartitioning.\r\n   * [x] Handle all Content methods in a generalized way in Python.\r\n      * [x] Some methods return value from first.\r\n      * [x] Some methods evaluate all and concatenate.\r\n      * [x] Other methods evaluate all and return a new PartitionedArray, preserving regularity.\r\n      * [x] Other methods do not preserve regularity.\r\n   * [x] Test PartitionedArray in _everything_ by temporarily making `ak.Array` be partitioned with `numpartitions == 1`.\r\n   * [x] Add `ak.repartition(array, # or None)` to give the user control over partitioning.\r\n   * ~~Repartitioning means running down the tree, finding the IndexedArrays, and changing their `index` to reflect a new starting point.~~ **No it doesn't:** the slicing only applies to the top level, and no IndexedArrays _inside_ the structure have that top level as their `content`. When we add RedirectArray, the target of redirection will be the original, unsliced, array.\r\n   * [x] Explicitly test structure operations that didn't get tested by the \"ak.Array is partitioned\" test:\r\n      * [x] mask\r\n      * [x] zip\r\n      * [x] unzip\r\n      * [x] with_name\r\n      * [x] with_field\r\n      * [x] singletons\r\n      * [x] firsts\r\n      * [x] atleast_1d\r\n   * [x] Explicitly test broadcasting of string equality where one side or the other is partitioned.\r\n   * [x] In Numba, a common `numbatype` is required for compilation. The `__getitem__` is inefficient (because you have to search through `stops`) but `__iter__` is reasonably efficient (doesn't have to search for the partition id and only creates new `ArrayViews` at the boundaries between partitions).\r\n   * ~~The Arrow version of this node type is a RecordBatch.~~ This will be done before Arrow.",
  "closed_at":"2020-04-19T15:29:39Z",
  "comments":1,
  "created_at":"2020-04-13T19:12:09Z",
  "draft":false,
  "id":599076760,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDAyNzkyNjA3",
  "number":212,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-19T15:29:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"PartitionedArray, which only applies to the root of a structure.",
  "updated_at":"2020-04-19T15:29:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Currently, PartitionedArrays require all partitions to have identical high-level types. This can be loosened to any arrays that are `Content::mergeable` (but compared at the level of `Type::`). Given an equivalence class of mergeable types, there is a \"broadest\" member of that set, and all members can be expanded to meet those requirements (e.g. by simplifying unions of numbers and by wrapping arrays with OptionType).\r\n\r\n   * [ ] Loosen the already existing `equals` definition to allow named RecordType fields and UnionType types to be in different orders, as well as squashing double-OptionType and double-UnionType.\r\n   * [ ] Implement `mergeable` for `Type` subclasses.\r\n   * [ ] Implement `broadest` to find the most general of a set of mergeable types.\r\n   * [ ] Implement `broaden(array)`, which ensures that an array has the broadened type.\r\n\r\nCare will have to be taken to integrate this with VirtualArray. If VirtualArray is implemented before the above, then VirtualArray will require its materialized array to have exactly the type in its specification, but afterward, it can be relaxed to `broaden` its materialized array.\r\n",
  "closed_at":"2020-12-11T22:41:16Z",
  "comments":1,
  "created_at":"2020-04-16T15:05:44Z",
  "id":601142044,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDExNDIwNDQ=",
  "number":213,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Need to define \"consistent, but not equal, types\"",
  "updated_at":"2020-12-11T22:41:16Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"As mentioned in #204 \r\n",
  "closed_at":"2020-04-21T14:55:58Z",
  "comments":10,
  "created_at":"2020-04-17T21:10:32Z",
  "draft":true,
  "id":602235216,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA1MzQxODQ5",
  "number":214,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Use `IndexedArray` instead of `carry` in ak.combinations. ",
  "updated_at":"2020-04-21T14:55:59Z",
  "user":"MDQ6VXNlcjc0NjYzNjQ="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is a step that will be needed to prepare the Python code for GPUs, as it uses a bit of NumPy to manipulate arrays in a few operations (particularly those that had to be written quickly, at the last minute, but it was pretty much necessary for something as complex as broadcasting). Like Awkward0, we shouldn't be accessing the `numpy` module directly if we want to automatically swap it out for `cupy`.\r\n\r\nThe layout nodes need a readonly `numpy` property that returns `py::import(\"numpy\")` for now. When layout nodes have a CPU-vs-GPU-device-number indicator, they'll use this to decide whether to return `py::import(\"numpy\")` or `py::import(\"cupy\")` (with an appropriate \"how to install CuPy\" message instead of a bare `ImportError`).\r\n\r\nThen I'll also need to do a survey of all the ways NumPy is used, to make sure that CuPy supports all of these functions and arguments.",
  "closed_at":"2020-08-18T00:18:17Z",
  "comments":1,
  "created_at":"2020-04-17T22:31:09Z",
  "id":602267765,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDIyNjc3NjU=",
  "number":215,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Access \"numpy\" module through indirection on the array at hand, to replace with \"cupy\"",
  "updated_at":"2020-08-18T00:18:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@nsmith- may be interested in following this.\r\n\r\nAn initial design is described here: https://github.com/scikit-hep/awkward-1.0/issues/57#issuecomment-589862540\r\n\r\n   * [x] Forms for each array node class\r\n   * [x] ArrayCache\r\n   * [x] ArrayGenerator\r\n   * [x] Form::equal\r\n   * [x] Basic implementation of VirtualArray materialization\r\n   * [x] The `\"__cache_key__\"` parameter\r\n   * [x] SlicedGenerator\r\n   * [x] Single-level `__getitem__` behavior\r\n   * [x] Iterator should force-materialize and hang onto a copy of the materialized array\r\n   * [x] All the methods\r\n   * [x] Numba\r\n      * [x] Forms \u2192 Layouts\r\n      * [x] Layouts \u2192 unmaterialized VirtualArrays\r\n      * [x] calling Python materialization from within Numba\r\n   * [x] JSON \u2192 Forms\r\n   * [x] High-level functions for virtualization\r\n      * [x] Create a high-level virtual array\r\n      * ~~Create a record array of virtual fields~~\r\n      * [x] Replace the caches of all virtual arrays in a structure in one swoop\r\n      * [x] Chain the caches (maybe a parameter of the above)\r\n   * [x] VirtualArrays inside VirtualArrays\r\n   * [x] When a VirtualArray is sliced, if the original is in cache, slice and return that.",
  "closed_at":"2020-04-29T02:31:24Z",
  "comments":0,
  "created_at":"2020-04-19T15:52:14Z",
  "draft":false,
  "id":602750347,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA1Njg2OTM0",
  "number":216,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-29T02:31:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"VirtualArray, which loads its data on demand and interacts with a cache.",
  "updated_at":"2020-04-29T02:31:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"When trying to solve #211 by using dynamic linking I was trying to understand how compiler decides where to emit typeinfo for a given class. Many workarounds for the typeinfo mismatches will rely on virtual calls. Turns out the vtable are also emitted without any control. Because the rules for emitting vtable seem to be outlined better than those for typeinfo, it seems like they are a good choice to start working on.\r\n\r\nThis PR is taking a bite at reducing the symbol duplication across the translation units. For example, this leaves no defined \"vtable for awkward::\" symbols from the translation units of the python extension as well as some of the typeinfo and template methods. This should give some benefits for smaller object files and speedier linking times. This only deals with libawkward for now.",
  "closed_at":"2020-04-20T23:03:45Z",
  "comments":4,
  "created_at":"2020-04-19T22:19:02Z",
  "draft":false,
  "id":602835697,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA1NzQ1Nzgy",
  "number":217,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-20T23:03:45Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"libawkward: pin vtables to the library",
  "updated_at":"2020-04-20T23:03:45Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"...before committing #212. It [showed up here](https://dev.azure.com/jpivarski/Scikit-HEP/_build/results?buildId=1914&view=logs&j=37fb9890-1dda-57f6-e555-40c397ef4a75&t=d4d3d92e-3135-5e2b-430f-fb7c34209463), indicating that it _wasn't_ a figment of my imagination. (Or, as I reasoned, a test with a non-final version of the code.)\r\n\r\nIt shows up very rarely in PartitionedArray iteration in Numba. However, it might be due to an earlier test but the attempt to delete still-referenced data happens later (at random times).",
  "closed_at":"2020-04-20T05:45:09Z",
  "comments":1,
  "created_at":"2020-04-19T22:52:47Z",
  "draft":false,
  "id":602843143,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA1NzUxNDMy",
  "number":218,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-20T05:45:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix a segfault I suspected but couldn't reproduce",
  "updated_at":"2020-04-20T05:45:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"NONE",
  "body":"The problem I encountered is that `numba.core.typing` is not present e.g. in numba v0.47 which is the latest for Python 3.5.\r\n\r\nI found the corresponding commit: https://github.com/scikit-hep/awkward-1.0/commit/3df1e14622cdc1f7561914252f19f5b39ffde2ae\r\n\r\nThis was probably not caught by the awkward1 test suite. Here is the error which came up in my library:\r\n\r\n```python\r\nvenv/lib/python3.5/site-packages/awkward1/_connect/_numba/__init__.py:10: in register\r\n    import awkward1._connect._numba.arrayview\r\nvenv/lib/python3.5/site-packages/awkward1/_connect/_numba/arrayview.py:9: in <module>\r\n    import numba.core.typing\r\nE   ImportError: No module named 'numba.core'\r\n```\r\n\r\nI thought making a PR which replaces `import numba.core.typing` with `import numba.typing` etc. (in `_connect/_numba/arrayview.py` and `_connect/_numba/builder.py`) would solve the problem but apparently `numba.typing.ctypes` does not exist in 0.47, which is also used:\r\n\r\n```python\r\nIn [1]: import numba.typing\r\n\r\nIn [2]: numba.typing.ctypes_utils\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-d7a62042b95a> in <module>\r\n----> 1 numba.typing.ctypes_utils\r\n\r\nAttributeError: module 'numba.typing' has no attribute 'ctypes_utils'\r\n\r\nIn [3]: numba.__version__\r\nOut[3]: '0.47.0'\r\n```\r\n\r\nWhat works is:\r\n\r\n```python\r\nIn [1]: from numba.typing import ctypes_utils\r\n```\r\n\r\nThis on the other hand will not work for numba 0.50+\r\n\r\n```python\r\nIn [1]: from numba.typing import ctypes_utils\r\n/usr/local/bin/ipython:1: NumbaDeprecationWarning: An import was requested from a module that has moved location.\r\nImport of 'ctypes_utils' requested from: 'numba.typing', please update to use 'numba.core.typing' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\r\n  #!/usr/local/bin/python\r\n```\r\n\r\nWhat do you think about some special code for Python 3.5 (`ImportError` catches or version check blocks and alike)?",
  "closed_at":"2020-04-30T11:26:28Z",
  "comments":5,
  "created_at":"2020-04-20T12:53:20Z",
  "id":603215235,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDMyMTUyMzU=",
  "number":219,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add a warning about Numba and Python 3.5 compatibility.",
  "updated_at":"2020-04-30T11:27:18Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-04-20T15:12:21Z",
  "comments":1,
  "created_at":"2020-04-20T14:45:09Z",
  "draft":false,
  "id":603294195,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA2MTA4Njk1",
  "number":220,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-20T15:12:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"This PR fixes a minor bug in localbuild.py, which halts the build procedure.",
  "updated_at":"2020-04-20T15:12:22Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Sorry if I miss some obvious information: I just worked through the demo notebook for Numba developers (https://github.com/scikit-hep/awkward-1.0/blob/master/docs-demo-notebooks/2020-01-22-numba-demo-EVALUATED.ipynb) and could not run the numba example. I also was not able to install the exact version required as it is not on PyPI (`pip install 'awkward1==0.1.87'`), so I tried one above and one below (`0.1.92` and `0.1.38`) but got the same message (see below).\r\n\r\nWhat is the actual status of the Numba support? In the notebook it seems that for array layouts it already worked quite well, which I really look forward to! Is there a new way of providing the Awkward1 structures?\r\n\r\nMy original problem btw. is the lack of a `np.unique` utility function for which I'll open a new issue or PR if I find more time, so I thought I'll quickly hack together a JITted function.\r\n\r\n```python\r\nimport numba as nb\r\n\r\n@nb.jit(nopython=True)\r\ndef run(array):\r\n    out = np.empty(len(array), np.float64)\r\n    for i in range(len(array)):\r\n        out[i] = array[i][\"x\"]\r\n        for y in array[i][\"y\"]:\r\n            out[i] += y\r\n    return out\r\n\r\nakarray = ak.Array([{\"x\": 100, \"y\": [1.1, 2.2]}, {\"x\": 200, \"y\": []}, {\"x\": 300, \"y\": [3.3]}])\r\n\r\n# Works for the layout nodes, but not the high-level ak.Array wrapper yet.\r\nrun(akarray.layout)\r\n```\r\n\r\ngives (this is with `awkward=='0.2.16'` and `numba=='0.49.0'` but the error was similar for older Awkward versions and also older versions of Numba):\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nTypingError                               Traceback (most recent call last)\r\n<ipython-input-5-34ffcbcddf9c> in <module>\r\n     13 \r\n     14 # Works for the layout nodes, but not the high-level ak.Array wrapper yet.\r\n---> 15 run(akarray.layout)\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws)\r\n    399                 e.patch_message(msg)\r\n    400 \r\n--> 401             error_rewrite(e, 'typing')\r\n    402         except errors.UnsupportedError as e:\r\n    403             # Something unsupported is present in the user code, add help info\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/dispatcher.py in error_rewrite(e, issue_type)\r\n    342                 raise e\r\n    343             else:\r\n--> 344                 reraise(type(e), e, None)\r\n    345 \r\n    346         argtypes = []\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/utils.py in reraise(tp, value, tb)\r\n     77         value = tp()\r\n     78     if value.__traceback__ is not tb:\r\n---> 79         raise value.with_traceback(tb)\r\n     80     raise value\r\n     81 \r\n\r\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\r\nInvalid use of Function(<built-in function len>) with argument(s) of type(s): (awkward1.RecordArrayType((awkward1.NumpyArrayType(array(int64, 1d, C), none, {}), awkward1.ListArrayType(array(int64, 1d, C), awkward1.NumpyArrayType(array(float64, 1d, C), none, {}), none, {})), (('x', 'y')), none, {}))\r\n * parameterized\r\nIn definition 0:\r\n    All templates rejected with literals.\r\nIn definition 1:\r\n    All templates rejected without literals.\r\nIn definition 2:\r\n    All templates rejected with literals.\r\nIn definition 3:\r\n    All templates rejected without literals.\r\nIn definition 4:\r\n    All templates rejected with literals.\r\nIn definition 5:\r\n    All templates rejected without literals.\r\nIn definition 6:\r\n    All templates rejected with literals.\r\nIn definition 7:\r\n    All templates rejected without literals.\r\nIn definition 8:\r\n    All templates rejected with literals.\r\nIn definition 9:\r\n    All templates rejected without literals.\r\nIn definition 10:\r\n    All templates rejected with literals.\r\nIn definition 11:\r\n    All templates rejected without literals.\r\nIn definition 12:\r\n    All templates rejected with literals.\r\nIn definition 13:\r\n    All templates rejected without literals.\r\nIn definition 14:\r\n    All templates rejected with literals.\r\nIn definition 15:\r\n    All templates rejected without literals.\r\nIn definition 16:\r\n    All templates rejected with literals.\r\nIn definition 17:\r\n    All templates rejected without literals.\r\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\r\n[1] During: resolving callee type: Function(<built-in function len>)\r\n[2] During: typing of call at <ipython-input-5-34ffcbcddf9c> (5)\r\n\r\n\r\nFile \"<ipython-input-5-34ffcbcddf9c>\", line 5:\r\ndef run(array):\r\n    out = np.empty(len(array), np.float64)\r\n    ^\r\n```\r\n\r\nI also tried getting rid of `len(array)` to see where it chokes but it seem that the index accessing is already causing trouble, as seen by this tiny example:\r\n\r\n```python\r\nimport numba as nb\r\n\r\n@nb.jit(nopython=True)\r\ndef run(array):\r\n    out = np.empty(3)\r\n    for i in range(3):\r\n        out[i] = array[i]\r\n    return out\r\n\r\nakarray = ak.Array([1, 2, 3])\r\n\r\n# Works for the layout nodes, but not the high-level ak.Array wrapper yet.\r\nrun(akarray.layout)\r\n```\r\n\r\nwhich gives:\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nTypingError                               Traceback (most recent call last)\r\n<ipython-input-9-09f2be2cb22a> in <module>\r\n     11 \r\n     12 # Works for the layout nodes, but not the high-level ak.Array wrapper yet.\r\n---> 13 run(akarray.layout)\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws)\r\n    399                 e.patch_message(msg)\r\n    400 \r\n--> 401             error_rewrite(e, 'typing')\r\n    402         except errors.UnsupportedError as e:\r\n    403             # Something unsupported is present in the user code, add help info\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/dispatcher.py in error_rewrite(e, issue_type)\r\n    342                 raise e\r\n    343             else:\r\n--> 344                 reraise(type(e), e, None)\r\n    345 \r\n    346         argtypes = []\r\n\r\n~/Dev/km3io/venv/lib/python3.8/site-packages/numba/core/utils.py in reraise(tp, value, tb)\r\n     77         value = tp()\r\n     78     if value.__traceback__ is not tb:\r\n---> 79         raise value.with_traceback(tb)\r\n     80     raise value\r\n     81 \r\n\r\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\r\nInvalid use of Function(<built-in function getitem>) with argument(s) of type(s): (awkward1.NumpyArrayType(array(int64, 1d, C), none, {}), int64)\r\n * parameterized\r\nIn definition 0:\r\n    All templates rejected with literals.\r\nIn definition 1:\r\n    All templates rejected without literals.\r\nIn definition 2:\r\n    All templates rejected with literals.\r\nIn definition 3:\r\n    All templates rejected without literals.\r\nIn definition 4:\r\n    All templates rejected with literals.\r\nIn definition 5:\r\n    All templates rejected without literals.\r\nIn definition 6:\r\n    All templates rejected with literals.\r\nIn definition 7:\r\n    All templates rejected without literals.\r\nIn definition 8:\r\n    All templates rejected with literals.\r\nIn definition 9:\r\n    All templates rejected without literals.\r\nIn definition 10:\r\n    All templates rejected with literals.\r\nIn definition 11:\r\n    All templates rejected without literals.\r\nIn definition 12:\r\n    All templates rejected with literals.\r\nIn definition 13:\r\n    All templates rejected without literals.\r\nIn definition 14:\r\n    All templates rejected with literals.\r\nIn definition 15:\r\n    All templates rejected without literals.\r\nIn definition 16:\r\n    All templates rejected with literals.\r\nIn definition 17:\r\n    All templates rejected without literals.\r\nIn definition 18:\r\n    All templates rejected with literals.\r\nIn definition 19:\r\n    All templates rejected without literals.\r\nIn definition 20:\r\n    All templates rejected with literals.\r\nIn definition 21:\r\n    All templates rejected without literals.\r\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\r\n[1] During: typing of intrinsic-call at <ipython-input-9-09f2be2cb22a> (7)\r\n\r\nFile \"<ipython-input-9-09f2be2cb22a>\", line 7:\r\ndef run(array):\r\n    <source elided>\r\n    for i in range(3):\r\n        out[i] = array[i]\r\n        ^\r\n```\r\n",
  "closed_at":"2020-04-20T15:30:21Z",
  "comments":4,
  "created_at":"2020-04-20T14:55:24Z",
  "id":603302053,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDMzMDIwNTM=",
  "number":221,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Status of Numba support",
  "updated_at":"2020-04-20T15:30:22Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I am trying to count the number of elements in a nested data structure using `awkward1.count` following the [docs](https://awkward-array.readthedocs.io/en/latest/_auto/ak.count.html), I tried to apply different `axis` values to count elements at different levels of nesting.\r\n\r\n```\r\naxis (None or int) \u2013 If None, combine all values from the array into a single scalar result; if an int, group by that axis: 0 is the outermost, 1 is the first level of nested lists, etc., and negative axis counts from the innermost: -1 is the innermost, -2 is the next level up, etc.\r\n```\r\n\r\nHere is how I proceed:\r\n\r\n```python\r\nimport uproot\r\nimport numpy as np\r\nimport awkward1 as ak1\r\n\r\nfit = ak1.Array(uproot.open(my_file)[\"E/Evt/trks/trks.fitinf\"].array())\r\nprint(fit)\r\n>>> [[[0.00496, 0.00342, -295, 142, 99.1, 1.8e+308, 4.24e-12, 10, ... [], [], [], []]]\r\ntype(fit)\r\n>>> awkward1.highlevel.Array\r\n```\r\n1) Counting the outermost level of nesting: `axis=0`\r\n\r\nI tried the following to get the outermost level of nesting:\r\n \r\n```python\r\nak1.count(fit, axis=0)\r\n```\r\nthis raises the following error:\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj)\r\n    700                 type_pprinters=self.type_printers,\r\n    701                 deferred_pprinters=self.deferred_printers)\r\n--> 702             printer.pretty(obj)\r\n    703             printer.flush()\r\n    704             return stream.getvalue()\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/lib/pretty.py in pretty(self, obj)\r\n    392                         if cls is not object \\\r\n    393                                 and callable(cls.__dict__.get('__repr__')):\r\n--> 394                             return _repr_pprint(obj, self, cycle)\r\n    395 \r\n    396             return _default_pprint(obj, self, cycle)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle)\r\n    682     \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\r\n    683     # Find newlines and replace them with p.break_()\r\n--> 684     output = repr(obj)\r\n    685     lines = output.splitlines()\r\n    686     with p.group():\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/highlevel.py in __repr__(self, limit_value, limit_total)\r\n   1134         value = awkward1._util.minimally_touching_string(limit_value,\r\n   1135                                                          self._layout,\r\n-> 1136                                                          self._behavior)\r\n   1137 \r\n   1138         name = getattr(self, \"__name__\", type(self).__name__)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in minimally_touching_string(limit_length, layout, behavior)\r\n    997             leftlen += len(l)\r\n    998 \r\n--> 999         r = next(rightgen)\r\n   1000         if r is not None:\r\n   1001             if (leftlen + rightlen + len(r)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in forever(iterable)\r\n    976 \r\n    977     def forever(iterable):\r\n--> 978         for token in iterable:\r\n    979             yield token\r\n    980         while True:\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in backward(x, space, brackets, wrap)\r\n    938                 sp = \"\"\r\n    939                 for i in range(len(x) - 1, -1, -1):\r\n--> 940                     for token in backward(x[i], sp):\r\n    941                         yield token\r\n    942                     sp = \", \"\r\n\r\nValueError: in ListArray64 attempting to get 27, starts[i] != stops[i] and stops[i] > len(content)\r\n```\r\nIt seems like there is an error with the `repr` of the returned object, I tried the following:\r\n\r\n```python\r\nt = ak1.count(fit, axis=0)\r\nprint(t.shape)\r\n>>> (56,)\r\n``` \r\nSo this did not raise an error, but the shape of `t` can't be 56.\r\n\r\nThe expected result of the outermost nesting level count is 10:\r\n\r\n```python\r\nak1.num(fit, axis=0)\r\n>>> 10\r\n```\r\nsame with \r\n\r\n```python\r\nlen(fit)\r\n>>>10\r\n```\r\n\r\n2) Counting the first level of nesting: `axis=1`\r\n\r\n```python\r\ncounts = ak1.count(fit, axis=1)\r\ncounts\r\n>>> <Array [[20, 20, 20, 20, 20, ... 1, 1, 1, 1]] type='10 * var * int64'>\r\nnp.array(counts)\r\n>>> array([[20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [19, 19, 19, 19, 19, 19, 19, 19,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [18, 18, 18, 18, 18, 18, 18, 18,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20, 20, 20, 20, 20,  2,  2,  2,  1,  1,  1,  1,  1,\r\n         1]])\r\n```\r\nSo I understand from this result that `fit` has 10 elements (the outermost nesting level), in element 0, there are 17 elements (let's call this the first nesting level):\r\n\r\n```python\r\ncounts[0]\r\n>>> <Array [20, 20, 20, 20, 20, ... 1, 1, 1, 1, 1] type='17 * int64'>\r\n```\r\nBut I am not sure if this result actually makes sense? I am not able to interpret these values.\r\n\r\nWhen I check to verify if this counting is correct, I do the following: \r\n\r\n```python\r\nnp.array(ak1.num(fit, axis=1))\r\n>>> array([56, 55, 56, 56, 56, 56, 56, 56, 54, 56])\r\n``` \r\nboth results don't match? am I misundersting something here?\r\n\r\nsame with \r\n\r\n```python\r\n[len(i) for i in fit]\r\n>>> [56, 55, 56, 56, 56, 56, 56, 56, 54, 56]\r\n```\r\n\r\n2) Counting the second level of nesting: `axis=2`\r\n\r\nThis one seems to work fine:\r\n\r\n```python\r\ncounts = ak1.count(fit, axis=2)\r\n>>> <Array [[17, 11, 8, 8, 8, ... 0, 0, 0, 0, 0]] type='10 * var * int64'>\r\ncounts[0]\r\n>>> <Array [17, 11, 8, 8, 8, 8, ... 0, 0, 0, 0, 0] type='56 * int64'>\r\n```\r\nchecking the results with `awkward1.num`\r\n\r\n```python\r\ncounts_with_num = ak1.Array([ak1.num(i, axis=1) for i in fit])\r\ncounts_with_num\r\n>>> <Array [[17, 11, 8, 8, 8, ... 0, 0, 0, 0, 0]] type='10 * var * int64'>\r\ncounts_with_num[0]\r\n>>> <Array [17, 11, 8, 8, 8, 8, ... 0, 0, 0, 0, 0] type='56 * int64'>\r\n```\r\nand with a simple loop\r\n\r\n```python\r\n[len(i) for i in fit[0]]\r\n>>> [17, 11, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n```\r\n\r\nI also tried to apply `awkward1.count`  on one element of my `fit` data using `axis=1` and it worked just fine:\r\n\r\n```python\r\nak1.count(fit[0], axis=1)\r\n>>> <Array [17, 11, 8, 8, 8, 8, ... 0, 0, 0, 0, 0] type='56 * int64'>\r\n```\r\n\r\nI also noticed that the same behaviour is true for `awkward1.count_nonzero`, when `axis=1` is specified: \r\n\r\n```python\r\nnp.array(ak1.count_nonzero(fit, axis=1))\r\n>>> array([[20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [19, 19, 19, 19,  1,  1, 19, 19,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [17, 17, 18, 18,  1,  1, 18, 18,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1],\r\n       [20, 20, 20, 20,  1,  1, 20, 20,  2,  2,  2,  0,  0,  1,  1,  1,\r\n         1]])\r\n```\r\nwhen `axis=2` it works just fine:\r\n\r\n```python\r\ncounts_nonzero = ak1.count_nonzero(fit, axis=2)\r\ncounts_nonzero[0]\r\n>>> <Array [15, 9, 6, 6, 6, 6, ... 0, 0, 0, 0, 0] type='56 * int64'>\r\n```\r\n\r\nwhen `axis=0` an error is raised:\r\n\r\n```python\r\nak1.count_nonzero(fit, axis=0)\r\n>>> ---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj)\r\n    700                 type_pprinters=self.type_printers,\r\n    701                 deferred_pprinters=self.deferred_printers)\r\n--> 702             printer.pretty(obj)\r\n    703             printer.flush()\r\n    704             return stream.getvalue()\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/lib/pretty.py in pretty(self, obj)\r\n    392                         if cls is not object \\\r\n    393                                 and callable(cls.__dict__.get('__repr__')):\r\n--> 394                             return _repr_pprint(obj, self, cycle)\r\n    395 \r\n    396             return _default_pprint(obj, self, cycle)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle)\r\n    682     \"\"\"A pprint that just redirects to the normal repr function.\"\"\"\r\n    683     # Find newlines and replace them with p.break_()\r\n--> 684     output = repr(obj)\r\n    685     lines = output.splitlines()\r\n    686     with p.group():\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/highlevel.py in __repr__(self, limit_value, limit_total)\r\n   1134         value = awkward1._util.minimally_touching_string(limit_value,\r\n   1135                                                          self._layout,\r\n-> 1136                                                          self._behavior)\r\n   1137 \r\n   1138         name = getattr(self, \"__name__\", type(self).__name__)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in minimally_touching_string(limit_length, layout, behavior)\r\n    997             leftlen += len(l)\r\n    998 \r\n--> 999         r = next(rightgen)\r\n   1000         if r is not None:\r\n   1001             if (leftlen + rightlen + len(r)\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in forever(iterable)\r\n    976 \r\n    977     def forever(iterable):\r\n--> 978         for token in iterable:\r\n    979             yield token\r\n    980         while True:\r\n\r\n~/miniconda3/envs/km3pipe/lib/python3.7/site-packages/awkward1/_util.py in backward(x, space, brackets, wrap)\r\n    938                 sp = \"\"\r\n    939                 for i in range(len(x) - 1, -1, -1):\r\n--> 940                     for token in backward(x[i], sp):\r\n    941                         yield token\r\n    942                     sp = \", \"\r\n\r\nValueError: in ListArray64 attempting to get 27, starts[i] > stops[i]\r\n```\r\n\r\nThe file I am reading data from is attached to this git issue.\r\n\r\n[aanet_v2.0.0.root.zip](https://github.com/scikit-hep/awkward-1.0/files/4504532/aanet_v2.0.0.root.zip)\r\n\r\nThank you for your help.\r\n\r\nI ping @tamasgal\r\n",
  "closed_at":"2020-04-20T19:15:10Z",
  "comments":10,
  "created_at":"2020-04-20T16:04:40Z",
  "id":603352189,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDMzNTIxODk=",
  "number":222,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.count with axis=0 is producing invalid arrays",
  "updated_at":"2020-04-21T11:36:01Z",
  "user":"MDQ6VXNlcjQ3MTExMDg3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Odd that I missed this because that would be the most common output for typical data distributions and `axis=0`.\r\n\r\nThis affects all reducers equally.",
  "closed_at":"2020-04-20T19:15:11Z",
  "comments":0,
  "created_at":"2020-04-20T18:55:13Z",
  "draft":false,
  "id":603459037,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA2MjQwMDQ1",
  "number":223,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-20T19:15:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed #222. It failed to initialize starts and stops at the end of its output array, leaving uninitialized junk.",
  "updated_at":"2020-04-20T19:15:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjM5ODc4Njc1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"This PR adds the Arrow to Awkward and vice-versa conversions.",
  "closed_at":"2020-05-13T18:44:11Z",
  "comments":12,
  "created_at":"2020-04-20T21:25:37Z",
  "draft":false,
  "id":603545886,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA2MzExMzMx",
  "number":224,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"toarrow and fromarrow #68",
  "updated_at":"2020-05-13T18:44:12Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I have been trying to use the `index` method, but it seems to always return 0.\r\n\r\nHere is how I proceed:\r\n\r\n```python\r\n\r\nimport awkward1 as ak1\r\n\r\ntest = ak1.Array([[[1, 2, 3], [1, 2, 3], [1]],\r\n                  [[0], [1, 2, 3]],\r\n                  [[0], [1, 2, 3], [0], [1, 2, 3], [1, 2, 3]]])\r\n\r\nprint(test[1].index(ak1.Array([1, 2, 3])))\r\n# 0\r\nprint(test[2].index(ak1.Array([1, 2, 3])))\r\n# 0\r\n```\r\nany ideas why this is happening?\r\n\r\nThank you.\r\n\r\nping @tamasgal",
  "closed_at":"2020-04-21T16:37:27Z",
  "comments":5,
  "created_at":"2020-04-21T15:20:01Z",
  "id":604082832,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MDQwODI4MzI=",
  "number":225,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"index method seems to always return zero when the element used is an awkward1 Array",
  "updated_at":"2020-04-21T16:37:27Z",
  "user":"MDQ6VXNlcjQ3MTExMDg3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"As discussed in #193 , this PR rewrites `is_none()` in C++ and also implements an `axis` parameter. \r\n\r\nI don't want help on this one unless I explicitly ask or do something very wrong. I will be documenting progress here in steps rather making a big PR.\r\n\r\nThe main idea is to internally have two functions \r\n```C++ \r\nisnone(int64_t axis, int64_t depth);\r\nisnone_axis0();\r\n```\r\nAs far as I can tell only `IndexedOptionArray` is capable of storing `None` at it's own level (?). So if `axis = depth` we call `isnone_axis0()` else we return a `NumpyArray` of booleans with the same length as the current array.\r\nMany other functions use `axis` and `depth` to iterate downwards which can serve as a helpful reference (eg. [pad_none](https://awkward-array.readthedocs.io/en/latest/_auto/ak.pad_none.html)). \r\n`IndexedOptionArray` also has a [`bytemask()`](https://awkward-array.readthedocs.io/en/latest/_static/classawkward_1_1IndexedArrayOf.html#a059a33ea0c250d17075bd20ebd6a4d10) function which directly gives us the mask. The mask is of type `Index8` and 1 &rarr; None, 0 &rarr; Not None so it needs flipping after which a `NumpyArray` can be created. \r\n\r\nSub-tasks:\r\n- [ ] Tests\r\n- [x] Documentation\r\n- [x] `IndexedArray`\r\n- [x]  `ListArray`\r\n- [x] `ListOffsetArray`\r\n- [x] `RecordArray`\r\n- [x] `Record`\r\n- [x] `UnionArray`\r\n- [x] Remaining types\r\n",
  "closed_at":"2020-05-15T16:31:23Z",
  "comments":8,
  "created_at":"2020-04-22T12:40:19Z",
  "draft":true,
  "id":604725473,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDA3MjY0MDY5",
  "number":226,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"[WIP] Implement `is_none()` with axis parameter in C++",
  "updated_at":"2020-09-04T20:46:25Z",
  "user":"MDQ6VXNlcjc0NjYzNjQ="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"And also add a link to my EIC talk in the README.",
  "closed_at":"2020-04-30T12:08:43Z",
  "comments":1,
  "created_at":"2020-04-29T11:29:09Z",
  "draft":false,
  "id":608981849,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEwNjUzNTM4",
  "number":227,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-30T12:08:43Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Write CONTRIBUTING.md.",
  "updated_at":"2020-04-30T12:08:46Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-04-30T20:15:17Z",
  "comments":0,
  "created_at":"2020-04-30T12:44:04Z",
  "draft":false,
  "id":609932656,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDExNDQ0MjY5",
  "number":228,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-04-30T20:15:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Prepare the second Coffea demo.",
  "updated_at":"2020-05-04T01:37:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-04T20:04:12Z",
  "comments":1,
  "created_at":"2020-05-02T13:08:12Z",
  "draft":false,
  "id":611185530,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEyNDQ5MjYy",
  "number":229,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-04T20:04:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update to JupyterBook's new Sphinx-based build system.",
  "updated_at":"2020-05-04T20:04:19Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"With\r\n```python\r\nrec = ak.zip(\r\n    {\r\n        \"x\": ak.virtual(lambda: ak.Array([1, 2, 3, 4]), length=4),\r\n    },\r\n    depth_limit=1\r\n)\r\n```\r\n\r\nThe following line segfaults: `rec.x[1:]*2`\r\nPossibly related, `rec.x[1:]` by itself throws an error in the VirtualArray constructor:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/awkward1/highlevel.py\", line 1155, in __repr__\r\n    highlevel=False)\r\n  File \"/usr/local/lib/python3.7/site-packages/awkward1/operations/structure.py\", line 2325, in with_cache\r\n    awkward1.operations.convert.to_layout(array), getfunction)\r\n  File \"/usr/local/lib/python3.7/site-packages/awkward1/_util.py\", line 762, in recursively_apply\r\n    return custom()\r\n  File \"/usr/local/lib/python3.7/site-packages/awkward1/operations/structure.py\", line 2316, in <lambda>\r\n    layout.generator,\r\nValueError: VirtualArray's generator is not a Python function\r\n```",
  "closed_at":"2020-05-04T01:35:33Z",
  "comments":4,
  "created_at":"2020-05-03T17:58:25Z",
  "id":611470056,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MTE0NzAwNTY=",
  "number":230,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Segfault in derived virtual array",
  "updated_at":"2020-05-04T01:35:33Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Because of the typo here: https://github.com/scikit-hep/awkward-1.0/blob/6db9f5996d09e7ee04e7b94100d0cdccfe1c2a07/src/libawkward/Index.cpp#L23\r\nmaking a ListOffsetArray32 form doesn't work:\r\n```\r\n>>> awkward1.forms.ListOffsetForm(\"i32\", awkward1.forms.EmptyForm())\r\n{\r\n    \"class\": \"UnrecognizedListOffsetArray\",\r\n    \"offsets\": \"i8\",\r\n    \"content\": {\r\n        \"class\": \"EmptyArray\"\r\n    }\r\n}\r\n```\r\n\r\nI can make the patch.",
  "closed_at":"2020-05-03T22:03:41Z",
  "comments":0,
  "created_at":"2020-05-03T19:24:54Z",
  "id":611487214,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MTE0ODcyMTQ=",
  "number":231,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"IndexForm roundtrip to json fails for i32/u32",
  "updated_at":"2020-05-03T22:03:41Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Fixes #231",
  "closed_at":"2020-05-03T22:03:41Z",
  "comments":1,
  "created_at":"2020-05-03T19:29:51Z",
  "draft":false,
  "id":611488261,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEyNjUzNDM4",
  "number":232,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-03T22:03:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix bug in IndexForm possible types",
  "updated_at":"2020-05-03T22:03:41Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"",
  "closed_at":"2020-05-15T20:35:36Z",
  "comments":4,
  "created_at":"2020-05-03T22:22:04Z",
  "draft":false,
  "id":611521654,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEyNjc2MjQw",
  "number":233,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-15T20:35:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"libawkward: fix vtable regressions",
  "updated_at":"2020-05-17T18:56:53Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-04T01:35:33Z",
  "comments":0,
  "created_at":"2020-05-03T23:27:01Z",
  "draft":false,
  "id":611532826,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEyNjg0MTcw",
  "number":234,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-04T01:35:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Working on #230 segfault.",
  "updated_at":"2020-05-04T01:35:44Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@nsmith-: just so that you don't write something around Forms to give them this capability (i.e. to fetch objects from an object store with a naming convention), it really ought to be part of the Forms.\r\n\r\nThese keys aren't needed to check that VirtualArrays make sense, but they might be needed for bookkeeping in a system that reconstructs Awkward Arrays from one-dimensional arrays. Only the minimum needed so far has been written, but we can definitely add such a thing so that you don't have to work around them not having it.",
  "closed_at":"2020-07-23T00:00:04Z",
  "comments":7,
  "created_at":"2020-05-04T19:54:13Z",
  "id":612127552,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MTIxMjc1NTI=",
  "number":235,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Forms should have optional keys, so that they can be used to look up data in regular, named containers",
  "updated_at":"2020-07-23T00:00:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-05T19:23:38Z",
  "comments":1,
  "created_at":"2020-05-05T00:55:52Z",
  "draft":false,
  "id":612259643,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEzMjU4NTY3",
  "number":236,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-05T19:23:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Writing tutorials 2.",
  "updated_at":"2020-05-05T19:23:42Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-08T01:00:16Z",
  "comments":1,
  "created_at":"2020-05-05T19:31:12Z",
  "draft":false,
  "id":612842122,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDEzNzEwMjQw",
  "number":237,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T01:00:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Keep writing those tutorials.",
  "updated_at":"2020-05-08T01:00:20Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-08T19:14:58Z",
  "comments":48,
  "created_at":"2020-05-08T12:43:36Z",
  "draft":false,
  "id":614719841,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MjE2Mzg5",
  "number":238,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Try out the allcontributors bot.",
  "updated_at":"2020-05-08T20:28:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @jpivarski as a contributor for bug, code, content, doc, design, example, ideas, infra, maintenance, question, review, test, tutorial, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625801137)",
  "closed_at":"2020-05-08T14:34:12Z",
  "comments":1,
  "created_at":"2020-05-08T12:53:50Z",
  "draft":false,
  "id":614725061,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MjIwNTg5",
  "number":239,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T14:34:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add jpivarski as a contributor",
  "updated_at":"2020-05-08T14:34:17Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @nsmith as a contributor for bug, code, example, ideas, question, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625849204)",
  "closed_at":"2020-05-08T15:07:01Z",
  "comments":0,
  "created_at":"2020-05-08T14:42:43Z",
  "draft":false,
  "id":614786291,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MjY5NzE4",
  "number":240,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T15:07:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add nsmith as a contributor",
  "updated_at":"2020-05-08T15:07:05Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @ianna as a contributor for code, ideas, maintenance, test.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625862588)",
  "closed_at":"2020-05-08T15:47:17Z",
  "comments":2,
  "created_at":"2020-05-08T15:10:26Z",
  "draft":false,
  "id":614803385,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MjgzNDcy",
  "number":241,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T15:47:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add ianna as a contributor",
  "updated_at":"2020-05-08T15:47:40Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @lgray as a contributor for bug, code, ideas, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625881247)",
  "closed_at":"2020-05-08T15:53:05Z",
  "comments":0,
  "created_at":"2020-05-08T15:50:32Z",
  "draft":false,
  "id":614826500,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzAyMTAy",
  "number":242,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T15:53:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add lgray as a contributor",
  "updated_at":"2020-05-08T15:53:08Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @henryiii as a contributor for bug, code, ideas, infra, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625882010)",
  "closed_at":"2020-05-08T15:53:57Z",
  "comments":0,
  "created_at":"2020-05-08T15:52:13Z",
  "draft":false,
  "id":614827454,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzAyODQ5",
  "number":243,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add henryiii as a contributor",
  "updated_at":"2020-05-08T15:54:04Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @henryiii as a contributor for bug, code, ideas, infra, test, talk, example.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625883592)",
  "closed_at":"2020-05-08T17:50:11Z",
  "comments":0,
  "created_at":"2020-05-08T15:55:43Z",
  "draft":false,
  "id":614829564,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzA0NTY1",
  "number":244,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T17:50:11Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add henryiii as a contributor",
  "updated_at":"2020-05-08T17:50:14Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @reikdas as a contributor for code, ideas, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625943411)",
  "closed_at":"2020-05-08T18:04:55Z",
  "comments":0,
  "created_at":"2020-05-08T18:04:32Z",
  "draft":false,
  "id":614895842,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzU4Mjg1",
  "number":245,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:04:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add reikdas as a contributor",
  "updated_at":"2020-05-08T18:04:58Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @trickarcher as a contributor for code, ideas, test.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625944063)",
  "closed_at":"2020-05-08T18:07:08Z",
  "comments":0,
  "created_at":"2020-05-08T18:05:55Z",
  "draft":false,
  "id":614896513,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzU4ODQ2",
  "number":246,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:07:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add trickarcher as a contributor",
  "updated_at":"2020-05-08T18:07:12Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @Ellipse0934 as a contributor for code, ideas, test.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625946082)",
  "closed_at":"2020-05-08T18:11:46Z",
  "comments":0,
  "created_at":"2020-05-08T18:10:43Z",
  "draft":false,
  "id":614898801,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzYwNzQx",
  "number":247,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:11:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add Ellipse0934 as a contributor",
  "updated_at":"2020-05-08T18:11:50Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @veprbl as a contributor for bug, code, infra, test.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625947094)",
  "closed_at":"2020-05-08T18:13:46Z",
  "comments":0,
  "created_at":"2020-05-08T18:13:06Z",
  "draft":false,
  "id":614899931,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzYxNjgz",
  "number":248,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:13:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add veprbl as a contributor",
  "updated_at":"2020-05-08T18:13:49Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @glass-ships as a contributor for code, ideas, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625947876)",
  "closed_at":"2020-05-08T18:15:29Z",
  "comments":0,
  "created_at":"2020-05-08T18:15:10Z",
  "draft":false,
  "id":614900924,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzYyNDk4",
  "number":249,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:15:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add glass-ships as a contributor",
  "updated_at":"2020-05-08T18:15:32Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @EscottC as a contributor for code, ideas, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625949434)",
  "closed_at":"2020-05-08T18:19:23Z",
  "comments":0,
  "created_at":"2020-05-08T18:18:51Z",
  "draft":false,
  "id":614902754,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzYzOTg5",
  "number":250,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:19:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add EscottC as a contributor",
  "updated_at":"2020-05-08T18:19:26Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @masonproffitt as a contributor for bug, code, ideas, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625952186)",
  "closed_at":"2020-05-08T18:25:31Z",
  "comments":0,
  "created_at":"2020-05-08T18:25:12Z",
  "draft":false,
  "id":614905763,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzY2NDg4",
  "number":251,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:25:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add masonproffitt as a contributor",
  "updated_at":"2020-05-08T18:25:34Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @mhedges as a contributor for code, ideas, question, test, talk.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625954020)",
  "closed_at":"2020-05-08T18:30:12Z",
  "comments":0,
  "created_at":"2020-05-08T18:29:37Z",
  "draft":false,
  "id":614907964,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzY4MzAx",
  "number":252,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:30:11Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add mhedges as a contributor",
  "updated_at":"2020-05-08T18:30:15Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @guitargeek as a contributor for code, ideas, test.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625955333)",
  "closed_at":"2020-05-08T18:33:10Z",
  "comments":0,
  "created_at":"2020-05-08T18:32:37Z",
  "draft":false,
  "id":614909447,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzY5NTE5",
  "number":253,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:33:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add guitargeek as a contributor",
  "updated_at":"2020-05-08T18:33:14Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @Jayd-1234 as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625963436)",
  "closed_at":"2020-05-08T18:51:27Z",
  "comments":0,
  "created_at":"2020-05-08T18:50:58Z",
  "draft":false,
  "id":614918398,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1Mzc2OTAz",
  "number":254,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:51:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add Jayd-1234 as a contributor",
  "updated_at":"2020-05-08T18:51:31Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @benkrikler as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625964471)",
  "closed_at":"2020-05-08T18:53:46Z",
  "comments":0,
  "created_at":"2020-05-08T18:53:22Z",
  "draft":false,
  "id":614919588,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1Mzc3ODg1",
  "number":255,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:53:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add benkrikler as a contributor",
  "updated_at":"2020-05-08T18:53:49Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @bfis as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625964984)",
  "closed_at":"2020-05-08T18:54:58Z",
  "comments":0,
  "created_at":"2020-05-08T18:54:34Z",
  "draft":false,
  "id":614920150,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1Mzc4MzMw",
  "number":256,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:54:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add bfis as a contributor",
  "updated_at":"2020-05-08T18:55:01Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @douglasdavis as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625965568)",
  "closed_at":"2020-05-08T18:56:15Z",
  "comments":0,
  "created_at":"2020-05-08T18:55:54Z",
  "draft":false,
  "id":614921003,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1Mzc5MDQ5",
  "number":257,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T18:56:15Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add douglasdavis as a contributor",
  "updated_at":"2020-05-08T18:56:19Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @jpata as a contributor for ideas.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625967094)",
  "closed_at":"2020-05-08T19:06:40Z",
  "comments":0,
  "created_at":"2020-05-08T18:59:25Z",
  "draft":false,
  "id":614923270,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzgxMDI1",
  "number":258,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T19:06:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add jpata as a contributor",
  "updated_at":"2020-05-08T19:06:44Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @martindurant as a contributor for ideas.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-625968099)",
  "closed_at":"2020-05-08T19:02:08Z",
  "comments":1,
  "created_at":"2020-05-08T19:01:46Z",
  "draft":false,
  "id":614924758,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1MzgyMjcz",
  "number":259,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T19:02:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add martindurant as a contributor",
  "updated_at":"2020-05-08T19:03:40Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @gordonwatts as a contributor for ideas.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/238#issuecomment-626005928)",
  "closed_at":"2020-05-08T20:28:26Z",
  "comments":0,
  "created_at":"2020-05-08T20:28:00Z",
  "draft":false,
  "id":614969420,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE1NDE5MjY2",
  "number":260,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-08T20:28:26Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add gordonwatts as a contributor",
  "updated_at":"2020-05-08T20:28:29Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Address issue #204 \r\n\r\nFollowing a discussion with @jpivarski to finish what @Ellipse0934 has started in https://github.com/scikit-hep/awkward-1.0/pull/214\r\n",
  "closed_at":"2020-06-30T19:56:18Z",
  "comments":33,
  "created_at":"2020-05-12T12:00:21Z",
  "draft":false,
  "id":616599581,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE2Njc4OTE3",
  "number":261,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-30T19:56:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"replace carry with indexedarray",
  "updated_at":"2020-07-01T07:17:36Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"I'll leave the explanation to everything I have done in a bit. @reikdas, You'd be particularly interested in this since your parser depends on the structure of the class! And I don't intend to merge this into master! ",
  "closed_at":"2020-05-25T15:13:41Z",
  "comments":10,
  "created_at":"2020-05-13T14:14:36Z",
  "draft":true,
  "id":617485561,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE3MzkyNTY1",
  "number":262,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-25T15:13:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"This is an example PR demonstrating the use of a KernelCore Class. ",
  "updated_at":"2020-06-01T13:20:48Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"99.5% of the work on this PR was done by @trickarcher. I tried using GitHub's \"check out locally\" and followed instructions, but it won't let me commit back to his repo and get it all done under one PR. So I have to close his and open a new PR to put my last touch-ups on it, but most of the work is his.",
  "closed_at":"2020-05-14T02:53:21Z",
  "comments":5,
  "created_at":"2020-05-13T18:41:25Z",
  "draft":false,
  "id":617670000,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE3NTQyNTU3",
  "number":263,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-14T02:53:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Continue from #224: fromarrow and toarrow.",
  "updated_at":"2020-05-14T12:49:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"First, thanks for this awesome package! I'm looking forward to the new ways of analysis that we will be able to do with it.\r\n\r\nI might have found a problem with `ak.any` and `axis=2` which seems to happen in cases when the last element of the array is an empty list:\r\n\r\n```pycon\r\n>>> import awkward1 as ak\r\n>>> a = ak.from_iter([[], [[False, False, True]], [], [[False], [True, False]], []])\r\n>>> ak.any(a, axis=2)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/nikolai/venv/akward/lib/python3.8/site-packages/awkward1/highlevel.py\", line 1108, in __repr__\r\n    value = awkward1._util.minimally_touching_string(limit_value,\r\n  File \"/home/nikolai/venv/akward/lib/python3.8/site-packages/awkward1/_util.py\", line 1166, in minimally_touching_string\r\n    r = next(rightgen)\r\n  File \"/home/nikolai/venv/akward/lib/python3.8/site-packages/awkward1/_util.py\", line 1145, in forever\r\n    for token in iterable:\r\n  File \"/home/nikolai/venv/akward/lib/python3.8/site-packages/awkward1/_util.py\", line 1107, in backward\r\n    for token in backward(x[i], sp):\r\nValueError: in ListOffsetArray64 attempting to get 4, offsets[i] > offsets[i + 1]\r\n>>> ak.any(a[:-1], axis=2)\r\n<Array [[], [True], [], [False, True]] type='4 * var * bool'>\r\n```\r\nwith `a[:-2]` it sometimes also raises the Exception, but sometimes produces an incorrect result:\r\n\r\n```pycon\r\n>>> ak.any(a[:-2], axis=2)\r\n<Array [[], [], [True]] type='3 * var * bool'>\r\n```\r\n\r\nI tried this on the current master (0.2.20)\r\n",
  "closed_at":"2020-05-14T17:43:28Z",
  "comments":4,
  "created_at":"2020-05-14T15:25:17Z",
  "id":618321738,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MTgzMjE3Mzg=",
  "number":264,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Reductions at axis=N inside lists that are empty at axis=N-1 at the end of the N-1 array.",
  "updated_at":"2020-05-14T17:43:28Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The entire fix:\r\n\r\n```diff\r\nindex 1740b74..18c7c68 100644\r\n--- a/src/cpu-kernels/reducers.cpp\r\n+++ b/src/cpu-kernels/reducers.cpp\r\n@@ -2398,7 +2398,6 @@ ERROR awkward_listoffsetarray_reduce_local_outoffsets_64(\r\n   int64_t parentsoffset,\r\n   int64_t lenparents,\r\n   int64_t outlength) {\r\n-  outoffsets[outlength] = lenparents;\r\n   int64_t k = 0;\r\n   int64_t last = -1;\r\n   for (int64_t i = 0;  i < lenparents;  i++) {\r\n@@ -2408,6 +2407,10 @@ ERROR awkward_listoffsetarray_reduce_local_outoffsets_64(\r\n       last++;\r\n     }\r\n   }\r\n+  while (k <= outlength) {\r\n+    outoffsets[k] = lenparents;\r\n+    k++;\r\n+  }\r\n   return success();\r\n }\r\n```\r\n\r\nWe shouldn't just set the last value, but all values past the end of `parents`.",
  "closed_at":"2020-05-14T17:58:55Z",
  "comments":0,
  "created_at":"2020-05-14T17:40:48Z",
  "draft":false,
  "id":618418586,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE4MTUwNTUx",
  "number":265,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-14T17:58:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #264, reductions at axis=N inside empty lists at axis=N-1 at the end of the N-1 array.",
  "updated_at":"2020-05-14T17:58:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The first commit is just black.",
  "closed_at":"2020-05-14T19:47:35Z",
  "comments":0,
  "created_at":"2020-05-14T18:09:15Z",
  "draft":false,
  "id":618435488,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE4MTY0NDM0",
  "number":266,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-14T19:47:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Running black and flake8 on the Python codebase.",
  "updated_at":"2020-05-14T20:16:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This was inspired by #267. I can't write it at the moment, but clearly there needs to be a prominent place for \"which Awkward features work and which don't in Numba.\"",
  "closed_at":"2020-05-15T21:20:36Z",
  "comments":0,
  "created_at":"2020-05-15T12:57:05Z",
  "draft":false,
  "id":618948379,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE4NTc3MjM5",
  "number":268,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-15T21:20:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add stubs for Numba documentation.",
  "updated_at":"2020-05-15T21:20:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"@jpivarski \r\n@trickarcher although this may not be directly relevant to your infrastructure code, you might be interested in taking a look :) ",
  "closed_at":"2020-06-12T11:27:56Z",
  "comments":8,
  "created_at":"2020-05-15T19:02:47Z",
  "draft":false,
  "id":619178917,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE4NzU0NTg0",
  "number":269,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-12T11:27:55Z"
  },
  "reactions":{
   "rocket":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Generate Python code for CPU kernels",
  "updated_at":"2020-06-12T11:28:08Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"If all goes well, this should become permanent when Numba 0.50 is released.\r\n\r\n(Also, Numba 0.50 would become the minimally acceptable version for Awkward.)",
  "closed_at":"2020-06-12T12:51:30Z",
  "comments":1,
  "created_at":"2020-05-18T12:24:28Z",
  "draft":false,
  "id":620166566,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE5NDY2ODA5",
  "number":270,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-12T12:51:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update the minimum Numba version to 0.50 when that becomes available.",
  "updated_at":"2020-06-12T12:51:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"ID is always a primitive type. \r\nMakes it easier to generate code that can be parsed by pycparser.\r\n\r\nSince this commit _might_ have implications outside of #269 I decided to open it as a separate PR. ",
  "closed_at":"2020-05-18T14:30:41Z",
  "comments":3,
  "created_at":"2020-05-18T13:48:53Z",
  "draft":false,
  "id":620225809,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE5NTE1MDQ2",
  "number":271,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-18T14:30:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add brackets around ID cast",
  "updated_at":"2020-05-18T14:30:44Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Can the following parameters used to declare `ArrayGenerator` be exposed to python: `callable`, `args`, `kwargs`?\r\nAlready `form` and `length` are available.",
  "closed_at":"2020-05-19T14:34:00Z",
  "comments":2,
  "created_at":"2020-05-18T14:43:39Z",
  "id":620267681,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MjAyNjc2ODE=",
  "number":272,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ArrayGenerator parameters",
  "updated_at":"2020-05-19T14:34:00Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I got quite confused when i (wrongly) assumed that i can assign fields to arrays\r\n\r\n```pycon\r\n>>> import numpy as np\r\n>>> offsets = np.random.randint(0, 10, size=5)\r\n>>> x = ak.zip({k : [np.random(off) for off in offsets] for k in [\"a\", \"b\"]})\r\n>>> d = 2 * x.a\r\n>>> x.d = d # wrongly assumed this is equivalent to x[\"d\"] = d\r\n>>> x = x[x.a > 0.9] # ups, now x.d is gone\r\n```\r\n\r\nWould it make sense/be possible to implement `__setattr__` to do the same thing as  `__setitem__`? Or if that introduces other problems, warn users they should not do that?\r\n",
  "closed_at":"2020-06-05T12:58:21Z",
  "comments":5,
  "created_at":"2020-05-18T15:44:28Z",
  "id":620313081,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MjAzMTMwODE=",
  "number":273,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add a \"path\" to ak.with_field and array[\"outer\", \"inner\", \"new_field\"] = new_field syntax to ak.Array/Record.",
  "updated_at":"2020-06-05T12:58:21Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is for #272.",
  "closed_at":"2020-05-19T14:34:00Z",
  "comments":5,
  "created_at":"2020-05-18T16:12:01Z",
  "draft":false,
  "id":620335007,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDE5NjAyNDc2",
  "number":274,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-19T14:34:00Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Broaden access to ArrayGenerator attributes in Python",
  "updated_at":"2020-05-19T14:34:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"@jpivarski, since you labelled my feature request #273 as \"good first issue\" i'm taking this as a broad hint to give it a try. I made `ak.with_field` also take `where` as a list or tuple, which is then interpreted as a path to where to add the new field. Does this make sense? Or should it better be a separate argument?\r\nBesides that it is now implemented by recursively calling `ak.with_field`. This might create lots of intermediate copies if the structure is rather deep. If there is a reasonable way to avoid that this would of course be better.\r\n\r\nWhile trying to test this i noticed i can only add fields to deeper levels if the top level already has at least 2 fields:\r\n\r\nThis works:\r\n```pycon\r\n>>> import awkward1 as ak\r\n>>> base = ak.zip({\"a\" : ak.zip({\"x\" : [1, 2, 3]}), \"b\" : [1, 2, 3]}, depth_limit=1)\r\n>>> ak.with_field(base, ak.with_field(base.a, [1.1, 2.2, 3.3], \"y\"), \"a\")\r\n<Array [{b: 1, a: {x: 1, ... y: 3.3}}] type='3 * {\"b\": int64, \"a\": {\"x\": int64, ...'>\r\n```\r\n\r\nThis doesn't:\r\n```pycon\r\n>>> base = ak.zip({\"a\" : ak.zip({\"x\" : [1, 2, 3]})}, depth_limit=1)\r\n>>> ak.with_field(base, ak.with_field(base.a, [1.1, 2.2, 3.3], \"y\"), \"a\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/nikolai/python/awkward-1.0/awkward1/operations/structure.py\", line 477, in with_field\r\n    out = awkward1._util.broadcast_and_apply([base, what], getfunction, behavior)\r\n  File \"/home/nikolai/python/awkward-1.0/awkward1/_util.py\", line 820, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/nikolai/python/awkward-1.0/awkward1/_util.py\", line 481, in apply\r\n    checklength([x for x in inputs if isinstance(x, awkward1.layout.Content)])\r\n  File \"/home/nikolai/python/awkward-1.0/awkward1/_util.py\", line 447, in checklength\r\n    raise ValueError(\r\nValueError: cannot broadcast RegularArray of length 0 with RegularArray of length 1\r\n```\r\n\r\nWhy is that?",
  "closed_at":"2020-05-26T15:04:05Z",
  "comments":9,
  "created_at":"2020-05-22T10:28:06Z",
  "draft":false,
  "id":623112712,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDIxODQyMzE5",
  "number":275,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-26T15:04:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implements #273, option to pass path to ak.with_field",
  "updated_at":"2020-06-03T15:42:29Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"The `awkward_cuda*` functions are just a passthrough, for now. The kernel namespace centralizes dispatch between `awkward_*`(soon to be renamed to `awkward_cpu_*`) and `awkward_cuda_*` .",
  "closed_at":"2020-05-25T15:13:39Z",
  "comments":0,
  "created_at":"2020-05-23T06:50:42Z",
  "draft":false,
  "id":623596456,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDIyMjMyNzg1",
  "number":276,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-25T15:13:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add a base for incremental CUDA kernels development.",
  "updated_at":"2020-05-25T15:13:43Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Linking to the libawkward dynamic library was failing on macOS at my previous attempt in #210. This PR should get shared libawkward to a working state.",
  "closed_at":"2020-05-25T17:06:52Z",
  "comments":4,
  "created_at":"2020-05-24T23:52:54Z",
  "draft":false,
  "id":623972726,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDIyNDg4NjUx",
  "number":277,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-25T17:06:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Link python extension to the shared libawkward",
  "updated_at":"2020-05-27T17:39:42Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Right now, @reikdas and @trickarcher are working on CUDA kernels for Awkward, which involves building a new target, libawkward-cuda-kernels.so (\"gpu-kernels\" in the diagram below), and if-else logic in libawkward.so (\"C++ classes\" in the diagram below) to pick the right kernel for pointers that reside on the GPU.\r\n\r\n<center><img src=\"https://github.com/scikit-hep/awkward-1.0/raw/master/docs-img/diagrams/awkward-1-0-layers.png\" width=\"500\"></center>\r\n\r\n(We went with the name \"cuda-kernels\" to allow for alternative implementations that can coexist with CUDA. Hopefully, we'll be able to move to a non-vendor-specific GPU implementation in the future.)\r\n\r\nI think it's okay to say that we won't be building wheels on PyPI that support GPUs, but I'd like to make the GPU-enabled version a conda option. Thus, it at least needs to be _compilable_ for the GPU with pip.\r\n\r\nSo far, the only way I've managed to do that is through an environment variable. (I struggled with pip's `--global-option`, `--build-option`, and `--install-option` all morning.) That's disappointing, but it could be good enough for a system administrator who is custom-compiling the library for a machine known to have GPUs. Is is also good enough for setting up the conda build?\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/2f09ecad3218e78d7cdb8f64e3002d0c0220fec7/setup.py#L30-L31\r\n\r\nAny thoughts, opinions, or suggestions, @chrisburr @henryiii @veprbl?",
  "closed_at":"2020-07-17T13:29:28Z",
  "comments":4,
  "created_at":"2020-05-25T15:35:09Z",
  "id":624369144,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MjQzNjkxNDQ=",
  "number":278,
  "performed_via_github_app":null,
  "reactions":{
   "eyes":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"What's the best way to make CUDA-enabled Awkward available?",
  "updated_at":"2020-07-17T13:29:28Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"As soon as this passes, merge it!",
  "closed_at":"2020-05-27T16:09:14Z",
  "comments":0,
  "created_at":"2020-05-27T15:05:08Z",
  "draft":false,
  "id":625777263,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDIzOTE3MjA5",
  "number":279,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-27T16:09:14Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix ArrayBuilder's access to type in __repr__.",
  "updated_at":"2020-05-27T16:09:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"As soon as it passes tests, merge it.",
  "closed_at":"2020-05-27T20:34:02Z",
  "comments":0,
  "created_at":"2020-05-27T20:04:41Z",
  "draft":false,
  "id":625993835,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI0MDg2NjQ3",
  "number":280,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-27T20:34:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix ak.pandas.dfs function for simple rows.",
  "updated_at":"2020-05-27T20:34:06Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-05-29T00:33:16Z",
  "comments":2,
  "created_at":"2020-05-29T00:16:12Z",
  "draft":false,
  "id":626912422,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI0ODE3NzQ5",
  "number":281,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-05-29T00:33:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Revert to static linking libawkward.so because it broke the wheel-deployment.",
  "updated_at":"2020-05-29T19:41:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-06-01T11:13:23Z",
  "comments":0,
  "created_at":"2020-05-31T11:34:15Z",
  "draft":false,
  "id":627945025,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI1NTk4NjM0",
  "number":282,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-01T11:13:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove redundant includes from cpu-kernels",
  "updated_at":"2020-06-01T11:13:27Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Paves the way for easier translation to CUDA in the future",
  "closed_at":"2020-06-01T12:39:09Z",
  "comments":0,
  "created_at":"2020-05-31T19:00:07Z",
  "draft":false,
  "id":628022737,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI1NjU0ODQ0",
  "number":283,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-01T12:39:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Replace std::vector with C style code",
  "updated_at":"2020-06-01T12:39:12Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Following #263, it's now possible to pull big data into awkward of a form that outsiders from the project will appreciate and allow, for instance, parquet and orc reading (this may already exist). This raises the interesting question of how people in the wider community (i.e., non-root) might interact with awkward for nested dataset processing, especially where that data is big enough to need parallel and/or out-of-core processing with dask. This is different from the original question me and @jpivarski talked about, how to make use of Dask within awkward.\r\n\r\nFirstly, in my opinion, an awkward array is best seen as a one-dimensional array of things, where those things have structure (whether variable-length components, structs or maps), and so maps best into existing python-land as a pandas series or column. I understand that much of the current coding style is numpy-like, and it may seem that of the dask collections, it most resembles the dask-array codebase. However, usage, to my mind, will be along the lines of\r\n\r\n```python\r\ndf = ak.read_parquet(awkward_columns=[...])  # other columns are simple pandas types; or we expose columns for extraction\r\ndf[filter_multi_column]\r\ndf.col1.map(numba_func)\r\ndf.col1.agg(numba_iterating_func)\r\n```\r\nwhere the `map` could be written `df.map_partitions(lambda d: d.map(numba_func)` but the aggregation required the same combination logic as any dataframe combinations currently do. The filter step would require the ability to iterate over the awkward array(s) as well as ordinary pandas series, together.\r\n\r\nA few notes:\r\n- the pandas codebase and indeed the dask.dataframe one respects the numpy protocol, so that (g)ufuncs are sensibly dealt with, and f(akarray)->akarray should work fine\r\n- wrapping awkwards arrays, or indeed seeing the whole arrow structure as a top-level record in awkward, is a very light-weight process\r\n- to enable the conversion to dask.dataframe, you would need simply to run arrow->awkward extension array on each piece, and not have to worry about chunks in awkward at all\r\n- conversely, if you happen to be starting with a chunked akarray (from root?), then one chunk becomes one partition, and, again, none of the partitions themselves are chunked; the only information you would currently loose is the row-count of each piece\r\n- caching of virtual arrays would not be handled in the first instance, but it would not be hard to do something sensible at the dask worker level; the scheduler will tend to keep tasks where an array piece was previously loaded into memory and round-robin pieces that have no dependencies on each other\r\n\r\n--\r\n\r\nIn addition, to kick off this conversation of awkward integration, I was confused in trying to build examples, so I have a couple of gists to share:\r\n- https://gist.github.com/martindurant/6a95e20bce620471462062083d1ac1ff#file-time1-py shows that although `len` mapped on a awkward pandas series is a few times faster than when mapped on a list-of-lists series; but only as fast as a python comprehension on the original lists, and *much* slower than it should be with numpy\r\n- https://gist.github.com/martindurant/6a95e20bce620471462062083d1ac1ff#file-ak-ipynb I couldn't actually get complex numba-jit functions to run, perhaps due to confusion over map and struc-like things when converting from python/json. I would have thought you could process maps too by iterating on the keys or key/value tuples.",
  "closed_at":"2020-10-30T22:07:43Z",
  "comments":4,
  "created_at":"2020-06-01T17:51:53Z",
  "id":628618533,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2Mjg2MTg1MzM=",
  "number":284,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Dasky thoughts for awkward",
  "updated_at":"2020-11-24T14:49:03Z",
  "user":"MDQ6VXNlcjYwNDIyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-06-02T11:25:52Z",
  "comments":1,
  "created_at":"2020-06-02T11:25:00Z",
  "draft":true,
  "id":629124498,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI2NTIyMjgx",
  "number":285,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fill out the array-fetching interface.",
  "updated_at":"2020-08-03T22:29:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"It seems something is going wrong when letting `ak.with_field` broadcast a single value (like `True`). When i create yet another field, there are circumstances where this breaks the previously added field:\r\n\r\n```pycon\r\n>>> import awkward1 as ak\r\n>>> a = ak.Array([[{\"x\" : 0.1, \"y\" : 0.2, \"z\" : 0.3}, {\"x\" : 0.4, \"y\" : 0.5, \"z\" : 0.6}]])\r\n>>> a[\"always_true\"] = True\r\n>>> ak.to_list(a)\r\n[[{'x': 0.1, 'y': 0.2, 'z': 0.3, 'always_true': True}, {'x': 0.4, 'y': 0.5, 'z': 0.6, 'always_true': True}]]\r\n>>> a[\"sometimes_true\"] = a.x > 0.3 # this breaks the \"always_true\" field\r\n>>> ak.to_list(a)\r\n[[{'x': 0.1, 'y': 0.2, 'z': 0.3, 'always_true': False, 'sometimes_true': False}, {'x': 0.4, 'y': 0.5, 'z': 0.6, 'always_true': False, 'sometimes_true': True}]]\r\n```\r\n\r\nIt seems to only happen in cases where the value is broadcasted by creating that stride 0 memory view @jpivarski explained in https://github.com/scikit-hep/awkward-1.0/pull/275#pullrequestreview-417815324:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/7e1001b6ee59f1cba96cf57d144e7f2719f07e69/src/awkward1/operations/structure.py#L477-L481\r\n\r\n\r\n",
  "closed_at":"2020-06-03T16:50:45Z",
  "comments":3,
  "created_at":"2020-06-03T14:40:00Z",
  "id":630054215,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MzAwNTQyMTU=",
  "number":286,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Unexpected behaviour when broadcasting single value in ak.with_field",
  "updated_at":"2020-06-03T16:50:45Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @nikoladze as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/275#issuecomment-638280639)",
  "closed_at":"2020-06-03T16:13:49Z",
  "comments":0,
  "created_at":"2020-06-03T15:42:26Z",
  "draft":false,
  "id":630106626,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI3MjkwMjM3",
  "number":287,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-03T16:13:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add nikoladze as a contributor",
  "updated_at":"2020-06-03T16:13:53Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"As discussed, here the fix for #286 by replacing the stride 0 view by `numpy.repeat`",
  "closed_at":"2020-06-03T16:50:45Z",
  "comments":1,
  "created_at":"2020-06-03T16:07:22Z",
  "draft":false,
  "id":630129207,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI3MzA4NzQy",
  "number":288,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-03T16:50:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fixes #286 broadcast single value with field",
  "updated_at":"2020-06-03T16:50:45Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-06-06T02:27:02Z",
  "comments":0,
  "created_at":"2020-06-05T15:30:46Z",
  "draft":false,
  "id":631692658,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDI4NTMxNzE0",
  "number":290,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-06T02:27:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Bug-fixes for HATS.",
  "updated_at":"2020-06-06T02:27:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This fails for `events` as an ak.Array:\r\n\r\n```python\r\n@nb.njit\r\ndef f(events):\r\n    for index, event in enumerate(events):\r\n        pass\r\n```\r\n\r\nbut it doesn't fail for NumPy arrays. That's because Numba's lowered enumerate doesn't accept any iterable (or ak.Arrays aren't recognized as such because I haven't registered them somewhere? They do have `iter` overloaded). Presumably, the right way to fix this is to specialize an implementation for `enumerate`, just as an implementation for `len` has been specialized.\r\n\r\nFor completeness, the error message is\r\n\r\n```\r\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\r\nInvalid use of Function(<class 'enumerate'>) with argument(s) of type(s): (awkward1.ArrayView(awkward1.RecordArrayType((awkward1.NumpyArrayType(array(int32, 1d, A), none, {}), awkward1.NumpyArrayType(array(uint32, 1d, A), none, {}), awkward1.NumpyArrayType(array(uint64, 1d, A), none, {}), awkward1.RecordArrayType((awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {})), (('x', 'y', 'z')), none, {}), awkward1.ListArrayType(array(int64, 1d, C), awkward1.RecordArrayType((awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(int32, 1d, A), none, {}), awkward1.NumpyArrayType(array(float32, 1d, A), none, {}), awkward1.NumpyArrayType(array(bool, 1d, A), none, {})), (('pt', 'eta', 'phi', 'mass', 'charge', 'pfRelIso04_all', 'tightId')), none, {}), none, {})), (('run', 'luminosityBlock', 'event', 'PV', 'muons')), none, {}), None, ()))\r\n * parameterized\r\nIn definition 0:\r\n    All templates rejected with literals.\r\nIn definition 1:\r\n    All templates rejected without literals.\r\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\r\n[1] During: resolving callee type: Function(<class 'enumerate'>)\r\n[2] During: typing of call at <ipython-input-158-85980f709330> (3)\r\n```\r\n\r\nbut the key thing is that the `enumerate` function doesn't recognize `ArrayView` as an argument. (`ArrayView` is qualified by a complex content type in this case.)\r\n\r\nI'm labeling this as a \"good first issue\" because it's a straightforward, self-contained project within Awkward-Numba lowering. However, lowering Numba function is itself not for the faint of heart\u2014to clarify, it's a good first issue for developers with background in or interest in learning Numba internals.\r\n",
  "closed_at":"2020-08-18T23:11:05Z",
  "comments":0,
  "created_at":"2020-06-05T21:07:08Z",
  "id":631960353,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MzE5NjAzNTM=",
  "number":291,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Awkward-Numba's ArrayView needs to support enumerate",
  "updated_at":"2020-08-18T23:11:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-06-10T13:29:24Z",
  "comments":2,
  "created_at":"2020-06-10T08:32:47Z",
  "draft":false,
  "id":636047725,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMyMjkzMzc0",
  "number":292,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-10T13:29:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix some typos in cpu-kernels",
  "updated_at":"2020-06-10T13:29:27Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"This PR separates `libawkward` from `libawkward-cuda-kernels`. The `cuda-kernels` are now loaded dynamically using `dlopen`. Memory trackers in the form of `enum` has been implemented and the corresponding code has been refactored to accommodate the changes. \r\n@jpivarski and @reikdas can you please help me with reviewing this PR?",
  "closed_at":"2020-07-09T14:57:36Z",
  "comments":8,
  "created_at":"2020-06-10T16:43:18Z",
  "draft":false,
  "id":636397739,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMyNTc3NTU5",
  "number":293,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T14:57:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Separation of cuda-kernels and memory_trackers implementation",
  "updated_at":"2020-07-09T14:57:40Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"`starts[parent]` should be `starts[startsoffset + parent]`",
  "closed_at":"2020-06-11T20:07:33Z",
  "comments":0,
  "created_at":"2020-06-11T19:17:57Z",
  "draft":false,
  "id":637259315,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzMjgxMTQ5",
  "number":294,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-11T20:07:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix some typos in cpu-kernels",
  "updated_at":"2020-06-11T20:07:36Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"With instructions to generate project documentation locally",
  "closed_at":"2020-06-15T11:29:51Z",
  "comments":5,
  "created_at":"2020-06-12T06:42:19Z",
  "draft":false,
  "id":637523536,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzNDk1NTQ3",
  "number":295,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-15T11:29:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update contributing.md",
  "updated_at":"2020-06-18T11:59:38Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-06-12T12:34:16Z",
  "comments":3,
  "created_at":"2020-06-12T12:07:09Z",
  "draft":false,
  "id":637703939,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzNjQxOTAx",
  "number":296,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-12T12:34:16Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Do not allow dynamic sized arrays in cpu-kernels",
  "updated_at":"2020-06-12T12:34:19Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Minimum Numba version is now 0.50",
  "closed_at":"2020-06-12T13:58:20Z",
  "comments":1,
  "created_at":"2020-06-12T13:33:49Z",
  "draft":false,
  "id":637753952,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzNjgyNTM0",
  "number":297,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update requirements-dev.txt",
  "updated_at":"2020-06-12T13:58:24Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I put a link to the kernels documentation at the bottom of the main Sphinx page:\r\n\r\n![Screenshot from 2020-06-12 10-08-01](https://user-images.githubusercontent.com/1852447/84517285-b3ce4b00-ac94-11ea-9c6f-c25c8e3c48d7.png)\r\n\r\nand gave it some header text to explain what it's all about.\r\n\r\n![Screenshot from 2020-06-12 10-08-22](https://user-images.githubusercontent.com/1852447/84517324-c2b4fd80-ac94-11ea-9483-eab404a9b49e.png)\r\n\r\nI also fixed that \"layers\" diagram to use the new name, \"CUDA kernels,\" rather than \"GPU kernels.\" That will eventually appear everywhere because this image is used in everything (but it might need to propagate out).",
  "closed_at":"2020-06-12T15:56:42Z",
  "comments":1,
  "created_at":"2020-06-12T15:10:37Z",
  "draft":false,
  "id":637821091,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzNzM3Njkx",
  "number":298,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-12T15:56:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Touch up the kernels documentation.",
  "updated_at":"2020-06-12T15:56:45Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"All the template functions have been moved to `kernel` namespace. The calling sites have been updated too, although I am relying on the default arguments for `KernelLib`. I have added the `ptr_lib` as a default argument for now, I can add the `ptr_lib` at the calling sites too, but I think it wouldn't be as automated as refactoring this PR was. Also, in this case none of the `IndexOf`, `IdentitiesOf`, `RawArray` and `NumpyArray` are aware of `KernelsLib`. Should I add them and update the calling site?",
  "closed_at":"2020-06-17T17:45:08Z",
  "comments":9,
  "created_at":"2020-06-13T05:23:17Z",
  "draft":false,
  "id":638099534,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDMzOTYxMzk1",
  "number":299,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-17T17:45:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"This PR moves all the template kernels from utils to kernels ",
  "updated_at":"2020-06-17T17:45:11Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"For automating Kernel test cases, we need a way to distinguish between kernel function parameters that shouldn't change (input) and the function parameters that should change (output) - in the tests we should only be testing the parameters that should change.\r\n\r\nWe can do this by either\r\n1) formalizing a naming scheme for all the kernel function parameters (something like prepending input parameters with `in_` and output parameters with `out_`)\r\n2) Using the [restrict](https://en.wikipedia.org/wiki/Restrict) keyword for output parameters. This would both solve the purpose of labelling the parameters as well as provide potential optimization.",
  "closed_at":"2020-08-03T22:27:47Z",
  "comments":0,
  "created_at":"2020-06-14T07:31:16Z",
  "id":638301282,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MzgzMDEyODI=",
  "number":300,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Kernels - Label to distinguish input and output parameters",
  "updated_at":"2020-08-03T22:27:47Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"To generate appropriate test cases for the different kernels, we need to assign \"roles\" to the kernel function input parameters - keywords that would be recognized by the automatic test case generator.\r\n\r\nWe would need to document the roles in Doxygen style comment blocks in the kernel functions.",
  "closed_at":"2020-08-03T22:27:47Z",
  "comments":0,
  "created_at":"2020-06-14T07:52:03Z",
  "id":638303781,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MzgzMDM3ODE=",
  "number":301,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Kernels - Recognize input parameter roles",
  "updated_at":"2020-08-03T22:27:47Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Once #301 is merged, we need to modify [genpython.py](https://github.com/scikit-hep/awkward-1.0/blob/master/dev/genpython.py) to be able to convert the doxygen style comment block in the CPU kernels written in C++ to Python docstrings in the generated Python code.",
  "closed_at":"2020-08-03T22:27:47Z",
  "comments":0,
  "created_at":"2020-06-14T07:57:03Z",
  "id":638304345,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2MzgzMDQzNDU=",
  "number":302,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"genpython - C++ comment block to Python docstring",
  "updated_at":"2020-08-03T22:27:48Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Prompted by [this stackoverflow question](https://stackoverflow.com/questions/62410128/how-should-i-process-nested-data-structures-e-g-json-xml-parquet-with-dask), to which my internal answer was \"that's what awkward is for\". Is there yet an example of how you might do the circuit of parquet file with complicated schema, to numba-jit function and fast processing.",
  "closed_at":"2020-07-17T01:54:01Z",
  "comments":16,
  "created_at":"2020-06-16T16:05:23Z",
  "id":639792611,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2Mzk3OTI2MTE=",
  "number":303,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Does awkward want to promote itself yet as a general nested processor?",
  "updated_at":"2020-07-17T01:54:01Z",
  "user":"MDQ6VXNlcjYwNDIyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It should NEP 18 to [np.sort](https://numpy.org/doc/1.18/reference/generated/numpy.sort.html). There's no equivalent for our `ascending` or their `order`, though `kind` can be partially supported because `kind=\"stable\"` corresponds to our `stable=True`. (Is our `stable=False` one of \"quicksort\", \"mergesort\", \"heapsort\"?)\r\n\r\nI meant to include this in #168, but forgot.",
  "closed_at":"2020-07-16T17:32:13Z",
  "comments":1,
  "created_at":"2020-06-16T16:33:47Z",
  "id":639814004,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2Mzk4MTQwMDQ=",
  "number":304,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Remember to add a high-level interface to sorting (ak.sort)",
  "updated_at":"2020-07-16T17:32:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The `repr` is implemented in `awkward1._util.minimally_touching_string`; tokens corresponding to keys (that which precedes `\": \"`) should be wrapped in `repr` if they are not good identifiers. This will need to be done in both the forward and backward walks.\r\n\r\nA good identifier is a string that matches `[A-Za-z_][A-Za-z_0-9]*`. In other words, a key that could be used with the dot notation (`__getattr__`), rather than having to resort to a string-field slice (in `__getitem__`).\r\n\r\nIt's unclear how many tests will fail after that. A few tests assert that the array `repr` has a certain value; these will now have internal single-quotes that weren't there before, and some may have a different number of tokens because fewer fit into the allowed width. The correct procedure is to (1) verify that the new output looks right and (b) change the failing tests so that they agree with the new `repr` output.",
  "closed_at":"2020-07-17T16:30:31Z",
  "comments":0,
  "created_at":"2020-06-17T10:50:48Z",
  "id":640343637,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDAzNDM2Mzc=",
  "number":305,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"The ak.Array/ak.Record/ak.ArrayBuilder repr should quote keys that are not good identifiers",
  "updated_at":"2020-07-17T16:30:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-06-19T16:03:57Z",
  "comments":3,
  "created_at":"2020-06-18T11:42:00Z",
  "draft":false,
  "id":641139081,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDM2NDE2MTI0",
  "number":306,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-06-19T16:03:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Document interfaces of functions in sorting.cpp",
  "updated_at":"2020-06-19T16:04:01Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Fixes #300 \r\nFixes #301\r\nFixes #302\r\n\r\nThis is what the result looks like - \r\n![image](https://user-images.githubusercontent.com/11775615/85202299-0c4fb900-b323-11ea-8501-3e3790ef1335.png)\r\n\r\n@jpivarski Is this how we want it? I don't know if we should be enforcing a particular labelling method via `//` in the .cpp files (I updated CONTRIBUTING.md to reflect this) - but I don't see a way around it.\r\n\r\n(I'll create a different PR for the input parameter roles - they will be documented as Doxygen's `@param`)",
  "closed_at":"2020-08-03T22:27:48Z",
  "comments":29,
  "created_at":"2020-06-20T12:56:36Z",
  "draft":false,
  "id":642371352,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDM3NDA5MjM1",
  "number":307,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-03T22:27:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Create specification and generate tests for kernels based on hand written labels",
  "updated_at":"2020-08-03T22:27:53Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"To automatically generate CUDA kernels from CPU kernels, we would need to categorize them as embarrassingly parallel, having loop carried dependencies, etc.\r\n\r\nWe could label all of the C++ functions by hand, similar to what we are doing for test generation in #307 . \r\nBut, it would be better if we could build a custom tool that could perform loop dependence analysis on the C++ functions. Loop dependence analysis is a non-trivial problem, but since the C++ functions in our case follow a regular pattern and we would be okay with some false negatives, this might be possible here.",
  "closed_at":"2020-10-30T22:10:34Z",
  "comments":2,
  "created_at":"2020-06-21T05:17:45Z",
  "id":642497517,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDI0OTc1MTc=",
  "number":308,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Categorize Kernels by parallelizability ",
  "updated_at":"2020-10-30T22:10:34Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Using the roles assigned to the CPU kernels in #301 we need to generate \"relevant\"  tests for each of the kernels. All the kernel implementations - C++, Python, CUDA would need to pass these tests. ",
  "closed_at":"2020-08-06T17:49:39Z",
  "comments":2,
  "created_at":"2020-06-21T05:27:59Z",
  "id":642498736,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDI0OTg3MzY=",
  "number":309,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Generate unit tests for kernels",
  "updated_at":"2020-08-06T17:49:39Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The `keeplayout` parameter of [ak.from_awkward0](https://awkward-array.readthedocs.io/en/latest/_auto/ak.from_awkward0.html) and [ak.to_awkward0](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_awkward0.html) should be `keep_layout`, in keeping with the convention of putting underscores between whole words.\r\n\r\nThis is super-easy, just renaming a parameter on the Python side.",
  "closed_at":"2020-07-16T15:29:12Z",
  "comments":0,
  "created_at":"2020-06-22T16:44:09Z",
  "id":643218379,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDMyMTgzNzk=",
  "number":310,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Rename keeplayout \u2192 keep_layout in ak.{from,to}_awkward0",
  "updated_at":"2020-07-16T15:29:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Before https://github.com/scikit-hep/awkward-1.0/issues/303#issuecomment-647765943, @martindurant said,\r\n\r\n> Interesting case, I wonder if you can tell me the difference between\r\n> \r\n> ```\r\n> bikeroutes = ak.from_json(\"Bikeroutes.geojson\")\r\n> ```\r\n> \r\n> and\r\n> \r\n> ```\r\n> bikeroutes_json = open(\"Bikeroutes.geojson\").read()\r\n> bikeroutes_pyobj = json.loads(bikeroutes_json)\r\n> bikeroutes2 = ak.Record(bikeroutes_pyobj)\r\n> ```\r\n> \r\n> The former has some outer objects, but `bikeroutes[0][0]` appears identical to `bikeroutes2`; however, when used with the `compute_lengths` function, the former takes 1.95ms versus 170us (on my machine). Obviously, I would prefer the simpler-looking syntax.\r\n\r\nI think they ought to be the same, but I didn't manage to fix the issue with `ak.from_json` before I needed to make this demo. In `ak.from_json`, I simply forgot to consider the case in which the JSON is a single JSON object, rather than a JSON array.\r\n\r\nInternally, `ak.from_json` calls a C++ `Content::fromjson` method, which uses RapidJSON in SAX mode to fill an ArrayBuilder. Not going through the Python objects would be a time-saver (and probably memory, too).\r\n\r\nThe `ak.Record` constructor would call `ak.from_json` if the argument had been a string. Since it's a Python object, it uses pybind11 to walk over the Python objects, feeding an ArrayBuilder.\r\n\r\nArrayBuilder assumes that what it's getting is some kind of array (not a single record). In other words, for arrays, you don't have to start with `begin_list` and end with `end_list`, just adding objects fills it with the assumption that they are array elements. This also means there's one fewer error condition to consider: adding a second object is not an error, but it would be if ArrayBuilder didn't assume that what it's getting is an array. Also, ArrayBuilder is user-visible, and forgetting to call `begin_list` and `end_list` outside of the main loop would be a common error, if it had been required.\r\n\r\nThus, if the data are in one big record, that's the special case that has to be handled: first by recognizing that the wrapping structure is a record, then by implicitly calling `begin_record` and `end_record`, then by pulling the finished record out of the length-one array. The `ak.Record` constructor does this because just by using it, the user is communicating the fact that they want a record. `ak.from_json` should go through the same procedure once it recognizes that the outermost JSON structure is a JSON object, not a JSON array.\r\n\r\nI'll make an issue out of this.\r\n",
  "closed_at":"2020-08-06T17:17:43Z",
  "comments":2,
  "created_at":"2020-06-22T20:58:51Z",
  "id":643357011,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDMzNTcwMTE=",
  "number":311,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.from_json needs to return ak.Record for a JSON object, not a length-1 ak.Array",
  "updated_at":"2020-08-06T17:17:43Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"If you load the bikeroutes from [here](https://github.com/jpivarski/2020-07-06-scipy2020/blob/c951aa50bbfa879f011c9f2c343a3d0168be28e0/bikeroutes-execution.ipynb) and try to convert to arrow, it works:\r\n```\r\narr2 = ak.to_arrow(bikeroutes['features']). # cannot convert the top-level Record, so lose some attributes\r\nt = pa.Table.from_arrays([arr2], names=['features'])\r\n```\r\nbut this cannot be written to parquet because the schema is as follows\r\n```\r\nfeatures: struct<type: large_string, properties: struct<STREET: large_string, TYPE: large_string, BIKEROUTE: large_string, F_STREET: large_string, T_STREET: dictionary<values=large_string, indices=int64, ordered=0>>, geometry: struct<type: large_string, coordinates: large_list<item: large_list<item: large_list<item: double>>>>>\r\n  child 0, type: large_string\r\n  child 1, properties: struct<STREET: large_string, TYPE: large_string, BIKEROUTE: large_string, F_STREET: large_string, T_STREET: dictionary<values=large_string, indices=int64, ordered=0>>\r\n      child 0, STREET: large_string\r\n      child 1, TYPE: large_string\r\n      child 2, BIKEROUTE: large_string\r\n      child 3, F_STREET: large_string\r\n      child 4, T_STREET: dictionary<values=large_string, indices=int64, ordered=0>\r\n  child 2, geometry: struct<type: large_string, coordinates: large_list<item: large_list<item: large_list<item: double>>>>\r\n      child 0, type: large_string\r\n      child 1, coordinates: large_list<item: large_list<item: large_list<item: double>>>\r\n          child 0, item: large_list<item: large_list<item: double>>\r\n              child 0, item: large_list<item: double>\r\n                  child 0, item: double\r\n```\r\nArrow doesn't know how to write the \"large strings\", but none of the input actually has any strings long enough to need that, would be 2**31 bytes, 2GB. Of course, arrow *should* be able to cope, but it does not.\r\n",
  "closed_at":"2020-07-16T19:14:37Z",
  "comments":4,
  "created_at":"2020-06-23T19:56:09Z",
  "id":644105189,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDQxMDUxODk=",
  "number":312,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.to_arrow should convert to string instead of large_string",
  "updated_at":"2020-07-16T19:14:37Z",
  "user":"MDQ6VXNlcjYwNDIyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"For minimal modification (and a tiny performance advantage), this can be done in the NumpyArray constructor. (Also check the NumpyForm and conversions from JSON into NumpyForms.) That way, the unnecessary character can be removed once in one place, without having to fix every instance in NumpyArray where `format_` is used.\r\n\r\nIf NumPy arrays are created as big-endian and then are converted with `astype` to little-endian, they have this extra character in their formats. Uproot4 is using a work-around so that a new version of Awkward with this fix is not needed right away, but it's important to fix anyway.\r\n\r\nThis would be an easy fix, though it's entirely in C++, not Python.",
  "closed_at":"2020-07-16T01:20:27Z",
  "comments":1,
  "created_at":"2020-06-26T14:49:10Z",
  "id":646315043,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDYzMTUwNDM=",
  "number":313,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Make NumpyArray's format checks insensitive to '=' (or '<' if little-endian, '>' if big-endian) at the beginning of the string",
  "updated_at":"2020-07-16T01:20:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Start working on issue #163 ",
  "closed_at":"2020-07-20T17:56:45Z",
  "comments":5,
  "created_at":"2020-06-30T16:06:25Z",
  "draft":false,
  "id":648302283,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQyMTM0MzYx",
  "number":314,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-20T17:56:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement axis_wrap_if_negative",
  "updated_at":"2020-07-21T07:21:44Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"In the spirit of expanding [integer fancy indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html#integer-array-indexing) to masked arrays, let's review how we got here. We'll use\r\n```\r\nimport numpy as np\r\nimport pyarrow as pa\r\nimport awkward1 as ak\r\n```\r\n\r\nFor basic numpy arrays,\r\n```\r\na = np.arange(20).reshape(4, 5)\r\nb = np.array([[0,0], [1,1], [2,2], [3,3]])\r\nc = np.array([[0,1], [2,3], [4,4], [0,0]])\r\n```\r\nwe have that\r\n```\r\n>>> a[b, c]\r\n array([[ 0,  1],\r\n       [ 7,  8],\r\n       [14, 14],\r\n       [15, 15]])\r\n```\r\ni.e. the output has the same shape as `b` and `c` always, and we have to index each dimension of `a` individually.\r\nIn awkward, for rectangular arrays, this still holds true:\r\n```\r\na2 = ak.Array(a)\r\nb2 = ak.Array(b)\r\nc2 = ak.Array(c)\r\n```\r\ngives\r\n```\r\n>>> a2[b2, c2]\r\n <Array [[0, 1], [7, 8], [14, 14], [15, 15]] type='4 * 2 * int64'>\r\n```\r\n\r\nHowever, awkward does depart from numy as soon as a ListArray is involved. For example, even what appears to be the same array as `c`:\r\n```\r\ncj = ak.Array([[0,1], [2,3], [4,4], [0,0]])\r\n```\r\nwe can use `cj` by itself to achieve what previously used both `b` and `c`:\r\n```\r\n>>> ak.type(cj)\r\n 4 * var * int64\r\n>>> a2[cj]\r\n <Array [[0, 1], [7, 8], [14, 14], [15, 15]] type='4 * var * int64'>\r\n```\r\nNotice `var` in the type of `cj`, which causes the indexing operation to be interpreted differently. We've accepted this as a departure from numpy since the ListArray is a completely different beast and under \"our control\". Yet, the \"shape\" of the output continues to match `cj`, i.e. it has the same number of elements in each dimension.\r\n\r\nIn pyarrow, masked arrays inside indexing operations similarly preserve the \"shape\" of the indexer, where here we mean the length of the output array (as pyarrow only supports 1D arrays).\r\n```\r\nd = pa.array([0, 1, 2, None, 4, 5])\r\ne = pa.array([0, 2, None, 3])\r\n```\r\nwe have\r\n```\r\n>>> d.take(e)\r\n <pyarrow.lib.Int64Array object at 0x120e1b980>\r\n[\r\n  0,\r\n  2,\r\n  null,\r\n  null\r\n]\r\n```\r\nand awkward faithfully reproduces this:\r\n```\r\nd2 = ak.Array([0, 1, 2, None, 4, 5])\r\ne2 = ak.Array([0, 2, None, 3])\r\n```\r\ngives\r\n```\r\n>>> d2.take(e2)\r\n <Array [0, 2, None, None] type='4 * ?int64'>\r\n```\r\n\r\nNow, combining ListArrays and masked arrays, we continue to preserve the shape of the indexer in the output:\r\n```\r\nf = ak.Array([[0, None, 2], None, [3, 4], []])\r\ng = ak.Array([[1, 2, None], None, [], [None]])\r\n```\r\ngives\r\n```\r\n>>> f[g]\r\n <Array [[None, 2, None], None, [], [None]] type='4 * option[var * ?int64]'>\r\n```\r\n\r\nHowever, there are a few cases where this breaks down. The following two indexing operations raise an error\r\n```\r\ng2 = ak.Array([[], None, None, []])\r\nf[g2]\r\n```\r\nwhich should return `[[], None, None, []]`, and\r\n```\r\ng3 = ak.Array([[], [], [], []])\r\nf[g3]\r\n```\r\nwhich should probably return `[[], [], [], []]` to be consistent with the \"same shape\", or rather, \"trivially broadcastable\" property of the output with respect to the indexer. However, I can imagine that `[[], None, [], []]` might be an alternative result.",
  "closed_at":"2020-07-09T22:02:31Z",
  "comments":5,
  "created_at":"2020-07-01T22:18:49Z",
  "id":649359685,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NDkzNTk2ODU=",
  "number":315,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Integer fancy indexing with nulls behavior",
  "updated_at":"2020-07-09T22:02:31Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Would like to test these two changes.",
  "closed_at":"2020-08-19T23:56:55Z",
  "comments":13,
  "created_at":"2020-07-03T08:20:10Z",
  "draft":false,
  "id":650430010,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQzOTIyMTI0",
  "number":316,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-19T23:56:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"libawkward export tuning",
  "updated_at":"2020-08-21T14:00:06Z",
  "user":"MDQ6VXNlcjI0NTU3Mw=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-07-05T15:04:39Z",
  "comments":0,
  "created_at":"2020-07-04T18:26:07Z",
  "draft":false,
  "id":650935737,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ0MzE0NTU1",
  "number":317,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-05T15:04:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove redundant cpu kernels from operations.h",
  "updated_at":"2020-07-05T15:04:42Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjExNzc1NjE1",
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"It would be nice to have a CI test that checks if the generated readthedocs documentation breaks. ",
  "closed_at":"2020-07-06T12:59:51Z",
  "comments":1,
  "created_at":"2020-07-04T18:34:55Z",
  "id":650936865,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTA5MzY4NjU=",
  "number":318,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"CI test to check if documentation is generated correctly",
  "updated_at":"2020-07-06T12:59:51Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Fixes #318 \r\n",
  "closed_at":"2020-07-06T12:59:51Z",
  "comments":1,
  "created_at":"2020-07-05T15:33:29Z",
  "draft":false,
  "id":651091661,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ0NDIzMDE5",
  "number":319,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-06T12:59:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"CI test to check if documentation is generated correctly",
  "updated_at":"2020-07-06T12:59:54Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It is usually cured by rerunning it, but an intermittent error is an error: something's wrong. The error manifests itself as a `ValueError` evaluating (I think!) one of the reducer tests. Next time, I should paste the error output here.",
  "closed_at":"2020-09-09T19:06:23Z",
  "comments":5,
  "created_at":"2020-07-06T12:17:00Z",
  "id":651491246,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTE0OTEyNDY=",
  "number":320,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"The MacOS test has an intermittent error in ak.argsort",
  "updated_at":"2020-09-09T19:06:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"There are some CPU kernels that need to be changed from being recursive to iterative (to make it easier to generate equivalent CUDA kernels)\r\nLike - \r\nhttps://github.com/scikit-hep/awkward-1.0/blob/master/src/cpu-kernels/getitem.cpp#L274\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/master/src/cpu-kernels/operations.cpp#L3268\r\n\r\nThese are non-trivial with each of the recursive calls being inside loops and I spent enough hours on them, that I thought I should make them into an issue.\r\n\r\nI am trying to do this with highest priority as it is a blocker for progress with https://github.com/scikit-hep/awkward-1.0/pull/307",
  "closed_at":"2020-09-11T17:29:28Z",
  "comments":1,
  "created_at":"2020-07-06T20:09:16Z",
  "id":651789430,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTE3ODk0MzA=",
  "number":321,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Change function from recursive -> iterative",
  "updated_at":"2020-09-11T17:29:28Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"First pass, some new kernels will need to be made.",
  "closed_at":"2020-07-09T17:45:38Z",
  "comments":6,
  "created_at":"2020-07-07T15:46:18Z",
  "draft":false,
  "id":652429953,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ1NDk5NDIx",
  "number":322,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T17:45:38Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Revised getitem operation for masked jagged indexers",
  "updated_at":"2020-07-09T17:45:38Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"There was an error in the parser if the return type of a function was present in the name of the function.\r\n\r\nShould fix the doc generation CI error in @trickarcher 's branch.",
  "closed_at":"2020-07-08T15:16:15Z",
  "comments":0,
  "created_at":"2020-07-08T14:42:45Z",
  "draft":false,
  "id":653355612,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ2MjkwNTI0",
  "number":323,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-08T15:16:15Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed Python generation",
  "updated_at":"2020-07-08T15:16:18Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-09T12:08:40Z",
  "comments":0,
  "created_at":"2020-07-08T22:19:06Z",
  "draft":false,
  "id":653632196,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ2NTE0MDgz",
  "number":324,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T12:08:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix an error in partitionedarray: array['field', 10].",
  "updated_at":"2020-08-03T22:29:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-09T15:49:00Z",
  "comments":0,
  "created_at":"2020-07-09T15:05:18Z",
  "draft":false,
  "id":654134348,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ2OTIwMzcy",
  "number":325,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T15:49:00Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"These tests pass if you've pip installed awkward1, but sometimes you need to work from the localbuild directory.",
  "updated_at":"2020-07-09T15:49:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-09T18:10:22Z",
  "comments":0,
  "created_at":"2020-07-09T16:36:12Z",
  "draft":false,
  "id":654198676,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ2OTcxNTM2",
  "number":326,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T18:10:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix a lot of warnings that have recently been introduced.",
  "updated_at":"2020-07-09T18:10:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Extending the C parser to handle more cases.\r\n\r\nShould fix the failing CI documentation generation tests.",
  "closed_at":"2020-07-09T19:37:14Z",
  "comments":0,
  "created_at":"2020-07-09T18:53:52Z",
  "draft":false,
  "id":654277266,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ3MDM1ODQx",
  "number":327,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-09T19:37:14Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Lookahead Python code generation for assignment with ArrayRef node having incr operator",
  "updated_at":"2020-07-09T19:37:41Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"There's no way to do this from the mixin since there is no initialize hook.\r\nA possible alternative, which might also be useful for other things, would be to rewrite `Array.__init__` using `__new__` and allowing the mixin to override initialization.",
  "closed_at":"2020-07-12T20:12:20Z",
  "comments":0,
  "created_at":"2020-07-12T19:51:55Z",
  "draft":false,
  "id":655465083,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ3OTQ2Njk4",
  "number":330,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-12T20:12:20Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Attach docstrings to newly created highlevel arrays",
  "updated_at":"2020-07-12T20:12:20Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"For the arrays:\r\n```\r\nimport awkward1\r\nex = awkward1.Array([ [1.0], [2.0, 3.0] ])\r\np4 = awkward1.zip({\"pt\": ex, \"eta\": ex, \"phi\": ex, \"mass\": ex})\r\np4c = awkward1.cartesian([p4, p4])\r\n```\r\nwe can convert `p4` to pandas just fine:\r\n```\r\n>>> awkward1.pandas.df(p4)\r\n                 pt  eta  phi mass\r\nentry subentry\r\n0     0         1.0  1.0  1.0  1.0\r\n1     0         2.0  2.0  2.0  2.0\r\n      1         3.0  3.0  3.0  3.0\r\n```\r\nbut the combinations fails to work:\r\n```\r\n>>> awkward1.pandas.df(p4c)\r\n                  0    1\r\nentry subentry\r\n0     0         NaN  NaN\r\n1     0         NaN  NaN\r\n      1         NaN  NaN\r\n      2         NaN  NaN\r\n      3         NaN  NaN\r\n```\r\nIt seems to be related to the indexed array, since even looking at just one of the records, it writes NaNs:\r\n```\r\n>>> awkward1.pandas.df(p4c[\"0\"])\r\n               values\r\nentry subentry\r\n0     0           NaN\r\n1     0           NaN\r\n      1           NaN\r\n      2           NaN\r\n      3           NaN\r\n```\r\nwhere\r\n```\r\n>>> p4c[\"0\"].layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 1 5]\" offset=\"0\" length=\"3\" at=\"0x7fee8c437920\"/></offsets>\r\n    <content><IndexedArray64>\r\n        <index><Index64 i=\"[0 1 1 2 2]\" offset=\"0\" length=\"5\" at=\"0x7fee8c4b9670\"/></index>\r\n        <content><RecordArray>\r\n            <field index=\"0\" key=\"pt\">\r\n                <NumpyArray format=\"d\" shape=\"3\" data=\"1 2 3\" at=\"0x7fee8c4b7df0\"/>\r\n            </field>\r\n            <field index=\"1\" key=\"eta\">\r\n                <NumpyArray format=\"d\" shape=\"3\" data=\"1 2 3\" at=\"0x7fee8c466890\"/>\r\n            </field>\r\n            <field index=\"2\" key=\"phi\">\r\n                <NumpyArray format=\"d\" shape=\"3\" data=\"1 2 3\" at=\"0x7fee8c4b8210\"/>\r\n            </field>\r\n            <field index=\"3\" key=\"mass\">\r\n                <NumpyArray format=\"d\" shape=\"3\" data=\"1 2 3\" at=\"0x7fee8c476880\"/>\r\n            </field>\r\n        </RecordArray></content>\r\n    </IndexedArray64></content>\r\n</ListOffsetArray64>\r\n```",
  "closed_at":"2020-11-05T22:02:54Z",
  "comments":1,
  "created_at":"2020-07-13T17:36:40Z",
  "id":656023348,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTYwMjMzNDg=",
  "number":331,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Pandas conversion chokes on indexed arrays",
  "updated_at":"2020-11-05T22:02:54Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Although rare, sometimes its easier to do certain operations on the awkward1 layouts than their wrapped arrays. It would be convenient if numba functions could be called interchangeably, e.g.\r\n```\r\nimport awkward1\r\nimport numba\r\n\r\n@numba.njit\r\ndef dostuff(x):\r\n    return x[0]\r\n\r\na = awkward1.Array([1, 2, 3])\r\ndostuff(a.layout)\r\n```\r\ncrashes, seemingly unnecessarily since wrapping any layout with `awkwrad1.Array` passes it through.",
  "closed_at":"2020-12-07T22:27:37Z",
  "comments":6,
  "created_at":"2020-07-13T17:52:46Z",
  "id":656032482,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTYwMzI0ODI=",
  "number":332,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Can numba functions accept layouts?",
  "updated_at":"2020-12-07T22:27:37Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Sometimes, when building arrays at a low level, it is useful to manipulate `Index64` and similar from python.\r\nThe usual getitem method does not accept python slices, however:\r\n```python\r\nimport awkward1\r\na = awkward1.Array([[1, 2, 3], [4, 5], [6]])\r\na.layout.offsets[:-1]\r\n```\r\ngives:\r\n```python\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-30-53dc196bd178> in <module>\r\n      2 \r\n      3 a = awkward1.Array([[1, 2, 3], [4, 5], [6]])\r\n----> 4 a.layout.offsets[:-1]\r\n\r\nTypeError: __getitem__(): incompatible function arguments. The following argument types are supported:\r\n    1. (self: awkward1._ext.Index64, arg0: int) -> int\r\n    2. (self: awkward1._ext.Index64, arg0: int, arg1: int) -> awkward1._ext.Index64\r\n\r\nInvoked with: <Index64 i=\"[0 3 5 6]\" offset=\"0\" length=\"4\" at=\"0x7f869cad1a00\"/>, slice(None, -1, None)\r\n```\r\n\r\nAmusingly, one can do `a.layout.offsets.__getitem__(0, -1)`",
  "closed_at":"2020-07-16T01:20:27Z",
  "comments":1,
  "created_at":"2020-07-13T17:58:06Z",
  "id":656035516,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTYwMzU1MTY=",
  "number":333,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Layout indexes don't support slices",
  "updated_at":"2020-07-16T01:20:27Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"The ternary form of `ak.where` seems to misbehave when it must broadcast inputs, e.g. for:\r\n```python\r\nimport awkward1\r\na = awkward1.Array([1, 2, 3, 4])\r\nb = awkward1.Array([-1])\r\nc = awkward1.Array([True, False, True, True])\r\n```\r\nwe get\r\n```python\r\n>>> awkward1.where(c, a, b)\r\n<Array [1, 844429361811768, 3, 4] type='4 * int64'>\r\n```\r\nwhere we expect\r\n```python\r\n>>> awkward1.where(*awkward1.broadcast_arrays(c, a, b))\r\n<Array [1, -1, 3, 4] type='4 * int64'>\r\n```\r\n\r\nSimilarly, `awkward1.where(c, a, -1)` returns a TypeError, when again after broadcasting it is OK:\r\n```python\r\n>>> awkward1.where(*awkward1.broadcast_arrays(c, a, -1))\r\n<Array [1, -1, 3, 4] type='4 * int64'>\r\n```",
  "closed_at":"2020-11-17T19:33:02Z",
  "comments":1,
  "created_at":"2020-07-13T18:05:06Z",
  "id":656039444,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTYwMzk0NDQ=",
  "number":334,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Ternary ak.where issues on non-trivially-broadcastable arrays",
  "updated_at":"2020-11-17T19:33:02Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"It seems the dtype of numpy arrays converted from awkward Index64 have a dtype roundtrip issue. Consider:\r\n```python\r\nimport awkward1\r\nimport numpy\r\n\r\na = awkward1.layout.Index64([0, 1, 2, 3])\r\nb = numpy.asarray(a)\r\n```\r\n`b.dtype.char` is `q`, while the platform I am on expects `l`. Numpy handles this gracefully:\r\n```python\r\n>>> numpy.arange(4).dtype.char\r\n'l'\r\n>>> b + numpy.arange(4)\r\narray([0, 2, 4, 6], dtype=int64)\r\n```\r\nhowever awkward1 does not:\r\n```python\r\n>>> b + awkward1.Array([0, 1, 2, 3])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/ncsmith/src/awkward-1.0/awkward1/highlevel.py\", line 1169, in __repr__\r\n    typestr = repr(str(awkward1._util.highlevel_type(layout, self._behavior, True)))\r\n  File \"/Users/ncsmith/src/awkward-1.0/awkward1/_util.py\", line 1110, in highlevel_type\r\n    return awkward1.types.ArrayType(layout.type(typestrs(behavior)), len(layout))\r\nValueError: Numpy format \"q\" cannot be expressed as a PrimitiveType\r\n```\r\n\r\nIt is sufficient to recast (despite the dtype not actually changing other than `char`):\r\n```python\r\n>>> b.astype('i8') + awkward1.Array([0, 1, 2, 3])\r\n<Array [0, 2, 4, 6] type='4 * int64'>\r\n```",
  "closed_at":"2020-07-16T01:20:27Z",
  "comments":4,
  "created_at":"2020-07-13T19:16:27Z",
  "id":656078361,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTYwNzgzNjE=",
  "number":335,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Numpy dtype of Index64",
  "updated_at":"2020-07-16T01:20:27Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Currently it seems a bit cumbersome to create a contiguous numpy array (after padding and filling - e.g. for input into ML models) from records with fields of different numeric types (e.g. int and float or float and double). I'm looking for a similar behaviour like `.values` or `.to_numpy()` in pandas:\r\n\r\n```pycon\r\n>>> df = pd.DataFrame({\"a\" : [1, 2, 3], \"b\" : [1.1, 2.2, 3.3]})\r\n>>> df.dtypes\r\na      int64\r\nb    float64\r\ndtype: object\r\n>>> df.to_numpy()\r\narray([[1. , 1.1],\r\n       [2. , 2.2],\r\n       [3. , 3.3]])\r\n>>> df.to_numpy().dtype\r\ndtype('float64')`\r\n```\r\n\r\nThere are two obstacles when trying this with awkward:\r\n\r\n- When i call `ak.fill_none` this will result in a union type that can't be converted to numpy e.g.\r\n```pycon\r\n>>> import awkward1 as ak\r\n>>> array = ak.zip({\"a\" : [[1, 2], [], [3, 4, 5]], \"b\" : [[1.1, 2.2], [], [3.3, 4.4, 5.5]]})\r\n>>> ak.fill_none(ak.pad_none(array, 2, clip=True), 0)\r\n<Array [[{a: 1, b: 1.1}, ... a: 4, b: 4.4}]] type='3 * 2 * union[{\"a\": int64, \"b...'>\r\n>>> padded = ak.fill_none(ak.pad_none(array, 2, clip=True), 0)\r\n>>> padded\r\n<Array [[{a: 1, b: 1.1}, ... a: 4, b: 4.4}]] type='3 * 2 * union[{\"a\": int64, \"b...'>\r\n>>> ak.type(padded)\r\n3 * 2 * union[{\"a\": int64, \"b\": float64}, int64]\r\n```\r\n- When i have a record that can be converted to numpy it will result in a structured numpy array which i will still have to cast to a consistent dtype for many ML applications\r\n\r\nI believe @nsmith-  also ran into this when trying to show the padding and filling features of awkward in his tutorial on NanoEvents yesterday.\r\n\r\nNot sure how to best implement convenience functions for this, but maybe one could add extra options to `ak.fill_none` and `ak.to_numpy` roughly like the following (+figure out how to deal with nested records)\r\n\r\n```python\r\ndef new_fill_none(array, value, cast_value=False, **kwargs):\r\n    if cast_value and len(ak.keys(array)) > 0:\r\n        # having this as a fill value won't result in a union array\r\n        value = {k : value for k in ak.keys(array)}\r\n    return ak.fill_none(array, value, **kwargs)\r\n\r\ndef new_to_numpy(array, consistent_dtype=None, **kwargs):\r\n    np_array = ak.to_numpy(array, **kwargs)\r\n    if consistent_dtype is not None:\r\n        if len(ak.keys(array)) == 0:\r\n            raise ValueError(\"Can't use `consistent_dtype` when array has no fields\")\r\n        np_array = np_array.astype(\r\n            [(k, consistent_dtype) for k in ak.keys(array)], copy=False\r\n        ).view((consistent_dtype, len(ak.keys(array))))\r\n    return np_array\r\n\r\n>>> import awkward1 as ak\r\n>>> array = ak.zip({\"a\" : [[1, 2], [], [3, 4, 5]], \"b\" : [[1.1, 2.2], [], [3.3, 4.4, 5.5]]})\r\n>>> new_to_numpy(new_fill_none(ak.pad_none(array, 2, clip=True), 0, cast_value=True), consistent_dtype=\"float64\")\r\narray([[[1. , 1.1],\r\n        [2. , 2.2]],\r\n\r\n       [[0. , 0. ],\r\n        [0. , 0. ]],\r\n\r\n       [[3. , 3.3],\r\n        [4. , 4.4]]])\r\n```",
  "closed_at":null,
  "comments":5,
  "created_at":"2020-07-14T09:26:38Z",
  "id":656468227,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTY0NjgyMjc=",
  "number":336,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Convenience function to turn an Awkward Array into a NumPy array in anyway that it can",
  "updated_at":"2023-02-01T18:30:04Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"  - [X] `util::dtype` enum for all the recognized primitives.\r\n  - [X] functions for converting between `(format, itemsize)` and `util::dtype`.\r\n  - [x] `util::dtype npdtype` as a third type parameter in NumpyArray and NumpyForm, part of the constructor.\r\n  - [x] Replace uses of `format` with uses of `npdtype` without changing behavior.\r\n  - [x] Prefer `npdtype` when converting NumpyArray to and from np.ndarray.\r\n  - [x] Use the same mechanism for `IndexOf<T>`.\r\n  - [ ] ~~Extend NumpyArray implementations to all `util::dtype` values (except `NOT_PRIMITIVE`).~~\r\n  - [ ] ~~Extend reducers as well.~~\r\n  - [x] Revisit the linked issues to see if they've been fixed:\r\n    - [x] #313\r\n    - [x] #333\r\n    - [x] #335\r\n  - [x] NumpyForm JSON string representations should cover all of the `util::dtype` values (except `NOT_PRIMITIVE`).\r\n  - [x] We need a function that turns NumPy dtypes into NumpyForms. The JSON trick is dumb.",
  "closed_at":"2020-07-16T01:20:27Z",
  "comments":1,
  "created_at":"2020-07-14T18:27:33Z",
  "draft":false,
  "id":656811370,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDQ5MDQxNjc1",
  "number":337,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-16T01:20:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Try to fully resolve the NumPy format string issues.",
  "updated_at":"2020-07-16T01:20:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-16T15:29:12Z",
  "comments":0,
  "created_at":"2020-07-16T15:06:53Z",
  "draft":false,
  "id":658286313,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUwMjcwMTU5",
  "number":338,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-16T15:29:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Renamed keeplayout \u2192 keep_layout in ak.{from,to}_awkward0",
  "updated_at":"2020-07-16T15:29:16Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The function parameters are a little different from NumPy's (adds `ascending` and `stable`, does not include `kind` and `order`). Unfortunately, the `stable` parameter is not 1:1 with NumPy's `kind`.",
  "closed_at":"2020-07-16T17:32:13Z",
  "comments":0,
  "created_at":"2020-07-16T16:52:32Z",
  "draft":false,
  "id":658374331,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUwMzQ1MTA3",
  "number":339,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-16T17:32:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Adds a high-level interface to sorting (ak.sort)",
  "updated_at":"2020-07-16T17:32:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes #312, as preparation for adding Parquet input and output.",
  "closed_at":"2020-07-16T19:14:37Z",
  "comments":3,
  "created_at":"2020-07-16T18:01:34Z",
  "draft":false,
  "id":658427362,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUwMzkxMjQ1",
  "number":340,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-16T19:14:37Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Convert 64-bit unsigned 32-bit Awkward arrays into 32-bit Arrow arrays if their indexes are small enough.",
  "updated_at":"2020-07-16T19:59:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I would want it to take the ArrayBuilder as part of a closure, not a constant. Maybe ask about this on the Numba Gitter.",
  "closed_at":"2020-08-18T23:11:05Z",
  "comments":0,
  "created_at":"2020-07-16T18:33:19Z",
  "id":658450898,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTg0NTA4OTg=",
  "number":341,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Numba \"cannot lower constant of type awkward1.ArrayBuilderType(None)\": can anything be done?",
  "updated_at":"2020-08-18T23:11:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This came up a few times while I was creating examples.",
  "closed_at":"2020-07-17T13:31:03Z",
  "comments":1,
  "created_at":"2020-07-16T18:34:06Z",
  "id":658451474,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NTg0NTE0NzQ=",
  "number":342,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Awkward-Numba is missing `enumerate` implementations, which would be very helpful.",
  "updated_at":"2020-07-17T13:31:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-17T01:54:01Z",
  "comments":1,
  "created_at":"2020-07-16T20:03:21Z",
  "draft":false,
  "id":658521194,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUwNDczMjM5",
  "number":343,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-17T01:54:01Z"
  },
  "reactions":{
   "heart":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Convert Arrow <--> Parquet, and hence Awkward <--> Parquet.",
  "updated_at":"2020-07-17T01:54:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-17T16:30:32Z",
  "comments":0,
  "created_at":"2020-07-17T13:55:16Z",
  "draft":false,
  "id":659276925,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUxMTQxODQx",
  "number":344,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-17T16:30:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"The ak.Array/ak.Record/ak.ArrayBuilder repr quotes keys that are not good identifiers.",
  "updated_at":"2020-07-17T16:32:15Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-07-23T00:50:54Z",
  "comments":3,
  "created_at":"2020-07-18T14:27:57Z",
  "draft":false,
  "id":660181080,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDUxOTYwMDkz",
  "number":345,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T00:50:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Prepare the Python Layer for the CUDA Kernels, and add Docker Images for CI",
  "updated_at":"2020-07-23T00:51:14Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Addresses issue https://github.com/scikit-hep/awkward-1.0/issues/173",
  "closed_at":"2020-08-06T00:45:03Z",
  "comments":25,
  "created_at":"2020-07-21T07:59:28Z",
  "draft":false,
  "id":662717620,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU0MjQyNTEx",
  "number":346,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-06T00:45:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Operation to change the number type",
  "updated_at":"2020-08-06T00:45:08Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-07-21T12:11:05Z",
  "comments":0,
  "created_at":"2020-07-21T09:17:05Z",
  "draft":false,
  "id":662787329,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU0MzAzMjQ3",
  "number":347,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-21T12:11:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove redundant line from reducers kernel",
  "updated_at":"2020-07-21T12:11:08Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-23T00:00:04Z",
  "comments":0,
  "created_at":"2020-07-22T14:28:21Z",
  "draft":false,
  "id":663806357,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1MTU1MTYw",
  "number":348,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T00:00:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Added form_key (optional string) to all Forms.",
  "updated_at":"2020-07-23T00:00:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-07-23T11:41:37Z",
  "comments":1,
  "created_at":"2020-07-23T10:32:49Z",
  "draft":false,
  "id":664368101,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1NjE4NjQ3",
  "number":349,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T11:41:37Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix Python SyntaxWarning",
  "updated_at":"2020-07-23T11:48:24Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This was one of the design goals described in the [original motivations document](https://docs.google.com/document/d/1lj8ARTKV1_hqGTh0W_f01S6SsmpzZAXz9qqqWnEB3j4/edit?usp=sharing), but it has required some non-intuitive sorcery to implement and it's not clear to me that it's a valuable feature. To be clear, we're talking about\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> import pandas as pd\r\n>>> pd.DataFrame({\"awkward\": ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]])})\r\n           awkward\r\n0  [1.1, 2.2, 3.3]\r\n1               []\r\n2       [4.4, 5.5]\r\n```\r\n\r\nand not \r\n\r\n```python\r\n>>> ak.pandas.df(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]))\r\n                values\r\nentry subentry        \r\n0     0            1.1\r\n      1            2.2\r\n      2            3.3\r\n2     0            4.4\r\n      1            5.5\r\n```\r\n\r\nThe explicit conversion into a MultiIndex DataFrame with [ak.pandas.df](https://awkward-array.readthedocs.io/en/latest/ak.pandas.df.html) has no issues: the implementation is straightforward and I know how I would use it\u2014there are plenty of Pandas functions for dealing with MultiIndex. For example,\r\n\r\n```python\r\n>>> df = ak.pandas.df(ak.Array([[1.1, 2.2, 3.3], [], [4.4, 5.5]]))\r\n>>> df.unstack()\r\n         values          \r\nsubentry      0    1    2\r\nentry                    \r\n0           1.1  2.2  3.3\r\n2           4.4  5.5  NaN\r\n```\r\n\r\nBut for the Awkward-in-Pandas, the only things I know of that can be used directly are ufuncs:\r\n\r\n```python\r\n>>> pd.DataFrame({\"awkward\": ak.Array([[1, 2, 3], [], [4, 5]])}) + 100\r\n           awkward\r\n0  [101, 102, 103]\r\n1               []\r\n2       [104, 105]\r\n```\r\n\r\nbut not all ufuncs, for some Pandas reason:\r\n\r\n```python\r\n>>> np.sqrt(pd.DataFrame({\"awkward\": ak.Array([[1, 2, 3], [], [4, 5]])}))\r\nTraceback (most recent call last):\r\n  File \"/home/pivarski/irishep/awkward-1.0/awkward1/highlevel.py\", line 996, in __getattr__\r\n    raise AttributeError(\"no field named {0}\".format(repr(where)))\r\nAttributeError: no field named 'sqrt'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: loop of ufunc does not support argument 0 of type Array which has no callable sqrt method\r\n```\r\n\r\nPresumably, we could narrow in on that reason and get it to work, but there are a _lot_ of Pandas functions to test. The fundamental problem is that Awkward objects are \"black boxes\" to Pandas. Sure, we can put them _in_ a DataFrame, but what's Pandas going to do with them once they're there?\r\n\r\nThere are other downsides to making Awkward Arrays subclasses of `pandas.core.arrays.base.ExtensionArray` (so that they can be columns). For one thing, it implies that we have to `import pandas` at startup, which can cost up to a second on slow machines or might try to import a broken installation of Pandas even if the user isn't planning on using Pandas. (If Pandas is not installed, we can change the class hierarchy, but that means `ak.Array` behaves differently, depending on whether you've installed Pandas, even if you're not using it.)\r\n\r\nTo avoid the above, the current implementation only makes `ak.Array` inherit from `pandas.core.arrays.base.ExtensionArray` if you try to use it in Pandas, which can be detected by a call to `dtype`. But for consistency, that's even worse, since the inheritance of `ak.Array` now changes at runtime, depending on whether you've ever tried to use an Awkward Array in a DataFrame. This came up in a difference in behavior (reported on Slack) that I couldn't reproduce at first because my test didn't invoke Pandas. Namely, the `pandas.core.arrays.base.ExtensionArray` defines some methods, and these methods exist or don't exist on `ak.Array` unless they're overshadowed by my own implementations. At the very least, I should overshadow all the non-underscored ones so that their existence is not history-dependent, but it fills up the `ak.Array` namespace with names I don't necessarily want.\r\n\r\n   * `to_numpy`: This would be fine; it would call [ak.to_numpy](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_numpy.html), though the other methods don't have an underscore, such as `tolist` (for consistency with NumPy).\r\n   * `dtype`: Already tricky, since Pandas requires a new one, `AwkwardDType`, and Dask requires `np.dtype(\"O\")`.\r\n   * `shape`: Pandas needs this to be one-dimensional, which is misleading for an Awkward Array. Preferably, Awkward Arrays would have _no_ `shape` at all; the combined `dtype` and `shape` can only be fully captured by [ak.type](https://awkward-array.readthedocs.io/en/latest/_auto/ak.type.html).\r\n   * `ndim`: Much like `shape`, it's misleading for this to always be `1`.\r\n   * `nbytes`: This is fine, and other libraries expect such a property, too.\r\n   * `astype`: This was the surprise that triggered this issue: I didn't think Awkward Arrays had an `astype`, since it's not clear what it should mean. For changing numeric types, there's an open PR #346, but it's a new function since it doesn't change the whole type of the array, it descends to the leaves where the numbers are.\r\n   * `isna`: This can go to [ak.is_none](https://awkward-array.readthedocs.io/en/latest/_auto/ak.is_none.html), though \"na\" is not how we refer to missing data.\r\n   * `argsort`: This can go to [ak.argsort](https://awkward-array.readthedocs.io/en/latest/_auto/ak.argsort.html).\r\n   * `fillna`: This can go to [ak.fill_none](https://awkward-array.readthedocs.io/en/latest/_auto/ak.fill_none.html), but see the note on `isna` above.\r\n   * `dropna`: We don't have an `ak.drop_none`, but such a thing wouldn't be too hard to write.\r\n   * `shift`: This one _only_ makes sense for rectangular tables. (See [the definition](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html).)\r\n   * `unique`: We don't have an `ak.unique` and there could be some subtitles there. We don't have a definition for record equality, for example, and string equality is already handled through a [behavioral extension](https://awkward-array.readthedocs.io/en/latest/ak.behavior.html).\r\n   * `searchsorted`: Only makes sense if the data are actually sorted. Should there be an `axis=1` version of this for variable-length lists? Usually, physics events are unsorted but the particles (`axis=1`) are sorted by `pT`.\r\n   * `factorize`: This is a non-intuitive name, but it could be good to have an Awkward function that turns arrays into an [IndexedArray](https://awkward-array.readthedocs.io/en/latest/ak.layout.IndexedArray.html) of unique values. But for complex objects like records, this brings up the same issues as `unique` (above).\r\n   * `repeat`: We don't have an `ak.repeat`, but that might be useful in some contexts. I usually find [np.repeat](https://numpy.org/doc/stable/reference/generated/numpy.repeat.html) and [np.tile](https://numpy.org/doc/stable/reference/generated/numpy.tile.html) to be a pair that have to be used together, usually to make a Cartesian product (and we already have [ak.cartesian](https://awkward-array.readthedocs.io/en/latest/_auto/ak.cartesian.html)).\r\n   * `take`: This seems unnecessary to me, since we already have `__getitem__` with integer arrays.\r\n   * `copy`: I don't know if we have a high-level \"copy\" function, but we have the low-level ones to link it up.\r\n   * `view`: This wouldn't make much sense for an Awkward Array. It's not a simple buffer.\r\n   * `ravel`: Maybe the equivalent of this is [ak.flatten](https://awkward-array.readthedocs.io/en/latest/_auto/ak.flatten.html)? Flattening variable-length arrays, particularly ones that include records, is a different kind of thing from flattening rectilinear data.\r\n\r\nGiven these mismatches, I'm strongly considering removing the Awkward-in-Pandas feature before Awkward1 actually becomes 1.0. The explicit conversion functions, [ak.pandas.df](https://awkward-array.readthedocs.io/en/latest/ak.pandas.df.html) and [ak.pandas.dfs](https://awkward-array.readthedocs.io/en/latest/ak.pandas.dfs.html), would be kept.\r\n\r\nBut I might be wrong\u2014there might be some fantastic use-case for Awkward-in-Pandas that I don't know about. This question is an informal vote on the feature. You might have been sent here by an error message, where the feature is provisionally removed with a way to opt-in. If you find it useful to include Awkward Arrays inside of Pandas DataFrames (distinct from the [ak.pandas.df](https://awkward-array.readthedocs.io/en/latest/ak.pandas.df.html) conversion), then say so here, describing the use-case. You can opt-in now by calling [ak.pandas.register()](https://awkward-array.readthedocs.io/en/latest/ak.pandas.register.html), but if I don't hear from people saying that they really use it, the feature will be removed and you won't be able to use it past 1.0.\r\n\r\nSo let me know!",
  "closed_at":"2020-09-18T20:21:14Z",
  "comments":11,
  "created_at":"2020-07-23T14:33:36Z",
  "id":664526115,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NjQ1MjYxMTU=",
  "number":350,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Should Awkward Arrays be usable as Pandas columns?",
  "updated_at":"2020-10-05T19:05:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Users are requested to explain their Awkward-in-Pandas use-cases on #350. If there aren't any applications (that couldn't be done in other ways), then this feature will be removed before Awkward1 really becomes 1.0.\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> import pandas as pd\r\n>>> pd.DataFrame({\"array\": ak.Array([[1, 2, 3], [], [4, 5]])})\r\n```\r\n\r\n```\r\nRuntimeError: You seem to be trying to use an Awkward Array as a Pandas Series or DataFrame column. This is\r\ncurrently allowed if you first call\r\n\r\n    ak.pandas.register()\r\n\r\nbut it is being considered for deprecation. See\r\n\r\n    https://github.com/scikit-hep/awkward-1.0/issues/350\r\n\r\nfor reasons why it may be removed and explain your use-case there if you don't want it to be removed. Note\r\nthat this is distinct from\r\n\r\n    ak.pandas.df(array)\r\n    ak.pandas.dfs(array)\r\n\r\nwhich may work better for you anyway, depending on what you're trying to accomplish.\r\n```\r\n\r\n```python\r\n>>> ak.pandas.register()\r\n>>> pd.DataFrame({\"array\": ak.Array([[1, 2, 3], [], [4, 5]])})\r\n       array\r\n0  [1, 2, 3]\r\n1         []\r\n2     [4, 5]\r\n```",
  "closed_at":"2020-07-23T16:07:32Z",
  "comments":0,
  "created_at":"2020-07-23T15:39:52Z",
  "draft":false,
  "id":664581132,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1Nzk5Njk3",
  "number":351,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T16:07:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Put the Awkward-in-Pandas feature up for a vote.",
  "updated_at":"2020-07-23T16:07:38Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-23T16:35:28Z",
  "comments":0,
  "created_at":"2020-07-23T16:08:02Z",
  "draft":false,
  "id":664600058,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1ODE1Mjc0",
  "number":352,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T16:35:28Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Replace metadata containing cache with just cache (no premature generalization).",
  "updated_at":"2020-07-23T16:35:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"As is done for Array.",
  "closed_at":"2020-07-23T19:37:35Z",
  "comments":0,
  "created_at":"2020-07-23T17:25:39Z",
  "draft":false,
  "id":664646291,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1ODUzNTQ3",
  "number":353,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-23T19:37:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add docstring also to Record",
  "updated_at":"2020-07-23T19:37:36Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Provide some convenience functions for making new behavior classes.",
  "closed_at":"2020-07-25T13:16:30Z",
  "comments":2,
  "created_at":"2020-07-23T20:43:36Z",
  "draft":false,
  "id":664753236,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU1OTQxNzQw",
  "number":354,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-25T13:16:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Mixin class decorators",
  "updated_at":"2020-07-27T23:56:56Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This is a tracking issue for migrating https://github.com/CoffeaTeam/coffea/blob/master/coffea/nanoevents/methods/mixin.py into awkward. The decorators allow a more concise declaration of mixin classes, e.g.:\r\n```python\r\nfrom awkward1 import mixin_class, mixin_class_method\r\n\r\n\r\n@mixin_class(ak.behavior)\r\nclass Point:\r\n    def distance(self, other):\r\n        return np.sqrt((self.x - other.x) ** 2 + (self.y - other.y) ** 2)\r\n\r\n    @mixin_class_method(np.equal, {\"Point\"})\r\n    def point_equal(self, other):\r\n        return np.logical_and(self.x == other.x, self.y == other.y)\r\n\r\n    @mixin_class_method(np.abs)\r\n    def point_abs(self):\r\n        return np.sqrt(self.x ** 2 + self.y ** 2)\r\n```\r\nreproduces the functionality outlined in the `ak.behavior` introductory documents.",
  "closed_at":"2020-07-25T13:16:29Z",
  "comments":2,
  "created_at":"2020-07-23T22:49:05Z",
  "id":664811042,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NjQ4MTEwNDI=",
  "number":355,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Decorators for making new mixins",
  "updated_at":"2020-07-27T00:08:05Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-24T23:03:22Z",
  "comments":1,
  "created_at":"2020-07-24T19:18:59Z",
  "draft":false,
  "id":665365970,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU2NDQ4NTMx",
  "number":356,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-24T23:03:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Adapt to pyarrow/Arrow 1.0.",
  "updated_at":"2020-07-24T23:03:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-07-28T15:04:17Z",
  "comments":1,
  "created_at":"2020-07-25T05:21:00Z",
  "draft":false,
  "id":665518070,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU2NTY4MDc4",
  "number":357,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-28T15:04:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Cleanup the Docker Residues like .test files and .dockerignore.",
  "updated_at":"2020-07-28T15:04:21Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"",
  "closed_at":"2020-07-27T00:08:53Z",
  "comments":4,
  "created_at":"2020-07-26T18:01:55Z",
  "draft":false,
  "id":665830942,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU2Nzg0MjQ3",
  "number":358,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-27T00:08:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed typo",
  "updated_at":"2024-02-18T11:52:07Z",
  "user":"MDQ6VXNlcjIxMDIwNDgy"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Greetings, `awkward` devs!\r\n\r\nOver at [cudf](https://github.com/rapidsai/cudf), we are introducing a [ListDtype](https://github.com/rapidsai/cudf/issues/5610) and an associated ListColumn that is similar to awkard's jagged array - just for use with DataFrames and related operations. We're also looking to introduce other \"awkward\" column types in the future, such as a `StructColumn` analogous to Arrow's [StructArray](https://arrow.apache.org/docs/python/generated/pyarrow.StructArray.html).\r\n\r\nSomething we'd like to be able to do is leverage Numba/CUDA to run user-defined functions (UDFs) on ListColumns -- pretty much exactly what is discussed [here](https://numba.discourse.group/t/making-awkward-arrays-work-in-the-cuda-target/63).\r\n\r\nIt seems like some redundancy between cuDF and awkward could be avoided here, by building out the required Numba extensions in a way that's easily reusable by both libraries. More importantly, it would lead to a better experience for users, as the same UDFs would run identically on both awkward arrays and cuDF.\r\n\r\nOpening this issue to hear your thoughts about this, and as a place to collect ideas on how this might be achieved. Thanks!\r\n\r\ncc: @kkraus14 @gmarkall",
  "closed_at":"2020-12-11T22:46:14Z",
  "comments":3,
  "created_at":"2020-07-27T21:38:01Z",
  "id":666601068,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NjY2MDEwNjg=",
  "number":359,
  "performed_via_github_app":null,
  "reactions":{
   "heart":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Reusable Numba extension for CUDA target?",
  "updated_at":"2020-12-11T22:46:14Z",
  "user":"MDQ6VXNlcjMxOTA0MDU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-28T14:11:39Z",
  "comments":0,
  "created_at":"2020-07-27T23:38:22Z",
  "draft":false,
  "id":666650234,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU3NDU2OTk1",
  "number":360,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-28T14:11:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Ensure that Matplotlib raises ValueError on non-flat arrays and keep test_0341 from leaking Parquet files.",
  "updated_at":"2020-07-28T14:11:42Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"address Issue https://github.com/scikit-hep/awkward-1.0/issues/184",
  "closed_at":"2020-11-15T17:47:49Z",
  "comments":23,
  "created_at":"2020-07-28T09:49:12Z",
  "draft":true,
  "id":666936508,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU3Njk2MzEz",
  "number":361,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"concatenate for a nonzero axis operation",
  "updated_at":"2020-11-17T19:33:40Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-18T13:46:58Z",
  "comments":9,
  "created_at":"2020-07-28T14:10:10Z",
  "draft":false,
  "id":667105994,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDU3ODM2MjMy",
  "number":362,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add from_cupy to Index class",
  "updated_at":"2020-09-09T18:59:40Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-31T14:59:32Z",
  "comments":1,
  "created_at":"2020-07-31T14:03:08Z",
  "draft":false,
  "id":669850511,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYwMTc1OTM2",
  "number":363,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-31T14:59:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"jupyter-books 0.7.3 no longer supports 'headers'.",
  "updated_at":"2020-07-31T14:59:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-07-31T21:45:53Z",
  "comments":0,
  "created_at":"2020-07-31T15:56:45Z",
  "draft":false,
  "id":669960461,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYwMjcyMjEz",
  "number":364,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-07-31T21:45:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add Pandas deprecation warnings and other clean-ups.",
  "updated_at":"2020-07-31T21:45:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-04T12:13:48Z",
  "comments":1,
  "created_at":"2020-08-04T07:21:15Z",
  "draft":false,
  "id":672567756,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYyNTgwMjQy",
  "number":365,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-04T12:13:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Do not iterate over lists while comparing in pytest",
  "updated_at":"2020-08-04T12:13:54Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This was originally suggested by @nsmith-, and I've been waiting for @reikdas's PR #307 before making this sweep.\r\n\r\nIt will be accomplished in several passes:\r\n\r\n   - [x] Define a `data` member on everything with a `ptr` (Index, Identities, NumpyArray, RawArray) that returns the pointer with offset accounted for.\r\n   - [x] Swap `ptr` \u2192 `data` and `offset` \u2192 `0` in all kernels, verifying that nothing breaks.\r\n   - [x] Label all places where offsets are to be removed with `oink` and `boink`. Set offsets to 999 or 123 (restoring them to zero with `oink` and `boink`) to ensure that we've found all the places.\r\n   - [x] Remove the _application_ of `offset` from the kernel implementations (i.e. keep it in the argument list but don't use it in the code), verifying that nothing breaks.\r\n   - [x] Remove the `offset` arguments, verifying that nothing breaks.\r\n\r\nAlso,\r\n\r\n   - [x] Be sure to remove the `at` argument from `kernel::NumpyArray_getitem_at`.\r\n   - [x] `ptr_lib` should become the first argument of every kernel (at the calling sites).\r\n   - [x] `kernel::lib` should be lowercase (like `util::dtype`).\r\n   - [x] `kernel::lib` should be an `enum class`.\r\n   - [x] The `kernel` namespace should be in the `awkward` namespace.\r\n   - [x] \"`if(`\" \u2192 \"`if (`\"\r\n   - [ ] ~~Move cpu-kernels/\\*.h to kernels/\\*.h.~~\r\n\r\nAnd finally,\r\n\r\n   - [x] Re-enable Reik's kernel tests when you're done!",
  "closed_at":"2020-08-05T22:57:22Z",
  "comments":0,
  "created_at":"2020-08-04T13:57:13Z",
  "draft":false,
  "id":672813359,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYyNzgzODMx",
  "number":366,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-05T22:57:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove 'offset' arguments from all kernels, only passing in pointers that have already been offset.",
  "updated_at":"2020-08-05T22:57:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Currently, a pandas DataFrame with a column of eg. datetime[ns] dtype is resulting in an obscure ValueError:\r\n`ValueError: cannot include dtype 'M' in a buffer`\r\n\r\n\r\n```python\r\nvalues = {'time':  ['20190902093000','20190913093000','20190921200000']}\r\ndf = pd.DataFrame(values, columns = ['time'])\r\ndf['time'] = pd.to_datetime(df['time'], format='%Y%m%d%H%M%S')\r\ndf.dtypes\r\n```\r\n\r\n```bash\r\ntime       datetime64[ns]\r\ndtype: object\r\n```\r\n\r\n```python\r\n# current workaround\r\ndf['time'] = df.time.values.astype(int)\r\nakarr = ak.Record({c: df[c].values for c in df.columns})\r\n```",
  "closed_at":"2021-06-10T19:39:53Z",
  "comments":18,
  "created_at":"2020-08-04T16:42:42Z",
  "id":672930410,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzI5MzA0MTA=",
  "number":367,
  "performed_via_github_app":null,
  "reactions":{
   "+1":4,
   "total_count":4
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Support for datetime[*] numpy dtype",
  "updated_at":"2021-06-11T00:15:24Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Currently, reading from partitioned parquet datasets ([Partitioning](https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Partitioning.html#pyarrow.dataset.Partitioning) and [partitioning](https://arrow.apache.org/docs/python/generated/pyarrow.dataset.partitioning.html#pyarrow.dataset.partitioning)) is not supported.\r\n\r\n```python\r\nfrom pathlib import Path\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport awkward1 as ak # '0.2.27'\r\n```\r\n\r\n```python\r\nparquet_dir = Path('./dataset')\r\nvalues = {'time':  ['20190902093000','20190913093000','20190921200000']}\r\ndf = pd.DataFrame(values, columns = ['time'])\r\ndf['time'] = pd.to_datetime(df['time'], format='%Y%m%d%H%M%S')\r\ndf['year'] = df.time.year\r\n\r\n# create partitioned parquet dataset\r\ndf.to_parquet(parquet_dir,\r\n              partition_cols=['year'])\r\n\r\n###\r\n# pandas does this under the hood without the metadata collector and version spec\r\n###\r\ntable = pa.Table.from_pandas(df, preserve_index=True)\r\n\r\n# Write a dataset and collect metadata information of all written files\r\nmetadata_collector = []\r\npq.write_to_dataset(table,\r\n                    root_path=parquet_dir,\r\n                    partition_cols=['year', 'month', 'day'],\r\n                    version='2.0',\r\n                    data_page_version='2.0'\r\n                    metadata_collector=metadata_collector)\r\n\r\n# Write the ``_common_metadata`` parquet file without row groups statistics\r\npq.write_metadata(table.schema, parquet_dir / '_common_metadata')\r\n\r\n# Write the ``_metadata`` parquet file with row groups statistics of all files\r\npq.write_metadata(table.schema, parquet_dir / '_metadata',\r\n                  metadata_collector=metadata_collector)\r\n```\r\n\r\n```bash\r\nls -LR\r\n./dataset/year=2019:\r\n<uuid1>.parquet  <uuid2>.parquet\r\n```\r\n\r\nA simple [`ak.from_parquet(parquet_dir)` would fail](https://github.com/scikit-hep/awkward-1.0/blob/master/src/awkward1/operations/convert.py#L2085) with `ArrowIOError`.\r\n\r\n```python\r\n# current workaround with pandas\r\ndf = pd.read_parquet(parquet_dir)\r\n# cast time columns till it is supported by awkward/pybind11\r\n# see Issue #367 \r\ndf['time'] = df.time.values.astype('uint64')\r\nakarr = ak.Record({c: df[c].values for c in df.columns})\r\n\r\n# current workaround with pq directly\r\ntable = pq.read_table(parquet_dir)\r\n### cast time fields #367 \r\n# careful drops col metadata!\r\nfields = []\r\nfor field, dtype in zip(table.schema.names, table.schema.types):\r\n    if isinstance(dtype, pa.lib.TimestampType):\r\n        fields.append(pa.field(field, pa.int64())) # pyarrow does not support casting from uint64\r\n    else:\r\n        fields.append(pa.field(field, dtype))\r\nnew_schema = pa.schema(fields, metadata=table.schema.metadata)\r\ntable_awk = table.cast(new_schema)\r\n\r\nak.from_arrow(table_awk)\r\n```",
  "closed_at":"2021-02-05T23:24:33Z",
  "comments":4,
  "created_at":"2020-08-04T19:09:52Z",
  "id":673015819,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzMwMTU4MTk=",
  "number":368,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Support for partitioned parquet files in read_parquet",
  "updated_at":"2021-02-06T09:24:13Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Should fix the errors that @ianna has been seeing in the CI for her PR.",
  "closed_at":"2020-08-04T19:48:58Z",
  "comments":0,
  "created_at":"2020-08-04T19:12:17Z",
  "draft":false,
  "id":673018014,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYyOTU0MTY0",
  "number":369,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-04T19:48:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Improve C++ to C generator",
  "updated_at":"2020-08-04T19:49:02Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Not sure if bug or feature.\r\n\r\nSlicing by an array of indices would be very handy but currently fails (or is unreliable).\r\n\r\nMinimal working example taken (mostly based on the README.md): \r\n```python\r\nimport awkward1 as ak # 0.2.27\r\narray = ak.Array([\r\n    [{\"x\": 1.1, \"y\": [1]}],\r\n    [{\"x\": 2.2, \"y\": [11, 12]}],\r\n    [{\"x\": 3.3, \"y\": [21, 22, 23]}],\r\n    #[], # cannot slice this by index\r\n    [{\"x\": 3.3, \"y\": [31, 32, 33]}],\r\n    [{\"x\": 4.4, \"y\": [41, 42, 43, 44]}],\r\n    [{\"x\": 5.5, \"y\": [51, 52, 53, 54, 55]}]\r\n])\r\n# slicing should work by python objects or numpy\r\n# but singleton seems to produce more reliable results\r\n# strangely singletons sometimes do not convert 1-D numpy\r\n# idx = np.array([0, 0, 1, 1, 2, 2])#[:, np.newaxis]\r\nstartIndices = ak.singletons([[0], [0], [1], [1], [2], [2]])\r\n\r\n# slice each `y` in `array` from start to end resp. [0], [0:1], [1:2], [1], [2:], [2:3]\r\n# endIndices = ak.singletons([[0], [1], [2], [1], [None], [3]])\r\n\r\nassert array.shape[0] == startIndices.shape[0]\r\n\r\n# this works\r\narray['y', ... , 1:]\r\n# while this fails with ValueError: in ListArray64 attempting to get 1, index out of range\r\n# but should return the same?\r\narray['y', ... , 1]\r\n# (as a consequence) this also fails\r\narray['y', ... , startIndices]\r\n```\r\nMaybe I am missing something here. \r\nEventually would be nice to achieve a slice from `startIndices` to `endIndicecs` _without_ creating boolean arrays of the entire length or a numba for loop.\r\n```python\r\nmask = np.array([[True], [True, True], [False, True, True], [False, True, False], [False, False, True, True], [False, False, True, False]])\r\narray['y', mask]\r\n```\r\nFails with \r\n`ValueError: arrays used as an index must be a (native-endian) integer or boolean`",
  "closed_at":"2020-08-05T18:20:01Z",
  "comments":7,
  "created_at":"2020-08-05T15:48:26Z",
  "id":673646348,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzM2NDYzNDg=",
  "number":370,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Unintuitive slicing behaviour when slicing with Arrays",
  "updated_at":"2020-08-06T13:53:23Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-06T12:10:32Z",
  "comments":0,
  "created_at":"2020-08-06T01:19:56Z",
  "draft":false,
  "id":673945590,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYzNzI0MTkx",
  "number":371,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-06T12:10:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Removing the last offset parameters (missed them before because they're in an array).",
  "updated_at":"2020-08-06T12:10:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-24T22:58:07Z",
  "comments":0,
  "created_at":"2020-08-06T05:44:09Z",
  "draft":false,
  "id":674034317,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYzNzk2Njgx",
  "number":372,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-24T22:58:07Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add to and from_cupy for Numpy Array and Identities",
  "updated_at":"2020-08-24T22:58:11Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"The code generator will improve with each new kernel that it can handle; and this PR will likely be a rather long one. ",
  "closed_at":"2020-08-31T13:59:47Z",
  "comments":4,
  "created_at":"2020-08-06T11:54:56Z",
  "draft":false,
  "id":674255459,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDYzOTc4NjUx",
  "number":373,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-31T13:59:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Generate CUDA kernels from kernel specification",
  "updated_at":"2020-08-31T13:59:50Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-06T15:56:33Z",
  "comments":0,
  "created_at":"2020-08-06T15:32:10Z",
  "draft":false,
  "id":674404996,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY0MTAyNjEw",
  "number":374,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-06T15:56:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Pandas deprecation version is 0.3.0 and ak.to_pandas is documented.",
  "updated_at":"2020-08-06T15:56:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"https://gcc.gnu.org/onlinedocs/cpp/Standard-Predefined-Macros.html\r\n\r\nThis would be incredibly helpful for interpreting user's bug reports. It's the missing link between Python exceptions and C++ exceptions. (Maybe the full stack trace is also missing, but the file and line number at the end are usually more important to me and long stack traces can sometimes be problems in themselves.)\r\n\r\nMaybe to get just the file name (and not the full path on the Azure instances that build the wheels), we can use [this one weird trick that I learned on the Internet](https://stackoverflow.com/a/54335644/1623645).\r\n\r\nOr I could just manually define a macro in each .cpp file, like the second half of [this suggestion](https://stackoverflow.com/a/30764776/1623645), and format it like a URL to the code in GitHub. With VERSION_INFO, I could match it to the exact tag, something like this:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/0.2.27/src/libawkward/array/ListArray.cpp#L1324\r\n\r\n(where `0.2.27` is a possible value of the VERSION_INFO `#define`).",
  "closed_at":"2020-08-19T04:09:13Z",
  "comments":0,
  "created_at":"2020-08-06T21:59:54Z",
  "id":674625234,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzQ2MjUyMzQ=",
  "number":375,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Include __FILE__ and __LINE__, maybe also VERSION_INFO, in all the C++ exceptions",
  "updated_at":"2020-08-19T04:09:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"A high-level wrapper for the function @ianna added of the same name. It should go in src/awkward1/operations/structure.py.",
  "closed_at":"2020-08-07T15:12:41Z",
  "comments":2,
  "created_at":"2020-08-07T13:11:21Z",
  "id":675006319,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzUwMDYzMTk=",
  "number":376,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Don't forget to add a high-level ak.numbers_to_type function.",
  "updated_at":"2020-08-07T15:12:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-07T15:12:41Z",
  "comments":1,
  "created_at":"2020-08-07T13:59:11Z",
  "draft":false,
  "id":675035331,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY0NjIxNDQ2",
  "number":377,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-07T15:12:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Rename 'astype' to 'numbers_to_type', for use as a high-level function. Also removed 'can_cast', since it's exactly the same as the NumPy version(users should use NumPy).",
  "updated_at":"2020-08-07T15:12:45Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-07T21:23:45Z",
  "comments":1,
  "created_at":"2020-08-07T21:20:17Z",
  "draft":false,
  "id":675296755,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY0ODM4NzM5",
  "number":378,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-07T21:23:45Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update the what-is-awkward to align with (and include) the video.",
  "updated_at":"2020-08-07T21:23:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-10T14:36:52Z",
  "comments":0,
  "created_at":"2020-08-08T16:10:05Z",
  "draft":false,
  "id":675548668,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1MDQ3MzQ4",
  "number":379,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-10T14:36:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fill in a lot of stubs on awkward-array.org.",
  "updated_at":"2020-08-10T14:36:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"@reikdas I have shown an example as to how you could go about integrating functions into the codebase. @jpivarski This can be merged if you want. But if you'd like to merge this, can you give me an example for writing tests for `Identities`(I'd like to have a integration test in place although since it's just casting it should pass)",
  "closed_at":"2020-08-21T16:06:00Z",
  "comments":3,
  "created_at":"2020-08-10T07:34:22Z",
  "draft":false,
  "id":675932119,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1MzMxNTg3",
  "number":380,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Example of Identities_to_Identities64 integration with the codebase.",
  "updated_at":"2020-08-21T16:06:23Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-11T22:51:59Z",
  "comments":0,
  "created_at":"2020-08-10T18:06:19Z",
  "draft":false,
  "id":676318463,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1NjUwOTAw",
  "number":381,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-11T22:51:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Writing more awkward-array.org documentation.",
  "updated_at":"2020-08-11T22:52:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Somehow the kernel documentation at https://awkward-array.readthedocs.io/en/latest/_auto/kernels.html broke with the latest commits to master - this fixes it.\r\n\r\nAnd this also silences a sphinx-build warning.",
  "closed_at":"2020-08-10T20:14:09Z",
  "comments":3,
  "created_at":"2020-08-10T19:01:40Z",
  "draft":false,
  "id":676348359,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1Njc1MDcy",
  "number":382,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-10T20:14:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed broken kernel page in sphinx docs and silenced a sphinx-build warning",
  "updated_at":"2020-08-10T20:14:12Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@ianna Minimal reproducer:\r\n\r\n```python\r\n>>> ak.numbers_to_type(ak.Array([{\"x\": 1.1}, {\"x\": 3.3}]), np.float32) + 1\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/numpy/lib/mixins.py\", line 21, in func\r\n    return ufunc(self, other)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/highlevel.py\", line 1275, in __array_ufunc__\r\n    return awkward1._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_connect/_numpy.py\", line 105, in array_ufunc\r\n    out = awkward1._util.broadcast_and_apply(inputs, getfunction, behavior)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 820, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 659, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 743, in apply\r\n    apply(\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 487, in apply\r\n    return function()\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_connect/_numpy.py\", line 100, in <lambda>\r\n    awkward1.layout.NumpyArray(getattr(ufunc, method)(*inputs, **kwargs)),\r\nRuntimeError: Item size 8 for PEP 3118 buffer format string f does not match the dtype f item size 4.\r\n```\r\n\r\nAlso, @henryiii suggested  better name: `ak.numbers_astype` (only for the high-level Python function; the low-level method can stay as-is).",
  "closed_at":"2020-08-11T00:35:51Z",
  "comments":2,
  "created_at":"2020-08-10T22:30:24Z",
  "id":676455268,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzY0NTUyNjg=",
  "number":383,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.numbers_to_type is setting buffer itemsize incorrectly",
  "updated_at":"2020-08-11T00:35:51Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This wraps all RecordArray child nodes with VirtualArray.",
  "closed_at":"2020-08-11T14:54:35Z",
  "comments":2,
  "created_at":"2020-08-10T22:58:31Z",
  "draft":false,
  "id":676465429,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1NzcyMTEx",
  "number":384,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-11T14:54:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Make from_arrayset even more lazy",
  "updated_at":"2020-08-11T14:54:36Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-11T00:35:51Z",
  "comments":0,
  "created_at":"2020-08-10T23:01:36Z",
  "draft":false,
  "id":676466551,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY1NzczMDY1",
  "number":385,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-11T00:35:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed #383, prevented conversion of characters in strings, and renamed ak.numbers_to_type -> ak.values_astype.",
  "updated_at":"2020-08-11T00:35:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I want to get group by results on json data. How can I do it with awkward-array?",
  "closed_at":"2020-10-30T22:28:06Z",
  "comments":3,
  "created_at":"2020-08-11T02:46:44Z",
  "id":676537582,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzY1Mzc1ODI=",
  "number":386,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Adding a \"group by\" operation (how general? only numbers/strings or also records/lists)?",
  "updated_at":"2021-02-12T03:23:23Z",
  "user":"MDQ6VXNlcjc4OTgzMjk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"So the body of these functions have to be moved to new underscored (private) methods that `__repr__` and `__str__` call.",
  "closed_at":"2020-08-11T22:51:59Z",
  "comments":0,
  "created_at":"2020-08-11T19:19:17Z",
  "id":677132547,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzcxMzI1NDc=",
  "number":387,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Highlevel ak.Array, ak.Record, ak.ArrayBuilder __repr__ and __str__ methods must not have parameters",
  "updated_at":"2020-08-11T22:51:59Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-18T00:18:17Z",
  "comments":1,
  "created_at":"2020-08-12T17:51:10Z",
  "draft":false,
  "id":677870945,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY2OTE4NzU0",
  "number":388,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-18T00:18:17Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Abstract all uses of NumPy, so that GPU arrays will use CuPy instead.",
  "updated_at":"2020-08-18T00:18:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-15T00:16:39Z",
  "comments":0,
  "created_at":"2020-08-12T18:04:31Z",
  "draft":false,
  "id":677878473,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY2OTI0OTIz",
  "number":389,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-15T00:16:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix that cuda-kernels build!",
  "updated_at":"2020-08-15T00:16:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Sliced virtual arrays could have a form if the original virtual array does, but this requires duplicating the entire getitem logic in parallel for Form classes. This is a big task, which can be put off. However, we need at least to be able to find `purelist_parameter(\"__record__\")` to properly type the highlevel virtual arrays, so this implements just enough Form traversal to always be able to extract the `__record__` type.\r\n\r\nIn parallel (probably should have been a separate PR) numba needs a Form to type sliced VirtualArrays. Since they are materialized on entry into the numba function, we can cache the Form in ArrayGenerator when it was not previously available.",
  "closed_at":"2020-08-19T17:33:10Z",
  "comments":5,
  "created_at":"2020-08-14T00:05:11Z",
  "draft":false,
  "id":678809897,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY3Njk3NzE3",
  "number":390,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-19T17:33:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"VirtualArray has correct __record__ parameter",
  "updated_at":"2020-08-19T17:33:10Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I've recently started switching over to awkawrd1, and I'd like to create a new array with the same layout (or just shape - I'm not yet sure if different content types are considered different layouts - say int vs float or even int8 vs int32). For example, I have a constant mass hypothesis that I want with every jagged four vector. Or a constant weight for each row. I'm happy to add a concrete example if helpful.\r\n\r\nIn awkward0, I would call `ones_like()` and then multiply by my value. For numpy, I would use `np.ones_like(...)` and again multiply. But having looked through the awkward1 documentation, I can't seem to find the equivalent. As far as I understand, I can't just do this with `ak.Array`. I'm sure it's possible in awkward1 and that I'm overlooking the right term (I've been reading the awkward1 docs over a number of updates, so it's certainly possible that I've missed it), but some additional documentation on this could be helpful - I imagine that I won't be the only person looking for something like this. Or if it already exists, could you point me in the right direction?\r\n\r\nThanks!",
  "closed_at":"2022-07-06T17:21:10Z",
  "comments":7,
  "created_at":"2020-08-14T10:35:05Z",
  "id":679067414,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzkwNjc0MTQ=",
  "number":391,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Requesting Awkward 0 \u2192 Awkward 1 cheat-sheet",
  "updated_at":"2022-07-06T17:34:02Z",
  "user":"MDQ6VXNlcjE1NzE5Mjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Probably low priority, as ``awkward1.from_numpy`` does.\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> import numpy as np\r\n\r\n>>> ak.from_iter([0j])\r\n\r\n~/venv/awkward/lib/python3.6/site-packages/awkward1/operations/convert.py in from_iter(iterable, highlevel, behavior, allow_record, initial, resize)\r\n    359     out = awkward1.layout.ArrayBuilder(initial=initial, resize=resize)\r\n    360     for x in iterable:\r\n--> 361         out.fromiter(x)\r\n    362     layout = out.snapshot()\r\n    363     if highlevel:\r\n\r\nValueError: cannot convert 0j (type complex) to an array element\r\n\r\n>>> ak.from_numpy(np.asarray([0j]))\r\n <Array [0j] type='1 * complex128'>\r\n```",
  "closed_at":"2021-02-02T16:09:46Z",
  "comments":10,
  "created_at":"2020-08-14T12:41:35Z",
  "id":679148505,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2NzkxNDg1MDU=",
  "number":392,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Complex numbers (in ak.from_iter and elsewhere)",
  "updated_at":"2021-02-02T16:09:46Z",
  "user":"MDQ6VXNlcjM1MzAyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I've opened some trees with uproot4 and written the arrays in the parquet format using `ak.to_parquet` (from some quick tests that I ran, reading from parquet files seems much faster for doubly jagged arrays as compared to TTrees). When the parquet file is read back, from the docs I understand that the type is not exactly the same because the fields are nullable. This appears to lead to some unintuitive results (for the same data, `arrays` is loaded from the parquet file, while`arrays_original` is read directly via uproot):\r\n\r\n```python\r\nIn [1]: arrays_original[\"data.fJetPt\"].layout\r\nOut[1]: <NumpyArray format=\"f\" shape=\"25109\" data=\"22.3846 21.4953 20.3251 26.6239 23.0994 ... 21.6158 21.8578 22.133 26.5842 20.8287\" at=\"0x7fafb6180000\"/>\r\n\r\nIn [2]: arrays_original[\"data.fJetPt\"] > 0\r\nOut[2]: <Array [True, True, True, ... True, True, True] type='25109 * bool'>\r\n\r\nIn [3]: arrays[\"data.fJetPt\"].layout\r\nOut[3]:\r\n<BitMaskedArray valid_when=\"true\" length=\"25109\" lsb_order=\"true\">\r\n    <mask><IndexU8 i=\"[255 255 255 255 255 ... 255 255 255 255 31]\" offset=\"0\" length=\"3139\" at=\"0x0001114b0000\"/></mask>\r\n    <content><NumpyArray format=\"f\" shape=\"25109\" data=\"22.3846 21.4953 20.3251 26.6239 23.0994 ... 21.6158 21.8578 22.133 26.5842 20.8287\" at=\"0x0001140be600\"/></content>\r\n</BitMaskedArray>\r\n\r\nIn [4]: arrays[\"data.fJetPt\"] > 0\r\nOut[4]: <Array [None, None, None, ... None, None, None] type='25109 * ?bool'>\r\n```\r\n\r\nThe output from [4] is not so intuitive from my perspective. My expectation was that it would evaluate to a mask, and if there were somehow missing values (which isn't the case here), then either leave them as None, or return False (because the condition couldn't be evaluated). I think I can sort of follow what's happening: the array is wrapped in a `BitMaskedArray` (hence the nullable), so asking for `bool > 0` is interpreted as a comparison that can't be made, and it returns `None`. I also see that I can work with the arrays as normal by `ak.fill_none(arrays[\"data.fJetPt\"], 0)`, which then makes the types non-nullable.\r\n\r\nI'm filling this as a bug report because it seems confusing, but it could alternatively be interpreted as a documentation request to add a note to the arrow conversion page that users will likely want to apply `fill_none` (not ideal if you actually mean to have `None`, but I'm not sure what to do in that case). Otherwise, it seems that many of the `ak` functions don't work (for example, `ak.to_numpy` also doesn't work), which can be rather confusing.\r\n\r\nThanks!",
  "closed_at":"2020-08-17T13:35:36Z",
  "comments":8,
  "created_at":"2020-08-16T23:53:05Z",
  "id":679852538,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2Nzk4NTI1Mzg=",
  "number":393,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Unintuitive results working with nullable data (from parquet)",
  "updated_at":"2020-08-17T13:36:10Z",
  "user":"MDQ6VXNlcjE1NzE5Mjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-17T13:35:36Z",
  "comments":0,
  "created_at":"2020-08-17T13:05:09Z",
  "draft":false,
  "id":680220515,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY4ODE5MzA0",
  "number":394,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-17T13:35:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixed #393 (BitMaskedArray::bytemask output should be equivalent to valid_when=False).",
  "updated_at":"2020-08-17T13:35:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"When passing sliced arrays to a numba jitted function, I'm receiving inconsistent values in the array. It's probably easiest to see in the reproducer code:\r\n\r\n```python\r\nimport awkward1 as ak\r\nimport numba as nb\r\n\r\nparquet_arrays = ak.from_parquet(\"AnalysisResults.18q.parquet\")\r\n# zip because I usually have other arrays\r\narrays = ak.zip({\"parent_index\": parquet_arrays[\"matched.fJetSplittings.fParentIndex\"]})\r\n\r\n@nb.njit\r\ndef reproduce(arrays):\r\n    i = 0\r\n    for values in arrays:\r\n        print(\"======== i =\", i)\r\n        parent_indices = values.parent_index\r\n        print(\"parent_indices\", parent_indices)\r\n        j = 0\r\n        for p in parent_indices:\r\n            print(j, \":\", p)\r\n            assert p == parent_indices[j]  # How??\r\n            j += 1\r\n        i += 1\r\n```\r\n\r\nThis gives a truncated output of:\r\n\r\n```\r\n>>> reproduce(arrays[:, :2])\r\n======== i = 0\r\nparent_indices []\r\n======== i = 1\r\nparent_indices [-1]\r\n0 : -1\r\n======== i = 2\r\nparent_indices [-1]\r\n0 : -1\r\n======== i = 3\r\nparent_indices [-1, 0]\r\n0 : 1\r\n1 : 2\r\n======== i = 4\r\nparent_indices []\r\n======== i = 5\r\nparent_indices [-1, 0]\r\n0 : 0\r\n1 : -1\r\n...\r\n```\r\n\r\nThe trouble starts at i = 3. Based on the printed values from `parent_indices`, it should be 0 : -1, 1: 0 (checked outside of the jitted function). Instead, the values are incremented by 2. Then for i = 5, the values are switched. Some observations:\r\n\r\n- `njit` -> `jit` has the same issue.\r\n- Asserting the `p` values vs parent_indices at the index claims that they agree.\r\n- If I drop the numba decorator, everything works fine.\r\n- If I remove the `:2` slice, everything works fine.\r\n\r\nFor reference, the truncated expected output:\r\n\r\n```\r\n======== i = 0\r\nparent_indices []\r\n======== i = 1\r\nparent_indices [-1]\r\n0 : -1\r\n======== i = 2\r\nparent_indices [-1]\r\n0 : -1\r\n======== i = 3\r\nparent_indices [-1, 0]\r\n0 : -1\r\n1 : 0\r\n======== i = 4\r\nparent_indices []\r\n======== i = 5\r\nparent_indices [-1, 0]\r\n0 : -1\r\n1 : 0\r\n...\r\n```\r\n\r\nand the layout:\r\n```python\r\n>>> arrays.parent_index.layout\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 0 1 2 8 ... 47597 47598 47598 47598 47599]\" offset=\"0\" length=\"25110\" at=\"0x7fcb16199000\"/></offsets>\r\n    <content><NumpyArray format=\"h\" shape=\"47599\" data=\"-1 -1 -1 0 1 ... 0 -1 -1 -1 -1\" at=\"0x7fcb162b2000\"/></content>\r\n</ListOffsetArray64>\r\n```\r\n\r\nUnfortunately, I'm only able to reproduce this via a stored file. Maybe it's something about parquet, or maybe I didn't come up with a complex enough example. I need to keep it private, so I'm emailing it to you (it's similar but not identical to the file that I sent for the uproot4 issue last week). It was basically produced with:\r\n\r\n```python\r\nimport uproot4 as uproo4\r\ntree = uproot.open(\"AnalysisResults.root\")\r\narrays = tree.arrays([\"branch1\", ...])\r\nak.to_parquet(arrays, \"AnalysisResults.18q.parquet\")\r\n```\r\n\r\nI can also provide the original root file if it helps. Thanks!",
  "closed_at":"2020-08-18T18:09:44Z",
  "comments":3,
  "created_at":"2020-08-17T20:06:53Z",
  "id":680494673,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODA0OTQ2NzM=",
  "number":395,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Sliced arrays yields inconsistent values in numba jitted function",
  "updated_at":"2020-08-20T08:54:59Z",
  "user":"MDQ6VXNlcjE1NzE5Mjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This managed to escape earlier Numba IndexedArray tests because it's only invoked when there's an index and a viewport that doesn't start at `0`, such as an IndexedArray inside of a ListOffsetArray. The new test tests this and also non-zero offsets.",
  "closed_at":"2020-08-18T18:09:44Z",
  "comments":0,
  "created_at":"2020-08-18T16:04:27Z",
  "draft":false,
  "id":681159327,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY5NTk0NzM5",
  "number":396,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-18T18:09:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #395: IndexedArray was updating both the ArrayView viewport and 'nextat'; only one is allowed.",
  "updated_at":"2020-08-18T18:10:19Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-18T23:11:05Z",
  "comments":2,
  "created_at":"2020-08-18T18:17:29Z",
  "draft":false,
  "id":681239242,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY5NjYwNTYw",
  "number":397,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-18T23:11:04Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Awkward data should be registered as Numba constants so that they can be passed as closures to Numba-compiled functions.",
  "updated_at":"2020-08-18T23:11:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-18T20:51:30Z",
  "comments":0,
  "created_at":"2020-08-18T20:17:30Z",
  "draft":false,
  "id":681312913,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY5NzIxOTg0",
  "number":398,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-18T20:51:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Truncate generated outparams only to required length",
  "updated_at":"2020-08-18T20:51:33Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"   - [X] Add macros to all the C++ exceptions.\r\n   - [x] Add `filename` as an `Error` struct field and have all the kernels report their line numbers as well.\r\n   - [x] Make sure that the kernel-specification/documentation still works.\r\n   - [x] Use [this trick](https://stackoverflow.com/a/45973535/1623645) to do the same for all Python exceptions. Be careful to only say `sys._getframe()` if `hasattr(sys, \"_getframe\")`.",
  "closed_at":"2020-08-19T04:09:13Z",
  "comments":0,
  "created_at":"2020-08-19T01:03:37Z",
  "draft":false,
  "id":681473648,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDY5ODYyOTMy",
  "number":399,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-19T04:09:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"All exceptions should report their version, file, and line number as GitHub links.",
  "updated_at":"2020-08-19T04:09:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Moving @drahnreb's comment to a new issue, because it's unrelated to Parquet file partitioning. Original text below:\r\n\r\nI found a rather weird behaviour that seems to be linked to partitioned parquets and my suggested \"workaround\".\r\n> ```python\r\n> # current workaround with pq directly\r\n> table = pq.read_table(parquet_dir)\r\n> ak.from_arrow(table)\r\n> ```\r\n\r\nAs this is not a supported feature, I did not want to open a bug report but figured it's worth sharing as it took me a while to figure out that the above seems to cause the following issue.\r\nPreviously loaded partitioned data and slicing it (on a low level) will result in a `ValueError: in IndexedArray32 attempting to get xxx, index[i] >= len(content)` when saving to parquet and reloading.\r\n\r\nWorking Example:\r\nA bit more extensive that explains the principles of what I am trying to achieve, as I realized the combination of certain aspects matter esp. details about the containing dtypes and conversions.\r\nI couldn't figure out what is happening. I first suspected wrong advanced slicing (#370) or the type conversion awk-parquet-arrow as described [here](https://awkward-array.org/how-to-convert-arrow.html) or (#393).\r\nIt was difficult to reproduce the results - so it might not be really a minimal example. Sorry for that!\r\n\r\n```python\r\n# let's create some fake data that will be saved as parquet\r\ndf = pd.DataFrame([{\"id\": n, \"label\": np.random.choice([\"OK\", \"NOK\"], 1)[0], \"year\": np.random.choice([2019, 2020], 1), \"arr\": np.random.rand(np.random.randint(0,100))} for n in range(10000)])\r\n# cast label\r\ndf.label = df.label.astype(\"category\")\r\ndf.year = df.year.astype(\"uint32\")\r\n# index\r\ndf.set_index(['id'], inplace=True)\r\n# save as partioned parquet\r\ndf.to_parquet('test.parquet',\r\n              partition_cols=['year'], # this seems to be crucial\r\n              version='2.0',\r\n              data_page_version='2.0')\r\n# let's get started. reload\r\ntable = pq.read_table('t.parquet')\r\n# load as awkward array\r\noriginal = ak.from_arrow(table)\r\n```\r\n```python\r\n>>> original.layout\r\n<RecordArray>\r\n    <field index=\"0\" key=\"label\">\r\n        <IndexedArray64>\r\n            <index><Index64 i=\"[0 0 0 1 0 ... 19 19 19 18 18]\" offset=\"0\" length=\"20026\" at=\"0x55d32435ff10\"/></index>\r\n            <content><ListArray64>\r\n                <parameters>\r\n                    <param key=\"__array__\">\"string\"</param>\r\n                </parameters>\r\n                <starts><Index64 i=\"[0 3 5 8 10 ... 38 40 43 45 48]\" offset=\"0\" length=\"20\" at=\"0x55d31bdf77d0\"/></starts>\r\n                <stops><Index64 i=\"[3 5 8 10 13 ... 40 43 45 48 50]\" offset=\"0\" length=\"20\" at=\"0x55d31be3ff70\"/></stops>\r\n                <content><NumpyArray format=\"B\" shape=\"50\" data=\"78 79 75 79 75 ... 78 79 75 79 75\" at=\"0x55d30a4851b0\">\r\n                    <parameters>\r\n                        <param key=\"__array__\">\"char\"</param>\r\n                    </parameters>\r\n                </NumpyArray></content>\r\n            </ListArray64></content>\r\n        </IndexedArray64>\r\n    </field>\r\n    <field index=\"1\" key=\"arr\">\r\n        <ListArray64>\r\n            <starts><Index64 i=\"[0 26 46 54 81 ... 995057 995093 995152 995214 995284]\" offset=\"0\" length=\"20026\" at=\"0x55d3243870f0\"/></starts>\r\n            <stops><Index64 i=\"[26 46 54 81 150 ... 995093 995152 995214 995284 995357]\" offset=\"0\" length=\"20026\" at=\"0x55d3243ae2d0\"/></stops>\r\n            <content><IndexedOptionArray64>\r\n                <index><Index64 i=\"[0 1 2 3 4 ... 995352 995353 995354 995355 995356]\" offset=\"0\" length=\"995357\" at=\"0x55d328748590\"/></index>\r\n                <content><NumpyArray format=\"f\" shape=\"995357\" data=\"0.726096 0.590173 0.699854 0.116417 0.743831 ... 0.0755084 0.756987 0.240388 0.158446 0.722705\" at=\"0x55d312824ab0\"/></content>\r\n            </IndexedOptionArray64></content>\r\n        </ListArray64>\r\n    </field>\r\n    <field index=\"2\" key=\"id\">\r\n        <IndexedOptionArray64>\r\n            <index><Index64 i=\"[0 1 2 3 4 ... 20021 20022 20023 20024 20025]\" offset=\"0\" length=\"20026\" at=\"0x55d3243d54b0\"/></index>\r\n            <content><NumpyArray format=\"l\" shape=\"20026\" data=\"2 3 4 8 9 ... 9984 9987 9992 9996 9998\" at=\"0x55d312bf0b30\"/></content>\r\n        </IndexedOptionArray64>\r\n    </field>\r\n    <field index=\"3\" key=\"year\">\r\n        <NumpyArray format=\"i\" shape=\"20026\" data=\"2019 2019 2019 2019 2019 ... 2020 2020 2020 2020 2020\" at=\"0x55d3233b27b0\"/>\r\n    </field>\r\n</RecordArray>\r\n```\r\nMain focus is on the field `label` with a `ListArray64` that is nested in `IndexedArray64`.\r\n\r\nLet's now mask the array and slice based on indices within each variable length array.\r\n```python\r\n# might be irrelevant\r\nremove = np.random.choice([False, True], size=len(original))\r\nmasked = original[~remove].copy()\r\n# \"materialize\"\r\nmasked = ak.flatten(masked, axis=0)\r\n# slice nested arrays based on #370 (unofficial slicing)\r\nstarts = np.asarray(masked.arr.layout.starts).astype(\"uint64\")\r\nstops = np.asarray(masked.arr.layout.stops).astype(\"uint64\")\r\n# gather plausible indices with intrinsic information (here randomized)\r\ndef _get_each_idx(starts, stops):\r\n    diffs = stops-starts\r\n    nzd = diffs[np.where(diffs > 0)[0]]\r\n    rs = np.random.randint(np.zeros(len(nzd)).astype(int), nzd)\r\n    diffs[np.where(diffs != 0)[0]] = rs\r\n    return diffs.astype(\"uint64\")\r\n# set  new stops and starts\r\nstart_idx = _get_each_idx(starts, stops)\r\nnew_starts = start_idx + starts\r\nend_idx = _get_each_idx(new_starts, stops)\r\nnew_stops = end_idx + new_starts\r\n# change nested arrays (based on unofficial lowlevel layout)\r\nlayout = masked.layout\r\nfields = []\r\nfor k in layout.keys():\r\n    if not k in ['arr']:\r\n        fields.append(layout[k])\r\n    else:\r\n        fields.append(ak.layout.ListArray64(\r\n            ak.layout.Index64(starts_n),\r\n            ak.layout.Index64(stops_n),\r\n            layout[k].content\r\n            )\r\n        )\r\n\r\n# main result. reconstruct back to a RecordArray.   \r\nsliced = ak.layout.RecordArray(\r\n        fields,\r\n        layout.keys()\r\n    )\r\n```\r\nWhile this is a low level composing of arrays it provides consistent arrays and works until the result is exported as parquet.\r\n```python\r\n>>> ak.is_valid(original), ak.validity_error(original), ak.is_valid(masked), ak.validity_error(masked), ak.is_valid(sliced), ak.validity_error(sliced)\r\n(True, None, True, None, True, None)\r\n```\r\n\r\nThe problem starts when reloading data.\r\n```python\r\n>>> sliced_arr = ak.Array(sliced)\r\n>>> sliced_arr = ak.flatten(sliced_arr, axis=0)\r\n>>> ak.to_parquet(sliced_arr, \"tmp.parquet\")\r\n\r\n>>> loaded = ak.from_parquet(\"tmp.parquet\")\r\n>>> loaded\r\n<Array [{label: 'NOK', arr: [, ... year: 2020}] type='10054 * {\"label\": string, ...'>\r\n>>> ak.is_valid(loaded), ak.validity_error(loaded)\r\n(False,\r\n 'at layout.field(0) (IndexedArray32): index[i] >= len(content) at i=4936')\r\n```\r\n\r\nJagged arrays can be accessed along the entire axis.\r\n```python\r\n>>> sliced_arr.arr[10000]\r\n<Array [0.982, 0.695, 0.111, ... 0.637, 0.984] type='77 * ?float32'>\r\n>>> sliced_arr.label[10000]\r\n'NOK'\r\n>>> loaded.arr[10000]\r\n<Array [0.982, 0.695, 0.111, ... 0.637, 0.984] type='77 * ?float32'>\r\n```\r\n\r\n... `label` field will throw a ValueError: in IndexedArray32 attempting to get 4936, index[i] >= len(content)\r\n```python\r\nfor i in range(len(loaded)):\r\n    try:\r\n        loaded[i, 'label'].tolist()\r\n    except ValueError:        \r\n        print(i)\r\n        pass\r\n```\r\n\r\n\r\n@jpivarski\r\n\r\n_Originally posted by @drahnreb in https://github.com/scikit-hep/awkward-1.0/issues/368#issuecomment-676286664_",
  "closed_at":"2020-08-19T18:46:06Z",
  "comments":11,
  "created_at":"2020-08-19T14:31:08Z",
  "id":681888573,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODE4ODg1NzM=",
  "number":400,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Writing a non-minimal categorical/dictionary to Parquet corrupts it",
  "updated_at":"2020-08-22T14:49:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-19T18:46:06Z",
  "comments":0,
  "created_at":"2020-08-19T17:04:41Z",
  "draft":false,
  "id":682001478,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcwMzAwNTky",
  "number":401,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-19T18:46:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add some missing GitHub URLs in exceptions (finishing #399).",
  "updated_at":"2020-08-19T18:46:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I closed PR #390 as-is because it solves @nsmith-'s problem, but `Form::getitem_field` is defined in a non-intuitive way.\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/6a3e6bed7fb5312d3190f2299abca71299b1a86c/include/awkward/Content.h#L226-L234\r\n\r\nThis issue is to clean that up and make sure that @nsmith-'s tests still work. Maybe we should add `Form::getitem_fields` as well, since it's nearly the same thing and would be expected to have the same materializing/non-materializing behavior.\r\n\r\nThis is good first issue for someone interested in how these nodes fit together and is willing to delve into C++.",
  "closed_at":"2020-11-09T23:23:21Z",
  "comments":0,
  "created_at":"2020-08-19T17:46:46Z",
  "id":682024681,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODIwMjQ2ODE=",
  "number":402,
  "performed_via_github_app":null,
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":"completed",
  "title":"Make Form::getitem_field correctly mirror Content::getitem_field",
  "updated_at":"2020-11-09T23:23:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"As discussed in #400.\r\n\r\nDon't forget:\r\n\r\n  - [x] Better string representation of categorical types.\r\n  - [x] Zip without an explicit `depth_limit` should not break up strings.\n  - [x] Arrays from Arrow without a bitmask must be mapped to `UnmaskedArray` to maintain type.\r\n  - [x] Apply this to Arrow conversion.\r\n",
  "closed_at":"2020-08-20T15:16:24Z",
  "comments":0,
  "created_at":"2020-08-19T18:55:44Z",
  "draft":false,
  "id":682072796,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcwMzYwNzQ3",
  "number":403,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-20T15:16:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Introduce a 'categorical' type (behavioral, just as 'string' is) that is the only thing that passes to Arrow as DictionaryArray.",
  "updated_at":"2020-08-20T15:21:18Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The validity rules can be defined in Python and passed into C++ in much the same way that `__typestr__` is passed from behavior into the C++ `typestr` method, and callbacks from C++ into Python can be enabled with a similar technique as ArrayGenerator.\r\n\r\nBut basically, [ak.is_valid](https://awkward-array.readthedocs.io/en/latest/_auto/ak.is_valid.html) and [ak.validity_error](https://awkward-array.readthedocs.io/en/latest/_auto/ak.validity_error.html) should complain if string validity rules aren't satisfied:\r\n\r\n   * `\"string\"` and `\"bytestring\"` can only be applied to ListArray, ListOffsetArray, and RegularArray.\r\n   * `\"char\"` and `\"byte\"` can only be applied to NumpyArray.\r\n   * The `\"char\"`/`\"byte\"` must be directly embedded within the `\"string\"`/`\"bytestring\"`.\r\n\r\nThe categorical validity rules must also be satisfied:\r\n\r\n   * `\"categorical\"` can only be applied to IndexedArray* and IndexedOptionArray*.\r\n   * That indexed array's `content` must consist of unique values.",
  "closed_at":"2021-06-07T20:34:15Z",
  "comments":2,
  "created_at":"2020-08-19T20:28:30Z",
  "id":682158504,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODIxNTg1MDQ=",
  "number":404,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Validity-checking should depend on known parameters, like \"string\" and \"categorical\".",
  "updated_at":"2021-06-07T20:34:15Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"",
  "closed_at":"2020-11-30T14:20:20Z",
  "comments":7,
  "created_at":"2020-08-20T18:31:29Z",
  "draft":true,
  "id":683008631,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcxMTY4MDg5",
  "number":405,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Introduce ak.from_pandas",
  "updated_at":"2021-04-25T21:51:10Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Also fixes single kernel spec printing.\r\n\r\nThis should make the Python -> CUDA generation a little easier.",
  "closed_at":"2020-08-21T14:01:23Z",
  "comments":14,
  "created_at":"2020-08-21T11:48:49Z",
  "draft":false,
  "id":683505097,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcxNTg2NTk1",
  "number":406,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-21T14:01:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Handle some cases where C for loop was translated to Python while loop",
  "updated_at":"2020-08-21T14:02:19Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-21T14:22:33Z",
  "comments":0,
  "created_at":"2020-08-21T13:52:37Z",
  "draft":false,
  "id":683577679,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcxNjQ3MTE2",
  "number":407,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-21T14:22:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix warnings reported by MacOS/Cling and try PIP_ONLY_BINARY instead of restricting cmake version.",
  "updated_at":"2020-08-21T14:22:36Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"# Overview\r\nWhen running `ak.argmin()` over certain arrays, the indices are negative.\r\n\r\n## Reproduce\r\nHere is an excerpt of an array i am using that caused the bug:\r\n```\r\ntester = ak.Array([[[10.249728202819824, 8.437639236450195, 7.679991722106934, 1.2447497844696045, 9.229813575744629, 0.005525465123355389], [None, None, None, None, None, None]], \r\n    [[None , None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None]], \r\n    [[9.047218322753906, 2.489292621612549, 13.802090644836426, 0.040674030780792236, 0.6052520275115967, 12.557860374450684, 24.019344329833984, 2.9109175205230713, 0.9435217380523682], [None, None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None, None]]])       \r\nak.argmin(tester, axis=-1)  \r\n# [[5, None], [None, None], [-19, None, None, None]]   \r\n# Should be [[5, None], [None, None], [3, None, None, None]]\r\n```\r\nIf there are a block of nones ahead of subarray that has numbers that need to be actually minimized, the value becomes negative. Also, the indices get more and more negative farther in the list, as if the indexing problem cascades to the next block.\r\n\r\nNot sure if this helps either, but the other axes fail as well in the same way.\r\n```\r\nak.argmin(tester, axis=-2)\r\n#  [[0, -6, -12, -18, -24, -30],\r\n#   [None, None, None, None, None, None, None, None],\r\n#   [-3, -9, -15, -21, -27, -33, -38, -43, -46]]\r\n```\r\n",
  "closed_at":"2020-08-22T09:08:30Z",
  "comments":7,
  "created_at":"2020-08-21T14:25:54Z",
  "id":683600430,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODM2MDA0MzA=",
  "number":408,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Argmin gives negative values",
  "updated_at":"2020-08-22T09:14:03Z",
  "user":"MDQ6VXNlcjEyNDU1NDc5"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-10-08T16:21:23Z",
  "comments":0,
  "created_at":"2020-08-21T14:53:58Z",
  "draft":false,
  "id":683618412,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcxNjgxNDUw",
  "number":409,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-10-08T16:21:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"The next section is \"Creating arrays,\" though I'll fill out whatever documentation makes sense next.",
  "updated_at":"2020-10-08T16:21:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Bug reported in #408, but https://github.com/scikit-hep/awkward-1.0/issues/408#issuecomment-678403354 may be more fundamental.\r\n\r\n~~Maybe this should finally address #203, since we want the output of argmin/max to be _useful_.~~",
  "closed_at":"2020-08-22T09:08:30Z",
  "comments":0,
  "created_at":"2020-08-21T17:30:45Z",
  "draft":false,
  "id":683708193,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcxNzU1ODE5",
  "number":410,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-22T09:08:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix argmin/max positions for missing values.",
  "updated_at":"2020-08-22T09:08:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"After doing a `pip install awkward-1.0`, I get the following warnings from brew:\r\n\r\n```\r\nWarning: Unbrewed dylibs were found in /usr/local/lib.\r\nIf you didn't put them there on purpose they could cause problems when\r\nbuilding Homebrew formulae, and may need to be deleted.\r\n\r\nUnexpected dylibs:\r\n  /usr/local/lib/libawkward-cpu-kernels.dylib\r\n  /usr/local/lib/libawkward.dylib\r\n\r\nWarning: Unbrewed header files were found in /usr/local/include.\r\nIf you didn't put them there on purpose they could cause problems when\r\nbuilding Homebrew formulae, and may need to be deleted.\r\n\r\nUnexpected header files:\r\n  /usr/local/include/awkward/Content.h\r\n  /usr/local/include/awkward/Identities.h\r\n  /usr/local/include/awkward/Index.h\r\n  /usr/local/include/awkward/Iterator.h\r\n  /usr/local/include/awkward/Reducer.h\r\n  /usr/local/include/awkward/Slice.h\r\n  /usr/local/include/awkward/array/EmptyArray.h\r\n  /usr/local/include/awkward/array/IndexedArray.h\r\n  /usr/local/include/awkward/array/ListArray.h\r\n  /usr/local/include/awkward/array/ListOffsetArray.h\r\n  /usr/local/include/awkward/array/None.h\r\n  /usr/local/include/awkward/array/NumpyArray.h\r\n  /usr/local/include/awkward/array/RawArray.h\r\n  /usr/local/include/awkward/array/Record.h\r\n  /usr/local/include/awkward/array/RecordArray.h\r\n  /usr/local/include/awkward/array/RegularArray.h\r\n  /usr/local/include/awkward/array/UnionArray.h\r\n  /usr/local/include/awkward/builder/ArrayBuilder.h\r\n  /usr/local/include/awkward/builder/ArrayBuilderOptions.h\r\n  /usr/local/include/awkward/builder/BoolBuilder.h\r\n  /usr/local/include/awkward/builder/Builder.h\r\n  /usr/local/include/awkward/builder/Float64Builder.h\r\n  /usr/local/include/awkward/builder/GrowableBuffer.h\r\n  /usr/local/include/awkward/builder/IndexedBuilder.h\r\n  /usr/local/include/awkward/builder/Int64Builder.h\r\n  /usr/local/include/awkward/builder/ListBuilder.h\r\n  /usr/local/include/awkward/builder/OptionBuilder.h\r\n  /usr/local/include/awkward/builder/RecordBuilder.h\r\n  /usr/local/include/awkward/builder/StringBuilder.h\r\n  /usr/local/include/awkward/builder/TupleBuilder.h\r\n  /usr/local/include/awkward/builder/UnionBuilder.h\r\n  /usr/local/include/awkward/builder/UnknownBuilder.h\r\n  /usr/local/include/awkward/cpu-kernels/getitem.h\r\n  /usr/local/include/awkward/cpu-kernels/identities.h\r\n  /usr/local/include/awkward/cpu-kernels/operations.h\r\n  /usr/local/include/awkward/cpu-kernels/reducers.h\r\n  /usr/local/include/awkward/cpu-kernels/util.h\r\n  /usr/local/include/awkward/io/json.h\r\n  /usr/local/include/awkward/io/root.h\r\n  /usr/local/include/awkward/python/content.h\r\n  /usr/local/include/awkward/python/identities.h\r\n  /usr/local/include/awkward/python/index.h\r\n  /usr/local/include/awkward/python/util.h\r\n  /usr/local/include/awkward/type/ArrayType.h\r\n  /usr/local/include/awkward/type/ListType.h\r\n  /usr/local/include/awkward/type/OptionType.h\r\n  /usr/local/include/awkward/type/PrimitiveType.h\r\n  /usr/local/include/awkward/type/RecordType.h\r\n  /usr/local/include/awkward/type/RegularType.h\r\n  /usr/local/include/awkward/type/Type.h\r\n  /usr/local/include/awkward/type/UnionType.h\r\n  /usr/local/include/awkward/type/UnknownType.h\r\n  /usr/local/include/awkward/util.h\r\n\r\nWarning: Unbrewed static libraries were found in /usr/local/lib.\r\nIf you didn't put them there on purpose they could cause problems when\r\nbuilding Homebrew formulae, and may need to be deleted.\r\n\r\nUnexpected static libraries:\r\n  /usr/local/lib/libawkward-cpu-kernels-static.a\r\n  /usr/local/lib/libawkward-static.a\r\n```\r\n\r\nI'm still wrestling with the best place to put headers and libraries, but for now, might it be a good idea to split the package into two parts; a python-only part (with the compiled python modules), and a \"using python packaging to distribute a non-python module\" one? For example, if you wanted to add awkward-1 to a package manager, a simple `pip install awkward-1` currently would overwrite the files. In the spirit of pytest's `--disable_test_id_escaping_and_forfeit_all_rights_to_community_support`, you could call it `awkward-c-libraries-will-install-to-your-core-folders-if-not-in-a-virtual-environment` ;). Or, more realistically, `awkward-cpp`. (`awkward-core` would make it seem like `awkward` would depend on it, which it would not).",
  "closed_at":"2020-09-08T01:57:31Z",
  "comments":4,
  "created_at":"2020-08-21T20:56:27Z",
  "id":683823649,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODM4MjM2NDk=",
  "number":411,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"pip installing awkward causes warning in brew about unexpected files being present",
  "updated_at":"2020-09-08T02:10:45Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-22T17:14:22Z",
  "comments":2,
  "created_at":"2020-08-22T15:40:35Z",
  "draft":false,
  "id":684017258,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcyMDAyNDA4",
  "number":412,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-22T17:14:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add const info to kernel spec",
  "updated_at":"2020-08-22T19:31:13Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-23T21:58:53Z",
  "comments":0,
  "created_at":"2020-08-23T18:22:48Z",
  "draft":false,
  "id":684232388,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcyMTU5ODI5",
  "number":413,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-23T21:58:52Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Better error message if unable to find cpu-kernel shared object",
  "updated_at":"2020-08-23T21:58:58Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"tests-cuda-kernels will be a new directory in the future",
  "closed_at":"2020-08-24T13:38:08Z",
  "comments":1,
  "created_at":"2020-08-24T11:10:44Z",
  "draft":false,
  "id":684579744,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDcyNDQzMjg1",
  "number":414,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-24T13:38:08Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Restructure test locations",
  "updated_at":"2020-08-24T13:38:11Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Thanks for adding the ``to_parquet`` writing functionality.\r\n\r\nI've been trying it out and run into a couple of issues. Here is a test case:\r\n\r\n```python\r\n@pytest.mark.parametrize(\"dtype\", [np.float32, np.complex64])\r\ndef test_awkward_arrays_pandas(tmp_path, dtype):\r\n    ak = pytest.importorskip(\"awkward1\")\r\n    pa = pytest.importorskip(\"pyarrow\")\r\n    fastparquet = pytest.importorskip(\"fastparquet\")\r\n\r\n\r\n    builder = ak.ArrayBuilder()\r\n    A = ak.from_numpy(np.array([0, 1, 2], dtype=dtype))\r\n    B = ak.from_numpy(np.array([0, 1], dtype=dtype))\r\n\r\n    with builder.list():\r\n        builder.append(A)\r\n\r\n    with builder.list():\r\n        builder.append(A)\r\n\r\n    with builder.list():\r\n        pass\r\n\r\n    with builder.list():\r\n        builder.append(B)\r\n\r\n    ak.to_parquet(builder.snapshot(), tmp_path / \"data.parquet\")\r\n```\r\n\r\nWith the float32 parametrization the following error occurs:\r\n\r\n```pybt\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:2116: in to_parquet\r\n    writer = pyarrow.parquet.ParquetWriter(**options)\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/pyarrow/parquet.py:551: in __init__\r\n    self.writer = _parquet.ParquetWriter(\r\npyarrow/_parquet.pyx:1280: in pyarrow._parquet.ParquetWriter.__cinit__\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   pyarrow.lib.ArrowNotImplementedError: Unhandled type for Arrow to Parquet schema conversion: dense_union<0: float=0, 1: float=1>\r\n\r\n```\r\n\r\n\r\nWith the complex64 parametrization, the following error occurs:\r\n\r\n```\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:2111: in to_parquet\r\n    first = next(iterator)\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:2107: in batch_iterator\r\n    yield pyarrow.RecordBatch.from_arrays([to_arrow(layout)], [\"\"])\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1693: in to_arrow\r\n    return recurse(layout)\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1441: in recurse\r\n    return recurse(small_layout, mask=mask)\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1412: in recurse\r\n    content_buffer = recurse(layout.content[: offsets[-1]])\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1552: in recurse\r\n    values = [recurse(x) for x in layout.contents]\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1552: in <listcomp>\r\n    values = [recurse(x) for x in layout.contents]\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1617: in recurse\r\n    return recurse(layout.content[index], mask)\r\n../../../../.cache/pypoetry/virtualenvs/ms-backends-8aHy9NJ9-py3.8/lib/python3.8/site-packages/awkward1/operations/convert.py:1336: in recurse\r\n    arrow_type = pyarrow.from_numpy_dtype(numpy_arr.dtype)\r\npyarrow/types.pxi:2591: in pyarrow.lib.from_numpy_dtype\r\n    ???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\n>   ???\r\nE   pyarrow.lib.ArrowNotImplementedError: Unsupported numpy type 14\r\n\r\npyarrow/error.pxi:105: ArrowNotImplementedError\r\n```\r\n\r\nThe failure on complex numbers is understandable given that the Arrow doesn't seem to natively support Complex Numbers, but I thought I'd post it here. I'd imagine that a reasonable solution would be to establish a 2D view of floats on the 1D array of complex numbers and output that to Arrow? Should this conversion happen in awkward or in pyarrow? I'm starting to learn the whole Arrow/Parquet ecosystem, so I'm feeling things out. xref #392.\r\n\r\nHowever, my gut feel is that the float32 case should work. What do you think?",
  "closed_at":"2020-08-25T19:01:18Z",
  "comments":6,
  "created_at":"2020-08-25T08:55:36Z",
  "id":685301919,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODUzMDE5MTk=",
  "number":415,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ArrayBuilder.append behavior can be confusing: what to do about union of T and T in snapshots?",
  "updated_at":"2020-08-26T07:29:59Z",
  "user":"MDQ6VXNlcjM1MzAyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-08-25T15:44:20Z",
  "comments":0,
  "created_at":"2020-08-25T14:35:45Z",
  "draft":false,
  "id":685539826,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDczMjQ5NzQ0",
  "number":416,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-25T15:44:20Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix references to np.object (where 'np' is a NumpyMetadata singleton).",
  "updated_at":"2020-08-25T15:44:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"At least fix the bug in #415; maybe also address the original complaint about unions of T and T. (What's the best way to proceed? Make it automatic, slowing down some `snapshot` operations, or make `ak.simplify` a user-visible operation?)",
  "closed_at":"2020-08-25T19:01:18Z",
  "comments":0,
  "created_at":"2020-08-25T15:23:10Z",
  "draft":false,
  "id":685578686,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDczMjgyODMz",
  "number":417,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-25T19:01:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix nesting structure of arrays passed to ArrayBuilder.append.",
  "updated_at":"2020-08-25T19:01:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Not sure if this is supported, but if i manually construct a `ListOffsetArray` that uses a numpy array in fortran order as content (happened to me accidentally since the output of some np operations return fortran ordered arrays) then things go wrong when i try multidimensional indexing:\r\n\r\n```pycon\r\n>>> import awkward1 as ak\r\n>>> import numpy as np\r\n>>> offsets = ak.layout.Index64(np.arange(0, 1010, 10))\r\n>>> np_content = np.asfortranarray(np.arange(0, 3000).reshape(-1, 3))\r\n>>> content = ak.layout.NumpyArray(np_content)\r\n>>> loa = ak.Array(ak.layout.ListOffsetArray64(offsets, content))\r\n>>> loa[0][0] # this is fine\r\n<Array [0, 1, 2] type='3 * int64'>\r\n>>> np_content[0]\r\narray([0, 1, 2])\r\n>>> loa[0, 0] # this goes wrong\r\n<Array [0, 0, 140236515206304] type='3 * int64'>\r\n```\r\n\r\nThe underlying `NumpyArray` seems to be aware of the fortran order strides and indexing it works as expected:\r\n\r\n```pycon\r\n>>> content\r\n<NumpyArray format=\"l\" shape=\"1000 3\" strides=\"8, 8000\" data=\"0x 00000000 00000000 03000000 00000000 ... b20b0000 00000000 b50b0000 00000000\" at=\"0x56001c85b610\"/>\r\n>>> content[0]\r\n<NumpyArray format=\"l\" shape=\"3\" strides=\"8000\" data=\"0 1 2\" at=\"0x56001c85b610\"/>\r\n>>> content[0][1]\r\n1\r\n>>> content[0, 1]\r\n1\r\n```",
  "closed_at":"2020-08-27T18:16:09Z",
  "comments":3,
  "created_at":"2020-08-27T14:09:25Z",
  "id":687274469,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODcyNzQ0Njk=",
  "number":418,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Multi dimensional indexing goes wrong for ListOffsetArray with numpy array content that is in fortran order",
  "updated_at":"2020-08-28T07:38:09Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"im trying to install the lib on a raspibian buster  but i cant \r\n\r\nim usinh python 3.7 and cmake 3.13\r\nsome one can help me ?",
  "closed_at":"2020-10-30T22:33:14Z",
  "comments":1,
  "created_at":"2020-08-27T14:49:48Z",
  "id":687305676,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2ODczMDU2NzY=",
  "number":419,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Pip3 install awkward1 on raspibian error",
  "updated_at":"2020-10-30T22:33:14Z",
  "user":"MDQ6VXNlcjcxMjEwMjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes #418.",
  "closed_at":"2020-08-27T18:16:09Z",
  "comments":0,
  "created_at":"2020-08-27T16:50:39Z",
  "draft":false,
  "id":687393043,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc0ODI2ODcz",
  "number":420,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-27T18:16:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"NumpyArray::bytelength and NumpyArray::carry were wrong for non-contiguous; fixed.",
  "updated_at":"2020-08-27T18:16:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Closes #392 ",
  "closed_at":"2020-11-26T14:19:41Z",
  "comments":18,
  "created_at":"2020-08-28T11:07:27Z",
  "draft":true,
  "id":687997172,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc1MzQxMjAx",
  "number":421,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Support complex numbers",
  "updated_at":"2020-11-26T14:19:41Z",
  "user":"MDQ6VXNlcjM1MzAyMTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"In addition to `__record__` since both are queried in every highlevel array instantiation.\r\nThis is a follow-up to #390 ",
  "closed_at":"2020-08-28T18:11:11Z",
  "comments":1,
  "created_at":"2020-08-28T15:30:07Z",
  "draft":false,
  "id":688157036,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc1NDczNTE5",
  "number":422,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-28T18:11:11Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Forward purelist_parameter \"__doc__\" in lazy slices",
  "updated_at":"2020-08-28T18:11:11Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Adds @sjperkins as a contributor for code.\n\nThis was requested by jpivarski [in this comment](https://github.com/scikit-hep/awkward-1.0/pull/421#issuecomment-682747852)",
  "closed_at":"2020-08-28T15:49:28Z",
  "comments":0,
  "created_at":"2020-08-28T15:48:40Z",
  "draft":false,
  "id":688168717,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc1NDgzMzA0",
  "number":423,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-28T15:49:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"docs: add sjperkins as a contributor",
  "updated_at":"2020-08-28T15:49:30Z",
  "user":"MDM6Qm90NDY0NDczMjE="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-08-29T13:10:44Z",
  "comments":2,
  "created_at":"2020-08-29T11:04:22Z",
  "draft":false,
  "id":688511500,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc1NzYwNzA0",
  "number":424,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-29T13:10:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Change const representation in kernel spec",
  "updated_at":"2020-08-29T13:10:59Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I got tired of looking at that as a \"bug\" when it's easily fixable.",
  "closed_at":"2020-08-31T15:51:18Z",
  "comments":0,
  "created_at":"2020-08-31T15:27:05Z",
  "draft":false,
  "id":689294059,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc2MzY5NzU2",
  "number":425,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-08-31T15:51:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #186; proper string-escape sequences in util::quote.",
  "updated_at":"2020-08-31T15:51:22Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Some of the kernels I had been able to generate don't work perfectly with the tests from the specification, implying that they might have been a little wrong. I have moved them down from `KERNEL_WHITELIST` to `KERNEL_CURIOUS`. ",
  "closed_at":"2020-09-01T17:49:24Z",
  "comments":0,
  "created_at":"2020-09-01T14:31:33Z",
  "draft":false,
  "id":690193101,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc3MTIzMTA4",
  "number":426,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-01T17:49:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Generate tests for CUDA kernels",
  "updated_at":"2020-09-01T17:49:27Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"To prevent undetectable cycles in nested virtual arrays as constructed often by `ak.from_arrayset`\r\n\r\nBasically, it seems python `gc` cannot find cycles that go through pybind11 members, and so a VirtualArray node may have a cache reference that contains a child layout node, preventing cleanup. This impacted NanoEvents quite badly: essentially all materialized arrays lasted forever.\r\nThe PR fixes this by making all virtual layout nodes hold weak references to the cache. It is up to the highlevel array object (and/or the user) to hold a strong reference to the array cache. Since all highlevel array operations forward `Array.cache`, the strong reference should be sticky enough for most purposes. In the case the cache reference is lost, the `ArrayCache` wrapper treats it as an error condition.",
  "closed_at":"2020-09-02T00:17:44Z",
  "comments":0,
  "created_at":"2020-09-01T23:47:19Z",
  "draft":false,
  "id":690520566,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc3Mzk1ODgx",
  "number":427,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-02T00:17:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement weak reference to virtual array caches",
  "updated_at":"2020-09-02T00:27:21Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Because I descoped cache chaining. Reasoning: as far as I can see, either:\r\n  a) the highlevel array has a cache property, in which case no need to chain\r\n  just for repr; or\r\n  b) the array does not have a cache which means either no virtual nodes are\r\n  in it or someone has very consciously said \u201cmaterialize every time\u201d, in which\r\n  case why should we provide a cache for repr",
  "closed_at":"2020-09-03T21:41:22Z",
  "comments":3,
  "created_at":"2020-09-02T02:30:23Z",
  "draft":false,
  "id":690665712,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc3NTI4OTEz",
  "number":428,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-03T21:41:22Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix a bug in repr due to weak cache refs",
  "updated_at":"2020-09-03T21:41:22Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-04T12:13:01Z",
  "comments":3,
  "created_at":"2020-09-02T10:13:37Z",
  "draft":false,
  "id":690896779,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc3NzE2MTgx",
  "number":429,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-04T12:13:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Generate more CUDA kernels",
  "updated_at":"2020-09-04T12:13:12Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello,\r\n\r\nI just found this library (looks awesome, looking forward to using it), but I am getting an error on import. Installing with pip raised no problems that I recall.\r\n\r\nI ran `import awkward1 as ak` in jupyter, and get the error:\r\n\r\n![image](https://user-images.githubusercontent.com/64329370/92030465-ecbe0f00-ed1b-11ea-861b-6428b86601c5.png)\r\n\r\nWhat causes this error, and how might I solve it? \r\n\r\nThank you!",
  "closed_at":"2020-09-21T20:55:50Z",
  "comments":22,
  "created_at":"2020-09-02T20:14:27Z",
  "id":691388701,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTEzODg3MDE=",
  "number":430,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Installing (and then importing) awkward1 on Windows",
  "updated_at":"2020-09-21T20:55:50Z",
  "user":"MDQ6VXNlcjY0MzI5Mzcw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"An omission from the previous implementation of weakrefs.\r\nApparently I had no cases of creating arrays that didn't have some sort of cache.",
  "closed_at":"2020-09-03T21:51:05Z",
  "comments":2,
  "created_at":"2020-09-03T20:58:21Z",
  "draft":false,
  "id":692350638,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc4OTU1MDg1",
  "number":431,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-03T21:51:05Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Allow ArrayCache(None) construction",
  "updated_at":"2020-09-03T21:51:05Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Starting with:\r\n```python\r\nimport awkward1 as ak\r\n\r\nclass Canary(dict):\r\n    def __getitem__(self, key):\r\n        print(f\"getting {key}\")\r\n        return super().__getitem__(key)\r\n\r\n\r\na = ak.zip({\"x\": [[0, 1, 2], [3, 4], [5]], \"y\": [[0, -1, -2], [-3, -4], [-5]]})\r\nform, container, _ = ak.to_arrayset(a)\r\n```\r\n\r\nIf I create a lazy array and call some method that should only need the offsets of the ListArray, everything works as expected:\r\n```python\r\nprint(\"no extra fields\")\r\nlazy = ak.from_arrayset(form, Canary(container), lazy=True, lazy_lengths=3)\r\nprint(\"calling firsts\")\r\nak.firsts(lazy)\r\n```\r\nreturns\r\n```\r\nno extra fields\r\ncalling firsts\r\ngetting node0-offsets\r\n```\r\n\r\nbut if I add a few new derived fields to the record, then for some reason the `y` field gets materialized:\r\n```python\r\nprint(\"extra fields\")\r\nlazy = ak.from_arrayset(form, Canary(container), lazy=True, lazy_lengths=3)\r\nlazy[\"a\"] = lazy.x * 1\r\nlazy[\"b\"] = lazy.x * 2\r\nlazy[\"c\"] = lazy.x * 3\r\nprint(\"calling firsts\")\r\nak.firsts(lazy)\r\n```\r\n\r\nreturns\r\n```\r\nextra fields\r\ngetting node0-offsets\r\ngetting node2\r\ncalling firsts\r\ngetting node3\r\n```\r\n\r\nPossibly related is the fact that `lazy.layout` in the second instance looks rather peculiar:\r\n```\r\n<ListOffsetArray64>\r\n    <offsets><Index64 i=\"[0 3 5 6]\" offset=\"0\" length=\"4\" at=\"0x7fe338801000\"/></offsets>\r\n    <content><RecordArray>\r\n        <field index=\"0\" key=\"x\">\r\n            <NumpyArray format=\"l\" shape=\"6\" data=\"0 1 2 3 4 5\" at=\"0x7fe3381020c0\"/>\r\n        </field>\r\n        <field index=\"1\" key=\"y\">\r\n            <VirtualArray cache_key=\"ak4\">\r\n                <SliceGenerator>\r\n                    <slice>[array([0, 1, 2, ..., 3, 4, 5])]</slice>\r\n                    <content><VirtualArray cache_key=\"ak3\">\r\n                        <SliceGenerator>\r\n                            <slice>[array([0, 1, 2, ..., 3, 4, 5])]</slice>\r\n                            <content><VirtualArray cache_key=\"ak2\">\r\n                                <SliceGenerator>\r\n                                    <slice>[array([0, 1, 2, ..., 3, 4, 5])]</slice>\r\n                                    <content><VirtualArray cache_key=\"ak.from_arrayset:1-node3-virtual\">\r\n                                        <ArrayGenerator f=\"<function _form_to_layout at 0x1199773a0>\" args=\"({\r\n    \"class\": \"NumpyArray\",\r\n    \"itemsize\": 8,\r\n    \"format\": \"l\",\r\n    \"primitive\": \"int64\",\r\n    \"form_key\": \"node3\"\r\n}, {'node0-offsets': array([0, 3, 5, 6], dtype=int64), 'node2': array([0, 1, 2, 3, 4, 5]), 'node3': array([ 0, -1, -2, -3, -4, -5])}, None, '', '-', False, <ArrayCache mapping=\"<awkward1._util.MappingProxy object at 0x1199b2...\"/>, 'ak.from_arrayset:1', 6)\">\r\n                                            <length>6</length>\r\n                                            <form>\r\n                                                {\r\n                                                    \"class\": \"NumpyArray\",\r\n                                                    \"itemsize\": 8,\r\n                                                    \"format\": \"l\",\r\n                                                    \"primitive\": \"int64\",\r\n                                                    \"form_key\": \"node3\"\r\n                                                }\r\n                                            </form>\r\n                                        </ArrayGenerator>\r\n                                        <ArrayCache mapping=\"<awkward1._util.MappingProxy object at 0x1199b2...\"/>\r\n                                        <array><NumpyArray format=\"l\" shape=\"6\" data=\"0 -1 -2 -3 -4 -5\" at=\"0x7fe335ca2d60\"/></array>\r\n                                    </VirtualArray></content>\r\n                                </SliceGenerator>\r\n                            </VirtualArray></content>\r\n                        </SliceGenerator>\r\n                    </VirtualArray></content>\r\n                </SliceGenerator>\r\n            </VirtualArray>\r\n        </field>\r\n        <field index=\"2\" key=\"a\">\r\n            <NumpyArray format=\"l\" shape=\"6\" data=\"0 1 2 3 4 5\" at=\"0x7fe338102120\"/>\r\n        </field>\r\n        <field index=\"3\" key=\"b\">\r\n            <NumpyArray format=\"l\" shape=\"6\" data=\"0 2 4 6 8 10\" at=\"0x7fe3381027a0\"/>\r\n        </field>\r\n        <field index=\"4\" key=\"c\">\r\n            <NumpyArray format=\"l\" shape=\"6\" data=\"0 3 6 9 12 15\" at=\"0x7fe3381021c0\"/>\r\n        </field>\r\n    </RecordArray></content>\r\n</ListOffsetArray64>\r\n```\r\nNotice the stacking of the same slice generator, which seems to have no purpose (why is it there?)",
  "closed_at":"2020-10-30T22:51:28Z",
  "comments":2,
  "created_at":"2020-09-04T15:05:35Z",
  "id":693270577,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTMyNzA1Nzc=",
  "number":432,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Adding fields to lazy records causes over-materialization",
  "updated_at":"2020-10-30T22:51:28Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"and some code cleanup.",
  "closed_at":"2020-09-11T21:05:03Z",
  "comments":0,
  "created_at":"2020-09-04T16:05:56Z",
  "draft":false,
  "id":693338911,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDc5ODM2NTY1",
  "number":433,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-11T21:05:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Auto generate more CUDA kernels",
  "updated_at":"2020-09-11T21:05:06Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"If I run\r\n```\r\nIn [3]: a = ak.Array([[0, 1, 2], [3, 4], [5]])\r\n\r\nIn [5]: ak.argmin(a, axis=1, keepdims=True)\r\nOut[5]: <Array [[0], [0], [0]] type='3 * 1 * ?int64'>\r\n```\r\nthe output is of fixed size in the last axis, and as such it cannot be used in a slice:\r\n```\r\nIn [6]: a[ak.argmin(a, axis=1, keepdims=True)]\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-83ba94cb4af4> in <module>\r\n----> 1 a[ak.argmin(a, axis=1, keepdims=True)]\r\n\r\n~/src/awkward-1.0/awkward1/highlevel.py in __getitem__(self, where)\r\n    939         \"\"\"\r\n    940         return awkward1._util.wrap(\r\n--> 941             self._layout[where], self._behavior, cache=self._cache\r\n    942         )\r\n    943\r\n\r\nValueError: slice items can have all fixed-size dimensions (to follow NumPy's slice rules) or they can have all var-sized dimensions (for jagged indexing), but not both in the same slice item\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.2.36/src/libawkward/array/RegularArray.cpp#L846)\r\n```\r\n\r\nA workaround is to use `ak.singletons`:\r\n```\r\nIn [7]: ak.singletons(ak.argmin(a, axis=1))\r\nOut[7]: <Array [[0], [0], [0]] type='3 * var * int64'>\r\n\r\nIn [8]: a[_7]\r\nOut[8]: <Array [[0], [3], [5]] type='3 * var * int64'>\r\n```\r\n",
  "closed_at":"2020-09-10T04:49:13Z",
  "comments":1,
  "created_at":"2020-09-04T19:11:22Z",
  "id":693511737,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTM1MTE3Mzc=",
  "number":434,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"argmin/max with keepdims=True returns regulararray",
  "updated_at":"2020-09-10T05:01:45Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Addressing issue #320 ",
  "closed_at":"2020-09-09T19:06:23Z",
  "comments":5,
  "created_at":"2020-09-05T13:31:05Z",
  "draft":false,
  "id":694086833,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgwNTIwMTE0",
  "number":435,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-09T19:06:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"intermittent error bugfix",
  "updated_at":"2020-09-10T11:15:59Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-15T13:58:02Z",
  "comments":2,
  "created_at":"2020-09-06T12:34:57Z",
  "draft":false,
  "id":694365412,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgwNzUyMTc3",
  "number":436,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-15T13:58:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Working on the Loop Dependent Kernels.",
  "updated_at":"2020-09-15T13:58:05Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"This is my first time using awkward and json. I was analyzing the data related to the paper by Guest, Collado, Baldi, Hsu, Urban, Whiteson                                                                                                           \r\nviz. \u201cJet Flavor Classification in High-Energy Physics with Deep Neural Networks\u201d . Each time I was trying to do the conversion from json to ak array : **ak.from_json('dataset.json'),**  I was getting the error \"**ValueError: JSON error at char 2453: The document root must not be followed by other values**.\"\r\n\r\n```\r\nimport json\r\nimport awkward1 as ak\r\nak.from_json('dataset.json')\r\n```\r\n\r\nHere is the dataset - http://mlphysics.ics.uci.edu/data/hb_jet_flavor_2016/dataset.json.gz\r\nand the details - http://mlphysics.ics.uci.edu/data/hb_jet_flavor_2016/readme.txt\r\n\r\n@reikdas @jpivarski ",
  "closed_at":"2020-12-03T23:44:16Z",
  "comments":3,
  "created_at":"2020-09-06T16:01:47Z",
  "id":694432879,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTQ0MzI4Nzk=",
  "number":437,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Handle stream-of-many-JSON files? Options for `\"NaN\"` strings as NaN floats?",
  "updated_at":"2020-12-03T23:44:16Z",
  "user":"MDQ6VXNlcjMwNDI2NDM2"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-08T17:39:40Z",
  "comments":2,
  "created_at":"2020-09-06T17:07:48Z",
  "draft":false,
  "id":694453734,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgwODI4NjIy",
  "number":438,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-08T17:39:40Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Restructure test generation - store only roles in specification",
  "updated_at":"2020-09-08T17:39:47Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Also, we're going to get the `dependent-project` into the tests again by making\r\n\r\n```bash\r\npython -m awkward1.config --cflags --libs\r\n```\r\n\r\nreturn\r\n\r\n```\r\n-std=c++11 -I/path/to/include -L/path/to/lib -lawkward -lawkward-cpu-kernels\r\n```\r\n\r\nand using that to get the location of the currently installed Awkward library.",
  "closed_at":"2020-09-08T01:57:31Z",
  "comments":0,
  "created_at":"2020-09-07T19:09:20Z",
  "draft":false,
  "id":695346372,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgxNjA0Mzgx",
  "number":439,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-08T01:57:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Libraries and includes should only go into the Python directory, not multiple places.",
  "updated_at":"2020-09-08T01:57:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-09T18:54:30Z",
  "comments":0,
  "created_at":"2020-09-09T09:21:06Z",
  "draft":false,
  "id":696642050,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgyNjk3NjQz",
  "number":440,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-09T18:54:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix cuda shared object retrieval",
  "updated_at":"2020-09-09T18:54:33Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-09T18:56:19Z",
  "comments":0,
  "created_at":"2020-09-09T09:49:18Z",
  "draft":false,
  "id":696666089,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgyNzE4NDU2",
  "number":441,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-09T18:56:19Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix typo in documentation",
  "updated_at":"2020-09-09T18:56:22Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Raised by @tamasgal in https://github.com/scikit-hep/uproot4/issues/90#issuecomment-689459702:\r\n\r\n> Another problem, which I will post in a future issue that working with these arrays is far from the numpy performance (doing things like `arr > 0.5` takes ~2ms for 100 entries, while in numpy/Julia/C it should be more around a few hundred ns), but that's another story.\r\n\r\nOriginal dataset: http://131.188.167.67:8889/doubly_jagged.root\r\n\r\n```python\r\nimport uproot4\r\nimport awkward1 as ak\r\ntrks = uproot4.open(\"uproot-issue-90.root:E/Evt/trks\")\r\narray = trks[\"trks.rec_stages\"].array()\r\nak.to_parquet(array, \"awkward-issue-442.parquet\")\r\narray\r\n# <Array [[[1, 2, 5, 3, 5, 4], ... 1], [1], [1]]] type='145028 * var * var * int64'>\r\n```\r\n\r\nAs Parquet (faster to download and read into Awkward): https://drive.google.com/file/d/1JbiFaBaouH_amUxvGnsSHegYAQjRTJ8u/view?usp=sharing\r\nAs Pickle (larger, but retains structure: Parquet adds option-type, which complicates the performance analysis): https://drive.google.com/file/d/1KnYebahkvLK29ZggISGROHxjcpCUdO0H/view?usp=sharing\r\n\r\nThe basic idea of performance in Awkward Array is that we don't worry about the constant-time metadata manipulation but should worry about the linear-time scaling. In particular, computing `array > 3` of a doubly jagged array is pure Python: it unwraps the doubly jagged structure and calls NumPy's own `np.greater` on the inner flat content.\r\n\r\nBecause of the constant-time unwrapping, it shouldn't be surprising that the Awkward version doesn't start scaling until the array is at least 1000 entries or so. What _is_ surprising is that the linear scaling for Awkward doesn't line up with the linear scaling for NumPy, because in theory, _it isn't doing anything other than calling NumPy_.\r\n\r\n![quick-plot](https://user-images.githubusercontent.com/1852447/92609164-e2e85e80-f27b-11ea-869c-25ac6177d292.png)\r\n\r\nSo this is a quandary.",
  "closed_at":"2020-09-09T16:20:27Z",
  "comments":5,
  "created_at":"2020-09-09T14:03:32Z",
  "id":696843980,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTY4NDM5ODA=",
  "number":442,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Performance of ufuncs",
  "updated_at":"2020-09-09T17:36:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"The following issue arose while processing larger ROOT files with `uproot4` where the iterative read-in is required due to memory limitations. The analysis approach is event-by-event, which means that during the iteration, many branches needs to be accessed  while the amount of data per iteration is quite low (e.g. awkward-arrays with a few hundred or thousand entries).\r\n\r\nThe main problem is that single operations on these awkward arrays take orders of magnitude longer compared to what should be possible by the hardware (crosschecks with numpy and Julia). The reason is the overhead of access the data inside the awkward arrays and also the construction of those.\r\n\r\nOf course I know one can request `numpy` arrays from `uproot4` explicitly via `TBranch.array(library=\"np\")` but in our case it's a bit difficult since some branches needs to be awkward arrays, others are better as numpy arrays etc. so in the following, let's assume that our starting point is an awkward array.\r\n\r\nAnother point is that the wholemeal approach is usually the preferred way but it's complicated and ugly to extend the calculations to be done on bigger chunks of the file and many things inside the iterations needs some special care, so it's very hard to do it on single operations. Let alone the memory footprint, which can only be managed by a clever chunking... Of course, if there is no other way, we will go that path, but I want to make sure that I am not overlooking anything obvious.\r\n\r\nHere is what I mean:\r\n\r\nAwkward array construction (in this example from numpy arrays), which I assume does more or less the same work when e.g. creating the output array of operations (e.g. `awkward_array * 10` etc.). This means, it creates the class instance, checks the dtype and swallows the input data without copying it. The overhead seems to be somewhere in the `18us` range and is obviously not depending on the data size (no-copy):\r\n\r\n```python\r\nfor n in (10**i for i in range(9)):\r\n    arr = np.random.rand(n)\r\n    %timeit ak.Array(arr)\r\n18.5 \u00b5s \u00b1 154 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.9 \u00b5s \u00b1 147 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.4 \u00b5s \u00b1 156 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.4 \u00b5s \u00b1 251 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.4 \u00b5s \u00b1 87.5 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.3 \u00b5s \u00b1 161 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.3 \u00b5s \u00b1 164 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.3 \u00b5s \u00b1 147 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n18.4 \u00b5s \u00b1 97.9 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\r\n```\r\n\r\nWhenever there is an operation on such arrays, this construction time is already the lower threshold. Furthermore, there is (let's call it) access time, which is the time the code needs to reach the underlying data. I only measured the time of the whole function call, but it's obvious that we have an access+init overhead of something around `140us`. Which means `~20us` for constructing the output array and the remaining time is `~120us` to get to the data + actual calculation (usually a few nanoseconds per item for basic arithmetic operations):\r\n\r\n```python\r\nfor n in (10**i for i in range(9)):\r\n    arr = ak.Array(np.random.rand(n))\r\n    %timeit arr / 10\r\n146 \u00b5s \u00b1 1.25 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n147 \u00b5s \u00b1 1.06 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n149 \u00b5s \u00b1 1.17 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n155 \u00b5s \u00b1 2.78 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n157 \u00b5s \u00b1 1.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n212 \u00b5s \u00b1 5.43 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n1.29 ms \u00b1 14 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n12 ms \u00b1 61.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n105 ms \u00b1 588 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n```\r\n\r\nIn one of the cases I am now trying to improve, a lot of such operations are taking place (as mentioned above) and the user is literally iterating over an (event) index and accesses such (small) arrays individually from many branches.\r\n\r\nHere is a direct comparison between different ways to calculate the same thing and you can see that `numpy`s overhead is extremely tiny compared to `awkward1`:\r\n\r\n```python\r\narr_np = np.random.rand(100)\r\narr_ak = ak.Array(arr_np)\r\n%timeit arr_np / 10\r\n%timeit arr_ak / 10\r\n%timeit arr_ak.__array__() / 10\r\n%timeit np.divide(arr_ak, 10)\r\n\r\n937 ns \u00b1 8.75 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\r\n148 \u00b5s \u00b1 2.83 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n9.5 ms \u00b1 138 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n144 \u00b5s \u00b1 1.17 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n```\r\n\r\nAlthough I have many questions, one of the most important ones is what you recommend to do to get a quicker access to the underlying data, which should have a C-compatible binary layout, so in principle we should be able to reach numpy-like calculation times but this means that also the construction of awkward arrays needs to be sped up quite a lot.\r\n\r\nWhat do you think?",
  "closed_at":"2020-09-09T17:16:26Z",
  "comments":4,
  "created_at":"2020-09-09T14:13:55Z",
  "id":696852355,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTY4NTIzNTU=",
  "number":443,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Access (initialisation) overhead",
  "updated_at":"2020-09-09T17:30:04Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes #442.",
  "closed_at":"2020-09-09T19:00:59Z",
  "comments":0,
  "created_at":"2020-09-09T15:59:44Z",
  "draft":false,
  "id":696940849,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgyOTUwMzE5",
  "number":444,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-09T19:00:59Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Always assuming ListArrays/ListOffsetArrays have incompatible structure is too conservative. Check for consistency and shortcut if possible.",
  "updated_at":"2020-09-09T19:01:02Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"We should add a flag to allow `cuda-build.sh` to use the system nvcc to compile the CUDA source files, instead of always using docker to do so. \r\nAlso, it would be good to allow the user to set their own options to nvcc's `--gencode` flag - https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation-generate-code",
  "closed_at":"2020-09-10T12:10:52Z",
  "comments":6,
  "created_at":"2020-09-09T16:09:01Z",
  "id":696947687,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU2OTY5NDc2ODc=",
  "number":445,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add flags to cuda-build.sh - use system nvcc, nvcc's gencode flag",
  "updated_at":"2020-09-10T12:10:52Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I noticed this while handling those performance issues.",
  "closed_at":"2020-09-09T20:04:20Z",
  "comments":0,
  "created_at":"2020-09-09T19:26:50Z",
  "draft":false,
  "id":697092712,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgzMDgxMDMx",
  "number":446,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-09T20:04:20Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix ak.flatten for arrays that have been sliced.",
  "updated_at":"2020-09-09T20:04:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes #434.",
  "closed_at":"2020-09-10T04:49:13Z",
  "comments":0,
  "created_at":"2020-09-10T02:52:47Z",
  "draft":false,
  "id":697351549,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgzMzA0NDU1",
  "number":447,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-10T04:49:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix reducer dimension regularity.",
  "updated_at":"2020-09-10T04:49:17Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Corresponds to scikit-hep/uproot4#96.",
  "closed_at":"2020-09-12T13:25:30Z",
  "comments":1,
  "created_at":"2020-09-10T15:25:30Z",
  "draft":false,
  "id":698123288,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDgzOTk3ODkz",
  "number":448,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-12T13:25:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Set up interface between Uproot and Awkward so that Awkward can be used to optimize object-reading.",
  "updated_at":"2020-09-12T13:25:33Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@ianna This might impact your work on PR #361, but the fact that only two arrays can be merged at a time is now a bottleneck (see https://github.com/scikit-hep/uproot4/pull/96#issuecomment-690622622).\r\n\r\nSpecifically, this interface:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/911ba0b56429ed9ec19c42993c6a5c95a3447ff8/include/awkward/Content.h#L654-L657\r\n\r\nis going to become:\r\n\r\n```c++\r\n virtual const ContentPtr \r\n   merge(const ContentPtrVec& others) const = 0; \r\n```\r\n\r\n(where `ContentPtrVec` is `std::vector<std::shared_ptr<Content>>`). I'll be updating this method and everything that calls it, which includes this Python:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/911ba0b56429ed9ec19c42993c6a5c95a3447ff8/src/awkward1/operations/structure.py#L747-L754\r\n\r\nIf you're accessing `merge` by calling [UnionArray::simplify_uniontype](https://github.com/scikit-hep/awkward-1.0/blob/911ba0b56429ed9ec19c42993c6a5c95a3447ff8/src/libawkward/array/UnionArray.cpp#L471), then the direct interface changes may be hidden from you. On the other hand, you might be arranging loops to set things up in a pairwise way; with this fix, they could be made more efficient by loading all at once. If you're okay with that refactoring, then you could put off addressing this until the end, as a (huge) performance improvement.\r\n\r\nThe Content::mergeable interface, however,\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/911ba0b56429ed9ec19c42993c6a5c95a3447ff8/include/awkward/Content.h#L642-L652\r\n\r\nwill _not_ be changing. This only checks for type-compatibility and doesn't stand to benefit in performance from taking a list as an argument.",
  "closed_at":"2020-09-12T12:54:57Z",
  "comments":2,
  "created_at":"2020-09-10T19:43:06Z",
  "draft":false,
  "id":698414001,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg0MjU5NDA3",
  "number":449,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-12T12:54:57Z"
  },
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Upgrade Content::merge from a single 'other' argument to a std::vector of 'others'.",
  "updated_at":"2020-09-12T12:55:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"cupy.cumsum does not cast Python list and NumPy array to CuPy array from 8.0.0rc1.\r\nhttps://github.com/cupy/cupy/issues/3984",
  "closed_at":"2020-09-13T19:10:13Z",
  "comments":0,
  "created_at":"2020-09-13T17:46:49Z",
  "draft":false,
  "id":700614916,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg2MjE1NTgw",
  "number":450,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-13T19:10:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Explicitly cast list to CuPy array in cumsum test",
  "updated_at":"2020-09-13T19:10:16Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-15T13:38:51Z",
  "comments":0,
  "created_at":"2020-09-13T20:17:51Z",
  "draft":false,
  "id":700640017,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg2MjM0MzQ0",
  "number":451,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-15T13:38:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Change kernel specification format",
  "updated_at":"2020-09-15T13:38:54Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"For parallelizability categorisation in the future",
  "closed_at":"2020-09-15T14:44:06Z",
  "comments":0,
  "created_at":"2020-09-15T13:49:42Z",
  "draft":false,
  "id":701947603,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg3MzExNDQ5",
  "number":452,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-15T14:44:06Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add description field to specification",
  "updated_at":"2020-09-15T14:44:10Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Black seems to be inconsistent with how ti wants to format `from parser_utils import PYGEN_BLACKLIST, SUCCESS_TEST_BLACKLIST, TEST_BLACKLIST`",
  "closed_at":"2020-09-17T13:37:20Z",
  "comments":2,
  "created_at":"2020-09-17T08:43:57Z",
  "draft":false,
  "id":703389983,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg4NTA2MzQ2",
  "number":453,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-17T13:37:20Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add more kernel test cases",
  "updated_at":"2020-09-17T13:37:23Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-12-03T17:18:19Z",
  "comments":1,
  "created_at":"2020-09-17T11:25:33Z",
  "draft":false,
  "id":703500937,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg4NTk4MjAx",
  "number":454,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-03T17:18:19Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add some more Loop Dependent Kernels",
  "updated_at":"2020-12-03T17:18:22Z",
  "user":"MDQ6VXNlcjM5ODc4Njc1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"No longer generate it.",
  "closed_at":"2020-09-19T11:21:43Z",
  "comments":16,
  "created_at":"2020-09-17T12:36:34Z",
  "draft":false,
  "id":703547763,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg4NjM3MTQ3",
  "number":455,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-19T11:21:43Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Check kernel specification into git",
  "updated_at":"2020-09-19T11:21:50Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Also added a more clear error message when an unknown array type is encountered, e.g. when someday someone might pass a complex-valued numpy array to `ak.type`",
  "closed_at":"2020-09-17T21:48:36Z",
  "comments":0,
  "created_at":"2020-09-17T17:49:12Z",
  "draft":false,
  "id":703789188,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg4ODMzMDI3",
  "number":456,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-17T21:48:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add numpy boolean type to ak describe",
  "updated_at":"2020-09-18T16:08:01Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Currently, all ufuncs are broadcasted across all fields of a record:\r\n\r\n```python\r\n>>> ak_array = ak.Array([{\"x\": 1, \"y\": 1.1}, {\"x\": 2, \"y\": 2.2}, {\"x\": 3, \"y\": 3.3}])\r\n>>> ak_array\r\n<Array [{x: 1, y: 1.1}, ... {x: 3, y: 3.3}] type='3 * {\"x\": int64, \"y\": float64}'>\r\n\r\n>>> ak_array + 1\r\n<Array [{x: 2, y: 2.1}, ... {x: 4, y: 4.3}] type='3 * {\"x\": int64, \"y\": float64}'>\r\n```\r\n\r\nThis is causing some confusion because the fields of a record have qualitatively different meanings. Some are trigger booleans, some are momenta, some are ML-derived isolation variables, some are strings...\r\n\r\n```python\r\n>>> ak.Array([\"HAL\"]) + 1                      # should this even work?\r\n<Array [[73, 66, 77]] type='1 * var * uint8'>\r\n\r\n>>> [chr(x) for x in (ak.Array([\"HAL\"]) + 1)[0].tolist()]\r\n['I', 'B', 'M']\r\n```\r\n\r\nFurthermore, when @henryiii is writing [vector](https://github.com/scikit-hep/vector), he has to distinguish between `LorentzVector + LorentzVector` accidentally working because they're Cartesian (but not preserving their Lorentzness) and getting the wrong answer because they're not Cartesian. Even though the `+` behavior is defined, due to the fact that they are records, he has to be sure to override every case.\r\n\r\nI think there would be fewer surprises for both users and developers if broadcasting a ufunc through a record were an error (withe a nice error message). Custom behaviors for specialized records, like LorentzVectors, would still be possible to define, as they are now, but instead of replacing wrong behavior, they'd be replacing no behavior.\r\n\r\nNote that NumPy does not define such an operation on [structured arrays](https://numpy.org/doc/stable/user/basics.rec.html):\r\n\r\n```python\r\n>>> np_array = np.array([(1, 1.1), (2, 2.2), (3, 3.3)], [(\"x\", int), (\"y\", float)])\r\n>>> np_array\r\narray([(1, 1.1), (2, 2.2), (3, 3.3)], dtype=[('x', '<i8'), ('y', '<f8')])\r\n\r\n>>> np_array + 1\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: invalid type promotion\r\n```\r\n\r\nAlthough it does work for Pandas:\r\n\r\n```python\r\n>>> df = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [1.1, 2.2, 3.3]})\r\n>>> df\r\n   x    y\r\n0  1  1.1\r\n1  2  2.2\r\n2  3  3.3\r\n>>> df + 1\r\n   x    y\r\n0  2  2.1\r\n1  3  3.2\r\n2  4  4.3\r\n```\r\n\r\nit is not our intention to generalize from Pandas, only NumPy.\r\n\r\nThis would also affect ufuncs that return booleans, like comparison operators. For these, the argument isn't as strong. Maybe we want\r\n\r\n```python\r\n>>> ak_array > 1\r\n<Array [{x: False, y: True}, ... y: True}] type='3 * {\"x\": bool, \"y\": bool}'>\r\n```\r\n\r\nto work, maybe we don't.\r\n\r\nI'm considering removing ufuncs-through-records for all ufuncs, without affecting the custom ufunc behavior that can be assigned to any record with a name. (I'm not considering ufuncs-on-strings right now, though that's something to think about.) Does anyone have a strong argument about that?\r\n\r\n(I suppose this needs a deprecation cycle, though it would be a little difficult getting a warning into the middle of the broadcast-and-apply. I'm tempted to remove it all at once, like a band-aid...)",
  "closed_at":"2020-11-03T21:42:58Z",
  "comments":11,
  "created_at":"2020-09-17T22:57:44Z",
  "id":703961340,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MDM5NjEzNDA=",
  "number":457,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Removing ufunc-broadcasting across record fields",
  "updated_at":"2020-11-03T21:42:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"on https://github.com/conda-forge/staged-recipes/pull/12684/files#diff-4d5ada45354b5bb597c5bb127a4ae50a",
  "closed_at":"2020-09-18T15:41:51Z",
  "comments":1,
  "created_at":"2020-09-18T12:57:07Z",
  "draft":false,
  "id":704357282,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5Mjk4NzM0",
  "number":458,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-18T15:41:51Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Change the Windows build following @chrisburr's suggestion",
  "updated_at":"2020-09-18T15:41:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Consider\r\n```python\r\na = ak.Array(ak.layout.NumpyArray(np.arange(6, dtype=np.float32), parameters={\"asdf\": \"something\"}))\r\n```\r\nThen a common operation might be to mask certain values and replace them, e.g. \r\n```\r\nIn [51]: ak.fill_none(a.mask[a%2==0], -1)\r\nOut[51]: <Array [0, -1, 2, -1, 4, -1] type='6 * union[float32[parameters={\"asdf\": \"someth...'>\r\n\r\nIn [52]: ak.type(_51)\r\nOut[52]: 6 * union[float32[parameters={\"asdf\": \"something\"}], int64]\r\n```\r\nbut the union type is unnecessary and can be troublesome. It's not clear if we should throw away or propagate the parameters, but either way it would be nice to be able to simplify this type.",
  "closed_at":"2020-11-12T00:34:00Z",
  "comments":5,
  "created_at":"2020-09-18T14:48:56Z",
  "id":704440609,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MDQ0NDA2MDk=",
  "number":459,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Union of compatible types does not simplify if parameters are set",
  "updated_at":"2020-11-12T00:34:00Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-18T20:21:14Z",
  "comments":6,
  "created_at":"2020-09-18T19:39:57Z",
  "draft":false,
  "id":704611258,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NTA1MTUx",
  "number":460,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-18T20:21:14Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove Awkward-as-a-Pandas-column feature, as discussed in #350.",
  "updated_at":"2020-09-18T22:09:24Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-18T22:39:55Z",
  "comments":0,
  "created_at":"2020-09-18T21:23:44Z",
  "draft":false,
  "id":704665731,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NTQ3MTE5",
  "number":461,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-18T22:39:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Apply conda-forge/awkward1-feedstock#2 here to test it in our CI.",
  "updated_at":"2020-09-18T22:39:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-18T22:39:31Z",
  "comments":0,
  "created_at":"2020-09-18T21:35:14Z",
  "draft":false,
  "id":704670915,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NTUxMDMz",
  "number":462,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-18T22:39:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove ak.Array.tojson for 0.3.0 (use ak.to_json).",
  "updated_at":"2020-09-18T22:39:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-19T02:31:25Z",
  "comments":2,
  "created_at":"2020-09-18T22:42:28Z",
  "draft":false,
  "id":704695824,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NTcxNDE0",
  "number":463,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-19T02:31:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Generalize NumPy ufunc behavioral matching.",
  "updated_at":"2020-09-19T02:31:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"New properties:\r\n\r\n   * `ndim` to mean `self.layout.purelist_depth` (Pandas forced me to make `ndim` always 1, which is terrible)\r\n   * `fields` to mean `ak.fields`, and rename `ak.keys` to `ak.fields`\r\n   * `type` to mean `ak.type`\r\n\r\nwith a formal deprecation process (to 0.4.0) of `ak.keys` \u2192 `ak.fields` and the `keys` arguments of `ak.combinations`, and `ak.argcombinations` to `fields` (also a deprecation process, to 0.4.0).\r\n\r\n(@nsmith-)",
  "closed_at":"2020-09-19T11:18:26Z",
  "comments":0,
  "created_at":"2020-09-18T23:48:19Z",
  "draft":false,
  "id":704713283,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NTg1NjYw",
  "number":464,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-19T11:18:26Z"
  },
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Deprecate 'keys' -> 'fields' and add properties to ak.Array and ak.Record",
  "updated_at":"2020-09-19T11:18:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"As the version of the compilers used will change from time to time I think this might be a slightly more robust check to use.",
  "closed_at":"2020-09-19T11:17:36Z",
  "comments":1,
  "created_at":"2020-09-19T05:08:03Z",
  "draft":false,
  "id":704804128,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDg5NjY2NjQz",
  "number":465,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-19T11:17:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Attempt to make check for -A x64 flag more robust",
  "updated_at":"2020-09-19T11:17:43Z",
  "user":"MDQ6VXNlcjUyMjA1MzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"@henryiii Is this a relic of our original attempt to base Awkward's compilation on Scikit-Build?\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/e4932ec4c5c57b5731e609f1d6fbfdc4a439e7ea/pyproject.toml#L5\r\n\r\nIt might be causing #430 because the cmake pip package depends on Scikit-Build and Scikit-Build doesn't support Windows (in Cygwin).\r\n\r\nDo the dependencies declared in pyproject.toml get installed in all cases or only those involving the source distribution? If someone's getting this from a wheel, they shouldn't need CMake. If they're getting it from the source distribution, we're already in desperation mode\u2014it might be better to allow users in this mode the flexibility to use their own CMake. (That option would be better for @kpedro88.)\r\n\r\nI can try removing it and setting up an Azure node to try to install from a wheel to test it, but that will take some time. I'm wondering if you have want thoughts first. Thanks!",
  "closed_at":"2020-09-21T21:06:25Z",
  "comments":3,
  "created_at":"2020-09-19T18:45:07Z",
  "id":704978797,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MDQ5Nzg3OTc=",
  "number":466,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Can \"cmake\" be removed from pyproject.toml?",
  "updated_at":"2020-09-21T21:41:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-21T18:54:23Z",
  "comments":0,
  "created_at":"2020-09-21T13:53:16Z",
  "draft":false,
  "id":705619810,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkwMzE1MTE0",
  "number":467,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-21T18:54:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Try to solve Windows installation issue by always compiling in 'Release' mode.",
  "updated_at":"2020-09-21T18:54:26Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-22T04:57:23Z",
  "comments":0,
  "created_at":"2020-09-21T17:42:35Z",
  "draft":false,
  "id":705793541,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkwNDU4MTkw",
  "number":468,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-22T04:57:23Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Generate kernel header files from specification",
  "updated_at":"2020-09-22T04:57:37Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-21T21:36:10Z",
  "comments":0,
  "created_at":"2020-09-21T21:05:22Z",
  "draft":false,
  "id":705916305,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkwNTU5NjI2",
  "number":469,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-21T21:36:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"awkward1 must use THE SAME VERSION of awkward1-cuda-kernels when it uses any.",
  "updated_at":"2020-09-21T21:36:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-21T21:51:57Z",
  "comments":0,
  "created_at":"2020-09-21T21:28:02Z",
  "draft":false,
  "id":705928560,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkwNTY5ODg0",
  "number":470,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-21T21:51:57Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Put the 'cmake' PyPI package back into pyproject.toml.",
  "updated_at":"2020-09-21T21:52:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-23T11:17:59Z",
  "comments":0,
  "created_at":"2020-09-23T06:52:48Z",
  "draft":false,
  "id":707098534,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkxNTU4MDA4",
  "number":471,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-23T11:17:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"We do not need blacklists for kernel/test generation anymore",
  "updated_at":"2020-09-23T11:18:04Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This hack is no longer needed:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/4ba42ac43707555d5847a50deb200b6f157f78bd/.ci/azure-deploy-awkward.yml#L111-L112\r\n\r\nReported by @henryiii.\r\n\r\nBut maybe we should go further and adopt [cibuildwheel](https://github.com/joerick/cibuildwheel) (not sure what that involves).",
  "closed_at":"2020-10-29T19:37:53Z",
  "comments":1,
  "created_at":"2020-09-23T20:54:24Z",
  "id":707672654,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MDc2NzI2NTQ=",
  "number":472,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Update deploy procedure, possibly adopt cibuildwheel",
  "updated_at":"2020-10-29T19:37:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"",
  "closed_at":"2020-09-30T18:17:39Z",
  "comments":4,
  "created_at":"2020-09-25T14:52:46Z",
  "draft":false,
  "id":709002611,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkzMTI4NzM3",
  "number":473,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-30T18:17:39Z"
  },
  "reactions":{
   "heart":2,
   "total_count":2
  },
  "state":"closed",
  "state_reason":null,
  "title":"Properly broadcast over empty ListArray",
  "updated_at":"2020-09-30T18:17:39Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-09-26T01:47:21Z",
  "comments":0,
  "created_at":"2020-09-26T01:21:49Z",
  "draft":false,
  "id":709390746,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDkzNDYxOTY0",
  "number":474,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-26T01:47:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix broken links in documentation.",
  "updated_at":"2020-09-26T01:47:24Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"As far as I can tell, the CMakeLists.txt of this project makes it fairly hard to use an existing install of pybind11. I'd like to request an option to use either the builtin/submodule or external. Can prepare a PR if needed.\r\n",
  "closed_at":"2020-09-29T18:43:19Z",
  "comments":6,
  "created_at":"2020-09-28T21:56:02Z",
  "id":710605487,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTA2MDU0ODc=",
  "number":476,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Build with external PyBind11",
  "updated_at":"2020-09-29T18:43:19Z",
  "user":"MDQ6VXNlcjUwNTc4ODQ="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-30T16:48:35Z",
  "comments":6,
  "created_at":"2020-09-29T12:31:39Z",
  "draft":false,
  "id":711066692,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDk0Nzk1MzE0",
  "number":477,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-30T16:48:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"CPU kernel source files will have 1 file per kernel",
  "updated_at":"2020-09-30T16:48:39Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-09-30T19:44:42Z",
  "comments":1,
  "created_at":"2020-09-30T18:34:13Z",
  "draft":false,
  "id":712179079,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDk1NzAxODk5",
  "number":478,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-09-30T19:44:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix broken CUDA tests",
  "updated_at":"2020-09-30T19:44:45Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Apparently an `ak.zip()` of lazy arrays cannot be evaluated after it has been returned from a function:\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> import uproot4\r\n>>> def func():\r\n...     tree = uproot4.lazy('tests/scalars_tree_file.root')\r\n...     return ak.zip([tree['int_branch'], tree['long_branch']])\r\n... \r\n>>> print(func())\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/highlevel.py\", line 1253, in __str__\r\n    return self._str()\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/highlevel.py\", line 1273, in _str\r\n    return awkward1._util.minimally_touching_string(\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 1486, in minimally_touching_string\r\n    lft = next(leftgen)\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 1473, in forever\r\n    for token in iterable:\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 1367, in forward\r\n    for token in forward(x[i], sp):\r\n  File \"/home/mproffit/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 1377, in forward\r\n    for token in forward(x[str(i)], \"\"):\r\nRuntimeError: PyArrayCache has lost its weak reference to mapping\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.3.1/src/python/virtual.cpp#L334)\r\n```\r\n\r\nwhereas returning a plain `list` works just fine:\r\n\r\n```python\r\n>>> def func():\r\n...     tree = uproot4.lazy('tests/scalars_tree_file.root')\r\n...     return [tree['int_branch'], tree['long_branch']]\r\n... \r\n>>> print(func())\r\n[<Array [0, -1] type='2 * int32'>, <Array [0, -2] type='2 * int64'>]\r\n```",
  "closed_at":"2020-11-04T18:25:28Z",
  "comments":6,
  "created_at":"2020-09-30T19:09:44Z",
  "id":712205955,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTIyMDU5NTU=",
  "number":479,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Returning ak.zip() of lazy arrays loses \"its weak reference to mapping\"",
  "updated_at":"2020-11-04T18:25:28Z",
  "user":"MDQ6VXNlcjMyNzczMzA0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"This is for requesting new documentation or corrections/modifications/additions to existing documentation.\r\n\r\nIf you have a problem without an answer in the [How do I\u2026?](https://awkward-array.org/how-to.html) tutorials, ask it here and we will answer it as a new tutorial that will benefit everybody.\r\n\r\nIf your problem is too specific for that or it isn't exclusively related to Awkward Array, it might be more appropriate to ask on [StackOverflow with the [awkward-array] tag](https://stackoverflow.com/questions/tagged/awkward-array), instead of here. Be sure to include tags for any other libraries that you use, such as Pandas or PyTorch.\r\n\r\nHere are some additional links that might help you find what you're looking for. It would be helpful if requests to change existing documentation includes a link.\r\n\r\n   * [The tutorials site](https://scikit-hep.org/awkward-1.0/index.html)\r\n   * [The C++ API](https://awkward-array.readthedocs.io/en/latest/_static/index.html)\r\n   * [The Python API](https://awkward-array.readthedocs.io/en/latest/index.html)\r\n\r\nGiven I have a 2d np.ndarray, e.g. with shape (512, 128) and called arr, and I have a list or 1d np.ndarray with shape (512) and values indicating the indices for each row in arr, I want to create ak array (terminology might be wrong since I just noticed your amazing package) that takes the first k elements for each row, with k as each element in indices array. The following code shows the intended behavior.\r\n```\r\narr = np.random.rand(512, 128)\r\narr = ak.from_numpy(arr)\r\nind = np.random.randint(0, 10, 512).tolist()\r\nsub = arr[:, :ind]\r\n```\r\nI believe [How to filter lists within arrays using jagged slicing](https://awkward-array.org/how-to-filter-jagged.html) is related to this topic but there is no documentation yet. Would anyone be generously pointing me to the right location to look into this? Or write this doc? Thank you very much!\r\n",
  "closed_at":"2020-10-05T16:36:40Z",
  "comments":3,
  "created_at":"2020-10-05T02:51:30Z",
  "id":714471366,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTQ0NzEzNjY=",
  "number":480,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"How to slice array with a list or ndarray",
  "updated_at":"2020-10-05T16:36:40Z",
  "user":"MDQ6VXNlcjIzNDg3MjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"We got the 3.9 Linux deployments \"accidentally,\" but the MacOS and Windows ones have to be done on purpose.\r\n\r\nIn addition, all operating systems have to _test_ with the new Python version.",
  "closed_at":"2020-10-29T19:37:53Z",
  "comments":0,
  "created_at":"2020-10-05T22:03:04Z",
  "id":715192420,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTUxOTI0MjA=",
  "number":481,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Add Python 3.9 to all tests and deployed wheels",
  "updated_at":"2020-10-29T19:37:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-10-29T19:37:53Z",
  "comments":2,
  "created_at":"2020-10-06T14:14:29Z",
  "draft":false,
  "id":715719219,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDk4NTc5NDcz",
  "number":482,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-10-29T19:37:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add Python 3.9 to tests and deployment.",
  "updated_at":"2020-10-29T19:37:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I've been working on some fastjet bindings with an awkward1 interface based on pybind11 (I'm aware of pyjet and the SWIG bindings, but for various reasons, this was a better approach for me. I'm not linking them here because they're early and ugly and not really ready for anyone else, but the repo can be found on my profile if it's somehow helpful). I have an early version working on macOS, but when I moved to linux (ubuntu 18.04 for what it's worth, but I'm working in a virtualenv), it throws a TypeError whenever I try to pass an array layout to c++. For a trivial function which just returns what it receives, on linux I get\r\n\r\n```python\r\nPython 3.6.9 (default, Jul 17 2020, 12:50:27)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import awkward1 as ak\r\n>>> import pybind11_awkward as pba\r\n>>> pba.awkward_test(ak.Array([1,2,3]).layout)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: awkward_test(): incompatible function arguments. The following argument types are supported:\r\n    1. (arr: awkward::Content) -> awkward::Content\r\n\r\nInvoked with: <NumpyArray format=\"l\" shape=\"3\" data=\"1 2 3\" at=\"0x000001be97b0\"/>\r\n```\r\n\r\nOn macOS, I get:\r\n\r\n```python\r\nPython 3.8.5 (default, Jul 21 2020, 10:48:26)\r\n[Clang 11.0.3 (clang-1103.0.32.62)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import awkward1 as ak\r\n>>> import pybind11_awkward as pba\r\n>>> pba.awkward_test(ak.Array([1,2,3]).layout)\r\nIn function\r\n<NumpyArray format=\"l\" shape=\"3\" data=\"1 2 3\" at=\"0x7ff17b283a00\"/>\r\n```\r\n\r\nOther functions seem to work fine - it's apparently something about passing awkward arrays. I'm using awkward 0.3.1.\r\n\r\nI'm a bit stuck on how to proceed. I recognize there's a huge phase space where I could have gone wrong, so I made a quick repository that reproduces the issue, and I tried to keep as much consistent as possible. It's available [here](https://github.com/raymondEhlers/pybind11-awkward-array-test). You can install it with `poetry install`, and then run `test_simple.py`. (In principle, it should work with pip using PEP 517, but my build script isn't quite right, sorry). I'm not 100% sure that this is actually an awkward1 issue (there are still some differences in the setups), but it seems like a reasonable place to start.\r\n\r\nAs always, help or suggestions are greatly appreciated! Thanks!",
  "closed_at":"2020-10-07T14:07:49Z",
  "comments":19,
  "created_at":"2020-10-06T22:53:04Z",
  "id":716073241,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTYwNzMyNDE=",
  "number":483,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"In dependent project, ak.layout fails to convert to ak::Content. Update pybind11!",
  "updated_at":"2021-03-02T17:06:54Z",
  "user":"MDQ6VXNlcjE1NzE5Mjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Based on the usual masked take behavior (output structure matches mask structure), e.g.\r\n```python\r\n>>> ak.Array([1])[ak.Array([None, None])]\r\n<Array [None, None] type='2 * ?int64'>\r\n```\r\nI would expect the following to produce `[None, None]` as well:\r\n```python\r\n>>> ak.Array([])[ak.Array([None, None])]\r\n<Array [] type='0 * ?unknown'>\r\n```\r\nThis issue does seem to be true even for initially nonempty arrays:\r\n```python\r\n>>> ak.Array([1, 2, 3])[:0][ak.Array([None, None])]\r\n<Array [] type='0 * ?int64'>\r\n```",
  "closed_at":"2020-11-05T16:19:09Z",
  "comments":0,
  "created_at":"2020-10-06T23:01:49Z",
  "id":716076861,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MTYwNzY4NjE=",
  "number":484,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Masked take on empty array",
  "updated_at":"2020-11-05T16:19:09Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Fixes #483",
  "closed_at":"2020-10-07T14:07:50Z",
  "comments":3,
  "created_at":"2020-10-07T12:40:50Z",
  "draft":false,
  "id":716493582,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NDk5MjIwMzUz",
  "number":485,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-10-07T14:07:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Update to pybind11 2.5.0",
  "updated_at":"2024-01-18T17:23:09Z",
  "user":"MDQ6VXNlcjE1NzE5Mjc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Using `ar != None` results in an unexpected mask\r\n\r\nConsider:\r\n```\r\na = ak.Array([None, 2, None, 2, None])\r\nb = np.array([None, 2, None, 2, None])\r\na, b\r\n>>> (<Array [None, 2, None, 2, None] type='5 * ?int64'>,\r\n array([None, 2, None, 2, None], dtype=object))\r\n```\r\n\r\n```\r\na != None\r\n>>> <Array [None, True, None, True, None] type='5 * ?bool'>\r\n\r\nb != None\r\n>>> array([False,  True, False,  True, False])\r\n```\r\n\r\nExpected behaviour:\r\n```\r\na != None\r\n>>><Array [False, True, False, True, False] type='5 * ?bool'>\r\n```\r\nsuch that \r\n```\r\na[a != None]\r\n>>> <Array [2, 2] type='2 * ?int64'>,\r\n```",
  "closed_at":"2022-11-10T21:02:21Z",
  "comments":3,
  "created_at":"2020-10-13T15:08:38Z",
  "id":720395475,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjAzOTU0NzU=",
  "number":487,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ar != None unexpected behaviour",
  "updated_at":"2023-02-15T19:10:57Z",
  "user":"MDQ6VXNlcjEzMjI2NTAw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Advertise conda availability in README.\r\n\r\nNo code changes.",
  "closed_at":"2020-10-16T17:44:27Z",
  "comments":2,
  "created_at":"2020-10-16T16:53:26Z",
  "draft":false,
  "id":723378748,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTA0OTc0NTc3",
  "number":488,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-10-16T17:44:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add conda install instructions",
  "updated_at":"2020-10-16T17:44:27Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello,\r\n\r\nThanks for the excellent work!! So I'm working on an application where I want to apply `np.random.normal` on each element of the awkward array. I'm trying to do the followings:\r\n\r\n```\r\na = ak.from_iter([[8],[7],[9,11],[5]])\r\nf = lambda x : np.random.normal(x,x*0.15)\r\n# f(a) gives errors\r\nf_arr = np.frompyfunc(f, 1, 1) # try making ufunc\r\n# f_arr(a) also gives errors\r\n```\r\n\r\nI'm wondering if anyone here have suggestions as to what I should do in this case. \ud83d\ude04 Our solution right now is to basically do nested loops to change each element, which is not very efficient. ",
  "closed_at":"2022-04-15T19:49:31Z",
  "comments":11,
  "created_at":"2020-10-17T20:25:58Z",
  "id":723841330,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjM4NDEzMzA=",
  "number":489,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Apply NumPy's random functions using awkward inputs?",
  "updated_at":"2022-04-15T19:49:31Z",
  "user":"MDQ6VXNlcjM1MTcxNDE3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Hello \r\n\r\nI have an awkward array (1) which I obtained post-processing.\r\n\r\nAn array look like (with some of the elements as None):\r\n\r\n>>> a=ak.Array([96., 99., 67., 13.,  3.,  None, 1.,  1.,None])\r\n\r\nI want to remove the None elements from this array. I tried following but it does not give expected result: \r\n>>> b=a[a!=None]\r\n>>> b\r\n<Array [96, 99, 67, 13, ... None, 1, 1, None] type='9 * ?float64'>\r\n\r\n\r\n I could remove them using loop and worked, but I want to avoid it to save some computing time. Or writing a function and compiling using Numba is only option?\r\n\r\nThanks.\r\n",
  "closed_at":"2020-10-19T00:06:13Z",
  "comments":10,
  "created_at":"2020-10-18T23:58:36Z",
  "id":724171679,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjQxNzE2Nzk=",
  "number":490,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"removing none from awkward array 1",
  "updated_at":"2020-10-19T16:57:02Z",
  "user":"MDQ6VXNlcjQ5OTY2MDk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Dear Experts \r\n\r\nSince stackoverflow sometime does not behave good so I am just posting the issue here, \r\n\r\nhttps://stackoverflow.com/questions/64436398/ak-add-function-similar-to-np-add",
  "closed_at":"2020-10-20T00:21:15Z",
  "comments":2,
  "created_at":"2020-10-19T23:30:05Z",
  "id":725050830,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjUwNTA4MzA=",
  "number":491,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"add function similar to np.add",
  "updated_at":"2020-10-20T03:24:11Z",
  "user":"MDQ6VXNlcjQ5OTY2MDk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"(@jpivarski Feel free to suggest a better issue title. I can also add more information as needed.)\r\n\r\nI'm trying to analyze a data set that has N events, in which each event has M muons and G clusters of hits in a detector. The M muons can be matched to any of the G clusters (including multiple clusters). E.g. assume 7 clusters in an event 0,...,6 with muon0 being matched to cluster2 and cluster5, muon1 matched to cluster2 and cluster6, and the remaining clusters unmatched. The index array would look like (assuming the first two events do not have muons matching to clusters):\r\n```\r\n>>> sim_id_gem_cluster\r\n<Array [[], [], [[2, 5], [6, 2]]] type='3 * var * var * int64'>\r\n```\r\nMuon properties such as pT, eta, phi but also sim_id_gem_cluster are zipped together\r\n```\r\n    sim_muon = ak.zip({\r\n        \"pt\" : tree[\"sim_pt\"],        \r\n        \"eta\" : tree[\"sim_eta\"],    \r\n        \"phi\" : tree[\"sim_phi\"], \r\n        \"sim_id_gem_cluster\" : tree[\"sim_id_gem_cluster\"]  \r\n    })\r\n```\r\nAfter zipping together, the types are\r\n```\r\nsim_muon.pt -> type='1000 * var * var * int32'>\r\nsim_muon.sim_id_gem_cluster -> type='1000 * var * var * int64'>\r\n```\r\nSimilarly, cluster data is zipped together, e.g.\r\n```\r\n    gem_cluster = ak.zip( {\r\n        \"bx\" : tree[\"gem_cluster_bx\"],                \r\n        \"station\" : tree[\"gem_cluster_station\"]  \r\n    })\r\n```\r\nWith types\r\n```\r\ngem_cluster.bx -> type='1000 * var * int32'>\r\ngem_cluster.station -> type='1000 * var * int32'>\r\n```\r\nThe question is: how do I select select the muons which are matched to at least one cluster which satisfies the criteria ```gem_cluster.bx == 0``` and ```gem_cluster.station == 1```?",
  "closed_at":null,
  "comments":18,
  "created_at":"2020-10-21T04:16:29Z",
  "id":726117549,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjYxMTc1NDk=",
  "number":492,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"High-level function for selecting collections of different jaggedness; \"broadcast-slice\"?",
  "updated_at":"2021-07-21T15:41:18Z",
  "user":"MDQ6VXNlcjQxMzQ3ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Unlike this,\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> ar = ak.Array([[1, 2, 3], [], [4, 5]])\r\n>>> ak.broadcast_arrays(ar, 1)\r\n[<Array [[1, 2, 3], [], [4, 5]] type='3 * var * int64'>, <Array [[1, 1, 1], [], [1, 1]] type='3 * var * int64'>]\r\n>>> ak.broadcast_arrays(ar, 1.0)\r\n[<Array [[1, 2, 3], [], [4, 5]] type='3 * var * int64'>, <Array [[1, 1, 1], [], [1, 1]] type='3 * var * float64'>]\r\n```\r\n\r\nit should take its types from the data in `ar`. If `ar` is a record with `x` and `y` fields of different types, the 1's or 0's should have the same types as those fields. (I.e. it should be possible to have `uint8` or whatever.)\r\n\r\nAlso, `np.zeros_like` for strings returns empty strings, and `np.ones_like` for strings returns strings with `\"1\"` in them.",
  "closed_at":"2020-11-13T01:07:21Z",
  "comments":0,
  "created_at":"2020-10-21T15:29:46Z",
  "id":726600561,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjY2MDA1NjE=",
  "number":493,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ones/zeroes_like numpy equivalents",
  "updated_at":"2020-11-13T01:07:21Z",
  "user":"MDQ6VXNlcjEzMjI2NTAw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"```python\r\n>>> import awkward1 as ak\r\n>>> a = ak.Array([[], [5.5], [6.6, 7.7]])\r\n>>> indices = ak.Array([[], [0], [1]])\r\n>>> @nb.jit\r\n... def f(indices):\r\n...   return 1 in indices[2]\r\n... \r\n>>> f(indices)\r\n```\r\n\r\nThe relevant part of the error is\r\n\r\n```\r\n  Overload of function 'contains': File: <numerous>: Line N/A.\r\n    With argument(s): '(awkward1.ArrayView(awkward1.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), Literal[int](1))':\r\n   No match.\r\n```\r\n\r\nbut the full trace is\r\n\r\n```\r\n<stdin>:1: NumbaWarning: \r\nCompilation is falling back to object mode WITH looplifting enabled because Function \"f\" failed type inference due to: No implementation of function Function(<built-in function contains>) found for signature:\r\n \r\n >>> contains(awkward1.ArrayView(awkward1.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), Literal[int](1))\r\n \r\nThere are 16 candidate implementations:\r\n  - Of which 16 did not match due to:\r\n  Overload of function 'contains': File: <numerous>: Line N/A.\r\n    With argument(s): '(awkward1.ArrayView(awkward1.NumpyArrayType(array(int64, 1d, A), none, {}), None, ()), Literal[int](1))':\r\n   No match.\r\n\r\nDuring: typing of intrinsic-call at <stdin> (3)\r\n\r\nFile \"<stdin>\", line 3:\r\n<source missing, REPL/exec in use?>\r\n\r\n/home/jpivarski/miniconda3/lib/python3.8/site-packages/numba/core/object_mode_passes.py:177: NumbaWarning: Function \"f\" was compiled in object mode without forceobj=True.\r\n\r\nFile \"<stdin>\", line 1:\r\n<source missing, REPL/exec in use?>\r\n\r\n  warnings.warn(errors.NumbaWarning(warn_msg,\r\n/home/jpivarski/miniconda3/lib/python3.8/site-packages/numba/core/object_mode_passes.py:187: NumbaDeprecationWarning: \r\nFall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\r\n\r\nFor more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\r\n\r\nFile \"<stdin>\", line 1:\r\n<source missing, REPL/exec in use?>\r\n\r\n  warnings.warn(errors.NumbaDeprecationWarning(msg,\r\nTrue\r\n```",
  "closed_at":"2020-11-17T23:34:13Z",
  "comments":0,
  "created_at":"2020-10-21T17:12:41Z",
  "id":726698165,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MjY2OTgxNjU=",
  "number":494,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Using `in` on an array in Numba raises a type error; need to implement \"contains\"",
  "updated_at":"2020-11-17T23:34:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-11-11T18:41:45Z",
  "comments":4,
  "created_at":"2020-10-21T18:37:01Z",
  "draft":false,
  "id":726767786,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTA3NzgzMDE0",
  "number":495,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-11T18:41:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add a developer tool to check if kernel specification file is sorted",
  "updated_at":"2020-11-11T18:41:48Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"`localindex` is a very useful feature in awkward0 that seems to be present in various places in the source of awkward1, but isn't exposed through the `Array` interface as far as I can tell. That is, it would be nice to be able to get the awkward1 equivalent of:\r\n\r\n```python\r\n>>> import awkward \r\n>>> awkward.fromiter([[1], [2, 3]]).localindex\r\n<JaggedArray [[0] [0 1]] at 0x7ff85f9beac0>\r\n```",
  "closed_at":"2020-11-05T23:08:47Z",
  "comments":7,
  "created_at":"2020-10-22T14:06:53Z",
  "id":727423038,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Mjc0MjMwMzg=",
  "number":496,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Provide access to localindex",
  "updated_at":"2020-11-05T23:10:56Z",
  "user":"MDQ6VXNlcjMyNzczMzA0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Following up on a conversation from Slack: switching between integer indexing and boolean masking is a common task for me, so it would be nice if there were some high-level interface for these conversions.\r\n\r\n## Boolean mask -> integer-array slice conversion\r\n\r\nThis is basically a special case of an awkward [`np.nonzero()`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html). In awkward0, I use:\r\n```python\r\nindices = mask.localindex[mask]\r\n```\r\nso if `localindex` gets implemented in awkward1 (#496), this direction becomes almost trivial. It might be a good idea to just make a `nonzero()` in awkward anyway, though.\r\n\r\n## Integer-array slice -> boolean mask conversion\r\n\r\nIn awkward0, I use:\r\n```python\r\nmask = a.zeros_like().astype(bool)\r\nmask[indices] = True\r\n```\r\nWithout array mutability in awkward1, I need an alternative method to achieve this.",
  "closed_at":"2023-07-02T17:17:34Z",
  "comments":2,
  "created_at":"2020-10-22T14:47:29Z",
  "id":727459214,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Mjc0NTkyMTQ=",
  "number":497,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"High-level functions to convert between integer-array slices and boolean masks",
  "updated_at":"2023-07-02T17:42:47Z",
  "user":"MDQ6VXNlcjMyNzczMzA0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"It would be nice to have some sort of keyed reducer functionality, either through a new `ak.minby` etc. or maybe an optional `ak.min(..., key=None)` argument. Right now, as far as I can tell, the canonical workaround for `ak.min(array, key=condition, axis=1)` is `ak.firsts(array[ak.argmin(condition, axis=1, keepdims=True)])`, although I haven't worked through if that is general for all axes arguments.",
  "closed_at":"2020-10-23T20:21:11Z",
  "comments":1,
  "created_at":"2020-10-23T20:08:33Z",
  "id":728494972,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Mjg0OTQ5NzI=",
  "number":498,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Key for reducers",
  "updated_at":"2020-10-23T20:21:11Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I found a rather complex array layout that cannot for some reason be sliced by a boolean mask. Both are attached in the pickle file [take_bug.pkl.gz](https://github.com/scikit-hep/awkward-1.0/files/5431943/take_bug.pkl.gz) as I didn't want to recreate the whole layout with a more canned example, although it could probably be done.\r\nTo reproduce:\r\n```python\r\nimport gzip\r\nimport pickle\r\nimport awkward1 as ak\r\n\r\nwith gzip.open(\"take_bug.pkl.gz\", \"rb\") as fin:\r\n    a, b = pickle.load(fin)\r\n\r\n# works fine\r\nak.Array(ak.to_list(a))[b]\r\n\r\n# raises\r\na[b]\r\n```\r\nThere is definitely something peculiar about the layout that is causing issue since re-creating the array with a simplified layout allows the take to work.",
  "closed_at":"2020-11-02T22:09:53Z",
  "comments":3,
  "created_at":"2020-10-23T22:05:37Z",
  "id":728549113,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Mjg1NDkxMTM=",
  "number":499,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Bug in take operation on nested arrays",
  "updated_at":"2020-11-02T22:09:53Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Minimal working example (hopefully better than the last one):\r\n``` python\r\none = ak.Array([\"uno\", \"dos\", \"tres\"])\r\none_l = one.layout\r\ntwo = ak.Array([\"un\", \"deux\", \"trois\", \"quatre\"])\r\ntwo_l = two.layout\r\nthree = ak.Array([\"onay\", \"ootay\", \"eethray\"])\r\nthree_l = three.layout\r\nassert ak.to_list(one_l.mergemany([two_l, three_l])) == [\"uno\", \"dos\", \"tres\", \"un\", \"deux\", \"trois\", \"quatre\", \"onay\", \"ootay\", \"eethray\"]\r\nmerged = one_l.mergemany([two_l, three_l])\r\n```\r\nExpected behavior:\r\n``` python\r\none == \"uno\"\r\n>>> <Array [True, False, False] type='3 * ?bool'>\r\nmerged == \"longerstringthantyped\"\r\n>>> <Array [False, False, False, ... False, False] type='10 * ?bool'>\r\n```\r\nBug:\r\n``` python\r\nak.Array(merged) == \"uno\"\r\n>>> UFuncTypeError: ufunc 'equal' did not contain a loop with signature matching types (dtype('S3'), dtype('S3')) -> dtype('bool')\r\n```\r\n\r\nUnfortunately, I haven't caught up with the changes lately. My preliminary check suggests that, this behavior was introduced with [v.0.2.37](https://github.com/scikit-hep/awkward-1.0/compare/0.2.36...0.2.37#diff-5c46d0b61253440d84e39816781d3277efccea7fb0a7997657c58856c5b21260) (more specifically with .mergemany() ([PR#449](https://github.com/scikit-hep/awkward-1.0/pull/449)), and quick guess somewhere around [here](https://github.com/scikit-hep/awkward-1.0/blob/5a90e58fab4d48f46dbc2ff3e14275eccb688349/src/libawkward/array/NumpyArray.cpp#L1596)).\r\nI experienced this bug, when higher level functions like `from_arrow` (that call mergemany internally now) produced the same bug.\r\n",
  "closed_at":"2020-11-02T19:00:43Z",
  "comments":3,
  "created_at":"2020-10-29T18:07:42Z",
  "id":732540064,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzI1NDAwNjQ=",
  "number":501,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"string comparison of string typed array throws a UFuncTypeError",
  "updated_at":"2020-11-02T19:00:43Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-10-30T22:29:09Z",
  "comments":1,
  "created_at":"2020-10-30T22:12:39Z",
  "id":733546777,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzM1NDY3Nzc=",
  "number":502,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Awkward 0 \u2192 Awkward 1 cheat sheet!",
  "updated_at":"2020-10-30T22:29:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEyNDg0MTM=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":null,
  "closed_at":"2022-11-18T01:35:55Z",
  "comments":17,
  "created_at":"2020-10-30T22:24:29Z",
  "id":733551332,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzM1NTEzMzI=",
  "number":503,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Move libawkward.so (etc) into its own package",
  "updated_at":"2023-02-15T19:10:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This should not happen:\r\n\r\n```python\r\n>>> import awkward1 as ak\r\n>>> ak.Array([\"HAL\"]) + 1\r\n<Array [[73, 66, 77]] type='1 * var * uint8'>\r\n```\r\n\r\nIt should raise an error.",
  "closed_at":"2020-11-04T22:21:09Z",
  "comments":0,
  "created_at":"2020-10-30T22:40:14Z",
  "id":733556653,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzM1NTY2NTM=",
  "number":504,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"NumPy ufuncs should not apply to strings",
  "updated_at":"2020-11-04T22:21:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-02T14:51:24Z",
  "comments":0,
  "created_at":"2020-10-30T23:36:52Z",
  "draft":false,
  "id":733575009,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTEzMzMxMzky",
  "number":505,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-02T14:51:24Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Superflous line.",
  "updated_at":"2020-11-02T14:51:27Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Results for awkard.argsort is wrong for arrays with dimensions greater than 2. Example output from awkward1 version 0.3.1\r\n\r\nCode \r\n```\r\nimport awkward1\r\nx = awkward1.Array([[[0.01539855, 0.45536142, 0.9510973 , 0.17593855, 0.30485241],\r\n                     [0.57157337, 0.2281758 , 0.1437675 , 0.80287155, 0.11580015],],\r\n                    [[0.77897828, 0.75505657, 0.61302232, 0.56694878, 0.99761142],\r\n                     [0.38639971, 0.69037858, 0.61298759, 0.6602239 , 0.93297311],],]) # 2x2x5 array generated from numpy.random\r\nprint(awkward1.to_numpy(awkward1.argsort(x,axis=-1)))\r\n```\r\nResulting output: \r\n```\r\n[[[0 3 4 1 2]\r\n  [4 2 1 0 3]]\r\n [[3 2 1 0 4]\r\n  [0 2 3 1 4]]]\r\n```\r\n\r\nExpected output:\r\n```\r\n[[[0 3 4 1 2]\r\n  [3 2 1 4 0]]\r\n [[3 2 1 0 4]\r\n  [0 3 1 2 4]]]\r\n```",
  "closed_at":"2020-11-02T15:02:48Z",
  "comments":7,
  "created_at":"2020-11-02T02:32:50Z",
  "id":734132840,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzQxMzI4NDA=",
  "number":506,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"awkward.argsort is wrong for arrays with dimensions > 2",
  "updated_at":"2020-11-02T16:34:39Z",
  "user":"MDQ6VXNlcjExNzAzNjQ0"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-02T19:00:43Z",
  "comments":0,
  "created_at":"2020-11-02T18:14:30Z",
  "draft":false,
  "id":734718856,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE0MjM1NTU2",
  "number":507,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-02T19:00:43Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #501 and generalizes from_numpy/to_layout to accept NumPy arrays of strings",
  "updated_at":"2020-11-02T19:00:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-02T22:09:53Z",
  "comments":1,
  "created_at":"2020-11-02T20:39:51Z",
  "draft":false,
  "id":734803967,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE0MzA0MjQ3",
  "number":508,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-02T22:09:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #499 by removing gaps from ListArray::content.",
  "updated_at":"2020-11-02T22:09:56Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Inside a Numba-JITed function, users might want to call NumPy functions (`np.*`) on Awkward Arrays that happen to be 1D/simple/flat. Right now, they have to cast such an array with `np.asarray` and then call the NumPy function, which they don't have to do outside of Numba. And that's surprising. It may be possible to register Awkward Arrays (or just NumpyArrayType) as \"array-like\" in Numba, so that it does this conversion automatically.",
  "closed_at":null,
  "comments":3,
  "created_at":"2020-11-03T13:21:30Z",
  "id":735314226,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzUzMTQyMjY=",
  "number":509,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Auto-conversion to NumPy arrays within a Numbafied function",
  "updated_at":"2022-09-01T13:38:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is policy change #457, which has a deprecation message, and also introduces a deprecation mechanism (function in _util.py).",
  "closed_at":"2020-11-03T21:42:58Z",
  "comments":0,
  "created_at":"2020-11-03T20:15:14Z",
  "draft":false,
  "id":735606570,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE0OTY4MzE0",
  "number":510,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-03T21:42:58Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Remove broadcasting over the fields of records",
  "updated_at":"2020-11-03T21:43:01Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I used to do this ([deprecated](https://github.com/scikit-hep/awkward-1.0/issues/350#issue-664526115)) for a deep copy:\r\n```python\r\n>>> import awkward1 as ak\r\n>>> array = ak.Array([])\r\n>>> array.copy() # deprecated with removal of pandas integration #350 \r\n```\r\nYou could do this:\r\n```python\r\n>>> ak.Array(array.layout.deep_copy()) # unwrap and rewrap required similar to #496 \r\n>>> # or\r\n>>> import copy\r\n>>> copy.deepcopy(array)\r\n```\r\n\r\nWould be nice to have something like this (with the same kwargs as the low-level?):\r\n```python\r\n>>> ak.copy(array) # or registered np.copy() which would be strictly deep as object elements aren't supported by awkward1\r\n```\r\n\r\n",
  "closed_at":"2020-11-04T23:28:21Z",
  "comments":1,
  "created_at":"2020-11-04T00:43:25Z",
  "id":735728812,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzU3Mjg4MTI=",
  "number":511,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"High-level access for deep copy",
  "updated_at":"2020-11-04T23:28:21Z",
  "user":"MDQ6VXNlcjI1ODgzNjA3"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-04T18:25:28Z",
  "comments":0,
  "created_at":"2020-11-04T17:30:27Z",
  "draft":false,
  "id":736296741,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE1NTM1MzU3",
  "number":512,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-04T18:25:28Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Always keep references to all caches in a ak.Array.",
  "updated_at":"2020-11-04T18:25:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-04T22:21:10Z",
  "comments":0,
  "created_at":"2020-11-04T21:44:07Z",
  "draft":false,
  "id":736443104,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE1NjU2NTg0",
  "number":513,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-04T22:21:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Blocked ufuncs on custom types, reopened them for categoricals using a new apply_ufunc interface, updated documentation.",
  "updated_at":"2020-11-04T22:21:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-04T23:28:21Z",
  "comments":0,
  "created_at":"2020-11-04T22:58:08Z",
  "draft":false,
  "id":736478341,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE1Njg1ODA1",
  "number":514,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-04T23:28:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Provides high-level access to copy and deepcopy operations.",
  "updated_at":"2020-11-04T23:28:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-05T00:10:55Z",
  "comments":0,
  "created_at":"2020-11-04T23:27:23Z",
  "draft":false,
  "id":736490535,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE1Njk1OTMy",
  "number":515,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-05T00:10:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix fall-through that happened with the deprecation message.",
  "updated_at":"2020-11-05T00:10:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Both functions in `awkward1._util` are used a few times in coffea.\r\nThe [wrapper function](https://github.com/scikit-hep/awkward-1.0/blob/master/src/awkward1/_connect/_numpy.py#L41) that broadcasts and flattens inputs for numpy ufuncs was copied in a simplified form to coffea lookup_tools: https://github.com/CoffeaTeam/coffea/blob/master/coffea/lookup_tools/lookup_base.py#L19-L45\r\nThe recursively_apply function [is used](https://github.com/CoffeaTeam/coffea/blob/akcache/coffea/nanoevents/methods/base.py#L65-L75) to make sure a index take operates on the flat array in NanoEvents cross-references.",
  "closed_at":"2022-08-19T21:59:43Z",
  "comments":1,
  "created_at":"2020-11-05T01:25:34Z",
  "id":736534318,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzY1MzQzMTg=",
  "number":516,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Public broadcast wrapper and recursively_apply tool",
  "updated_at":"2022-08-19T21:59:43Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-05T16:19:09Z",
  "comments":0,
  "created_at":"2020-11-05T15:21:14Z",
  "draft":false,
  "id":737024511,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE2MTM4MzI4",
  "number":517,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-05T16:19:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Masked take on an empty array should behave in a way that is consistent with non-empty arrays.",
  "updated_at":"2020-11-05T16:19:14Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-05T22:02:54Z",
  "comments":0,
  "created_at":"2020-11-05T17:12:14Z",
  "draft":false,
  "id":737115098,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE2MjEyNDI5",
  "number":518,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-05T22:02:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"to_pandas with IndexedArrays (and other types)",
  "updated_at":"2020-11-05T22:02:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-05T23:08:47Z",
  "comments":0,
  "created_at":"2020-11-05T22:33:08Z",
  "draft":false,
  "id":737315458,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE2Mzc5NDUy",
  "number":519,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-05T23:08:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Provide ak.local_index.",
  "updated_at":"2020-11-05T23:08:51Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-06T22:17:46Z",
  "comments":0,
  "created_at":"2020-11-06T19:48:00Z",
  "draft":false,
  "id":738001970,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE2OTQ1MDcx",
  "number":520,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-06T22:17:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually remove expired deprecations (they were supposed to go in 0.4.0).",
  "updated_at":"2020-11-06T22:17:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"This might be a result of me trying to use Awkward for something it isn't really intended for, but it seems like a bug.\r\n\r\nNumPy matrix multiplication always works in the lowest two dimensions and will broadcast over higher dimensions. This does not seem to work as expected in Awkward. Take this example:\r\n```py\r\nimport numpy as np\r\nimport awkward1 as ak\r\n\r\nn = np.array([[1, 2], [3, 4]])\r\nnn = np.array([n, n])\r\na = ak.Array(n)\r\naa = ak.Array(nn)\r\n\r\nprint('n @ n', n @ n)\r\nprint('nn @ n', nn @ n)\r\nprint('a @ a', a @ a)\r\nprint('aa @ a', aa @ a)\r\n```\r\nWhich would print\r\n```\r\nn @ n [[ 7 10]\r\n [15 22]]\r\nnn @ n [[[ 7 10]\r\n  [15 22]]\r\n [[ 7 10]\r\n  [15 22]]]\r\na @ a [[7, 10], [15, 22]]\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-67-4cd9e7253ac9>\", line 12, in <module>\r\n    print('aa @ a', aa @ a)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/numpy/lib/mixins.py\", line 21, in func\r\n    return ufunc(self, other)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/highlevel.py\", line 1369, in __array_ufunc__\r\n    return awkward1._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_connect/_numpy.py\", line 173, in array_ufunc\r\n    out = awkward1._util.broadcast_and_apply(\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 996, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 575, in apply\r\n    return apply(nextinputs, depth)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 606, in apply\r\n    return apply(\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 606, in apply\r\n    return apply(\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_util.py\", line 584, in apply\r\n    return function()\r\n  File \"/opt/anaconda/envs/fys-stk4155/lib/python3.8/site-packages/awkward1/_connect/_numpy.py\", line 126, in <lambda>\r\n    return lambda: (awkward1.layout.NumpyArray(result),)\r\nValueError: NumpyArray must not be scalar; try array.reshape(1)\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.4.3/src/python/content.cpp#L1822)\r\n```\r\nSo the higher-dimensional matrix multiplication errors out for the Awkward arrays.\r\n\r\nI started looking at Awkward because I needed to work with ragged arrays where the two lowest dimensions would be matrices (not ragged), but it seems Awkward's support for matrix operations are lacking. Are these operations in scope for Awkward, and is the example above thus  a bug?",
  "closed_at":"2020-11-13T23:12:34Z",
  "comments":4,
  "created_at":"2020-11-07T15:31:52Z",
  "id":738263431,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzgyNjM0MzE=",
  "number":521,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Matrix multiplication broadcasting different from NumPy",
  "updated_at":"2020-11-14T09:25:45Z",
  "user":"MDQ6VXNlcjgxNzAwMQ=="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Forwarding https://github.com/CoffeaTeam/coffea/issues/367 here since it is mostly likely an issue in awkward given the trace (click link for details).\r\n\r\nRepro is currently with NanoEvents to source data so you'll need the most recent coffea release to run this.\r\n```python3\r\nfrom coffea.nanoevents import NanoEventsFactory\r\nfname = 'https://raw.githubusercontent.com/CoffeaTeam/coffea/master/tests/samples/nano_dy.root'\r\nfactory = NanoEventsFactory.from_file(fname)\r\nevents = factory.events()\r\n\r\ngen_pt = awkward1.fill_none(events.Jet.matched_gen.pt, 0.)\r\njetPt = events.Jet.pt\r\n\r\nprint(-gen_pt + jetPt)  # produces correct answer\r\nprint(jetPt - gen_pt)  # fails with traceback as below\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/numpy/lib/mixins.py\", line 21, in func\r\n    return ufunc(self, other)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/highlevel.py\", line 1369, in __array_ufunc__\r\n    return awkward1._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_connect/_numpy.py\", line 174, in array_ufunc\r\n    inputs, getfunction, behavior, allow_records=False\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 996, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 847, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 589, in apply\r\n    depth,\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 655, in apply\r\n    nextinputs.append(x[mask].project(combo[str(i)]))\r\nValueError: no field of name 1\r\n```",
  "closed_at":"2020-11-12T00:34:01Z",
  "comments":1,
  "created_at":"2020-11-07T20:37:10Z",
  "id":738313878,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3MzgzMTM4Nzg=",
  "number":522,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Array order dependent math failure between ListOffsetArray64 and ListOffsetArray64 containing UnionArray8_64",
  "updated_at":"2020-11-12T00:34:01Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"The following code:\r\n\r\n```\r\nimport pickle\r\nimport awkward1 as ak\r\nwith open('arg_sort_boom.pcl', 'rb') as f:\r\n    data = pickle.load(f)\r\n    \r\n    ak.argsort(data, axis=1)\r\n```\r\n\r\nProduces the following output:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-8d8e8752b65b> in <module>\r\n      4     data = pickle.load(f)\r\n      5 \r\n----> 6     ak.argsort(data, axis=1)\r\n\r\n/opt/conda/lib/python3.7/site-packages/awkward1/operations/structure.py in argsort(array, axis, ascending, stable, highlevel)\r\n   1130         array, allow_record=False, allow_other=False\r\n   1131     )\r\n-> 1132     out = layout.argsort(axis, ascending, stable)\r\n   1133     if highlevel:\r\n   1134         return awkward1._util.wrap(out, awkward1._util.behaviorof(array))\r\n\r\nRuntimeError: argsort_next with unbranching depth > negaxis is only expected to return RegularArray or ListOffsetArray64; instead, it returned IndexedOptionArray64\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.4.3/src/libawkward/array/IndexedArray.cpp#L2311)\r\n```\r\n\r\nSee [arg_sort_boom.zip](https://github.com/scikit-hep/awkward-1.0/files/5506878/arg_sort_boom.zip) for the data file. \r\n\r\nFor completeness, the `print(data)` returns:\r\n\r\n```\r\n[[149, 115, 73.5, 49.1, 44.1, 40.8], [151, 94.8]]\r\n```\r\n\r\nand the representation:\r\n\r\n```\r\n<Array [[149, 115, 73.5, 49.1, ... [151, 94.8]] type='2 * option[var * ?float64]'>\r\n```\r\n\r\nNote that:\r\n\r\n```\r\nak.argsort(ak.Array([[149, 115, 73.5, 49.1, 44.1, 40.8], [151, 94.8]]), axis=1)\r\n```\r\n\r\nreturns the expected answer:\r\n\r\n```\r\nArray [[5, 4, 3, 2, 1, 0], [1, 0]] type='2 * var * int64'>\u200b\r\n```\r\n\r\nSo something is bad about the array that I'm using as input. Comments about the array:\r\n\r\n- It was loaded from standard ROOT files using `uproot4` into an `awkward1` array.\r\n- It was then saved to a parquet file using `ak.to_parquet`\r\n- It was then loaded from the parquet file using `ak.from_parquet`.\r\n- The type, `?float54` might be a clue here.\r\n\r\n\r\n",
  "closed_at":"2020-11-17T23:32:28Z",
  "comments":6,
  "created_at":"2020-11-08T17:51:34Z",
  "id":738518493,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Mzg1MTg0OTM=",
  "number":523,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"`argsort` fails with `RunTimeError` when processing awkward array",
  "updated_at":"2020-11-17T23:32:29Z",
  "user":"MDQ6VXNlcjE3NzgzNjY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"address https://github.com/scikit-hep/awkward-1.0/issues/523",
  "closed_at":"2020-11-17T20:24:15Z",
  "comments":3,
  "created_at":"2020-11-09T10:28:54Z",
  "draft":false,
  "id":738901054,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE3NjU2NzI3",
  "number":524,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T20:24:15Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"argsort and sort for indexed option arrays bug fix ",
  "updated_at":"2020-11-17T20:24:19Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-09T23:23:22Z",
  "comments":3,
  "created_at":"2020-11-09T17:24:47Z",
  "draft":false,
  "id":739218166,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE3OTE5NzI3",
  "number":525,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-09T23:23:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix #402: Form::getitem_field must return the Form of what Content::getitem_field would return.",
  "updated_at":"2020-11-09T23:23:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-10T20:25:07Z",
  "comments":0,
  "created_at":"2020-11-10T19:46:20Z",
  "draft":false,
  "id":740194183,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE4NzI0MTEz",
  "number":526,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-10T20:25:07Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix (infinite) recursion bug in Arrow translation.",
  "updated_at":"2020-11-10T20:25:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-12T00:34:01Z",
  "comments":0,
  "created_at":"2020-11-11T20:58:57Z",
  "draft":false,
  "id":741066244,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTE5NDQ3NzM2",
  "number":527,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-12T00:34:00Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix UnionArray ufuncs and parameters in merging.",
  "updated_at":"2020-11-12T00:34:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjE4NTI0NDc=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Following the nice invite in the docs to raise an issue for unfilled topics that should get higher priority, I am doing that here.\r\n\r\nI would like to write a numba function that returns an awkward array (specifically a ListOffsetArray) from other ListOffsetArrays. I need to run the equivalent of numpy.empty_like(...) and numpy.zeros_like(...) in numba-compiled Python with an awkward array. I suppose that filling the array is straight forward, I have trouble with the creation...\r\n\r\nOn a related note, is it possible to access the total size of a ListOffsetArray from within numba-compiled Python?",
  "closed_at":null,
  "comments":4,
  "created_at":"2020-11-12T12:35:25Z",
  "id":741564434,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDE1NjQ0MzQ=",
  "number":528,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Could you please extend https://awkward-array.org/how-to-use-in-numba-arraybuilder.html",
  "updated_at":"2024-01-20T01:06:35Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I checked the docs and it seems like the functions `empty_like`, `zeros_like` and `ones_like` are currently missing from awkward1. I think it would be great to have these, they are commonly needed when writing some array transforms. Ideally, these should also be available in Numba-compiled Python.",
  "closed_at":"2020-11-12T14:22:20Z",
  "comments":6,
  "created_at":"2020-11-12T12:38:47Z",
  "id":741566599,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDE1NjY1OTk=",
  "number":529,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Adding empty_like, zeros_like, ones_like?",
  "updated_at":"2020-11-17T17:25:16Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"From a report on Gitter, pyarrow 0.17.1 can fail with a segfault (illegal hardware instruction!) when used with Awkward Array, but in general it won't work with anything less than pyarrow 1.0 (possibly 2.0: have to check). The `import pyarrow` line should check the pyarrow version and raise an exception if the minimum isn't met (like we're already doing with Numba).",
  "closed_at":"2020-11-13T01:48:31Z",
  "comments":1,
  "created_at":"2020-11-12T17:14:52Z",
  "id":741777994,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDE3Nzc5OTQ=",
  "number":531,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Complain about minimal pyarrow version",
  "updated_at":"2020-11-13T01:48:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I can do `uproot4.open` for example, but when I do `help(uproot4)`, I won't find `open` listed there. I understand that `open` is implemented in a submodule, but `help` should list the function or class documentation on the level where that is available, because that's where people will look for it (I don't know exactly where `open` is implemented).",
  "closed_at":"2020-11-12T19:46:21Z",
  "comments":2,
  "created_at":"2020-11-12T19:40:48Z",
  "id":741876221,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDE4NzYyMjE=",
  "number":533,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"help() on uproot4 difficult to navigate",
  "updated_at":"2020-11-12T19:46:21Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"`uproot` had `recreate`, but it is missing in `uproot4` ",
  "closed_at":"2020-11-12T19:45:54Z",
  "comments":2,
  "created_at":"2020-11-12T19:43:09Z",
  "id":741877584,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDE4Nzc1ODQ=",
  "number":534,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"`uproot4.recreate` is missing",
  "updated_at":"2020-11-12T19:45:54Z",
  "user":"MDQ6VXNlcjI2MzE1ODY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-13T01:07:21Z",
  "comments":0,
  "created_at":"2020-11-12T21:34:29Z",
  "draft":false,
  "id":741943585,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIwMTcwODY4",
  "number":535,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-13T01:07:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implemented zeros_like, ones_like, and full_like, and fixed from_numpy for NumPy string arrays.",
  "updated_at":"2020-11-13T01:07:24Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-13T01:48:31Z",
  "comments":1,
  "created_at":"2020-11-13T01:08:43Z",
  "draft":false,
  "id":742044838,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIwMjU0NjA1",
  "number":536,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-13T01:48:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Enforce minimum Arrow version 2.0.0 and fix issues due to ARROW-9556.",
  "updated_at":"2020-11-13T01:48:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-13T23:12:34Z",
  "comments":0,
  "created_at":"2020-11-13T20:56:30Z",
  "draft":false,
  "id":742784574,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIwODQ4MTE5",
  "number":537,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-13T23:12:34Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix matrix multiplication.",
  "updated_at":"2020-11-13T23:12:37Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Trying to build jet systematics ran into some strange timing performance results. In particular this is assigning lists of variations of jets back into the list of jets, assignment by setattr is much more straightforward to use and better for bookkeeping, and I can imagine variations like this being written by end users for other corrections. The difference in performance is rather striking.\r\n\r\nThis is with 40 events / 188 jets, so most of the time is spent constructing descriptions of arrays.\r\n\r\n```python3\r\nimport random\r\nimport time\r\nimport copy\r\nimport awkward1\r\nfrom coffea.nanoevents import NanoEventsFactory\r\n\r\nfname = 'https://raw.githubusercontent.com/CoffeaTeam/coffea/master/tests/samples/nano_dy.root'\r\nfactory = NanoEventsFactory.from_file(fname)\r\nevents = factory.events()\r\n\r\ndecorated_jets = awkward1.flatten(events.Jet)\r\n\r\nnames = {'%06x' % random.randrange(16**6) for i in range(50)}\r\n\r\nprint('number of variants', len(names))\r\n\r\ntic = time.time()\r\n\r\nsyst_dict = {}\r\nfor name in names:\r\n    syst_dict[name] = awkward1.zip({'up': awkward1.flatten(events.Jet),\r\n                                    'down': awkward1.flatten(events.Jet)},\r\n                                    depth_limit=1,\r\n                                    with_name='JetSystematic')\r\ntoc = time.time()\r\n\r\nprint('time to make variants:', toc-tic)\r\n\r\ntic = time.time()\r\nfor name in names:\r\n    decorated_jets[name] = syst_dict[name]\r\ntoc = time.time()\r\nprint('time to assign with __setitem__:', toc-tic)\r\n\r\n\r\ntic = time.time()\r\nold_fields = awkward1.fields(decorated_jets)\r\nsyst_dict.update({field: decorated_jets[field] for field in old_fields})\r\ndecorated_jets = awkward1.zip(syst_dict, depth_limit=1, with_name='Jet')\r\ntoc = time.time()\r\nprint('time to assign with rezip:', toc-tic)\r\n```\r\n\r\nresults in:\r\n```\r\nnumber of variants 50\r\ntime to make variants: 0.40229296684265137\r\ntime to assign with __setitem__: 8.58899211883545\r\ntime to assign with rezip: 0.2941272258758545\r\n```\r\n\r\nNot to mention the latter does some very funky thing to the type of the array.\r\nOn a not-too-old macbook pro. ",
  "closed_at":"2020-11-17T01:10:33Z",
  "comments":5,
  "created_at":"2020-11-13T21:41:14Z",
  "id":742805318,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDI4MDUzMTg=",
  "number":538,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Assigning jet variations by setitem quite slow compared to bulk assignment by awkward.zip",
  "updated_at":"2020-11-17T01:10:34Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"address Issue #184\r\n\r\nTODO:\r\n\r\n- [x] introduce negative axis\r\n- [x] fix deprecated warning\r\n\r\ncode has been moved from https://github.com/scikit-hep/awkward-1.0/pull/361",
  "closed_at":"2020-11-17T13:05:40Z",
  "comments":7,
  "created_at":"2020-11-15T17:46:44Z",
  "draft":false,
  "id":743307141,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIxMjMxODU3",
  "number":539,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T13:05:39Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"concatenate for a nonzero axis operation",
  "updated_at":"2020-11-17T13:05:46Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-17T01:10:34Z",
  "comments":0,
  "created_at":"2020-11-16T19:04:07Z",
  "draft":false,
  "id":744084742,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIxODY2NTM1",
  "number":540,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T01:10:33Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix issue #538's performance issues.",
  "updated_at":"2020-11-17T01:10:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Below is not minimal but reflects where I first found the bug (NumpyArray), which seems to also extend to regular arrays?\r\n\r\nBelow produces an error on the master branch.\r\n\r\n```python3\r\nimport awkward1 as ak\r\nimport numpy as np\r\n\r\nFORM1 = {\r\n    \"class\": \"RegularArray\",\r\n    \"content\": \"float32\",\r\n    \"size\": 3\r\n}\r\n\r\nFORM2 = {\r\n    \"class\": \"NumpyArray\",\r\n    \"inner_shape\": [\r\n        3\r\n    ],\r\n    \"itemsize\": 4,\r\n    \"format\": \"f\",\r\n    \"primitive\": \"float32\"\r\n}\r\n\r\nrcd_array = ak.Array([{'x': 1.0} for i in range(100)])\r\n\r\nlength = len(rcd_array)\r\nx1 = ak.virtual(lambda length: np.ones((length, 3), dtype=np.float32),\r\n                args=(length, ),\r\n                length=length,\r\n                form=FORM1)\r\nx2 = ak.virtual(lambda length: ak.layout.NumpyArray(np.ones((length, 3), dtype=np.float32)),\r\n                args=(length, ),\r\n                length=length,\r\n                form=FORM2)\r\n\r\nrcd_array['test1'] = x1\r\nrcd_array['test2'] = x2\r\n```\r\n\r\nfails with:\r\n```\r\nTraceback (most recent call last):\r\n  File \"more_bugs.py\", line 32, in <module>\r\n    rcd_array['test1'] = x1\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/highlevel.py\", line 1026, in __setitem__\r\n    self._layout, what, where\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/operations/structure.py\", line 560, in with_field\r\n    [base, what], getfunction, behavior\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 996, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 572, in apply\r\n    return apply(nextinputs, depth)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 586, in apply\r\n    depth,\r\n  File \"/Users/lagray/miniconda3/envs/coffea-work/lib/python3.7/site-packages/awkward1/_util.py\", line 754, in apply\r\n    + exception_suffix(__file__)\r\nValueError: cannot broadcast RegularArray of size 3 with RegularArray of size 100\r\n```\r\n",
  "closed_at":"2020-11-17T15:20:42Z",
  "comments":5,
  "created_at":"2020-11-17T02:54:43Z",
  "id":744364401,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDQzNjQ0MDE=",
  "number":541,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Cannot assign Virtual Regular (or equivalent Numpy) Array - fails with broadcasting error",
  "updated_at":"2020-11-18T16:24:37Z",
  "user":"MDQ6VXNlcjEwNjgwODk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"By attaching the corresponding *Array and *Record classes to the module from which the class comes. May be fragile (but no more so than pickle itself)",
  "closed_at":"2020-11-17T16:45:30Z",
  "comments":3,
  "created_at":"2020-11-17T06:35:21Z",
  "draft":false,
  "id":744455900,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyMTc3MTI3",
  "number":542,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T16:45:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Pickle-able mixin classes from decorator",
  "updated_at":"2020-12-01T01:57:26Z",
  "user":"MDQ6VXNlcjY1ODc0MTI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Address Issue https://github.com/scikit-hep/awkward-1.0/issues/437\r\n\r\n- [x] stream JSON fragments from a JSON file\r\n- [x] stream JSON fragments from a string (same as above?)\r\n- [x] convert `\"NaN\"` and `\"Inf\"` strings as `NaN` and `Inf` floats\r\n- [x] convert `\"NaN\"` and `\"Inf\"` strings as other \"predefined\" strings\r\n- [x] allow user to re-defined \"from_string\" to \"to_string\" values (the UI?) \r\n\r\n@jpivarski - that seems to be working out of the box. I'm creating the PR to test it on different architectures.",
  "closed_at":"2020-11-30T12:29:56Z",
  "comments":14,
  "created_at":"2020-11-17T15:58:30Z",
  "draft":false,
  "id":744865063,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyNTE4ODM0",
  "number":543,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":null
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Options for \"NaN\" strings as NaN floats",
  "updated_at":"2020-12-04T08:42:41Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-17T19:33:02Z",
  "comments":0,
  "created_at":"2020-11-17T18:28:52Z",
  "draft":false,
  "id":744979572,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyNjE1MjI5",
  "number":544,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T19:33:02Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Simplified and generalized ak.where using broadcast_and_apply.",
  "updated_at":"2020-11-17T19:33:05Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"First, `ak.concatenate`'s call of `to_layout` should have `allow_other=True`:\r\n\r\n```python\r\n>>> ak.concatenate([ak.Array([[1, 2, 3], [], [4, 5]]), 999], axis=1)\r\n```\r\n\r\nshould return `[[1, 2, 3, 999], [999], [4, 5, 999]]`, not raise TypeError.\r\n\r\nSecond, the UnionArray that it creates should be simplified (`out.simplify(mergebool=False)`):\r\n\r\n```python\r\n>>> ak.concatenate([ak.Array([[1, 2, 3], [], [4, 5]]), ak.Array([[123], [223], [323]])], axis=1)\r\n<Array [[1, 2, 3, 123], [223], [4, 5, 323]] type='3 * var * union[int64, int64]'>\r\n```\r\n\r\nThe type should be `3 * var * int64`.\r\n\r\nFinally, I don't know why it's not broadcasting here:\r\n\r\n```python\r\n>>> ak.concatenate([ak.Array([[1, 2, 3], [], [4, 5]]), ak.Array([123, 223, 323])], axis=1)\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/operations/structure.py\", line 1020, in concatenate\r\n    out = awkward1._util.broadcast_and_apply(contents, getfunction,\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 996, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 759, in apply\r\n    outcontent = apply(nextinputs, depth + 1)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/_util.py\", line 577, in apply\r\n    function = getfunction(inputs, depth)\r\n  File \"/home/jpivarski/irishep/awkward-1.0/awkward1/operations/structure.py\", line 1015, in getfunction\r\n    out = inputs[0].mergemany_as_union(inputs[1:], 1)\r\nValueError: axis out of range for flatten\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/0.4.4/src/libawkward/array/NumpyArray.cpp#L1431)\r\n```\r\n\r\nI would expect the result `[[1, 2, 3, 123], [223], [4, 5, 323]]`.",
  "closed_at":"2020-11-18T15:33:12Z",
  "comments":9,
  "created_at":"2020-11-17T20:39:05Z",
  "id":745071055,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDUwNzEwNTU=",
  "number":545,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.concatenate tweaks",
  "updated_at":"2020-11-18T15:33:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"```python\r\n>>> array = ak.values_astype(ak.Array([1.1, 2.2, None, 3.3]), np.float32)\r\n>>> array\r\n<Array [1.1, 2.2, None, 3.3] type='4 * ?float32'>\r\n>>> ak.fill_none(array, np.float32(0))\r\n<Array [1.1, 2.2, 0, 3.3] type='4 * float64'>\r\n```\r\n\r\nBut if we explicitly make the fill value a `np.float32(0)`, we want the output to be `float32`.\r\n\r\nAwkward Array knows the NumPy type coercion rules, which would merge `float32` and `float32` to make `float32` (not `float64`). For example,\r\n\r\n```python\r\n>>> ak.concatenate([array, np.array([1, 2, 3], np.float32)])\r\n<Array [1.1, 2.2, None, 3.3, 1, 2, 3] type='7 * ?float32'>\r\n```",
  "closed_at":"2021-07-13T20:32:55Z",
  "comments":0,
  "created_at":"2020-11-17T20:43:25Z",
  "id":745073541,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDUwNzM1NDE=",
  "number":546,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.fill_none is losing the dtype of its replacement value",
  "updated_at":"2021-07-13T20:32:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-17T23:34:13Z",
  "comments":0,
  "created_at":"2020-11-17T22:55:19Z",
  "draft":false,
  "id":745148201,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyNzU3MDc0",
  "number":547,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-17T23:34:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implemented '__contains__' in and out of Numba.",
  "updated_at":"2020-11-17T23:34:16Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"address issue https://github.com/scikit-hep/awkward-1.0/issues/545",
  "closed_at":"2020-11-18T15:31:56Z",
  "comments":0,
  "created_at":"2020-11-17T23:07:01Z",
  "draft":false,
  "id":745153645,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyNzYxNjY3",
  "number":548,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-18T15:31:56Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"concatenate bug-fix",
  "updated_at":"2020-11-18T15:32:00Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"It would be great to see the latest version of awkward1 on Conda-Forge (it's right now at 0.3.1).\r\nI'd have no problem to wait for it longer should it be delayed on purpose. On the other hand, I'd love to try out the new versions.",
  "closed_at":"2020-11-25T10:35:01Z",
  "comments":4,
  "created_at":"2020-11-18T00:25:39Z",
  "id":745189364,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDUxODkzNjQ=",
  "number":549,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Conda-Forge Builds",
  "updated_at":"2020-11-25T10:35:01Z",
  "user":"MDQ6VXNlcjExMzA2NzMy"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-18T03:18:10Z",
  "comments":0,
  "created_at":"2020-11-18T00:26:04Z",
  "draft":false,
  "id":745189533,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIyNzkxNzQ1",
  "number":550,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-18T03:18:10Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implemented 'np.array(ak.Array)' in Numba.",
  "updated_at":"2020-11-18T03:18:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This would be Python only, and would take an `axis` parameter (most likely use `recursively_apply`).\r\n\r\nRegularArray \u2192 ListOffsetArray can use the existing [RegularArray::toListOffsetArray64](https://github.com/scikit-hep/awkward-1.0/blob/eae5de5bc54ac3177787ae9fb3b908e4d6cd6492/src/libawkward/array/RegularArray.cpp#L297-L307) function from the C++ side.\r\n\r\nListOffsetArray \u2192 RegularArray can use the existing [ListOffsetArray::toRegularArray](https://github.com/scikit-hep/awkward-1.0/blob/eae5de5bc54ac3177787ae9fb3b908e4d6cd6492/src/libawkward/array/ListOffsetArray.cpp#L336-L355) and [ListArray::toRegularArray](https://github.com/scikit-hep/awkward-1.0/blob/eae5de5bc54ac3177787ae9fb3b908e4d6cd6492/src/libawkward/array/ListArray.cpp#L306-L314), also from the C++ side.\r\n\r\nSo really, 90% of these two functions already exist. This is a super-easy project and would be a good introduction if anyone's interested in learning how things work.",
  "closed_at":"2020-11-18T23:57:01Z",
  "comments":0,
  "created_at":"2020-11-18T16:23:54Z",
  "id":745805836,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDU4MDU4MzY=",
  "number":551,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.to_var and ak.from_var: convert regular dimensions to and from variable dimensions with a high-level function",
  "updated_at":"2020-11-18T23:57:01Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Right-broadcasting is necessary for ufuncs to adhere to NumPy's behavior for regular-length lists. For uniformity, all functions that take multiple arrays as arguments do broadcasting, though these features make less sense in some cases. `broadcast_and_apply` should be parameterized to let different operations fine-tune their usage.\r\n\r\nSpecifically, `ak.with_field` does this:\r\n\r\n```python\r\n>>> data = ak.Array([{\"x\": i} for i in range(10)])\r\n>>> y = ak.Array(np.array([[i, i] for i in range(10)]))\r\n>>> data[\"y\"] = y\r\nTraceback (most recent call last):\r\n...\r\nValueError: cannot broadcast RegularArray of size 2 with RegularArray of size 10\r\n```\r\n\r\nBut we want it to do\r\n\r\n```python\r\n>>> data[\"y\"] = ak.from_iter(ak.to_list(y))\r\n>>> print(data)\r\n[{x: 0, y: [0, 0]}, {x: 1, y: [1, 1]}, ... x: 8, y: [8, 8]}, {x: 9, y: [9, 9]}]\r\n```\r\n\r\nThe conversion of the regular-length list into a variable-length list is an unnecessary computation, even if it is accelerated with #551. It's silly to have to go to all this effort to make it _not_ right-broadcast. Instead, we'd rather `ak.with_field` just not right-broadcast (by default, at least).",
  "closed_at":"2020-11-18T23:57:02Z",
  "comments":0,
  "created_at":"2020-11-18T21:33:07Z",
  "id":746024242,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDYwMjQyNDI=",
  "number":552,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Don't let `ak.with_field` right-broadcast (by default)",
  "updated_at":"2020-11-18T23:57:02Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-18T23:57:02Z",
  "comments":0,
  "created_at":"2020-11-18T22:21:36Z",
  "draft":false,
  "id":746065759,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTIzNTI1Mzg1",
  "number":553,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-18T23:57:01Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ak.with_field should not right-broadcast (by default).",
  "updated_at":"2020-11-18T23:57:10Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It would be convenient to have a function to get the first N highest/lowest entries as opposed to just the first max/min. From our side discussion, this could be ak.top/bottom.",
  "closed_at":null,
  "comments":2,
  "created_at":"2020-11-20T10:42:09Z",
  "id":747383178,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDczODMxNzg=",
  "number":554,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"Extending ak.max/min functionality to first N entries",
  "updated_at":"2021-08-02T16:40:34Z",
  "user":"MDQ6VXNlcjEzMjI2NTAw"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It's useful to have the opposite of `ak.flatten`:\r\n\r\n```python\r\n>>> original = ak.Array([[0, 1, 2], [], [3, 4], [5], [6, 7, 8, 9]])\r\n>>> counts = ak.num(original)\r\n>>> array = ak.flatten(original)\r\n>>> counts\r\n<Array [3, 0, 2, 1, 4] type='5 * int64'>\r\n>>> array\r\n<Array [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] type='10 * int64'>\r\n>>> ak.unflatten(array, counts)\r\n<Array [[0, 1, 2], [], ... [5], [6, 7, 8, 9]] type='5 * var * int64'>\r\n```\r\n\r\nIf the `counts` is a scalar integer, this would make a RegularArray; if it's a one-dimensional array (i.e. `ak.to_numpy(counts)` succeeds with the result being one-dimensional) of integers whose integers add up to less than the length of `array`, then it would make a ListOffsetArray. Such a function wouldn't take an `axis` and would probably live in `structure.py`, right after `flatten`.",
  "closed_at":"2020-12-10T21:40:12Z",
  "comments":0,
  "created_at":"2020-11-21T00:02:12Z",
  "id":747871474,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDc4NzE0NzQ=",
  "number":555,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"ak.unflatten: an operation like JaggedArray.fromcounts",
  "updated_at":"2020-12-10T21:40:12Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"",
  "closed_at":"2020-11-23T22:00:03Z",
  "comments":1,
  "created_at":"2020-11-22T11:10:04Z",
  "draft":false,
  "id":748219397,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI1MjY2Njg1",
  "number":556,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-23T22:00:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add script to clean generated files",
  "updated_at":"2020-11-23T22:00:06Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Using numpy 1.19.4 and awkward1 0.4.4 I get the following issue:\r\n\r\n\r\n```python\r\nimport awkward1 as ak\r\nimport numpy as np\r\n\r\nsample = ak.Array(np.arange(10))\r\nnp_array = ak.to_numpy(sample)\r\n\r\nprint(np.amax(np_array)) # prints 9\r\nprint(np.amax(sample)) # prints 9\r\n\r\nprint(np.amax(np_array, initial=10))  # prints 10\r\nprint(np.amax(sample, initial=10))  # TypeError: max() got an unexpected keyword argument 'initial'\r\n```\r\n\r\nNot sure what goes wrong internally, but `initial` is a valid (and useful) keyword argument:\r\nhttps://numpy.org/doc/stable/reference/generated/numpy.amax.html#numpy.amax\r\n\r\nUnfortunately, I do not know enough awkward1 to attempt a fix, any pointers would be helpful.\r\n\r\n\r\n### Full trace\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"example.py\", line 25, in <module>\r\n    print(np.amax(sample, initial=10))  # prints 9\r\n  File \"<__array_function__ internals>\", line 6, in amax\r\n  File \"/software/miniconda/envs/hep/lib/python3.7/site-packages/awkward1/highlevel.py\", line 1388, in __array_function__\r\n    return awkward1._connect._numpy.array_function(func, types, args, kwargs)\r\n  File \"/software/miniconda/envs/hep/lib/python3.7/site-packages/awkward1/_connect/_numpy.py\", line 31, in array_function\r\n    return function(*args, **kwargs)\r\nTypeError: max() got an unexpected keyword argument 'initial'\r\n```",
  "closed_at":"2020-12-01T21:40:59Z",
  "comments":3,
  "created_at":"2020-11-23T10:59:25Z",
  "id":748698219,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NDg2OTgyMTk=",
  "number":557,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Missing keyword arguments for np.amax(awkward1.Array)",
  "updated_at":"2020-12-03T08:50:00Z",
  "user":"MDQ6VXNlcjEyMTMyNzY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Fixes CoffeaTeam/coffea#372.",
  "closed_at":"2020-11-24T21:19:38Z",
  "comments":0,
  "created_at":"2020-11-24T20:12:24Z",
  "draft":false,
  "id":750012219,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI2NzM1NDIy",
  "number":558,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-24T21:19:37Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix VirtualArray getitem bug (getitem_next and getitem_next_jagged).",
  "updated_at":"2020-11-24T21:19:40Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-25T16:47:32Z",
  "comments":0,
  "created_at":"2020-11-25T16:05:26Z",
  "draft":false,
  "id":750942669,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI3NTQ5Mjg5",
  "number":559,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-25T16:47:32Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix booleans in Numba.",
  "updated_at":"2020-11-25T16:47:35Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"Python code to reproduce:\r\n```\r\nimport awkward1 as ak\r\na = ak.Array({\"x\": [1]})\r\na[\"y\"] = ak.virtual(lambda: [2], cache={}, length=1)\r\nprint(a)\r\n```\r\nThe last line raises the following error:\r\n`RuntimeError: PyArrayCache has lost its weak reference to mapping`\r\nThe error only appears if the length and cache parameters are supplied.\r\nTested on awkward1 0.4.5",
  "closed_at":"2020-11-25T22:48:43Z",
  "comments":1,
  "created_at":"2020-11-25T17:10:44Z",
  "id":750989167,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTA5ODkxNjc=",
  "number":560,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"RuntimeError when seting a field to virtual",
  "updated_at":"2020-11-25T22:48:43Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-25T22:48:43Z",
  "comments":0,
  "created_at":"2020-11-25T18:28:39Z",
  "draft":false,
  "id":751036160,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI3NjI1ODUw",
  "number":561,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-25T22:48:43Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #560, setting a field to virtual (don't lose references to caches).",
  "updated_at":"2020-11-25T22:48:46Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"Trying to do `python setup.py bdist_rpm` (since I prefer to let rpm manage the packages on my system) fails, at least on Fedora 32 with Python 3.8. \r\n\r\nThis creates a pretty straightforward RPM .spec file that seems like it should work:\r\n```\r\n%prep                           \r\n%setup -n %{name}-%{unmangled_version} -n %{name}-%{unmangled_version}\r\n                                                                                          \r\n%build                                                                                    \r\nenv CFLAGS=\"$RPM_OPT_FLAGS\" python3 setup.py build\r\n\r\n%install \r\npython3 setup.py install --single-version-externally-managed -O1 --root=$RPM_BUILD_ROOT --record=INSTALLED_FILES                                                                     \r\n                                                                                          \r\n%clean       \r\nrm -rf $RPM_BUILD_ROOT    \r\n                                                                                          \r\n%files -f INSTALLED_FILES             \r\n%defattr(-,root,root)     \r\n```\r\n\r\nThere are no apparent compilation issues, and the install step works (I verified by adding an extra printout at the end of run() in the Install class in setup.py), but then I get this error.\r\n\r\n`error: File not found: /home/cozzyd/Downloads/awkward-1.0/build/bdist.linux-x86_64/rpm/BUILDROOT/awkward1-0.4.5-1.x86_64/usr/lib64/python3.8/site-packages/awkward.cpython-38-x86_64-linux-gnu.so`\r\n\r\nWhile this file does not exist, it is listed in INSTALLED_FILES, which means somehow setuptools misrecorded the list of files for some reason (I attached the INSTALLED_FILES, with a .txt extension to make GitHub happy) \r\n\r\n[INSTALLED_FILES.txt](https://github.com/scikit-hep/awkward-1.0/files/5611654/INSTALLED_FILES.txt)\r\n\r\nThis is very similar to the problem reported in #182, where a `pip install -e .` failed on a completely different platform with a similar error, although that had nothing to do with trying to build an rpm, suggesting there is something a little funny about the setup.py. Note that none of the real .so files in  site-packages/awkward1 made it into INSTALLED_FILES either\r\n\r\nMy guess is somehow the install step is supposed to tell setuptools what files it needs to install, but I'm completely ignorant of setuptools internals, so it's not obvious what the problem is. \r\n\r\nIt seems like the name it picks is derived from:\r\n```\r\next_modules = [\r\n    CMakeExtension(\"awkward\"),\r\n]\r\n```\r\nIf I change `\"awkward\"` to \"awkward1/_ext\" then it looks for (one of?) the correct file, but it copies the .so's to the wrong place (now to awkward1/awkward1), so obviously that's not right either, but suggests a place to look. Probably the answer is obvious to someone who knows more than nothing about setuptools internals :). \r\n\r\n\r\n\r\n\r\n\r\n\r\n",
  "closed_at":"2020-12-07T22:15:20Z",
  "comments":11,
  "created_at":"2020-11-29T05:34:40Z",
  "id":752844256,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTI4NDQyNTY=",
  "number":562,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"setup.py problem;   python setup.py bdist_rpm not working ",
  "updated_at":"2020-12-08T20:06:26Z",
  "user":"MDQ6VXNlcjkyMDY1Njk="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-11-30T23:42:27Z",
  "comments":0,
  "created_at":"2020-11-30T16:08:31Z",
  "draft":false,
  "id":753605652,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI5NjUxMDgx",
  "number":563,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-11-30T23:42:27Z"
  },
  "reactions":{
   "hooray":2,
   "total_count":2
  },
  "state":"closed",
  "state_reason":null,
  "title":"The great name change: awkward1 -> awkward",
  "updated_at":"2020-11-30T23:42:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-01T00:57:29Z",
  "comments":1,
  "created_at":"2020-12-01T00:10:30Z",
  "draft":false,
  "id":753895400,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTI5ODg1NDU2",
  "number":564,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-01T00:57:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Make 'awkward1' package into a pass-through.",
  "updated_at":"2020-12-01T00:57:32Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"and reword flag from --check-sorted to --check-spec-sorted",
  "closed_at":"2020-12-02T14:00:13Z",
  "comments":4,
  "created_at":"2020-12-01T07:51:42Z",
  "draft":false,
  "id":754145109,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMwMDk3NjEx",
  "number":565,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-02T14:00:13Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Tool to check if kernel is implemented in all places",
  "updated_at":"2020-12-02T14:00:16Z",
  "user":"MDQ6VXNlcjExNzc1NjE1"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-01T21:40:59Z",
  "comments":0,
  "created_at":"2020-12-01T20:40:09Z",
  "draft":false,
  "id":754710241,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMwNTYyMTc1",
  "number":566,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-01T21:40:59Z"
  },
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Added the 'initial' argument to ak.min/ak.max.",
  "updated_at":"2020-12-01T21:41:03Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"My response to @sbuse's report on [Scikit-HEP/awkward-array](https://gitter.im/Scikit-HEP/awkward-array) (Gitter).\r\n\r\nI did a dirty but conclusive-enough experiment (watching htop while running commands in a Zoom meeting). The following consistently increased memory linearly: 100 MB in 80 seconds.\r\n\r\n```python\r\n% python -i -c 'import awkward as ak; import numpy as np; import gc'\r\n>>> for i in range(1000000):\r\n...   a = ak.ArrayBuilder()\r\n...   a.integer(i)\r\n...   del a\r\n...   tmp = gc.collect()\r\n... \r\n```\r\n\r\nand the following did not increase by even 10 MB in 80 seconds (where 10 MB is the level of noise\u2014other applications allocating and freeing memory on my system).\r\n\r\n```python\r\n% python -i -c 'import awkward as ak; import numpy as np; import gc'\r\n>>> for i in range(1000000):\r\n...   a = np.array([i])\r\n...   b = ak.Array(a)\r\n...   del a\r\n...   del b\r\n...   tmp = gc.collect()\r\n... \r\n```\r\n\r\nThe first is a simplified version of yours: your example creates arrays from Python data, which internally invoke the ArrayBuilder. The second makes Awkward Arrays by wrapping NumPy arrays. Your example,\r\n\r\n```python\r\n% python -i -c 'import awkward as ak; import numpy as np; import gc'\r\n>>> for i in range(1000000):\r\n...   a = ak.Array([i])\r\n...   del a\r\n...   tmp = gc.collect()\r\n... \r\n```\r\n\r\nis pretty much a combination of the two steps: ArrayBuilder, then wrap as ak.Array. Doing the above explicitly accumulated 120 MB in 80 seconds.\r\n\r\nSo it sounds like this is a memory leak in ArrayBuilder, very likely the GrowableBuffer that gets allocated is somehow not getting freed. The memory that GrowableBuffer allocates is in a `std::shared_ptr` that should be kept alive only by the fact that the ArrayBuilder is held as a Python reference. In my first example, `del a` should have dropped the Python reference count to zero and `gc.collect()` should have deleted the ArrayBuilder, then GrowableBuffer instance, which should have dropped the `std::shared_ptr` reference count to zero to immediately free the memory. That doesn't seem to be happening, but I know where to look.\r\n\r\n(For future triage: memory leaks are _bugs_, not _performance issues_.)",
  "closed_at":"2020-12-04T19:49:42Z",
  "comments":20,
  "created_at":"2020-12-03T13:47:26Z",
  "id":756209040,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTYyMDkwNDA=",
  "number":567,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Memory leak in ArrayBuilder/GrowableBuffer",
  "updated_at":"2020-12-17T15:01:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"Address Issue #437\r\n\r\nNote, it replaces #543 by moving `ianna/handle_stream_of_many_JSON_files` to a new branch.",
  "closed_at":"2020-12-03T22:26:35Z",
  "comments":3,
  "created_at":"2020-12-03T16:52:26Z",
  "draft":false,
  "id":756373004,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMxOTI4MzE5",
  "number":568,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-03T22:26:35Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Options for \"NaN\" strings as NaN floats",
  "updated_at":"2020-12-04T06:35:06Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-03T23:38:53Z",
  "comments":0,
  "created_at":"2020-12-03T23:09:16Z",
  "draft":false,
  "id":756663407,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMyMTc3NDQ3",
  "number":569,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-03T23:38:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Rename 'master' branch to 'main'.",
  "updated_at":"2020-12-03T23:39:09Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-04T19:49:42Z",
  "comments":0,
  "created_at":"2020-12-04T15:45:23Z",
  "draft":false,
  "id":757199821,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMyNjE1NDky",
  "number":570,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-04T19:49:42Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix ArrayBuilder memory leak.",
  "updated_at":"2020-12-04T19:49:45Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"COLLABORATOR",
  "body":"addressing issue https://github.com/scikit-hep/awkward-1.0/issues/404",
  "closed_at":"2020-12-22T19:34:25Z",
  "comments":3,
  "created_at":"2020-12-04T16:27:41Z",
  "draft":false,
  "id":757230874,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMyNjQxMjUx",
  "number":571,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-22T19:34:25Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"validity checking based on known parameters",
  "updated_at":"2020-12-29T16:49:59Z",
  "user":"MDQ6VXNlcjEzOTA2ODI="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I am need some functions which has to work on arrays with arbitrary dimensions, similar to the example below which traverses the `awkward.Array` recursively until it e.g. reaches `ndim == 2` and performs some operations. The problem is that `ak.Array.ndim` is not supported in `numba` and I have not found other ways to travel through dimensions \ud83d\udc68\u200d\ud83d\ude80. I guess it is just not connected to the numba interface, or is there another way to access the dimensionality which is preferable?\r\nI found some traces of `ndim` in the numba context here: https://awkward-array.readthedocs.io/en/latest/_auto/ak._connect._numba.layout.BitMaskedArrayType.html?highlight=ndim#ak-connect-numba-layout-bitmaskedarraytype-ndim\r\n\r\n```python\r\ndef mask_startend(arr, start, end):\r\n    builder = ak.ArrayBuilder()\r\n    _mask_startend(arr, start, end, builder)\r\n    return builder.snapshot()\r\n\r\n@nb.njit  # raises \r\ndef _mask_startend(arr, start, end, builder):\r\n    if arr.ndim == 2:  # recursion stop\r\n        for el in arr:\r\n            if ak.count(el) > 0 and el[0] == start and el[-1] == end:\r\n                builder.boolean(True)\r\n            else:\r\n                builder.boolean(False)\r\n        return\r\n    \r\n    for subarray in arr:\r\n        builder.begin_list()\r\n        _mask_startend(subarray, start, end, builder)\r\n        builder.end_list()\r\n```\r\n\r\nHere are some examples without `njit`:\r\n\r\n```python\r\n>>> mask_startend(ak.Array([[1,2,3], [1,2]]), 1, 3)\r\n<Array [True, False] type='2 * bool'>\r\n>>> mask_startend(ak.Array([[[1,2,3], [1,2]], [[1, 3]], [[1, 2], [3, 4]]]), 1, 3).tolist()\r\n[[True, False], [True], [False, False]]\r\n```\r\n\r\nand here the error raised with `njit`:\r\n\r\n```\r\nTypingError: Failed in nopython mode pipeline (step: nopython frontend)\r\nInternal error at resolving type of attribute \"ndim\" of \"arr\".\r\narray does not have a field with key 'ndim'\r\n\r\n(https://github.com/scikit-hep/awkward-1.0/blob/1.0.0rc2/src/awkward/_connect/_numba/layout.py#L324)\r\nDuring: typing of get attribute at <ipython-input-135-3d8beb6b636f> (8)\r\nEnable logging at debug level for details.\r\n\r\nFile \"<ipython-input-135-3d8beb6b636f>\", line 8:\r\ndef _mask_startend(arr, start, end, builder):\r\n    if arr.ndim == 2:  # recursion stop\r\n```",
  "closed_at":"2020-12-08T00:00:30Z",
  "comments":12,
  "created_at":"2020-12-04T16:29:42Z",
  "id":757232264,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTcyMzIyNjQ=",
  "number":572,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Missing awkward.Array.ndim in the numba context",
  "updated_at":"2020-12-08T17:50:02Z",
  "user":"MDQ6VXNlcjE3MzAzNTA="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-04T20:34:04Z",
  "comments":0,
  "created_at":"2020-12-04T19:59:56Z",
  "draft":false,
  "id":757366926,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMyNzU1ODU1",
  "number":573,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-04T20:34:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix ak.from_awkward0's Table (missing _view).",
  "updated_at":"2020-12-04T20:34:07Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"The docs for ```ak.cartesian``` say:\r\n`axis (int) \u2013 The dimension at which this operation is applied. The outermost dimension is 0, followed by 1, etc., and negative values count backward from the innermost: -1 is the innermost dimension, -2 is the next level up, etc.`\r\n\r\nHowever, passing  ```axis = -1``` results in \r\n```\r\nValueError: the 'axis' of cartesian must be non-negative\r\n```\r\n\r\n```\r\nAk Version:\r\n0.4.5\r\n```\r\n",
  "closed_at":"2020-12-09T02:34:29Z",
  "comments":5,
  "created_at":"2020-12-05T13:13:43Z",
  "id":757678755,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTc2Nzg3NTU=",
  "number":574,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Implement 'axis = -1' in ak.cartesian and ak.firsts",
  "updated_at":"2020-12-09T09:17:31Z",
  "user":"MDQ6VXNlcjExMzA2NzMy"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-07T20:21:46Z",
  "comments":0,
  "created_at":"2020-12-07T16:19:21Z",
  "draft":false,
  "id":758651086,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMzNzg5NDk1",
  "number":576,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-07T20:21:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Actually remove deprecated features from 1.0.x.",
  "updated_at":"2020-12-07T20:21:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-07T22:15:20Z",
  "comments":0,
  "created_at":"2020-12-07T20:26:40Z",
  "draft":false,
  "id":758822926,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTMzOTI3NzEy",
  "number":577,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-07T22:15:20Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix the setup.py --record argument, which is needed for bdist_rpm.",
  "updated_at":"2020-12-07T22:15:23Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-08T00:00:31Z",
  "comments":0,
  "created_at":"2020-12-07T23:01:27Z",
  "draft":false,
  "id":758915993,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM0MDAxODQ0",
  "number":578,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-08T00:00:30Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement ak.Array.ndim in the Numba context.",
  "updated_at":"2020-12-08T00:00:33Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Only `ak.argmin` and `ak.argmax` need _all_ of them; the rest should allow for `Index64(0)` to be passed through instead (without segfaults, obviously).\r\n\r\nIf we know that it will be applied at the bottom level (i.e. `negaxis == 1`), there are more opportunities to fast-track it. Rather than making tentative `parents` that get expanded at each level, the bottom level can be implemented by just making the `parents` at the bottom level alone.\r\n\r\nThere are enough tests of the \"full\" solution that exists now; switching to optimized versions will be well-tested by the existing suite of tests.\r\n\r\nThis optimization potential has been known for a while; I just need to remember to do it (and have the satisfaction of popping an issue when it's done).",
  "closed_at":"2021-12-07T21:19:00Z",
  "comments":1,
  "created_at":"2020-12-08T16:34:39Z",
  "id":759594691,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NTk1OTQ2OTE=",
  "number":579,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Remember to remove unnecessary intermediate arrays from most reducers",
  "updated_at":"2021-12-07T21:19:00Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-09T02:34:30Z",
  "comments":0,
  "created_at":"2020-12-08T22:02:47Z",
  "draft":false,
  "id":759816520,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM0NzUzNzE2",
  "number":582,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-09T02:34:29Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Propagate 'posaxis' through broadcast_and_apply and recursively_apply, then implement 'axis < 0' for some functions.",
  "updated_at":"2020-12-09T02:34:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This implements an `unflatten` function for awkward as described in #555.\r\nAs I really needed this function and the issue was marked as \"good first issue\" I thought I would give it a try.\r\nWould you like to have a unit test for the function? I'm not sure as this is my first pull request, but if needed I can write one.\r\n\r\nI noticed one problem with `cumsum` while writing this. However, this might need to go into a separate issue. Consider\r\n```\r\narr = ak.Array(cupy.array([1,2,3]))\r\nak.nplike.of(arr.layout).cumsum(arr.layout)\r\n```\r\nwill raise a `TypeError`. However it will work fine if you change `cupy` to `numpy`.",
  "closed_at":"2020-12-10T21:40:12Z",
  "comments":6,
  "created_at":"2020-12-09T12:52:27Z",
  "draft":false,
  "id":760303244,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM1MTU3OTEy",
  "number":583,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-10T21:40:12Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implement unflatten function",
  "updated_at":"2024-01-18T17:29:33Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-09T19:02:41Z",
  "comments":1,
  "created_at":"2020-12-09T17:13:42Z",
  "draft":false,
  "id":760513364,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM1MzMyMzQ5",
  "number":586,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-09T19:02:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fix corner-case revealed by issue #585, but distinct from that issue.",
  "updated_at":"2020-12-09T19:05:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-09T22:41:50Z",
  "comments":0,
  "created_at":"2020-12-09T22:06:08Z",
  "draft":false,
  "id":760707354,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM1NDkzNzg0",
  "number":587,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-09T22:41:50Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Modernize ak.is_none and add an 'axis' parameter.",
  "updated_at":"2020-12-09T22:41:54Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjEzOTA2ODI=",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This issue is to collect my thoughts about how RDataFrame integration could be done. Such a thing would be useful because physicists could then mix analyses using Awkward Array, Numba, _and_ ROOT C++ without leaving their environment. The benefits compound:\r\n\r\n   1. Data that are too complex to read from Uproot (efficiently or at all) can be loaded using `MakeRootDataFrame` and dumped into an Awkward Array.\r\n   2. Arbitrarily complex Awkward Arrays can be written to ROOT files by dumping the Awkward Arrays into an RDataFrame and taking a `Snapshot`.\r\n   3. Users can use ROOT C++ functions in an otherwise Awkward analysis at full speed. (\"Full\" in quotes; there is a conversion penalty, but it's compiled code, not so bad.)\r\n\r\n### Should we use Arrow? No.\r\n\r\nIn principle, we should be able to convert Awkward Arrays to and from RDataFrame using Apache Arrow, but there only seems to be an RArrowDS and not an action that converts back to Arrow (like `AsNumpy`), and even the RArrowDS only forwards a reference to `arrow::Table`\u2014trying to `include` the Arrow headers from my conda-installed version of ROOT fails. Perhaps the version of ROOT in conda-forge is not linked to Arrow. If Arrow access is not consistent across ROOT installations (i.e. it's a compile-time option or something), I don't want to rely on it\u2014it will fail for too many users.\r\n\r\nBesides, I didn't see an example of RArrowDS for anything but primitive types: if a jagged array is passed from Arrow to RDataFrame, how does it appear to a physicist writing code for a `Define` action? Like strange `arrow::` stuff? Taking this and the above consideration together, I don't think Arrow is the right route for Awkward \u2192 RDataFrame, despite first appearances.\r\n\r\n### Code generation to Awkward \u2192 RDataFrame\r\n\r\nBut code-generation could be a good way to go. Each distinct (different [Form](https://awkward-array.readthedocs.io/en/latest/ak.forms.Form.html)) attempt to create an RDataFrame from an Awkward Array (probably named `ak.to_rdataframe`) could try to import ROOT (no explicit dependence), create a string of C++ code, and run it through `ROOT.gInterpreter.Define` (with unique names, to permit repeated definitions). Any nested records could be declared as new structs so that nested fields can be accessed as `record.fieldName` (as long as field names are in `[A-Za-z_][A-Za-z_0-9]*`). Any nested lists could be emplaced into `ROOT::VecOps::RVec`. There's a performance penalty for converting columnar data into record-oriented data like this, but most physics use-cases don't run at such high speeds that this would be the bottleneck.\r\n\r\nThe code to generate would look a lot like this (shamelessly stolen from `RTrivialDS` with \"Trivial\" changed to \"Wonky\"):\r\n\r\n```c++\r\n#include \"ROOT/RDF/RInterface.hxx\"\r\n#include \"ROOT/RDataSource.hxx\"\r\n#include <ROOT/RDF/Utils.hxx>\r\n#include <ROOT/TSeq.hxx>\r\n#include <ROOT/RMakeUnique.hxx>\r\n#include <TError.h>\r\n\r\n#include <limits>\r\n\r\nnamespace ROOT {\r\n\r\nnamespace RDF {\r\n\r\nclass RWonkyDS final : public ROOT::RDF::RDataSource {\r\nprivate:\r\n   unsigned int fNSlots = 0U;\r\n   ULong64_t fSize = 0ULL;\r\n   bool fSkipEvenEntries = false;\r\n   std::vector<std::pair<ULong64_t, ULong64_t>> fEntryRanges;\r\n   std::vector<std::string> fColNames{\"col0\"};\r\n   std::vector<ULong64_t> fCounter;\r\n   std::vector<ULong64_t *> fCounterAddr;\r\n   std::vector<void *> GetColumnReadersImpl(std::string_view name, const std::type_info &);\r\n\r\nprotected:\r\n   std::string AsString() { return \"trivial data source\"; };\r\n\r\npublic:\r\n   RWonkyDS(ULong64_t size, bool skipEvenEntries = false);\r\n   /// This ctor produces a data-source that returns infinite entries\r\n   RWonkyDS();\r\n   ~RWonkyDS();\r\n   const std::vector<std::string> &GetColumnNames() const;\r\n   bool HasColumn(std::string_view colName) const;\r\n   std::string GetTypeName(std::string_view) const;\r\n   std::vector<std::pair<ULong64_t, ULong64_t>> GetEntryRanges();\r\n   bool SetEntry(unsigned int slot, ULong64_t entry);\r\n   void SetNSlots(unsigned int nSlots);\r\n   void Initialise();\r\n   std::string GetLabel();\r\n};\r\n\r\n// Make a RDF wrapping a RWonkyDS with the specified amount of entries\r\nRInterface<RDFDetail::RLoopManager, RWonkyDS> MakeWonkyDataFrame(ULong64_t size, bool skipEvenEntries = false);\r\n// Make a RDF wrapping a RWonkyDS with infinite entries\r\nRInterface<RDFDetail::RLoopManager, RWonkyDS> MakeWonkyDataFrame();\r\n\r\nstd::vector<void *> RWonkyDS::GetColumnReadersImpl(std::string_view, const std::type_info &ti)\r\n{\r\n   // We know we have only one column and that it's holding ULong64_t's\r\n   if (ti != typeid(ULong64_t)) {\r\n      throw std::runtime_error(\"The type specified for the column \\\"col0\\\" is not ULong64_t.\");\r\n   }\r\n   std::vector<void *> ret;\r\n   for (auto i : ROOT::TSeqU(fNSlots)) {\r\n      fCounterAddr[i] = &fCounter[i];\r\n      ret.emplace_back((void *)(&fCounterAddr[i]));\r\n   }\r\n   return ret;\r\n}\r\n\r\nRWonkyDS::RWonkyDS(ULong64_t size, bool skipEvenEntries) : fSize(size), fSkipEvenEntries(skipEvenEntries)\r\n{\r\n}\r\n\r\nRWonkyDS::RWonkyDS() : fSize(std::numeric_limits<ULong64_t>::max()), fSkipEvenEntries(false)\r\n{\r\n}\r\n\r\nRWonkyDS::~RWonkyDS()\r\n{\r\n}\r\n\r\nconst std::vector<std::string> &RWonkyDS::GetColumnNames() const\r\n{\r\n   return fColNames;\r\n}\r\n\r\nbool RWonkyDS::HasColumn(std::string_view colName) const\r\n{\r\n   return colName == fColNames[0];\r\n}\r\n\r\nstd::string RWonkyDS::GetTypeName(std::string_view) const\r\n{\r\n   return \"ULong64_t\";\r\n}\r\n\r\nstd::vector<std::pair<ULong64_t, ULong64_t>> RWonkyDS::GetEntryRanges()\r\n{\r\n   if (fSize == std::numeric_limits<ULong64_t>::max()) {\r\n      auto currentEntry = *std::max_element(fCounter.begin(), fCounter.end());\r\n      // infinite source, just make some ranges up\r\n      std::vector<std::pair<ULong64_t, ULong64_t>> ranges(fNSlots);\r\n      for (auto &range : ranges) {\r\n         range = std::make_pair(currentEntry, currentEntry + 10);\r\n         currentEntry += 10;\r\n      }\r\n      return ranges;\r\n   }\r\n\r\n   // empty fEntryRanges so we'll return an empty vector on subsequent calls\r\n   auto ranges = std::move(fEntryRanges);\r\n   return ranges;\r\n}\r\n\r\nbool RWonkyDS::SetEntry(unsigned int slot, ULong64_t entry)\r\n{\r\n   if (fSkipEvenEntries && 0 == entry % 2) {\r\n      return false;\r\n   }\r\n   fCounter[slot] = entry;\r\n   return true;\r\n}\r\n\r\nvoid RWonkyDS::SetNSlots(unsigned int nSlots)\r\n{\r\n   R__ASSERT(0U == fNSlots && \"Setting the number of slots even if the number of slots is different from zero.\");\r\n\r\n   fNSlots = nSlots;\r\n   fCounter.resize(fNSlots);\r\n   fCounterAddr.resize(fNSlots);\r\n}\r\n\r\nvoid RWonkyDS::Initialise()\r\n{\r\n   if (fSize == std::numeric_limits<ULong64_t>::max()) {\r\n      // infinite source, nothing to do here\r\n      return;\r\n   }\r\n\r\n   // initialize fEntryRanges\r\n   const auto chunkSize = fSize / fNSlots;\r\n   auto start = 0UL;\r\n   auto end = 0UL;\r\n   for (auto i : ROOT::TSeqUL(fNSlots)) {\r\n      start = end;\r\n      end += chunkSize;\r\n      fEntryRanges.emplace_back(start, end);\r\n      (void)i;\r\n   }\r\n   // TODO: redistribute reminder to all slots\r\n   fEntryRanges.back().second += fSize % fNSlots;\r\n}\r\n\r\nstd::string RWonkyDS::GetLabel()\r\n{\r\n   return \"WonkyDS\";\r\n}\r\n\r\nRInterface<RDFDetail::RLoopManager, RWonkyDS> MakeWonkyDataFrame(ULong64_t size, bool skipEvenEntries)\r\n{\r\n   auto lm = std::make_unique<RDFDetail::RLoopManager>(std::make_unique<RWonkyDS>(size, skipEvenEntries),\r\n                                                       RDFInternal::ColumnNames_t{});\r\n   return RInterface<RDFDetail::RLoopManager, RWonkyDS>(std::move(lm));\r\n}\r\n\r\nRInterface<RDFDetail::RLoopManager, RWonkyDS> MakeWonkyDataFrame()\r\n{\r\n   auto lm = std::make_unique<RDFDetail::RLoopManager>(std::make_unique<RWonkyDS>(), RDFInternal::ColumnNames_t{});\r\n   return RInterface<RDFDetail::RLoopManager, RWonkyDS>(std::move(lm));\r\n}\r\n\r\n} // ns RDF\r\n\r\n} // ns ROOT\r\n\r\nvoid testy() {\r\n  auto printEntrySlot = [](ULong64_t iEntry, ULong64_t slot) {\r\n      std::cout << \"Entry: \" << iEntry << \" Slot: \" << slot << std::endl;\r\n  };\r\n  auto d_s = ROOT::RDF::MakeWonkyDataFrame(10);\r\n  d_s.Foreach(printEntrySlot, {\"rdfentry_\", \"col0\" });\r\n}\r\n```\r\n\r\n### RDataFrame \u2192 Awkward\r\n\r\nFor the other direction, creating an Awkward Array from RDataFrame, it would perhaps be most natural to import the [ArrayBuilder functions](https://github.com/scikit-hep/awkward-1.0/blob/030eb02d2bd7b4d9077a8bcd8ab0986cb0972121/include/awkward/builder/ArrayBuilder.h#L305-L422) into the ROOT C++ context through function pointers, exactly as they have been imported into the Numba context. They could then be used by users in an RDataFrame `Foreach` action\u2014which is decidedly non-functional, but that's how it's done in Numba\u2014or we could monkey-patch an `AsAwkward` action onto `RInterface` that generate the arrays of the Awkward layout as columns and provide them to Python through `AsNumpy`. It can be exactly the format required by [ak.from_arrayset](https://awkward-array.readthedocs.io/en/latest/_auto/ak.from_arrayset.html).\r\n\r\nIt seems that monkey-patching is indeed possible:\r\n\r\n```python\r\n>>> import ROOT\r\n>>> ROOT.RDF.RInterface(\"ROOT::Detail::RDF::RLoopManager\", \"void\").whatever = lambda self: \"HELLO \" + repr(self)\r\n>>> \r\n>>> rdf = ROOT.RDF.MakeRootDataFrame(\"events\", \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/skhep_testdata/data/uproot-HZZ-objects.root\")\r\n>>> tmp = rdf.Define(\"x\", \"eventweight * 2\")\r\n>>> \r\n>>> rdf.whatever()\r\n'HELLO <cppyy.gbl.ROOT.RDataFrame object at 0x5575a14f19a0>'\r\n>>> tmp.whatever()\r\n'HELLO <cppyy.gbl.ROOT.RDF.RInterface<ROOT::Detail::RDF::RLoopManager,void> object at 0x5575a168a750>'\r\n```\r\n\r\nEven for objects made before the monkey-patching:\r\n\r\n```python\r\n>>> import ROOT\r\n>>> rdf = ROOT.RDF.MakeRootDataFrame(\"events\", \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/skhep_testdata/data/uproot-HZZ-objects.root\")\r\n>>> tmp = rdf.Define(\"x\", \"eventweight * 2\")\r\n>>> \r\n>>> ROOT.RDF.RInterface(\"ROOT::Detail::RDF::RLoopManager\", \"void\").whatever = lambda self: \"HELLO \" + repr(self)\r\n>>> \r\n>>> rdf.whatever()\r\n'HELLO <cppyy.gbl.ROOT.RDataFrame object at 0x55d8c4cd91b0>'\r\n>>> tmp.whatever()\r\n'HELLO <cppyy.gbl.ROOT.RDF.RInterface<ROOT::Detail::RDF::RLoopManager,void> object at 0x55d8c6063660>'\r\n```\r\n\r\nSo this allows us to fully decouple installation requirements (ROOT does not depend on Awkward Array and Awkward Array does not depend on ROOT) while allowing us to add an `AsAwkward` action to every `RInterface` in PyROOT. The downside is that it has to be installed by some Awkward import, such as\r\n\r\n```python\r\n>>> import awkward.pyroot   # or maybe awkward.ROOT?\r\n```\r\n\r\nWithout this import, the RDataFrame nodes would not have an `AsAwkward` action. Numba avoids this by checking for entry points in setuptools, but doing that here would require a change to ROOT. If this project goes well and people find it useful, then adding an entry points mechanism to PyROOT would be better motivated.\r\n\r\n### People who might be interested\r\n\r\n@eguiraud and @etejedor, probably! The above project is speculative at this point and no one has asked for it. I just got to thinking that such an interface should exist, since it would multiply the possibilities available to physicists doing analysis.",
  "closed_at":"2022-08-31T18:13:34Z",
  "comments":11,
  "created_at":"2020-12-10T01:08:48Z",
  "id":760794731,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjA3OTQ3MzE=",
  "number":588,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"RDataFrame integration",
  "updated_at":"2022-08-31T18:13:34Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The need for this came up in https://github.com/scikit-hep/awkward-1.0/pull/583#discussion_r540191180.\r\n\r\nWe'll have to make sure that the `size == 0` case doesn't cause any errors in any of its operations.",
  "closed_at":"2020-12-10T22:43:49Z",
  "comments":0,
  "created_at":"2020-12-10T14:03:57Z",
  "id":761268977,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjEyNjg5Nzc=",
  "number":589,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Allow RegularArray with size == 0.",
  "updated_at":"2020-12-10T22:43:49Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-10T22:43:49Z",
  "comments":0,
  "created_at":"2020-12-10T14:26:43Z",
  "draft":false,
  "id":761286863,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM1OTc1MDg5",
  "number":590,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-10T22:43:49Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Change the definition of RegularArray to accept size == 0.",
  "updated_at":"2020-12-10T22:43:53Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-10T18:35:55Z",
  "comments":0,
  "created_at":"2020-12-10T16:52:31Z",
  "draft":false,
  "id":761407847,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM2MDc3NDQ0",
  "number":591,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-10T18:35:55Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Now 'ak.to_numpy(ak.layout.NumpyArray(cupy.array([1, 2, 3]))' works.",
  "updated_at":"2020-12-10T18:35:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"- [x] Write `ak.to_buffers`\r\n- [x] Get `ak.to_arrayset` to pass through `ak.to_buffers` and all tests to work again\r\n- [x] Write `ak.from_buffers`\r\n- [x] Get `ak.from_arrayset` to pass through `ak.from_buffers` and get all tests to work again\r\n- [x] Set up all deprecation messages\r\n- [x] Test the documentation examples\r\n- [x] Convert the tests from `arrayset` functions to `buffers` functions\r\n- [x] Convert pickle-handling from `arrayset` functions to `buffers` functions\r\n- [x] Check Parquet-handling functions; does anything need to be done here? Uniformity of arguments?\r\n- [x] Update the `docs-src` Jupytext notebook examples\r\n- [x] Ensure that there are no more warnings",
  "closed_at":"2020-12-11T21:37:47Z",
  "comments":1,
  "created_at":"2020-12-11T00:29:43Z",
  "draft":false,
  "id":761743046,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM2MzY0NjM2",
  "number":592,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-11T21:37:46Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Replace to_arrayset/from_arrayset with to_buffers/from_buffers and deprecate the original.",
  "updated_at":"2020-12-11T21:39:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It looks like all of the data types, such as\r\n\r\nhttps://arrow.apache.org/docs/python/generated/pyarrow.ListType.html#pyarrow.ListType\r\n\r\ninclude attributes of type pyarrow.field (a recent addition?), which lets us parameterize the nullability of the data at this level:\r\n\r\nhttps://arrow.apache.org/docs/python/generated/pyarrow.field.html\r\n\r\nNot taking advantage of this is a bug: if we _can_ preserve nullability between Awkward and Arrow, we _must_.",
  "closed_at":"2020-12-15T23:42:21Z",
  "comments":2,
  "created_at":"2020-12-11T19:06:22Z",
  "id":762773357,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjI3NzMzNTc=",
  "number":593,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Investigate pyarrow.field to preserve nullability in Arrow conversion",
  "updated_at":"2020-12-15T23:42:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I noticed that PyCharm actually picks up the NumPy style docstrings's type definitions, which is really quite impressive. But, it picks up that behavior is a bool, well, because it is documented as such:\r\n\r\nhttps://github.com/scikit-hep/awkward-1.0/blob/518232b1c6758e3d9bf94fae91a72696d2d3e6ce/src/awkward/operations/convert.py#L638-L639\r\n\r\nThat even by definition should be at least an `Optional[bool]`, but better yet, I think it's a `Optional[dict]`?  Also, I'd highly recommend actual typing, with `typing; python_version<\"3.5\"` in the `install_requires` and Python 2-style `# type:` comments. It looks like you've already thought through all the allowed types, but making it formal and letting (other, less intelligent) IDE's and type checkers take advantage of it would be nice. :)\r\n\r\nUnrelated, but could the standard GitHub link be added to the top right corner of the docs? Like https://boost-histogram.readthedocs.io/en/latest/ 's top corner.\r\n\r\nOkay, back to work, just noticed that PyCharm was insisting that behavior was supposed to be a bool...\r\n\r\n<img width=\"717\" alt=\"Screen Shot 2020-12-11 at 4 21 04 PM\" src=\"https://user-images.githubusercontent.com/4616906/101956083-ff729a80-3bcc-11eb-9548-917f04b50317.png\">\r\n",
  "closed_at":"2020-12-11T21:56:08Z",
  "comments":2,
  "created_at":"2020-12-11T21:19:02Z",
  "id":762917857,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjI5MTc4NTc=",
  "number":594,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"docstring oddity: behavior is a bool?",
  "updated_at":"2020-12-11T21:56:08Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"We can override any NumPy function using our own internal `@ak._connect._numpy.implements` decorator, and this has been used to give NumPy functions Awkward generalizations. However, there are still a lot of NumPy functions that fail for Awkward Arrays, even flat ones, because NumPy isn't calling calling `__array__` on the `ak.Array`. Some NumPy functions do, others don't.\r\n\r\nTo make this more predictable, someone (me?) should do a survey of all functions in the `numpy` namespace find the ones that don't automatically call `__array__`, and define them in a submodule of their own, like this:\r\n\r\n```python\r\n@ak._connect._numpy.implements(\"whatever\")\r\ndef whatever(array_arg, another_array_arg, non_array_arg):\r\n    nplike = ak.nplike.of(array_arg, another_array_arg)._module\r\n    return nplike.whatever(nplike.asarray(array_arg), nplike.asarray(another_array_arg), non_array_arg)\r\n```\r\n\r\nThis could be done more systematically with `*args` and `**kwargs`, but we still need to know which arguments are supposed to be arrays to pass them through `nplike.asarray`. (Here, I'm using the direct `._module`, rather than going through the full [NumpyLike](https://github.com/scikit-hep/awkward-1.0/blob/68087850eabafd39f0c0de37ed96487fa44cc69f/src/awkward/nplike.py#L120) interface because I don't want to verify NumPy-CuPy agreement/lack-of-agreement for every one of these. The `nplike.asarray` function raises an exception if the Awkward Array isn't a rectilinear, numerical array, so this isn't generalizing NumPy's behavior so much as making Awkward-brand arrays usable as NumPy arrays in exactly the cases that NumPy itself covers (except `dtype=\"O\"` and strings).\r\n\r\nThese functions will _not_ be used in the main Awkward codebase, they will _not_ be exposed to the top-level `awkward` namespace, and they will _not_ be documented on ReadTheDocs. Among them are some functions that we might want to generalize someday, and that would mean moving them from this submodule to one of the standard places and possibly narrowing the argument list.\r\n\r\nThis submodule should probably be called `ak._connect._numpy_compatibility` or something. It should be imported by `__init__.py` after `ak._connect._numpy`.",
  "closed_at":"2021-07-15T19:58:56Z",
  "comments":0,
  "created_at":"2020-12-11T23:19:16Z",
  "id":763038755,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjMwMzg3NTU=",
  "number":595,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Define wrappers for pure NumPy functions that don't automatically call '__array__'",
  "updated_at":"2021-07-15T19:58:56Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"The `tests/samples` dir is missing from the PyPI tarball, causing a couple of tests from `test_0437` to fail when it is used to build and test awkward (1.0.0):\r\n\r\n```\r\n[   39s] ________________________________ test_fromfile _________________________________\r\n[   39s] \r\n[   39s]     def test_fromfile():\r\n[   39s]         # read multiple json fragments from a json file\r\n[   39s] >       array = ak.from_json(\"tests/samples/test-record-array.json\")\r\n[   39s] \r\n[   39s] tests/test_0437-stream-of-many-json-files.py:357: \r\n[   39s] ________________________________ test_fromfile _________________________________\r\n[   39s] \r\n[   39s]     def test_fromfile():\r\n[   39s]         # read multiple json fragments from a json file\r\n[   39s] >       array = ak.from_json(\"tests/samples/test-record-array.json\")\r\n[   39s] \r\n[   39s] tests/test_0437-stream-of-many-json-files.py:357: \r\n[   39s] =========================== short test summary info ============================\r\n[   39s] FAILED tests/test_0437-stream-of-many-json-files.py::test_two_arrays - ValueE...\r\n[   39s] FAILED tests/test_0437-stream-of-many-json-files.py::test_fromfile - ValueErr...\r\n[   39s] ================== 2 failed, 560 passed, 7 skipped in 20.68s ===================\r\n```",
  "closed_at":"2020-12-14T20:19:25Z",
  "comments":5,
  "created_at":"2020-12-13T14:12:19Z",
  "id":765421122,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjU0MjExMjI=",
  "number":596,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"PyPI source tarball does not have samples",
  "updated_at":"2020-12-14T21:37:38Z",
  "user":"MDQ6VXNlcjM1MzI0Njc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"I found https://awkward-array.org/how-to-convert-buffers.html which is really nice. Playing with this a bit i encountered a situation where this goes wrong with `lazy=True` (but works in non-lazy mode).\r\n\r\n```pycon\r\n>>> import awkward as ak\r\n>>> ak.__version__\r\n'1.0.1rc2'\r\n>>> array = ak.Array([[{\"a\": 1, \"b\" : [1, 2, 3]}],\r\n...                   [{\"a\": 1, \"b\" : [4, 5]}, {\"a\" : 4, \"b\" : [2]}]])\r\n```\r\n\r\nThis still works,\r\n\r\n```pycon\r\n>>> buffers = ak.to_buffers(array)\r\n>>> ak.from_buffers(*buffers, lazy=True)\r\n<Array [[{a: 1, b: [1, 2, 3, ... b: [2]}]] type='2 * var * {\"a\": int64, \"b\": var...'>\r\n```\r\n\r\nbut with the same structure where the record field under `\"b\"` is a `ListArray64` instead of a `ListOffsetArray64` works only without `lazy=True`:\r\n\r\n```pycon\r\n>>> array_new = ak.Array(\r\n...     ak.layout.ListOffsetArray64(\r\n...         array.layout.offsets,\r\n...         ak.layout.RecordArray(\r\n...             {\r\n...                 \"a\" : array.layout.content[\"a\"],\r\n...                 \"b\" : ak.layout.ListArray64(\r\n...                     array.layout.content[\"b\"].offsets[:-1],\r\n...                     array.layout.content[\"b\"].offsets[1:],\r\n...                     array.layout.content[\"b\"].content\r\n...                 ),\r\n...             }\r\n...         )\r\n...     )\r\n... )\r\n>>> buffers = ak.to_buffers(array_new)\r\n>>> ak.from_buffers(*buffers)\r\n<Array [[{a: 1, b: [1, 2, 3, ... b: [2]}]] type='2 * var * {\"a\": int64, \"b\": var...'>\r\n>>> buffers = ak.to_buffers(array_new)\r\n>>> ak.from_buffers(*buffers, lazy=True)\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n    ak.from_buffers(*buffers, lazy=True)\r\n  File \"/home/nikolai/.conda/envs/py37/lib/python3.7/site-packages/awkward/highlevel.py\", line 1238, in __repr__\r\n    return self._repr()\r\n  File \"/home/nikolai/.conda/envs/py37/lib/python3.7/site-packages/awkward/highlevel.py\", line 1250, in _repr\r\n    limit_value, self._layout, self._behavior\r\n  File \"/home/nikolai/.conda/envs/py37/lib/python3.7/site-packages/awkward/_util.py\", line 1511, in minimally_touching_string\r\n    lft = next(leftgen)\r\n  File \"/home/nikolai/.conda/envs/py37/lib/python3.7/site-packages/awkward/_util.py\", line 1498, in forever\r\n    for token in iterable:\r\n  File \"/home/nikolai/.conda/envs/py37/lib/python3.7/site-packages/awkward/_util.py\", line 1396, in forward\r\n    for token in forward(x[i], sp):\r\nValueError: generated array does not conform to expected form:\r\n\r\n{\r\n    \"class\": \"ListOffsetArray64\",\r\n    \"offsets\": \"i64\",\r\n    \"content\": {\r\n        \"class\": \"RecordArray\",\r\n        \"contents\": {\r\n            \"a\": {\r\n                \"class\": \"VirtualArray\",\r\n...\r\n```\r\n\r\n(seems to affect both the old `from_arrayset` and the new `from_buffers` interface)",
  "closed_at":"2020-12-14T19:51:25Z",
  "comments":1,
  "created_at":"2020-12-14T17:38:35Z",
  "id":766755864,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjY3NTU4NjQ=",
  "number":597,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"`ak.from_buffers` fails in certain constellations with `lazy=True`",
  "updated_at":"2020-12-14T19:51:25Z",
  "user":"MDQ6VXNlcjM3MDcyMjU="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-14T19:51:25Z",
  "comments":0,
  "created_at":"2020-12-14T19:05:39Z",
  "draft":false,
  "id":766831364,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM5NzM1NTQ5",
  "number":598,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-14T19:51:25Z"
  },
  "reactions":{
   "+1":1,
   "total_count":1
  },
  "state":"closed",
  "state_reason":null,
  "title":"Fixes ak.from_buffers failure for ListArray.",
  "updated_at":"2020-12-14T19:51:28Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-14T22:24:36Z",
  "comments":0,
  "created_at":"2020-12-14T21:16:12Z",
  "draft":false,
  "id":766935620,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTM5ODAzNjg2",
  "number":599,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-14T22:24:36Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Preemtively avoid warnings in NumPy 1.20 (untested).",
  "updated_at":"2020-12-14T22:24:39Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"## Software versions used ##\r\n* `awkward 1.0.1`\r\n* `Python 3.8.6`\r\n* `pytest-6.1.2`\r\n\r\n## Issue ##\r\nSome of the tests, namely:\r\n* tests/test_0056-partitioned-array.py,\r\n* tests/test_0080-flatpandas-multiindex-rows-and-columns.py,\r\n* tests/test_0166-0167-0170-random-issues.py, and\r\n* tests/test_0331-pandas-indexedarray.py\r\n\r\nfail on 32-bit i586 architectures (Linux OS), typically with the following error:\r\n`TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'`\r\n\r\nAll tests, including those listed above, pass without issues on 64 bit systems.\r\n\r\n## Full error log ##\r\n```\r\n[  229s] =================================== FAILURES ===================================\r\n[  229s] ______________________________ test_0167_strings _______________________________\r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] bound = <built-in method repeat of numpy.ndarray object at 0xec22c728>\r\n[  229s] \r\n[  229s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  229s]         bound = getattr(obj, method, None)\r\n[  229s]         if bound is None:\r\n[  229s]             return _wrapit(obj, method, *args, **kwds)\r\n[  229s]     \r\n[  229s]         try:\r\n[  229s] >           return bound(*args, **kwds)\r\n[  229s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  229s] \r\n[  229s] During handling of the above exception, another exception occurred:\r\n[  229s] \r\n[  229s]     def test_0167_strings():\r\n[  229s]         array = ak.repartition(\r\n[  229s]             ak.Array([\"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"]), 3\r\n[  229s]         )\r\n[  229s]     \r\n[  229s]         assert ak.to_list(array == \"two\") == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(\"two\" == array) == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(array == [\"two\"]) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list([\"two\"] == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(array == ak.Array([\"two\"])) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(ak.Array([\"two\"]) == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]     \r\n[  229s]         array = ak.Array([[\"one\", \"two\", \"three\"], [], [\"two\"], [\"two\", \"one\"], [\"three\"]])\r\n[  229s] >       assert ak.to_list(array == \"two\") == [\r\n[  229s]             [False, True, False],\r\n[  229s]             [],\r\n[  229s]             [True],\r\n[  229s]             [True, False],\r\n[  229s]             [False],\r\n[  229s]         ]\r\n[  229s] \r\n[  229s] tests/test_0056-partitioned-array.py:1083: \r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/lib/mixins.py:21: in func\r\n[  229s]     return ufunc(self, other)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/highlevel.py:1348: in __array_ufunc__\r\n[  229s]     return ak._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_connect/_numpy.py:195: in array_ufunc\r\n[  229s]     out = ak._util.broadcast_and_apply(\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:1001: in broadcast_and_apply\r\n[  229s]     out = apply(broadcast_pack(inputs, isscalar), 0, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:761: in apply\r\n[  229s]     outcontent = apply(nextinputs, depth + 1, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:800: in apply\r\n[  229s]     nextinputs.append(fcn(x, offsets))\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/behaviors/string.py:160: in _string_broadcast\r\n[  229s]     parents = nplike.repeat(nplike.arange(len(counts), dtype=counts.dtype), counts)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  229s]     return self._module.repeat(*args, **kwargs)\r\n[  229s] <__array_function__ internals>:5: in repeat\r\n[  229s]     ???\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  229s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  229s]     return _wrapit(obj, method, *args, **kwds)\r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xec22c728>\r\n[  229s] \r\n[  229s]     def _wrapit(obj, method, *args, **kwds):\r\n[  229s]         try:\r\n[  229s]             wrap = obj.__array_wrap__\r\n[  229s]         except AttributeError:\r\n[  229s]             wrap = None\r\n[  229s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  229s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  229s] _____________________________________ test _____________________________________\r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 2, 1, 4], dtype=int64),), kwds = {'axis': None}\r\n[  229s] bound = <built-in method repeat of numpy.ndarray object at 0xebe740c0>\r\n[  229s] \r\n[  229s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  229s]         bound = getattr(obj, method, None)\r\n[  229s]         if bound is None:\r\n[  229s]             return _wrapit(obj, method, *args, **kwds)\r\n[  229s]     \r\n[  229s]         try:\r\n[  229s] >           return bound(*args, **kwds)\r\n[  229s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  229s] \r\n[  229s] During handling of the above exception, another exception occurred:\r\n[  229s] \r\n[  229s]     @pytest.mark.skipif(\r\n[  229s]         distutils.version.LooseVersion(pandas.__version__)\r\n[  229s]         < distutils.version.LooseVersion(\"1.0\"),\r\n[  229s]         reason=\"Test Pandas in 1.0+ because they had to fix their JSON format.\",\r\n[  229s]     )\r\n[  229s]     def test():\r\n[  229s]         def key(n):\r\n[  229s]             if n in (\"values\", \"x\", \"y\"):\r\n[  229s]                 return n\r\n[  229s]             else:\r\n[  229s]                 return tuple(eval(n.replace(\"nan\", \"None\").replace(\"null\", \"None\")))\r\n[  229s]     \r\n[  229s]         def regularize(data):\r\n[  229s]             if isinstance(data, dict):\r\n[  229s]                 return dict((key(n), regularize(x)) for n, x in data.items())\r\n[  229s]             else:\r\n[  229s]                 return data\r\n[  229s]     \r\n[  229s]         array = ak.Array([[0.0, 1.1, 2.2], [], [3.3, 4.4], [5.5], [6.6, None, 8.8, 9.9]])\r\n[  229s] >       assert regularize(json.loads(ak.to_pandas(array).to_json())) == {\r\n[  229s]             \"values\": {\r\n[  229s]                 (0, 0): 0.0,\r\n[  229s]                 (0, 1): 1.1,\r\n[  229s]                 (0, 2): 2.2,\r\n[  229s]                 (2, 0): 3.3,\r\n[  229s]                 (2, 1): 4.4,\r\n[  229s]                 (3, 0): 5.5,\r\n[  229s]                 (4, 0): 6.6,\r\n[  229s]                 (4, 1): None,\r\n[  229s]                 (4, 2): 8.8,\r\n[  229s]                 (4, 3): 9.9,\r\n[  229s]             }\r\n[  229s]         }\r\n[  229s] \r\n[  229s] tests/test_0080-flatpandas-multiindex-rows-and-columns.py:34: \r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4321: in to_pandas\r\n[  229s]     for df in to_pandas(array, how=None, levelname=levelname, anonymous=anonymous):\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4393: in to_pandas\r\n[  229s]     for column, row_arrays, col_names in recurse(layout2, [], ()):\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4347: in recurse\r\n[  229s]     numpy.repeat(numpy.arange(len(counts), dtype=counts.dtype), counts)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  229s]     return self._module.repeat(*args, **kwargs)\r\n[  229s] <__array_function__ internals>:5: in repeat\r\n[  229s]     ???\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  229s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  229s]     return _wrapit(obj, method, *args, **kwds)\r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 2, 1, 4], dtype=int64),), kwds = {'axis': None}\r\n[  229s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xebe740c0>\r\n[  229s] \r\n[  229s]     def _wrapit(obj, method, *args, **kwds):\r\n[  229s]         try:\r\n[  229s]             wrap = obj.__array_wrap__\r\n[  229s]         except AttributeError:\r\n[  229s]             wrap = None\r\n[  229s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  229s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  229s] ______________________________ test_0167_strings _______________________________\r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] bound = <built-in method repeat of numpy.ndarray object at 0xe6bebca0>\r\n[  229s] \r\n[  229s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  229s]         bound = getattr(obj, method, None)\r\n[  229s]         if bound is None:\r\n[  229s]             return _wrapit(obj, method, *args, **kwds)\r\n[  229s]     \r\n[  229s]         try:\r\n[  229s] >           return bound(*args, **kwds)\r\n[  229s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  229s] \r\n[  229s] During handling of the above exception, another exception occurred:\r\n[  229s] \r\n[  229s]     def test_0167_strings():\r\n[  229s]         array = ak.Array([\"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"])\r\n[  229s]         assert ak.to_list(array == \"two\") == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(\"two\" == array) == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(array == [\"two\"]) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list([\"two\"] == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(array == ak.Array([\"two\"])) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(ak.Array([\"two\"]) == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]     \r\n[  229s]         array = ak.Array([[\"one\", \"two\", \"three\"], [], [\"two\"], [\"two\", \"one\"], [\"three\"]])\r\n[  229s] >       assert ak.to_list(array == \"two\") == [\r\n[  229s]             [False, True, False],\r\n[  229s]             [],\r\n[  229s]             [True],\r\n[  229s]             [True, False],\r\n[  229s]             [False],\r\n[  229s]         ]\r\n[  229s] \r\n[  229s] tests/test_0166-0167-0170-random-issues.py:162: \r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/lib/mixins.py:21: in func\r\n[  229s]     return ufunc(self, other)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/highlevel.py:1348: in __array_ufunc__\r\n[  229s]     return ak._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_connect/_numpy.py:195: in array_ufunc\r\n[  229s]     out = ak._util.broadcast_and_apply(\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:1001: in broadcast_and_apply\r\n[  229s]     out = apply(broadcast_pack(inputs, isscalar), 0, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:761: in apply\r\n[  229s]     outcontent = apply(nextinputs, depth + 1, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:800: in apply\r\n[  229s]     nextinputs.append(fcn(x, offsets))\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/behaviors/string.py:160: in _string_broadcast\r\n[  229s]     parents = nplike.repeat(nplike.arange(len(counts), dtype=counts.dtype), counts)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  229s]     return self._module.repeat(*args, **kwargs)\r\n[  229s] <__array_function__ internals>:5: in repeat\r\n[  229s]     ???\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  229s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  229s]     return _wrapit(obj, method, *args, **kwds)\r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xe6bebca0>\r\n[  229s] \r\n[  229s]     def _wrapit(obj, method, *args, **kwds):\r\n[  229s]         try:\r\n[  229s]             wrap = obj.__array_wrap__\r\n[  229s]         except AttributeError:\r\n[  229s]             wrap = None\r\n[  229s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  229s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  229s] ____________________________ test_0167_bytestrings _____________________________\r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] bound = <built-in method repeat of numpy.ndarray object at 0xe6aba278>\r\n[  229s] \r\n[  229s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  229s]         bound = getattr(obj, method, None)\r\n[  229s]         if bound is None:\r\n[  229s]             return _wrapit(obj, method, *args, **kwds)\r\n[  229s]     \r\n[  229s]         try:\r\n[  229s] >           return bound(*args, **kwds)\r\n[  229s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  229s] \r\n[  229s] During handling of the above exception, another exception occurred:\r\n[  229s] \r\n[  229s]     def test_0167_bytestrings():\r\n[  229s]         array = ak.Array([b\"one\", b\"two\", b\"three\", b\"two\", b\"two\", b\"one\", b\"three\"])\r\n[  229s]         assert ak.to_list(array == b\"two\") == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(b\"two\" == array) == [False, True, False, True, True, False, False]\r\n[  229s]         assert ak.to_list(array == [b\"two\"]) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list([b\"two\"] == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(array == ak.Array([b\"two\"])) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]         assert ak.to_list(ak.Array([b\"two\"]) == array) == [\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             True,\r\n[  229s]             True,\r\n[  229s]             False,\r\n[  229s]             False,\r\n[  229s]         ]\r\n[  229s]     \r\n[  229s]         array = ak.Array(\r\n[  229s]             [[b\"one\", b\"two\", b\"three\"], [], [b\"two\"], [b\"two\", b\"one\"], [b\"three\"]]\r\n[  229s]         )\r\n[  229s] >       assert ak.to_list(array == b\"two\") == [\r\n[  229s]             [False, True, False],\r\n[  229s]             [],\r\n[  229s]             [True],\r\n[  229s]             [True, False],\r\n[  229s]             [False],\r\n[  229s]         ]\r\n[  229s] \r\n[  229s] tests/test_0166-0167-0170-random-issues.py:280: \r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/lib/mixins.py:21: in func\r\n[  229s]     return ufunc(self, other)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/highlevel.py:1348: in __array_ufunc__\r\n[  229s]     return ak._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_connect/_numpy.py:195: in array_ufunc\r\n[  229s]     out = ak._util.broadcast_and_apply(\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:1001: in broadcast_and_apply\r\n[  229s]     out = apply(broadcast_pack(inputs, isscalar), 0, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:761: in apply\r\n[  229s]     outcontent = apply(nextinputs, depth + 1, user)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/_util.py:800: in apply\r\n[  229s]     nextinputs.append(fcn(x, offsets))\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/behaviors/string.py:160: in _string_broadcast\r\n[  229s]     parents = nplike.repeat(nplike.arange(len(counts), dtype=counts.dtype), counts)\r\n[  229s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  229s]     return self._module.repeat(*args, **kwargs)\r\n[  229s] <__array_function__ internals>:5: in repeat\r\n[  229s]     ???\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  229s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  229s]     return _wrapit(obj, method, *args, **kwds)\r\n[  229s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3, 4], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([3, 0, 1, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xe6aba278>\r\n[  229s] \r\n[  229s]     def _wrapit(obj, method, *args, **kwds):\r\n[  229s]         try:\r\n[  229s]             wrap = obj.__array_wrap__\r\n[  229s]         except AttributeError:\r\n[  229s]             wrap = None\r\n[  229s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  229s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  229s] _____________________________________ test _____________________________________\r\n[  229s] \r\n[  229s] obj = array([0, 1, 2, 3], dtype=int64), method = 'repeat'\r\n[  229s] args = (array([1, 0, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  229s] bound = <built-in method repeat of numpy.ndarray object at 0xe6f80340>\r\n[  229s] \r\n[  229s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  229s]         bound = getattr(obj, method, None)\r\n[  229s]         if bound is None:\r\n[  229s]             return _wrapit(obj, method, *args, **kwds)\r\n[  229s]     \r\n[  229s]         try:\r\n[  229s] >           return bound(*args, **kwds)\r\n[  229s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  229s] \r\n[  229s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  229s] \r\n[  229s] During handling of the above exception, another exception occurred:\r\n[  229s] \r\n[  229s]     def test():\r\n[  230s]         simple = ak.Array([0.0, 1.1, 2.2, 3.3, 4.4, 5.5])\r\n[  230s]         assert ak.to_pandas(simple)[\"values\"].values.tolist() == [\r\n[  230s]             0.0,\r\n[  230s]             1.1,\r\n[  230s]             2.2,\r\n[  230s]             3.3,\r\n[  230s]             4.4,\r\n[  230s]             5.5,\r\n[  230s]         ]\r\n[  230s]     \r\n[  230s]         index = ak.layout.Index64(np.array([3, 3, 1, 5], dtype=np.int64))\r\n[  230s]         indexed = ak.Array(ak.layout.IndexedArray64(index, simple.layout))\r\n[  230s]         assert indexed.tolist() == [3.3, 3.3, 1.1, 5.5]\r\n[  230s]     \r\n[  230s]         assert ak.to_pandas(indexed)[\"values\"].values.tolist() == [3.3, 3.3, 1.1, 5.5]\r\n[  230s]     \r\n[  230s]         tuples = ak.Array(ak.layout.RecordArray([simple.layout, simple.layout]))\r\n[  230s]         assert ak.to_pandas(tuples)[\"1\"].values.tolist() == [0.0, 1.1, 2.2, 3.3, 4.4, 5.5]\r\n[  230s]     \r\n[  230s]         offsets = ak.layout.Index64(np.array([0, 1, 1, 3, 4], dtype=np.int64))\r\n[  230s]         nested = ak.Array(ak.layout.ListOffsetArray64(offsets, indexed.layout))\r\n[  230s] >       assert ak.to_pandas(nested)[\"values\"].values.tolist() == [3.3, 3.3, 1.1, 5.5]\r\n[  230s] \r\n[  230s] tests/test_0331-pandas-indexedarray.py:35: \r\n[  230s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4321: in to_pandas\r\n[  230s]     for df in to_pandas(array, how=None, levelname=levelname, anonymous=anonymous):\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4393: in to_pandas\r\n[  230s]     for column, row_arrays, col_names in recurse(layout2, [], ()):\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4347: in recurse\r\n[  230s]     numpy.repeat(numpy.arange(len(counts), dtype=counts.dtype), counts)\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  230s]     return self._module.repeat(*args, **kwargs)\r\n[  230s] <__array_function__ internals>:5: in repeat\r\n[  230s]     ???\r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  230s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  230s]     return _wrapit(obj, method, *args, **kwds)\r\n[  230s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  230s] \r\n[  230s] obj = array([0, 1, 2, 3], dtype=int64), method = 'repeat'\r\n[  230s] args = (array([1, 0, 2, 1], dtype=int64),), kwds = {'axis': None}\r\n[  230s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xe6f80340>\r\n[  230s] \r\n[  230s]     def _wrapit(obj, method, *args, **kwds):\r\n[  230s]         try:\r\n[  230s]             wrap = obj.__array_wrap__\r\n[  230s]         except AttributeError:\r\n[  230s]             wrap = None\r\n[  230s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  230s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  230s] \r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  230s] _________________________________ test_broken __________________________________\r\n[  230s] \r\n[  230s] obj = array([0, 1, 2], dtype=int64), method = 'repeat'\r\n[  230s] args = (array([9, 0, 4], dtype=int64),), kwds = {'axis': None}\r\n[  230s] bound = <built-in method repeat of numpy.ndarray object at 0xebfe80c0>\r\n[  230s] \r\n[  230s]     def _wrapfunc(obj, method, *args, **kwds):\r\n[  230s]         bound = getattr(obj, method, None)\r\n[  230s]         if bound is None:\r\n[  230s]             return _wrapit(obj, method, *args, **kwds)\r\n[  230s]     \r\n[  230s]         try:\r\n[  230s] >           return bound(*args, **kwds)\r\n[  230s] E           TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  230s] \r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:58: TypeError\r\n[  230s] \r\n[  230s] During handling of the above exception, another exception occurred:\r\n[  230s] \r\n[  230s]     def test_broken():\r\n[  230s]         ex = ak.Array([[1, 2, 3], [], [4, 5]])\r\n[  230s]         p4 = ak.zip({\"x\": ex})\r\n[  230s]         p4c = ak.cartesian({\"a\": p4, \"b\": p4})\r\n[  230s] >       df = ak.to_pandas(p4c)\r\n[  230s] \r\n[  230s] tests/test_0331-pandas-indexedarray.py:71: \r\n[  230s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4321: in to_pandas\r\n[  230s]     for df in to_pandas(array, how=None, levelname=levelname, anonymous=anonymous):\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4393: in to_pandas\r\n[  230s]     for column, row_arrays, col_names in recurse(layout2, [], ()):\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/operations/convert.py:4347: in recurse\r\n[  230s]     numpy.repeat(numpy.arange(len(counts), dtype=counts.dtype), counts)\r\n[  230s] ../../BUILDROOT/python-awkward-1.0.1-1.1.i386/usr/lib/python3.8/site-packages/awkward/nplike.py:208: in repeat\r\n[  230s]     return self._module.repeat(*args, **kwargs)\r\n[  230s] <__array_function__ internals>:5: in repeat\r\n[  230s]     ???\r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:479: in repeat\r\n[  230s]     return _wrapfunc(a, 'repeat', repeats, axis=axis)\r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:67: in _wrapfunc\r\n[  230s]     return _wrapit(obj, method, *args, **kwds)\r\n[  230s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n[  230s] \r\n[  230s] obj = array([0, 1, 2], dtype=int64), method = 'repeat'\r\n[  230s] args = (array([9, 0, 4], dtype=int64),), kwds = {'axis': None}\r\n[  230s] wrap = <built-in method __array_wrap__ of numpy.ndarray object at 0xebfe80c0>\r\n[  230s] \r\n[  230s]     def _wrapit(obj, method, *args, **kwds):\r\n[  230s]         try:\r\n[  230s]             wrap = obj.__array_wrap__\r\n[  230s]         except AttributeError:\r\n[  230s]             wrap = None\r\n[  230s] >       result = getattr(asarray(obj), method)(*args, **kwds)\r\n[  230s] E       TypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n[  230s] \r\n[  230s] /usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:44: TypeError\r\n[  230s] =========================== short test summary info ============================\r\n[  230s] FAILED tests/test_0056-partitioned-array.py::test_0167_strings - TypeError: C...\r\n[  230s] FAILED tests/test_0080-flatpandas-multiindex-rows-and-columns.py::test - Type...\r\n[  230s] FAILED tests/test_0166-0167-0170-random-issues.py::test_0167_strings - TypeEr...\r\n[  230s] FAILED tests/test_0166-0167-0170-random-issues.py::test_0167_bytestrings - Ty...\r\n[  230s] FAILED tests/test_0331-pandas-indexedarray.py::test - TypeError: Cannot cast ...\r\n[  230s] FAILED tests/test_0331-pandas-indexedarray.py::test_broken - TypeError: Canno...\r\n[  230s] ================== 6 failed, 577 passed, 7 skipped in 57.06s ===================\r\n\r\n```",
  "closed_at":"2020-12-16T00:50:18Z",
  "comments":3,
  "created_at":"2020-12-15T00:26:02Z",
  "id":767046805,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjcwNDY4MDU=",
  "number":600,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Some tests fail on 32-bit (i586) Linux",
  "updated_at":"2020-12-16T00:50:56Z",
  "user":"MDQ6VXNlcjM1MzI0Njc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"Many C++ projects use Arrow as a common medium . We can convert Awkward Arrays to and from Arrow buffers using the [ak.to_arrow](https://awkward-array.readthedocs.io/en/latest/_auto/ak.to_arrow.html) and [ak.from_arrow](https://awkward-array.readthedocs.io/en/latest/_auto/ak.from_arrow.html) functions in Python, but a pure C++ implementation would be very valueable. One explicit example would be that we could then interoperate with RAPIDS's cuDF.\r\n\r\nBefore the Python functions were even written, we were planning on implementing them in C++ for this exact reason (#68). However, taking on Apache Arrow as a C++ dependency would be too much: that project can be hard to install and not every user is going to need this feature. We considered the Arrow project's C interface (https://github.com/scikit-hep/awkward-1.0/issues/68#issuecomment-598520012), but this turns out to be little more than a suggested common way to reimplement the format from scratch. Ultimately, we'll have to do what most projects do, which is to read the format specification carefully and convert our structures into Arrow manually.\r\n\r\nNow, however, we have the Python functions and very extensive unit tests. Applying the Python tests to a C++ converter would ensure that we're not misinterpreting the Arrow specification: the tests provide explicit targets for this new C++ function and the Python functions show what the C++ function should do for as-yet untested examples. Although this would be byte-level fiddling, at least there's no ambiguity about what it should do.\r\n\r\nIt should wait for issue #593 to be done, though. We're getting a lot of experience in Coffea and ServiceX with Arrow (and through it, Parquet) conversions.\r\n\r\nA Parquet converter is _not_ in scope for this issue. To convert Arrow into Parquet (and back), we really need the Arrow libraries and it's best to do that at the Python level.",
  "closed_at":"2022-04-15T19:45:40Z",
  "comments":2,
  "created_at":"2020-12-15T16:36:09Z",
  "id":767784857,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3Njc3ODQ4NTc=",
  "number":601,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Lower ak.to_arrow/ak.from_arrow to C++",
  "updated_at":"2022-04-15T19:45:41Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-15T23:42:21Z",
  "comments":3,
  "created_at":"2020-12-15T18:37:40Z",
  "draft":false,
  "id":767997664,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQwNTQ0MjM2",
  "number":602,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-15T23:42:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Use pyarrow.field to preserve nullability in Arrow conversion",
  "updated_at":"2020-12-15T23:42:25Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"CONTRIBUTOR",
  "body":"This issue is originating from the usage of Coffea's NanoEvents. It is a RecoardArray of large RecordArrays, that really need lazy loading.\r\n\r\n  <details>\r\n    <summary>Example code</summary>\r\n    <!-- have to be followed by an empty line! -->\r\n\r\n```python\r\nimport awkward as ak\r\nimport numpy as np\r\n\r\n\r\nclass Map(dict):\r\n    def __getitem__(self, key):\r\n        print(f\"Loading {key}\")\r\n        return dict.__getitem__(self, key)\r\n\r\nform = {\r\n    'class': 'RecordArray',\r\n    'contents': {\r\n        'Electron': {\r\n            'class': 'ListOffsetArray64',\r\n            'content': {\r\n                'class': 'RecordArray',\r\n                'contents': {\r\n                    'charge': {\r\n                        'class': 'NumpyArray',\r\n                        'form_key': 'loads_slowly1',\r\n                        'format': 'i',\r\n                        'has_identities': False,\r\n                        'inner_shape': [],\r\n                        'itemsize': 4,\r\n                        'parameters': {},\r\n                        'primitive': 'int32'}},\r\n                'form_key': 'invalid',\r\n                'parameters': {}},\r\n            'form_key': 'loads_quickly1',\r\n            'offsets': 'i64'},\r\n        'Muon': {\r\n            'class': 'ListOffsetArray64',\r\n            'content': {\r\n                'class': 'RecordArray',\r\n                'contents': {\r\n                    'charge': {\r\n                        'class': 'NumpyArray',\r\n                        'form_key': 'loads_slowly2',\r\n                        'format': 'i',\r\n                        'has_identities': False,\r\n                        'inner_shape': [],\r\n                        'itemsize': 4,\r\n                        'parameters': {},\r\n                        'primitive': 'int32'}},\r\n                'form_key': 'invalid',\r\n                'parameters': {'__record__': 'Muon'}},\r\n            'form_key': 'loads_quickly2',\r\n            'offsets': 'i64'}},\r\n    'form_key': '',\r\n    'parameters': {}}\r\n\r\nmap = Map({\r\n    \"part0-loads_quickly1-offsets\": np.array([0,1,2,3]),\r\n    \"part0-loads_quickly2-offsets\": np.array([0,1,2,3]),\r\n    \"part0-loads_slowly1-data\": np.array([5,5,5], dtype=np.int32),\r\n    \"part0-loads_slowly2-data\": np.array([5,5,5], dtype=np.int32)})\r\n\r\nprint(\"First concatenation\")\r\narr = ak.from_buffers(form, 3, map, lazy=True)\r\ncon = ak.concatenate([arr[\"Electron\"], arr[\"Muon\"]], axis=1)\r\nprint(\"Second concatenation\")\r\narr = ak.from_buffers(form, 3, map, lazy=True)\r\ncon = ak.concatenate([arr[\"Muon\"], arr[\"Muon\"]], axis=1)\r\nprint(\"Third concatenation\")\r\ndel form[\"contents\"][\"Muon\"][\"content\"][\"parameters\"][\"__record__\"]\r\narr = ak.from_buffers(form, 3, map, lazy=True)\r\ncon = ak.concatenate([arr[\"Electron\"], arr[\"Muon\"]], axis=1)\r\n\r\n```\r\n  </details>\r\n\r\nIf you execute above example, you will see that the first concatenation only loads the offsets. However the second and third concatenation load (in fact all) contents. This seems to be inconsistent.\r\nPreferably I would like to have none of the concatenates load the contents, because this can take really long. It seems content loading is not necessary, as the first concatenate is not doing it.\r\n",
  "closed_at":"2020-12-22T01:50:27Z",
  "comments":7,
  "created_at":"2020-12-15T19:31:03Z",
  "id":768083973,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NjgwODM5NzM=",
  "number":603,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"from_buffers/from_arrayset lazyness insonsistent when concatenating",
  "updated_at":"2021-01-11T22:32:07Z",
  "user":"MDQ6VXNlcjMwMDQxMDcz"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-16T00:50:18Z",
  "comments":0,
  "created_at":"2020-12-15T23:53:00Z",
  "draft":false,
  "id":768310608,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQwNzkxMTM3",
  "number":604,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-16T00:50:18Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Make tests work in 32-bit.",
  "updated_at":"2020-12-16T00:50:21Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"This is broken on conda-forge because it's running out of memory on Travis - you should always be able to build single threaded if you need to!\r\n\r\nAnd I've also avoided overriding the macOS deployment target - most build systems (cibuildwheel, conda-forge, etc) set this and you should avoid overriding that.\r\n\r\nSee https://github.com/pybind/cmake_example/blob/master/setup.py - this should be similar to that.\r\n\r\nThis is stopping this PR: https://github.com/conda-forge/awkward-feedstock/pull/58 (though the broken build is not the one that was being added in that PR). I'll add it as a patch as soon as it's merged. _Please be sure to Squash and Merge, not \"regular merge\", to make the patch clean and easy to apply._",
  "closed_at":"2020-12-16T18:47:09Z",
  "comments":1,
  "created_at":"2020-12-16T17:55:58Z",
  "draft":false,
  "id":769148739,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQxMzQxMjQ4",
  "number":605,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-16T18:47:09Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"fix: avoid hardcoded threads and macOS target",
  "updated_at":"2020-12-16T18:47:14Z",
  "user":"MDQ6VXNlcjQ2MTY5MDY="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-17T00:47:03Z",
  "comments":0,
  "created_at":"2020-12-16T21:18:55Z",
  "draft":false,
  "id":769278568,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQxNDQ0ODUy",
  "number":606,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-17T00:47:03Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"More complicated example revealed bugs in Arrow conversion.",
  "updated_at":"2020-12-17T00:47:13Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"It's important to get a red flag when\r\n\r\n```bash\r\njupyter-book build docs-src\r\n```\r\n\r\nfails. While we're at it, maybe find out why the sidebar now consists of expandable pull-down menus:\r\n\r\n![image](https://user-images.githubusercontent.com/1852447/102512569-cb292f00-404f-11eb-8e57-386f5c4c8ee4.png)\r\n\r\nI'd rather see them fully expanded:\r\n\r\n![image](https://user-images.githubusercontent.com/1852447/102512853-20fdd700-4050-11eb-9662-bf5cfc2eae69.png)\r\n\r\nI know it's because I have an older version of Jupyterbook on my computer, but if the name of the option has changed, I'd like to update to that new name. It used to be\r\n\r\n```yaml\r\n  expand_sections: true\r\n```\r\n\r\nin each item.",
  "closed_at":"2022-04-15T19:44:58Z",
  "comments":1,
  "created_at":"2020-12-17T16:12:13Z",
  "id":770177686,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NzAxNzc2ODY=",
  "number":607,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Include Jupyterbook documentation testing in the azure-doctest-awkward.yml",
  "updated_at":"2022-04-15T19:44:58Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-19T03:22:48Z",
  "comments":0,
  "created_at":"2020-12-19T00:56:32Z",
  "draft":false,
  "id":771263824,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQyODQ5Njgx",
  "number":610,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-19T03:22:48Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Revise concatenate with axis != 0",
  "updated_at":"2020-12-19T03:22:51Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"I just saw a failure when using uproot with the traceback:\r\n```\r\n+ python -c 'import uproot; assert len(uproot.open(\"root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root\")[\"Events\"][\"PV_x\"].array()) == 29308627'\r\nTraceback (most recent call last):\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/extras.py\", line 21, in awkward\r\n    import awkward\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/awkward/__init__.py\", line 29, in <module>\r\n    import awkward._cpu_kernels\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/awkward/_cpu_kernels.py\", line 7, in <module>\r\n    import pkg_resources\r\nModuleNotFoundError: No module named 'pkg_resources'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 2059, in array\r\n    _ranges_or_baskets_to_arrays(\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3430, in _ranges_or_baskets_to_arrays\r\n    uproot.source.futures.delayed_raise(*obj)\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/source/futures.py\", line 46, in delayed_raise\r\n    raise exception_value.with_traceback(traceback)\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3401, in basket_to_array\r\n    arrays[branch.cache_key] = interpretation.final_array(\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/interpretation/numerical.py\", line 115, in final_array\r\n    output = library.finalize(output, branch, self, entry_start, entry_stop)\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/interpretation/library.py\", line 481, in finalize\r\n    awkward = self.imported\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/interpretation/library.py\", line 478, in imported\r\n    return uproot.extras.awkward()\r\n  File \"/home/conda/feedstock_root/build_artifacts/uproot_1608368458292/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold/lib/python3.9/site-packages/uproot/extras.py\", line 23, in awkward\r\n    raise ImportError(\r\nImportError: install the 'awkward' package with:\r\n\r\n    pip install awkward\r\n\r\nAlternatively, you can use ``library=\"np\"`` or globally set ``uproot.default_library``\r\nto output as NumPy arrays, rather than Awkward arrays.\r\n\r\nTests failed for uproot-4.0.0-pyhd8ed1ab_0.tar.bz2 - moving package to /home/conda/feedstock_root/build_artifacts/broken\r\n```\r\n\r\nThe issue is that `pkg_resources` is part of `setuptools` and this isn't declared in the awkward `install_requires`. As it's a dependency of pip it's rare to be running on a system without it installed so it's often missed as a dependency.",
  "closed_at":"2020-12-19T14:24:53Z",
  "comments":1,
  "created_at":"2020-12-19T09:20:22Z",
  "draft":false,
  "id":771344404,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQyOTAyMTQ3",
  "number":611,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-19T14:24:53Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Add setuptools to requirements for pkg_resources",
  "updated_at":"2020-12-19T14:24:56Z",
  "user":"MDQ6VXNlcjUyMjA1MzM="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-21T16:08:47Z",
  "comments":0,
  "created_at":"2020-12-21T15:34:28Z",
  "draft":false,
  "id":772256458,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQzNTUyNjY3",
  "number":612,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-21T16:08:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Added 'axis_wrap_if_negative' to PartitionedArray.",
  "updated_at":"2020-12-21T16:08:52Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-22T01:50:27Z",
  "comments":0,
  "created_at":"2020-12-21T17:04:15Z",
  "draft":false,
  "id":772324709,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQzNjEwMzg2",
  "number":613,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-22T01:50:27Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"ak.concatenate should minimally touch lazy arrays",
  "updated_at":"2020-12-22T01:50:30Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The interface to [ak.sort](https://awkward-array.readthedocs.io/en/latest/_auto/ak.sort.html) and [ak.argsort](https://awkward-array.readthedocs.io/en/latest/_auto/ak.argsort.html) should be more like [np.sort](https://numpy.org/doc/stable/reference/generated/numpy.sort.html) and [np.argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html).\r\n\r\n   * The Awkward functions have an `ascending` (bool) argument that isn't really necessary, since one can just negate the input. This `ascending` argument is passed all the way down to the underlying kernel, so the code could be simplified by eliminating it. This is not super-important because we're allowed to have _more_ features than NumPy and the code's already there. But if writing the GPU kernels is simplified by dropping the `ascending` argument, then let's do it.\r\n   * The Awkward functions have a `stable` (bool)  to choose between C++'s stable and C++'s unstable sorting algorithm. NumPy has traditionally named explicit algorithms in a `kind` (str) argument, but since 1.15, it seems to be moving in the direction of describing only features, like \"stable\" vs \"unstable\", rather than explicit algorithms. @ianna has been thinking about GPU implementations of these sorting algorithms, and it looks like quicksort would be the most doable, so what we offer maps nicely onto the names NumPy defines:\r\n     * NumPy's `\"stable\"` \u2192 our C++ stable algorithm, available only on CPU\r\n     * NumPy's `\"mergesort\"` is a synonym for `\"stable\"`, but included only for backward compatibility \u2192 an informative error message, since our stable algorithm isn't exactly mergesort\r\n     * NumPy's `\"heapsort\"` \u2192 our C++ unstable algorithm, available only on CPU, which _really is_ heapsort\r\n     * NumPy's `\"quicksort\"` \u2192 the new algorithm @ianna is planning to implement by hand on CPU and GPU, the only algorithm available on the GPU.\r\n\r\nAt this stage, at least, I'll deprecate the `stable` (bool) option in favor of a `kind` (str), but leave `ascending` as it is.\r\n\r\nBefore doing this, I should create a formal roadmap with scheduled releases, since the deprecation date would not the Feb 1 date, but the one after that, whatever that is (#616).",
  "closed_at":"2023-11-08T11:50:49Z",
  "comments":3,
  "created_at":"2020-12-22T14:21:05Z",
  "id":772982960,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NzI5ODI5NjA=",
  "number":615,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"For NumPy compatibility, ak.sort's 'stable' (bool) should be 'kind' (str)",
  "updated_at":"2023-11-08T11:50:50Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"The roadmap will specify regular dates when specific minor versions will be introduced (\"at least by...\" earliest possible dates).\r\n\r\nThis should be centralized in one place, probably the GitHub README so that it's easy to find. (It's easy to see a table at a glance.) However, all the other documentation front pages (awkward-array.org, ReadTheDocs, PyPI) should have a link to it.\r\n\r\nOther options are to have the roadmap in a separate markdown page or in the wiki. Keep in mind that the wiki is world-writable\u2014intended to collect input from users (not that that happens much).",
  "closed_at":"2020-12-22T21:18:31Z",
  "comments":0,
  "created_at":"2020-12-22T14:30:20Z",
  "id":772989240,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NzI5ODkyNDA=",
  "number":616,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Formal roadmap",
  "updated_at":"2020-12-22T21:18:31Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-22T21:18:31Z",
  "comments":0,
  "created_at":"2020-12-22T20:00:57Z",
  "draft":false,
  "id":773210214,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ0MzM2NTky",
  "number":617,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-22T21:18:31Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Created a roadmap",
  "updated_at":"2020-12-22T21:18:38Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"As discussed in https://github.com/scikit-hep/awkward-1.0/discussions/614, it would be nice to have a feature that allows to select a name within multiple columns (i.e., slice columns within columns).\r\n\r\nExample:\r\nconsidering a record of records of the following type:\r\n```python\r\n10 * {\"eta\": {\"nominal\": int64, \"up\": int64}, \"phi\": {\"nominal\": int64, \"up\": int64}}\r\n``` \r\nthe new feature would allow to use the syntax:\r\n```python\r\nmy_array[[\"eta\", \"phi\"], \"up\"]\r\n```\r\nto get a record of type\r\n```python\r\n10 * {\"eta\": int64, \"phi\": int64}\r\n```\r\nAt the moment, this can be achieved with:\r\n```python\r\nak.zip({field: my_array[field, \"up\"] for field in ak.fields(my_array) if \"up\" in ak.fields(my_array[field])})\r\n```",
  "closed_at":"2020-12-23T21:23:44Z",
  "comments":2,
  "created_at":"2020-12-23T11:40:55Z",
  "id":773693003,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NzM2OTMwMDM=",
  "number":618,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Selecting a name within multiple records: array[[\"pt\", \"eta\", \"phi\"], \"nominal\"]",
  "updated_at":"2020-12-23T21:23:44Z",
  "user":"MDQ6VXNlcjI2MzA5NTMx"
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-23T21:23:44Z",
  "comments":0,
  "created_at":"2020-12-23T19:45:16Z",
  "draft":false,
  "id":774008226,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ1MDAwMzUy",
  "number":619,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-23T21:23:44Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Implemented column selection within multiple records.",
  "updated_at":"2020-12-23T21:23:47Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2021-01-04T18:09:47Z",
  "comments":5,
  "created_at":"2020-12-24T00:40:33Z",
  "draft":false,
  "id":774110800,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ1MDg1MDM4",
  "number":620,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2021-01-04T18:09:47Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Prototype Forth VM for filling Awkward Arrays from Uproot.",
  "updated_at":"2021-01-04T21:03:55Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"NONE",
  "body":"I'm getting a lot of mileage out of zero-copy (I think) conversions between awkward and Arrow. Thanks for all that functionality. However, when I introduce some slicing, I see some mismatches. Example below.\r\n\r\n```python\r\nimport numpy as np # 1.19.0\r\nimport awkward as ak # 1.0.1\r\nimport pyarrow as pa # 2.0.0\r\n\r\nnp_arr = np.random.normal(0,1,10)\r\nak_arr = ak.Array(np_arr)\r\npa_arr = ak.to_arrow(ak_arr)\r\n```\r\n\r\nThese are all identical, as expected.\r\n```python\r\n\r\n>>> print(np_arr)\r\n[ 0.12213336  0.07918481 -0.02079451  0.52849207  0.56343541  0.08746807\r\n  0.56490973 -0.47526351  0.295584    0.27810744]\r\n>>> print(ak_arr)\r\n[0.122, 0.0792, -0.0208, 0.528, 0.563, 0.0875, 0.565, -0.475, 0.296, 0.278]\r\n>>> print(pa_arr)\r\n[\r\n  0.122133,\r\n  0.0791848,\r\n  -0.0207945,\r\n  0.528492,\r\n  0.563435,\r\n  0.0874681,\r\n  0.56491,\r\n  -0.475264,\r\n  0.295584,\r\n  0.278107\r\n]\r\n```\r\n\r\nI would expect to see the same values here, but it looks like awkward is going to the beginning of the array.\r\n```python\r\n>>> print(pa_arr[5:])\r\n[\r\n  0.0874681,\r\n  0.56491,\r\n  -0.475264,\r\n  0.295584,\r\n  0.278107\r\n]\r\n>>> print(ak.from_arrow(pa_arr[5:]))\r\n[0.122, 0.0792, -0.0208, 0.528, 0.563]\r\n```\r\n",
  "closed_at":"2020-12-30T16:28:43Z",
  "comments":11,
  "created_at":"2020-12-29T04:38:37Z",
  "id":775693491,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWU3NzU2OTM0OTE=",
  "number":624,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"closed",
  "state_reason":"completed",
  "title":"Unexpected results when using ak.from_arrow()",
  "updated_at":"2021-01-04T20:32:54Z",
  "user":"MDQ6VXNlcjU3NjAwMjc="
 },
 {
  "active_lock_reason":null,
  "assignee":"MDQ6VXNlcjM5ODc4Njc1",
  "assignees":null,
  "author_association":"MEMBER",
  "body":"- [x] Implemented\r\n- [x] Tested",
  "closed_at":"2020-12-30T16:28:41Z",
  "comments":2,
  "created_at":"2020-12-29T20:21:27Z",
  "draft":false,
  "id":776069858,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ2NjIxNzM4",
  "number":625,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-30T16:28:41Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Fixes #624: unhandled 'offsets' in pyarrow arrays",
  "updated_at":"2020-12-30T16:28:45Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-30T22:57:54Z",
  "comments":0,
  "created_at":"2020-12-30T22:12:56Z",
  "draft":false,
  "id":776657071,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ3MTAzOTc0",
  "number":626,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-30T22:57:54Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"Homogenize and streamline pass-through of Array behavior.",
  "updated_at":"2020-12-30T22:57:57Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"",
  "closed_at":"2020-12-31T01:07:21Z",
  "comments":0,
  "created_at":"2020-12-31T00:36:48Z",
  "draft":false,
  "id":776692865,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDExOlB1bGxSZXF1ZXN0NTQ3MTMyNjUy",
  "number":627,
  "performed_via_github_app":null,
  "pull_request":{
   "merged_at":"2020-12-31T01:07:21Z"
  },
  "reactions":{},
  "state":"closed",
  "state_reason":null,
  "title":"A dict of arrays requires 'behaviorof(*arrays.values())'.",
  "updated_at":"2020-12-31T01:07:24Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 },
 {
  "active_lock_reason":null,
  "assignee":null,
  "assignees":null,
  "author_association":"MEMBER",
  "body":"```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/irishep/uproot4/uproot4/behaviors/TBranch.py\", line 1164, in arrays\r\n    return library.group(output, expression_context, how)\r\n  File \"/home/jpivarski/irishep/uproot4/uproot4/interpretation/library.py\", line 528, in group\r\n    return awkward1.zip(\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward1/operations/structure.py\", line 348, in zip\r\n    out = awkward1._util.broadcast_and_apply(layouts, getfunction, behavior)\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 972, in broadcast_and_apply\r\n    out = apply(broadcast_pack(inputs, isscalar), 0)\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 564, in apply\r\n    checklength([x for x in inputs if isinstance(x, awkward1.layout.Content)])\r\n  File \"/home/jpivarski/miniconda3/lib/python3.8/site-packages/awkward1/_util.py\", line 480, in checklength\r\n    length = len(inputs[0])\r\n```\r\n\r\nThe problem is in `awkward1/operations/structure.py\", line 348, in zip`; there needs to be a check for length zero arguments.\r\n\r\nThis ought to be super easy.",
  "closed_at":null,
  "comments":2,
  "created_at":"2020-09-26T21:54:33Z",
  "id":2108205658,
  "labels":null,
  "locked":false,
  "milestone":null,
  "node_id":"MDU6SXNzdWUyMTA4MjA1NjU4",
  "number":2993,
  "performed_via_github_app":null,
  "reactions":{},
  "state":"open",
  "state_reason":null,
  "title":"ak.zip needs to check for empty input and do something appropriate",
  "updated_at":"2024-01-30T15:59:04Z",
  "user":"MDQ6VXNlcjE4NTI0NDc="
 }
]